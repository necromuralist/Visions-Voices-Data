<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content="Adumbrations of data." name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>Visions, Voices, Data (old posts, page 7) | Visions, Voices, Data</title>
<link href="assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="rss.xml" hreflang="en" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/Visions-Voices-Data/index-7.html" rel="canonical">
<link href="." rel="prev" type="text/html">
<link href="index-6.html" rel="next" type="text/html"><!--[if lt IE 9]><script src="assets/js/html5.js"></script><![endif]-->
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script><!--
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/0.9.0/p5.min.js"
</script>
-->
<script async src="javascript/p5.min.js" type="text/javascript"></script>
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="/"><span id="blog-title">Visions, Voices, Data</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="/archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="/categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="/rss.xml">RSS feed</a></li>
<li class="nav-item dropdown"><a aria-expanded="false" aria-haspopup="true" class="nav-link dropdown-toggle" data-toggle="dropdown" href="#">Pages</a>
<div class="dropdown-menu"><a class="dropdown-item" href="https://necromuralist.github.io/">Cloistered Monkey</a> <a class="dropdown-item" href="/pages/giss/giss-yearly-anomalies-by-climate-zone">GISS Anomalies</a></div>
</li>
</ul>
<!-- DuckDuckGo custom search -->
<form action="https://duckduckgo.com/" class="navbar-form pull-left" id="search" method="get" name="search"><input name="sites" type="hidden" value="https://necromuralist.github.io/Visions-Voices-Data/"> <input name="k8" type="hidden" value="#444444"> <input name="k9" type="hidden" value="#D51920"> <input name="kt" type="hidden" value="h"> <input class="span2" maxlength="255" name="q" placeholder="Searchâ€¦" type="text"> <input style="visibility: hidden;display:none" type="submit" value="DuckDuckGo Search"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right"></ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<div class="postindex">
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="/posts/tutorials/categorical-values/">Categorical Values</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="/posts/tutorials/categorical-values/" rel="bookmark"><time class="published dt-published" datetime="2020-02-20T21:13:09-08:00" itemprop="datePublished" title="2020-02-20 21:13">2020-02-20 21:13</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="/posts/tutorials/categorical-values/#org0ac8449">Beginning</a>
<ul>
<li><a href="/posts/tutorials/categorical-values/#org1a14ae7">Imports</a>
<ul>
<li><a href="/posts/tutorials/categorical-values/#orgc1d8893">Python</a></li>
<li><a href="/posts/tutorials/categorical-values/#orgb659226">PyPi</a></li>
<li><a href="/posts/tutorials/categorical-values/#org6c17490">Others</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/categorical-values/#org80289f3">Set Up</a>
<ul>
<li><a href="/posts/tutorials/categorical-values/#orgd341ba0">Table</a></li>
<li><a href="/posts/tutorials/categorical-values/#orgf40aa35">Plottting</a></li>
<li><a href="/posts/tutorials/categorical-values/#org9ffa308">The Timer</a></li>
<li><a href="/posts/tutorials/categorical-values/#org1b13324">Environment</a></li>
<li><a href="/posts/tutorials/categorical-values/#org8aeeffe">The Data</a></li>
<li><a href="/posts/tutorials/categorical-values/#orgf29e1d4">Some Constants</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="/posts/tutorials/categorical-values/#orgb79e6d0">Middle</a>
<ul>
<li><a href="/posts/tutorials/categorical-values/#org6609184">Setup The Data</a></li>
<li><a href="/posts/tutorials/categorical-values/#org3ed2085">Score Dataset</a></li>
<li><a href="/posts/tutorials/categorical-values/#org2b3aefe">Step 1: Drop Categorical Columns</a></li>
<li><a href="/posts/tutorials/categorical-values/#orgdb4840f">Step 2: Label encoding</a>
<ul>
<li><a href="/posts/tutorials/categorical-values/#org76de614">Drop the Bad Columns</a></li>
<li><a href="/posts/tutorials/categorical-values/#org20636a1">Encode the Categorical Values</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/categorical-values/#org9a993d9">Step 3: Investigating cardinality</a>
<ul>
<li><a href="/posts/tutorials/categorical-values/#org05f6c11">Questions</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/categorical-values/#org7a79e92">Step 4: One-hot encoding</a></li>
<li><a href="/posts/tutorials/categorical-values/#orgd1e8f73">Step 5: Generate test predictions and submit your results</a>
<ul>
<li><a href="/posts/tutorials/categorical-values/#org0b16c94">Hyperparameter Tuning</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="/posts/tutorials/categorical-values/#orgf1fa4e5">End</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org0ac8449">
<h2 id="org0ac8449">Beginning</h2>
<div class="outline-text-2" id="text-org0ac8449">
<blockquote>
<p>Now it's your turn to test your new knowledge of <b>missing values</b> handling. You'll probably find it makes a big difference.</p>
</blockquote>
</div>
<div class="outline-3" id="outline-container-org1a14ae7">
<h3 id="org1a14ae7">Imports</h3>
<div class="outline-text-3" id="text-org1a14ae7"></div>
<div class="outline-4" id="outline-container-orgc1d8893">
<h4 id="orgc1d8893">Python</h4>
<div class="outline-text-4" id="text-orgc1d8893">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgb659226">
<h4 id="orgb659226">PyPi</h4>
<div class="outline-text-4" id="text-orgb659226">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">eli5.sklearn</span> <span class="kn">import</span> <span class="n">PermutationImportance</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span>
<span class="kn">from</span> <span class="nn">pdpbox</span> <span class="kn">import</span> <span class="n">pdp</span>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.experimental</span> <span class="kn">import</span> <span class="n">enable_iterative_imputer</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">IterativeImputer</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">RandomizedSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span><span class="p">,</span> <span class="n">OneHotEncoder</span>

<span class="kn">from</span> <span class="nn">tabulate</span> <span class="kn">import</span> <span class="n">tabulate</span>

<span class="kn">import</span> <span class="nn">eli5</span>
<span class="kn">import</span> <span class="nn">hvplot.pandas</span>
<span class="kn">import</span> <span class="nn">pandas</span>
<span class="kn">import</span> <span class="nn">shap</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org6c17490">
<h4 id="org6c17490">Others</h4>
<div class="outline-text-4" id="text-org6c17490">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">CountPercentage</span><span class="p">,</span> <span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">EnvironmentLoader</span><span class="p">,</span> <span class="n">Timer</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org80289f3">
<h3 id="org80289f3">Set Up</h3>
<div class="outline-text-3" id="text-org80289f3"></div>
<div class="outline-4" id="outline-container-orgd341ba0">
<h4 id="orgd341ba0">Table</h4>
<div class="outline-text-4" id="text-orgd341ba0">
<div class="highlight">
<pre><span></span><span class="n">TABLE</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">tabulate</span><span class="p">,</span> <span class="n">tablefmt</span><span class="o">=</span><span class="s2">"orgtbl"</span><span class="p">,</span> <span class="n">showindex</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="s2">"keys"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgf40aa35">
<h4 id="orgf40aa35">Plottting</h4>
<div class="outline-text-4" id="text-orgf40aa35">
<div class="highlight">
<pre><span></span><span class="n">SLUG</span> <span class="o">=</span> <span class="s2">"categorical-values"</span>
<span class="n">OUTPUT_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"../../files/posts/tutorials/"</span><span class="p">)</span><span class="o">/</span><span class="n">SLUG</span>
<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">folder_path</span><span class="o">=</span><span class="n">OUTPUT_PATH</span><span class="p">)</span>
<span class="n">Plot</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org9ffa308">
<h4 id="org9ffa308">The Timer</h4>
<div class="outline-text-4" id="text-org9ffa308">
<div class="highlight">
<pre><span></span><span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org1b13324">
<h4 id="org1b13324">Environment</h4>
<div class="outline-text-4" id="text-org1b13324">
<div class="highlight">
<pre><span></span><span class="n">ENVIRONMENT</span> <span class="o">=</span> <span class="n">EnvironmentLoader</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org8aeeffe">
<h4 id="org8aeeffe">The Data</h4>
<div class="outline-text-4" id="text-org8aeeffe">
<div class="highlight">
<pre><span></span><span class="n">DATA_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">ENVIRONMENT</span><span class="p">[</span><span class="s2">"HOUSE-PRICES-IOWA"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="n">DATA_PATH</span><span class="o">/</span><span class="s2">"train.csv"</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s2">"Id"</span><span class="p">)</span>

<span class="n">test_data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="n">DATA_PATH</span><span class="o">/</span><span class="s2">"test.csv"</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s2">"Id"</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgf29e1d4">
<h4 id="orgf29e1d4">Some Constants</h4>
<div class="outline-text-4" id="text-orgf29e1d4">
<div class="highlight">
<pre><span></span><span class="n">Data</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">target</span><span class="o">=</span><span class="s2">"SalePrice"</span><span class="p">,</span>
    <span class="n">train_size</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">random_seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgb79e6d0">
<h2 id="orgb79e6d0">Middle</h2>
<div class="outline-text-2" id="text-orgb79e6d0"></div>
<div class="outline-3" id="outline-container-org6609184">
<h3 id="org6609184">Setup The Data</h3>
<div class="outline-text-3" id="text-org6609184">
<p>Split up the target and features.</p>
<div class="highlight">
<pre><span></span><span class="k">assert</span> <span class="ow">not</span> <span class="n">train_data</span><span class="p">[</span><span class="n">Data</span><span class="o">.</span><span class="n">target</span><span class="p">]</span><span class="o">.</span><span class="n">hasnans</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="n">Data</span><span class="o">.</span><span class="n">target</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="n">Data</span><span class="o">.</span><span class="n">target</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="s2">"columns"</span><span class="p">)</span>
</pre></div>
<p>We know that there's missing data, but since this is about handling categorical data, not missing data, we'll just drop the columns that have missing values.</p>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[[</span><span class="n">column</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">X</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">hasnans</span><span class="p">]]</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
<pre class="example">
(1460, 79)
(1460, 60)
</pre>
<p>So we lost 19 columns - more than I was expecting.</p>
<p>Now do the train-test split.</p>
<div class="highlight">
<pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_validate</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_validate</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
    <span class="n">train_size</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">train_size</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">test_size</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">drop_X_train</span><span class="o">.</span><span class="n">info</span><span class="p">())</span>
</pre></div>
<pre class="example">
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
&lt;ipython-input-13-002dd7ea4a19&gt; in &lt;module&gt;
----&gt; 1 print(drop_X_train.info())

NameError: name 'drop_X_train' is not defined
</pre>
<blockquote>
<p>Notice that the dataset contains both numerical and categorical variables. You'll need to encode the categorical data before training a model.</p>
</blockquote>
</div>
</div>
<div class="outline-3" id="outline-container-org3ed2085">
<h3 id="org3ed2085">Score Dataset</h3>
<div class="outline-text-3" id="text-org3ed2085">
<p>This is the same function used in the missing-values tutorial. It's used to compare different models' Mean Absolute Error (MAE) as we make changes.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">score_dataset</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org2b3aefe">
<h3 id="org2b3aefe">Step 1: Drop Categorical Columns</h3>
<div class="outline-text-3" id="text-org2b3aefe">
<p>The first approach is to just drop all the non-numeric columns.</p>
<div class="highlight">
<pre><span></span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">column</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">X_train</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="nb">object</span><span class="p">]</span>
<span class="n">drop_X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span>
<span class="n">drop_X_validate</span> <span class="o">=</span> <span class="n">X_validate</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span>

<span class="k">print</span><span class="p">(</span><span class="s2">"MAE from Approach 1 (Drop categorical variables):"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{score_dataset(drop_X_train, drop_X_validate, y_train, y_validate):,}"</span><span class="p">)</span>
</pre></div>
<p>Using all the numeric columns does better than we did with our initial subset of columns (20,928.5), but not as good as we did with imputed values (16,656.3).</p>
</div>
</div>
<div class="outline-3" id="outline-container-orgdb4840f">
<h3 id="orgdb4840f">Step 2: Label encoding</h3>
<div class="outline-text-3" id="text-orgdb4840f">
<blockquote>
<p>Before jumping into label encoding, we'll investigate the dataset. Specifically, we'll look at the <code>'Condition2'</code> column. The code cell below prints the unique entries in both the training and validation sets.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">train_counter</span> <span class="o">=</span> <span class="n">CountPercentage</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">Condition2</span><span class="p">,</span> <span class="n">dropna</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">validate_counter</span> <span class="o">=</span> <span class="n">CountPercentage</span><span class="p">(</span><span class="n">X_validate</span><span class="o">.</span><span class="n">Condition2</span><span class="p">,</span> <span class="n">dropna</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">train_counter</span><span class="p">()</span>
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-right">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Value</th>
<th class="org-right" scope="col">Count</th>
<th class="org-right" scope="col">Percent (%)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Norm</td>
<td class="org-right">1160</td>
<td class="org-right">99.32</td>
</tr>
<tr>
<td class="org-left">Feedr</td>
<td class="org-right">4</td>
<td class="org-right">0.34</td>
</tr>
<tr>
<td class="org-left">PosA</td>
<td class="org-right">1</td>
<td class="org-right">0.09</td>
</tr>
<tr>
<td class="org-left">Artery</td>
<td class="org-right">1</td>
<td class="org-right">0.09</td>
</tr>
<tr>
<td class="org-left">RRAe</td>
<td class="org-right">1</td>
<td class="org-right">0.09</td>
</tr>
<tr>
<td class="org-left">PosN</td>
<td class="org-right">1</td>
<td class="org-right">0.09</td>
</tr>
</tbody>
</table>
<div class="highlight">
<pre><span></span><span class="n">validate_counter</span><span class="p">()</span>
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-right">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Value</th>
<th class="org-right" scope="col">Count</th>
<th class="org-right" scope="col">Percent (%)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Norm</td>
<td class="org-right">285</td>
<td class="org-right">97.60</td>
</tr>
<tr>
<td class="org-left">Feedr</td>
<td class="org-right">2</td>
<td class="org-right">0.68</td>
</tr>
<tr>
<td class="org-left">RRNn</td>
<td class="org-right">2</td>
<td class="org-right">0.68</td>
</tr>
<tr>
<td class="org-left">RRAn</td>
<td class="org-right">1</td>
<td class="org-right">0.34</td>
</tr>
<tr>
<td class="org-left">Artery</td>
<td class="org-right">1</td>
<td class="org-right">0.34</td>
</tr>
<tr>
<td class="org-left">PosN</td>
<td class="org-right">1</td>
<td class="org-right">0.34</td>
</tr>
</tbody>
</table>
<p>It looks like the validation data has values that aren't in the training data (and vice versa), e.g. <code>RRNn</code>, so encoding the training set won't work with the validation set.</p>
<blockquote>
<p>This is a common problem that you'll encounter with real-world data, and there are many approaches to fixing this issue. For instance, you can write a custom label encoder to deal with new categories. The simplest approach, however, is to drop the problematic categorical columns.</p>
<p>Run the code cell below to save the problematic columns to a Python list <code>bad_label_cols</code>. Likewise, columns that can be safely label encoded are stored in <code>good_label_cols</code>.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="c1"># All categorical columns</span>
<span class="n">object_columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">column</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">X_train</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="s2">"object"</span><span class="p">]</span>

<span class="c1"># Columns that can be safely label encoded</span>
<span class="n">good_label_columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">column</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">object_columns</span> <span class="k">if</span> 
                      <span class="nb">set</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">column</span><span class="p">])</span> <span class="o">==</span> <span class="nb">set</span><span class="p">(</span><span class="n">X_validate</span><span class="p">[</span><span class="n">column</span><span class="p">])]</span>

<span class="c1"># Problematic columns that will be dropped from the dataset</span>
<span class="n">bad_label_columns</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">object_columns</span><span class="p">)</span><span class="o">-</span><span class="nb">set</span><span class="p">(</span><span class="n">good_label_columns</span><span class="p">))</span>

<span class="k">print</span><span class="p">(</span><span class="s1">'Categorical columns that will be label encoded:'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">column</span> <span class="ow">in</span>  <span class="n">good_label_columns</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">" - {column}"</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Categorical columns that will be dropped from the dataset:'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">bad_label_columns</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">" - {column}"</span><span class="p">)</span>
</pre></div>
<p>Categorical columns that will be label encoded:</p>
<ul class="org-ul">
<li>MSZoning</li>
<li>Street</li>
<li>LotShape</li>
<li>LandContour</li>
<li>LotConfig</li>
<li>BldgType</li>
<li>HouseStyle</li>
<li>ExterQual</li>
<li>CentralAir</li>
<li>KitchenQual</li>
<li>PavedDrive</li>
<li>SaleCondition</li>
</ul>
<p>Categorical columns that will be dropped from the dataset:</p>
<ul class="org-ul">
<li>Condition1</li>
<li>RoofMatl</li>
<li>HeatingQC</li>
<li>ExterCond</li>
<li>RoofStyle</li>
<li>SaleType</li>
<li>Foundation</li>
<li>Condition2</li>
<li>Exterior2nd</li>
<li>Neighborhood</li>
<li>Heating</li>
<li>LandSlope</li>
<li>Utilities</li>
<li>Functional</li>
<li>Exterior1st</li>
</ul>
</div>
<div class="outline-4" id="outline-container-org76de614">
<h4 id="org76de614">Drop the Bad Columns</h4>
<div class="outline-text-4" id="text-org76de614">
<div class="highlight">
<pre><span></span><span class="n">label_X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">bad_label_columns</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s2">"columns"</span><span class="p">)</span>
<span class="n">label_X_validate</span> <span class="o">=</span> <span class="n">X_validate</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">bad_label_columns</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s2">"columns"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org20636a1">
<h4 id="org20636a1">Encode the Categorical Values</h4>
<div class="outline-text-4" id="text-org20636a1">
<p>We're going to use sklearn's <a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html">LabelEncoder</a>.</p>
<p><b>Note:</b> Sklearn's documentation says that this is meant only for categorical target data (the labels), not the input data like we're doing here. Later on we're going to use one-hot-encoding, which is what sklearn recommends (the LabelEncoder method implies that the numbers are values, not just numeric codes for strings).</p>
<p>It's going to create integer values for each of the unique values in each column.</p>
<div class="highlight">
<pre><span></span><span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">good_label_columns</span><span class="p">:</span>
    <span class="n">encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>    
    <span class="n">label_X_train</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">column</span><span class="p">]</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">label_X_train</span><span class="p">[</span><span class="n">column</span><span class="p">])</span>
    <span class="n">label_X_validate</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">column</span><span class="p">]</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">label_X_validate</span><span class="p">[</span><span class="n">column</span><span class="p">])</span>
</pre></div>
<p>Now check how it did.</p>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="s2">"MAE from Approach 2 (Label Encoding):"</span><span class="p">)</span> 
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{score_dataset(label_X_train, label_X_validate, y_train, y_validate):,}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
MAE from Approach 2 (Label Encoding):
17,575.291883561644
</pre>
<p>So it does a little better than the previous approach of just dropping all the categorical data, but not as well as it did when we imputed the missing numeric values.</p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org9a993d9">
<h3 id="org9a993d9">Step 3: Investigating cardinality</h3>
<div class="outline-text-3" id="text-org9a993d9">
<blockquote>
<p>So far, you've tried two different approaches to dealing with categorical variables. And, you've seen that encoding categorical data yields better results than removing columns from the dataset.</p>
<p>Soon, you'll try one-hot encoding. Before then, there's one additional topic we need to cover. Begin by running the next code cell without changes.</p>
</blockquote>
<p>Get number of unique entries in each column with categorical data</p>
<div class="highlight">
<pre><span></span><span class="n">object_nunique</span> <span class="o">=</span> <span class="p">[</span><span class="n">X_train</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">object_columns</span><span class="p">]</span>

<span class="c1">## Print number of unique entries by column, in descending</span>
<span class="n">cardinality</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">Column</span><span class="o">=</span><span class="n">object_columns</span><span class="p">,</span>
                                    <span class="n">Cardinality</span><span class="o">=</span><span class="n">object_nunique</span><span class="p">)</span>
                     <span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s2">"Cardinality"</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">TABLE</span><span class="p">(</span><span class="n">cardinality</span><span class="p">))</span>
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Column</th>
<th class="org-right" scope="col">Cardinality</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Neighborhood</td>
<td class="org-right">25</td>
</tr>
<tr>
<td class="org-left">Exterior2nd</td>
<td class="org-right">16</td>
</tr>
<tr>
<td class="org-left">Exterior1st</td>
<td class="org-right">15</td>
</tr>
<tr>
<td class="org-left">SaleType</td>
<td class="org-right">9</td>
</tr>
<tr>
<td class="org-left">Condition1</td>
<td class="org-right">9</td>
</tr>
<tr>
<td class="org-left">HouseStyle</td>
<td class="org-right">8</td>
</tr>
<tr>
<td class="org-left">RoofMatl</td>
<td class="org-right">7</td>
</tr>
<tr>
<td class="org-left">Functional</td>
<td class="org-right">6</td>
</tr>
<tr>
<td class="org-left">Heating</td>
<td class="org-right">6</td>
</tr>
<tr>
<td class="org-left">Foundation</td>
<td class="org-right">6</td>
</tr>
<tr>
<td class="org-left">RoofStyle</td>
<td class="org-right">6</td>
</tr>
<tr>
<td class="org-left">SaleCondition</td>
<td class="org-right">6</td>
</tr>
<tr>
<td class="org-left">Condition2</td>
<td class="org-right">6</td>
</tr>
<tr>
<td class="org-left">BldgType</td>
<td class="org-right">5</td>
</tr>
<tr>
<td class="org-left">ExterCond</td>
<td class="org-right">5</td>
</tr>
<tr>
<td class="org-left">LotConfig</td>
<td class="org-right">5</td>
</tr>
<tr>
<td class="org-left">HeatingQC</td>
<td class="org-right">5</td>
</tr>
<tr>
<td class="org-left">MSZoning</td>
<td class="org-right">5</td>
</tr>
<tr>
<td class="org-left">ExterQual</td>
<td class="org-right">4</td>
</tr>
<tr>
<td class="org-left">KitchenQual</td>
<td class="org-right">4</td>
</tr>
<tr>
<td class="org-left">LandContour</td>
<td class="org-right">4</td>
</tr>
<tr>
<td class="org-left">LotShape</td>
<td class="org-right">4</td>
</tr>
<tr>
<td class="org-left">LandSlope</td>
<td class="org-right">3</td>
</tr>
<tr>
<td class="org-left">PavedDrive</td>
<td class="org-right">3</td>
</tr>
<tr>
<td class="org-left">Street</td>
<td class="org-right">2</td>
</tr>
<tr>
<td class="org-left">Utilities</td>
<td class="org-right">2</td>
</tr>
<tr>
<td class="org-left">CentralAir</td>
<td class="org-right">2</td>
</tr>
</tbody>
</table>
<blockquote>
<p>The output above shows, for each column with categorical data, the number of unique values in the column. For instance, the <code>'Street'</code> column in the training data has two unique values: <code>'Grvl'</code> and <code>'Pave'</code>, corresponding to a gravel road and a paved road, respectively.</p>
<p>We refer to the number of unique entries of a categorical variable as the <b>cardinality</b> of that categorical variable. For instance, the <code>'Street'</code> variable has cardinality 2.</p>
</blockquote>
</div>
<div class="outline-4" id="outline-container-org05f6c11">
<h4 id="org05f6c11">Questions</h4>
<div class="outline-text-4" id="text-org05f6c11">
<blockquote>
<p>How many categorical variables in the training data have cardinality greater than 10?</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">cardinality</span><span class="p">[</span><span class="n">cardinality</span><span class="o">.</span><span class="n">Cardinality</span> <span class="o">&gt;</span> <span class="mi">10</span><span class="p">]))</span>
</pre></div>
<pre class="example">
3
</pre>
<blockquote>
<p>How many columns are needed to one-hot encode the 'Neighborhood' variable in the training data?</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">cardinality</span><span class="p">[</span><span class="n">cardinality</span><span class="o">.</span><span class="n">Column</span><span class="o">==</span><span class="s2">"Neighborhood"</span><span class="p">]</span><span class="o">.</span><span class="n">Cardinality</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
<pre class="example">
25
</pre>
<blockquote>
<p>For large datasets with many rows, one-hot encoding can greatly expand the size of the dataset. For this reason, we typically will only one-hot encode columns with relatively low cardinality. Then, high cardinality columns can either be dropped from the dataset, or we can use label encoding.</p>
<p>As an example, consider a dataset with 10,000 rows, and containing one categorical column with 100 unique entries.</p>
<ul class="org-ul">
<li>If this column is replaced with the corresponding one-hot encoding, how many entries are added to the dataset?</li>
<li>If we instead replace the column with the label encoding, how many entries are added?</li>
</ul>
</blockquote>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="mi">10000</span> <span class="o">*</span> <span class="mi">100</span> <span class="o">-</span> <span class="mi">10000</span><span class="p">)</span>
</pre></div>
<pre class="example">
990000
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org7a79e92">
<h3 id="org7a79e92">Step 4: One-hot encoding</h3>
<div class="outline-text-3" id="text-org7a79e92">
<blockquote>
<p>In this step, you'll experiment with one-hot encoding. But, instead of encoding all of the categorical variables in the dataset, you'll only create a one-hot encoding for columns with cardinality less than 10.</p>
<p>Run the code cell below without changes to set <code>low_cardinality_cols</code> to a Python list containing the columns that will be one-hot encoded. Likewise, <code>high_cardinality_cols</code> contains a list of categorical columns that will be dropped from the dataset.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">low_cardinality_columns</span> <span class="o">=</span> <span class="n">cardinality</span><span class="p">[</span><span class="n">cardinality</span><span class="o">.</span><span class="n">Cardinality</span> <span class="o">&lt;</span> <span class="mi">10</span><span class="p">]</span><span class="o">.</span><span class="n">Column</span>
<span class="n">high_cardinality_columns</span> <span class="o">=</span> <span class="n">cardinality</span><span class="p">[</span><span class="o">~</span><span class="n">cardinality</span><span class="o">.</span><span class="n">Column</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">low_cardinality_columns</span><span class="p">)]</span><span class="o">.</span><span class="n">Column</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="s2">"Categorical columns that will be one-hot encoded:"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">low_cardinality_columns</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">" - {column}"</span><span class="p">)</span>
</pre></div>
<p>Categorical columns that will be one-hot encoded:</p>
<ul class="org-ul">
<li>SaleType</li>
<li>Condition1</li>
<li>HouseStyle</li>
<li>RoofMatl</li>
<li>Functional</li>
<li>Heating</li>
<li>Foundation</li>
<li>RoofStyle</li>
<li>SaleCondition</li>
<li>Condition2</li>
<li>BldgType</li>
<li>ExterCond</li>
<li>LotConfig</li>
<li>HeatingQC</li>
<li>MSZoning</li>
<li>ExterQual</li>
<li>KitchenQual</li>
<li>LandContour</li>
<li>LotShape</li>
<li>LandSlope</li>
<li>PavedDrive</li>
<li>Street</li>
<li>Utilities</li>
<li>CentralAir</li>
</ul>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="s1">'Categorical columns that will be dropped from the dataset:'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">high_cardinality_columns</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">" - {column}"</span><span class="p">)</span>
</pre></div>
<p>Categorical columns that will be dropped from the dataset:</p>
<ul class="org-ul">
<li>Neighborhood</li>
<li>Exterior2nd</li>
<li>Exterior1st</li>
</ul>
<blockquote>
<p>Use the next code cell to one-hot encode the data in <code>X_train</code> and <code>X_valid</code>. Set the preprocessed DataFrames to <code>OH_X_train</code> and <code>OH_X_valid</code>, respectively.</p>
<ul class="org-ul">
<li>The full list of categorical columns in the dataset can be found in the Python list <code>object_cols</code>.</li>
<li>You should only one-hot encode the categorical columns in <code>low_cardinality_cols</code>. All other categorical columns should be dropped from the dataset.</li>
</ul>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">OH_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">low_cardinality_columns</span><span class="p">]</span>
<span class="n">OH_validate</span> <span class="o">=</span> <span class="n">X_validate</span><span class="p">[</span><span class="n">low_cardinality_columns</span><span class="p">]</span>

<span class="n">encoder</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">handle_unknown</span><span class="o">=</span><span class="s2">"ignore"</span><span class="p">)</span>

<span class="n">OH_train</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">OH_train</span><span class="p">))</span>
<span class="n">OH_validate</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">OH_validate</span><span class="p">))</span>

<span class="n">OH_train</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">index</span>
<span class="n">OH_validate</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">X_validate</span><span class="o">.</span><span class="n">index</span>

<span class="n">X_train_numeric</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">object_columns</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s2">"columns"</span><span class="p">)</span>
<span class="n">X_validate_numeric</span> <span class="o">=</span> <span class="n">X_validate</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">object_columns</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s2">"columns"</span><span class="p">)</span>

<span class="n">OH_X_train</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_train_numeric</span><span class="p">,</span> <span class="n">OH_train</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="s2">"columns"</span><span class="p">)</span>
<span class="n">OH_X_validate</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_validate_numeric</span><span class="p">,</span> <span class="n">OH_validate</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="s2">"columns"</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="s2">"MAE from Approach 3 (One-Hot Encoding):"</span><span class="p">)</span> 
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{score_dataset(OH_X_train, OH_X_validate, y_train, y_validate):,}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
MAE from Approach 3 (One-Hot Encoding):
17,429.93404109589
</pre>
<p>So we've improved slightly, but still not as well as the all numeric data with imputed data.</p>
</div>
</div>
<div class="outline-3" id="outline-container-orgd1e8f73">
<h3 id="orgd1e8f73">Step 5: Generate test predictions and submit your results</h3>
<div class="outline-text-3" id="text-orgd1e8f73">
<blockquote>
<p>After you complete Step 4, if you'd like to use what you've learned to submit your results to the leaderboard, you'll need to preprocess the test data before generating predictions.</p>
</blockquote>
<p>To get the imputation working again we need to re-add the columns with missing values. I'm also going to encode the entire dataset before splitting so that everything is encoded, rather than ignoring the values in the validation set that aren't in the training set.</p>
<div class="highlight">
<pre><span></span><span class="n">X_2</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="n">Data</span><span class="o">.</span><span class="n">target</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="s2">"columns"</span><span class="p">)</span>
<span class="n">objects</span> <span class="o">=</span> <span class="p">[</span><span class="n">column</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">X_2</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">X_2</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="o">==</span><span class="nb">object</span><span class="p">]</span>
<span class="n">missing</span> <span class="o">=</span> <span class="p">[</span><span class="n">column</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">objects</span> <span class="k">if</span> <span class="n">X_2</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">hasnans</span><span class="p">]</span>

<span class="n">X_2</span> <span class="o">=</span> <span class="n">X_2</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">missing</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s2">"columns"</span><span class="p">)</span>
<span class="n">OH_X</span> <span class="o">=</span> <span class="n">X_2</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">high_cardinality_columns</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s2">"columns"</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">low_cardinality_columns</span><span class="p">:</span>
    <span class="n">encoder</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="n">encoded</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span>
        <span class="n">OH_X</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">reencoded</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">encoded</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">encoder</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">())</span>
    <span class="n">OH_X</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">OH_X</span><span class="p">,</span> <span class="n">reencoded</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="s2">"columns"</span><span class="p">)</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span>
        <span class="n">column</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s2">"columns"</span><span class="p">)</span>

<span class="n">imputer</span> <span class="o">=</span> <span class="n">IterativeImputer</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
<span class="n">OH_X</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">OH_X</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="n">OH_X</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">OH_X_train</span><span class="p">,</span> <span class="n">OH_X_validate</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_validate</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">OH_X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
    <span class="n">train_size</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">train_size</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">test_size</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">OH_X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">preds_valid</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">OH_X_validate</span><span class="p">)</span>
<span class="n">error</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_validate</span><span class="p">,</span> <span class="n">preds_valid</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"MAE: {error:0.2f}"</span><span class="p">)</span>
</pre></div>
<p>It seems to have gotten worseâ€¦ but maybe that's because we tuned the hyperparameters to the numeric-only model.</p>
</div>
<div class="outline-4" id="outline-container-org0b16c94">
<h4 id="org0b16c94">Hyperparameter Tuning</h4>
<div class="outline-text-4" id="text-org0b16c94">
<div class="highlight">
<pre><span></span><span class="n">estimators</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">max_depth</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span> <span class="o">+</span> <span class="p">[</span><span class="bp">None</span><span class="p">]</span>

<span class="n">grid</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="n">estimators</span><span class="p">,</span>
            <span class="n">max_depth</span><span class="o">=</span><span class="n">max_depth</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">()</span>
<span class="n">search</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                            <span class="n">param_distributions</span><span class="o">=</span><span class="n">grid</span><span class="p">,</span>
                            <span class="n">n_iter</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
                            <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
                            <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">OH_X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">search</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"CV Training R^2: {search.best_score_:0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Training R^2: {model.score(OH_X_train, y_train): 0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Validation R^2: {model.score(OH_X_validate, y_validate):0.2f}"</span><span class="p">)</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">OH_X_validate</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Mean Absolute Error: {mean_absolute_error(y_validate, predictions)}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
</pre></div>
<pre class="example">
CV Training R^2: 0.86
Training R^2:  0.98
Validation R^2: 0.84
Mean Absolute Error: 17615.31526418787
{'n_estimators': 140, 'max_depth': 60}
</pre>
<p>So it can get a little better, but it doesn't do as well as with just the numeric features. Maybe we don't have enough data to make it work.</p>
<div class="highlight">
<pre><span></span><span class="n">permutor</span> <span class="o">=</span> <span class="n">PermutationImportance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">OH_X_validate</span><span class="p">,</span> <span class="n">y_validate</span><span class="p">)</span>
<span class="n">ipython_html</span> <span class="o">=</span> <span class="n">eli5</span><span class="o">.</span><span class="n">show_weights</span><span class="p">(</span>
    <span class="n">permutor</span><span class="p">,</span>
    <span class="n">feature_names</span><span class="o">=</span><span class="n">OH_X_validate</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
<span class="n">table</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_html</span><span class="p">(</span><span class="n">ipython_html</span><span class="o">.</span><span class="n">data</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="n">TABLE</span><span class="p">(</span><span class="n">table</span><span class="p">))</span>
</pre></div>
<pre class="example">
| Weight           | Feature      |
|------------------+--------------|
| 0.4825  Â± 0.1218 | OverallQual  |
| 0.1019  Â± 0.0350 | GrLivArea    |
| 0.0199  Â± 0.0082 | TotalBsmtSF  |
| 0.0171  Â± 0.0067 | BsmtFinSF1   |
| 0.0131  Â± 0.0062 | 1stFlrSF     |
| 0.0096  Â± 0.0078 | GarageCars   |
| 0.0084  Â± 0.0011 | 2ndFlrSF     |
| 0.0074  Â± 0.0026 | LotArea      |
| 0.0051  Â± 0.0022 | YearRemodAdd |
| 0.0050  Â± 0.0034 | GarageArea   |
| 0.0048  Â± 0.0047 | BedroomAbvGr |
| 0.0036  Â± 0.0009 | LotFrontage  |
| 0.0031  Â± 0.0021 | YearBuilt    |
| 0.0031  Â± 0.0014 | OverallCond  |
| 0.0029  Â± 0.0012 | WoodDeckSF   |
| 0.0021  Â± 0.0021 | MasVnrArea   |
| 0.0014  Â± 0.0016 | OpenPorchSF  |
| 0.0012  Â± 0.0009 | FullBath     |
| 0.0009  Â± 0.0008 | x0_RM        |
| 0.0008  Â± 0.0036 | GarageYrBlt  |
| â€¦ 142 more â€¦     | â€¦ 142 more â€¦ |
</pre>
<p>It looks like the most significant categorical features are <code>LandContour</code> (Bnk and Lvl), either <code>Condition1</code> or <code>Condition2</code> (Norm) and <code>ExterCond</code> (TA). I just took a quick look they don't seem to contribute a whole lot to the model.</p>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgf1fa4e5">
<h2 id="orgf1fa4e5">End</h2>
<div class="outline-text-2" id="text-orgf1fa4e5">
<p>This was a brief look at handling categorical data.</p>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="/posts/tutorials/missing-values/">Missing Values</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="/posts/tutorials/missing-values/" rel="bookmark"><time class="published dt-published" datetime="2020-02-20T21:07:15-08:00" itemprop="datePublished" title="2020-02-20 21:07">2020-02-20 21:07</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="/posts/tutorials/missing-values/#org4ef88d0">Beginning</a>
<ul>
<li><a href="/posts/tutorials/missing-values/#org4dce918">Imports</a>
<ul>
<li><a href="/posts/tutorials/missing-values/#orgfe1523e">Python</a></li>
<li><a href="/posts/tutorials/missing-values/#org9509447">PyPi</a></li>
<li><a href="/posts/tutorials/missing-values/#orgd143f12">Others</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/missing-values/#org7676bd0">Set Up</a>
<ul>
<li><a href="/posts/tutorials/missing-values/#org272dba6">Table</a></li>
<li><a href="/posts/tutorials/missing-values/#org60465db">Plottting</a></li>
<li><a href="/posts/tutorials/missing-values/#org8dfdcab">The Timer</a></li>
<li><a href="/posts/tutorials/missing-values/#org4aeabb0">Environment</a></li>
<li><a href="/posts/tutorials/missing-values/#org427c89a">The Data</a></li>
<li><a href="/posts/tutorials/missing-values/#org8c378f1">Some Constants</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="/posts/tutorials/missing-values/#orgfb58d5a">Middle</a>
<ul>
<li><a href="/posts/tutorials/missing-values/#org7b09c62">Remove Training Data with no Target</a></li>
<li><a href="/posts/tutorials/missing-values/#orgac20761">Numeric Data Only</a></li>
<li><a href="/posts/tutorials/missing-values/#org6c8fdcf">Split the Training and Validation Data</a></li>
<li><a href="/posts/tutorials/missing-values/#org1300780">Step 1: Preliminary investigation</a>
<ul>
<li><a href="/posts/tutorials/missing-values/#orgf11726e">Part A</a></li>
<li><a href="/posts/tutorials/missing-values/#org89f64e3">Part B</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/missing-values/#org11c1e67">score_dataset</a></li>
<li><a href="/posts/tutorials/missing-values/#org446b061">Step 2: Drop columns with missing values</a></li>
<li><a href="/posts/tutorials/missing-values/#orge4e71b6">Step 3: Imputation</a>
<ul>
<li><a href="/posts/tutorials/missing-values/#org01ee5ec">Part A</a></li>
<li><a href="/posts/tutorials/missing-values/#org0f265b2">Part B</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/missing-values/#org0e61bbe">Step 4: Generate test predictions</a>
<ul>
<li><a href="/posts/tutorials/missing-values/#orgd37aebc">Part A</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="/posts/tutorials/missing-values/#org27deac5">End</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org4ef88d0">
<h2 id="org4ef88d0">Beginning</h2>
<div class="outline-text-2" id="text-org4ef88d0">
<blockquote>
<p>Now it's your turn to test your new knowledge of <b>missing values</b> handling. You'll probably find it makes a big difference.</p>
</blockquote>
</div>
<div class="outline-3" id="outline-container-org4dce918">
<h3 id="org4dce918">Imports</h3>
<div class="outline-text-3" id="text-org4dce918"></div>
<div class="outline-4" id="outline-container-orgfe1523e">
<h4 id="orgfe1523e">Python</h4>
<div class="outline-text-4" id="text-orgfe1523e">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org9509447">
<h4 id="org9509447">PyPi</h4>
<div class="outline-text-4" id="text-org9509447">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">eli5.sklearn</span> <span class="kn">import</span> <span class="n">PermutationImportance</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span>
<span class="kn">from</span> <span class="nn">pdpbox</span> <span class="kn">import</span> <span class="n">pdp</span>

<span class="kn">import</span> <span class="nn">shap</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.experimental</span> <span class="kn">import</span> <span class="n">enable_iterative_imputer</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">IterativeImputer</span><span class="p">,</span> <span class="n">KNNImputer</span><span class="p">,</span> <span class="n">SimpleImputer</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">tabulate</span> <span class="kn">import</span> <span class="n">tabulate</span>

<span class="kn">import</span> <span class="nn">eli5</span>
<span class="kn">import</span> <span class="nn">hvplot.pandas</span>
<span class="kn">import</span> <span class="nn">pandas</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgd143f12">
<h4 id="orgd143f12">Others</h4>
<div class="outline-text-4" id="text-orgd143f12">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">EnvironmentLoader</span><span class="p">,</span> <span class="n">Timer</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org7676bd0">
<h3 id="org7676bd0">Set Up</h3>
<div class="outline-text-3" id="text-org7676bd0"></div>
<div class="outline-4" id="outline-container-org272dba6">
<h4 id="org272dba6">Table</h4>
<div class="outline-text-4" id="text-org272dba6">
<div class="highlight">
<pre><span></span><span class="n">TABLE</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">tabulate</span><span class="p">,</span> <span class="n">tablefmt</span><span class="o">=</span><span class="s2">"orgtbl"</span><span class="p">,</span> <span class="n">showindex</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="s2">"keys"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org60465db">
<h4 id="org60465db">Plottting</h4>
<div class="outline-text-4" id="text-org60465db">
<div class="highlight">
<pre><span></span><span class="n">SLUG</span> <span class="o">=</span> <span class="s2">"missing-values"</span>
<span class="n">OUTPUT_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"../../files/posts/tutorials/"</span><span class="p">)</span><span class="o">/</span><span class="n">SLUG</span>
<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">folder_path</span><span class="o">=</span><span class="n">OUTPUT_PATH</span><span class="p">)</span>
<span class="n">Plot</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org8dfdcab">
<h4 id="org8dfdcab">The Timer</h4>
<div class="outline-text-4" id="text-org8dfdcab">
<div class="highlight">
<pre><span></span><span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org4aeabb0">
<h4 id="org4aeabb0">Environment</h4>
<div class="outline-text-4" id="text-org4aeabb0">
<div class="highlight">
<pre><span></span><span class="n">ENVIRONMENT</span> <span class="o">=</span> <span class="n">EnvironmentLoader</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org427c89a">
<h4 id="org427c89a">The Data</h4>
<div class="outline-text-4" id="text-org427c89a">
<div class="highlight">
<pre><span></span><span class="n">DATA_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">ENVIRONMENT</span><span class="p">[</span><span class="s2">"HOUSE-PRICES-IOWA"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="n">DATA_PATH</span><span class="o">/</span><span class="s2">"train.csv"</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s2">"Id"</span><span class="p">)</span>

<span class="n">test_data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="n">DATA_PATH</span><span class="o">/</span><span class="s2">"test.csv"</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s2">"Id"</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org8c378f1">
<h4 id="org8c378f1">Some Constants</h4>
<div class="outline-text-4" id="text-org8c378f1">
<div class="highlight">
<pre><span></span><span class="n">Data</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">target</span><span class="o">=</span><span class="s2">"SalePrice"</span><span class="p">,</span>
    <span class="n">train_size</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">random_seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgfb58d5a">
<h2 id="orgfb58d5a">Middle</h2>
<div class="outline-text-2" id="text-orgfb58d5a"></div>
<div class="outline-3" id="outline-container-org7b09c62">
<h3 id="org7b09c62">Remove Training Data with no Target</h3>
<div class="outline-text-3" id="text-org7b09c62">
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{len(train_data):,}"</span><span class="p">)</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s2">"rows"</span><span class="p">,</span> <span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="n">Data</span><span class="o">.</span><span class="n">target</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{len(train_data):,}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
1,460
1,460
</pre>
<p>Doesn't look like there were any missing target values.</p>
<div class="highlight">
<pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="n">Data</span><span class="o">.</span><span class="n">target</span><span class="p">]</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="n">Data</span><span class="o">.</span><span class="n">target</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="s2">"columns"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgac20761">
<h3 id="orgac20761">Numeric Data Only</h3>
<div class="outline-text-3" id="text-orgac20761">
<blockquote>
<p>To keep things simple, we'll use only numerical predictors</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_train</span><span class="o">.</span><span class="n">columns</span><span class="p">))</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">exclude</span><span class="o">=</span><span class="p">[</span><span class="s2">"object"</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">))</span>
</pre></div>
<pre class="example">
79
36
</pre>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="o">.</span><span class="n">columns</span><span class="p">))</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">test_data</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">exclude</span><span class="o">=</span><span class="p">[</span><span class="s2">"object"</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_test</span><span class="o">.</span><span class="n">columns</span><span class="p">))</span>
</pre></div>
<pre class="example">
79
36
</pre></div>
</div>
<div class="outline-3" id="outline-container-org6c8fdcf">
<h3 id="org6c8fdcf">Split the Training and Validation Data</h3>
<div class="outline-text-3" id="text-org6c8fdcf">
<div class="highlight">
<pre><span></span><span class="n">x_train</span><span class="p">,</span> <span class="n">x_validate</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_validate</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
    <span class="n">train_size</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">train_size</span><span class="p">,</span>
    <span class="n">test_size</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">test_size</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org1300780">
<h3 id="org1300780">Step 1: Preliminary investigation</h3>
<div class="outline-text-3" id="text-org1300780">
<div class="highlight">
<pre><span></span><span class="n">missing_by_column</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">missed</span> <span class="o">=</span> <span class="n">missing_by_column</span><span class="p">[</span><span class="n">missing_by_column</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="n">TABLE</span><span class="p">(</span><span class="n">missed</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s2">"index"</span><span class="p">:</span> <span class="s2">"Feature"</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="s2">"Missing"</span><span class="p">})))</span>
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Feature</th>
<th class="org-right" scope="col">Missing</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">LotFrontage</td>
<td class="org-right">212</td>
</tr>
<tr>
<td class="org-left">MasVnrArea</td>
<td class="org-right">6</td>
</tr>
<tr>
<td class="org-left">GarageYrBlt</td>
<td class="org-right">58</td>
</tr>
</tbody>
</table>
<p>According to the data description these features are:</p>
<p><b>LotFrontage</b>: Linear feet of street connected to property <b>MasVnrArea:</b> Masonry veneer area in square feet <b>GarageYrBlt</b>: Year garage was built</p>
<div class="highlight">
<pre><span></span><span class="n">Missing</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">frontage</span> <span class="o">=</span> <span class="s2">"LotFrontage"</span><span class="p">,</span>
    <span class="n">masonry</span> <span class="o">=</span> <span class="s2">"MasVnrArea"</span><span class="p">,</span>
    <span class="n">garage</span> <span class="o">=</span> <span class="s2">"GarageYrBlt"</span><span class="p">,</span>
    <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"LotFrontage"</span><span class="p">,</span> <span class="s2">"MasVnrArea"</span><span class="p">,</span> <span class="s2">"GarageYrBlt"</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-orgf11726e">
<h4 id="orgf11726e">Part A</h4>
<div class="outline-text-4" id="text-orgf11726e"></div>
<ul class="org-ul">
<li><a id="orgd062fa9"></a>How many rows are in the training data?<br>
<div class="outline-text-5" id="text-orgd062fa9">
<div class="highlight">
<pre><span></span> <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{len(x_train):,}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
1,168
</pre></div>
</li>
<li><a id="orgeb94d89"></a>Fill in the line below: How many columns in the training data have missing values?<br>
<div class="outline-text-5" id="text-orgeb94d89">
<div class="highlight">
<pre><span></span> <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{sum([1 for column in x_train.columns if x_train[column].hasnans])}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
3
</pre></div>
</li>
<li><a id="org5e7f4c9"></a>Fill in the line below: How many missing entries are contained in all of the training data?<br>
<div class="outline-text-5" id="text-org5e7f4c9">
<div class="highlight">
<pre><span></span> <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{missed.sum()}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
276
</pre>
<p><b>Note:</b> For some reason it doesn't appear to be explicitly mentioned in the notebook, but if you don't deal with the missing values and try and fit the trees to the data you'll end up with an error.</p>
<div class="highlight">
<pre><span></span><span class="k">try</span><span class="p">:</span>
    <span class="n">score_dataset</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">x_validate</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_validate</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">ValueError</span> <span class="k">as</span> <span class="n">error</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>
</pre></div>
<pre class="example">
Input contains NaN, infinity or a value too large for dtype('float32').
</pre></div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-org89f64e3">
<h4 id="org89f64e3">Part B</h4>
<div class="outline-text-4" id="text-org89f64e3">
<blockquote>
<p>Considering your answers above, what do you think is likely the best approach to dealing with the missing values?</p>
</blockquote>
<p>For the cases where there are few missing values I would drop them - e.g. <code>MasVnrArea</code>. For <code>GarageYrBlt</code> I would use the most common value in the same neighborhood and for the <code>LotFrontage</code> I would use the mean or median.</p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org11c1e67">
<h3 id="org11c1e67">score_dataset</h3>
<div class="outline-text-3" id="text-org11c1e67">
<p>This function will help check the Mean Absolute Error (MAE) as we make changes to the dataset.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">score_dataset</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org446b061">
<h3 id="org446b061">Step 2: Drop columns with missing values</h3>
<div class="outline-text-3" id="text-org446b061">
<p>We'll try dropping the columns in the training and validation.</p>
<div class="highlight">
<pre><span></span><span class="n">missing_columns</span> <span class="o">=</span> <span class="n">missed</span><span class="o">.</span><span class="n">index</span>
<span class="n">keep</span> <span class="o">=</span> <span class="p">[</span><span class="n">column</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">x_train</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">x_train</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">hasnans</span><span class="p">]</span>
<span class="n">reduced_X_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="n">keep</span><span class="p">]</span>
<span class="n">reduced_X_valid</span> <span class="o">=</span> <span class="n">x_validate</span><span class="p">[</span><span class="n">keep</span><span class="p">]</span>

<span class="k">print</span><span class="p">(</span><span class="s2">"MAE (Drop columns with missing values):"</span><span class="p">)</span>
<span class="n">drop_columns_error</span> <span class="o">=</span> <span class="n">score_dataset</span><span class="p">(</span><span class="n">reduced_X_train</span><span class="p">,</span> <span class="n">reduced_X_valid</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_validate</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{drop_columns_error:0.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
MAE (Drop columns with missing values):
17837.83
</pre></div>
</div>
<div class="outline-3" id="outline-container-orge4e71b6">
<h3 id="orge4e71b6">Step 3: Imputation</h3>
<div class="outline-text-3" id="text-orge4e71b6"></div>
<div class="outline-4" id="outline-container-org01ee5ec">
<h4 id="org01ee5ec">Part A</h4>
<div class="outline-text-4" id="text-org01ee5ec">
<blockquote>
<p>Use the next code cell to impute missing values with the mean value along each column. Set the preprocessed DataFrames to <code>imputed_X_train</code> and <code>imputed_X_valid</code>. Make sure that the column names match those in <code>X_train</code> and <code>X_valid</code>.</p>
</blockquote>
<p>Here we'll use sklearn's <a href="https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html">SimpleImputer</a> which fills missing values with the means of the columns (by default). It accepts pandas DataFrames but returns a numpy array so we need to rebuild the DataFrame afterward. The notebook suggests you can just re-set the columns, but I don't know what they're expecting, since it isn't a DataFrame. As long as we end up with the same thing in the end I guess it's okay.</p>
<div class="highlight">
<pre><span></span><span class="n">imputer</span> <span class="o">=</span> <span class="n">SimpleImputer</span><span class="p">()</span>
<span class="n">imputed_X_train</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_train</span><span class="p">),</span>
                                   <span class="n">columns</span><span class="o">=</span><span class="n">x_train</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">imputed_X_valid</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">imputer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x_validate</span><span class="p">))</span>
</pre></div>
<p>Now check the Mean Absolute Error for our imputed frames.</p>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="s2">"MAE (Imputation):"</span><span class="p">)</span>
<span class="n">impute_mean_error</span> <span class="o">=</span> <span class="n">score_dataset</span><span class="p">(</span><span class="n">imputed_X_train</span><span class="p">,</span> <span class="n">imputed_X_valid</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_validate</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{impute_mean_error:0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Improvement: {drop_columns_error - impute_mean_error:0.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
MAE (Imputation):
18056.85
Improvement: -219.03
</pre>
<p>So we actually got a little worse using mean imputation.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org0f265b2">
<h4 id="org0f265b2">Part B</h4>
<div class="outline-text-4" id="text-org0f265b2">
<blockquote>
<p>Compare the MAE from each approach. Does anything surprise you about the results? Why do you think one approach performed better than the other?</p>
</blockquote>
<p>As note previously, the imputation did worse than discarding the columns did. It might be that using the mean threw the values off so much that it did worse than just throwing the values away. This might indicate that the values aren't symmetrically distributed so using a central tendency doesn't reflect the data very well.</p>
<div class="highlight">
<pre><span></span><span class="n">plot</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">hvplot</span><span class="o">.</span><span class="n">box</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="s2">"LotFrontage"</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"LotFrontage"</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">source</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"lot_frontage_box"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">source</span><span class="p">)</span>
</pre></div>
: <object data="/posts/tutorials/missing-values/lot_frontage_box.html" height="800" style="width:100%" type="text/html">:
<p>Figure Missing</p>
:</object>
<p>Looking at the plot you can see that it's right-skewed, with an extreme point over 300 square feet well over the mean:</p>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Mean: {x_train.LotFrontage.mean():0.2f} sq ft"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Max: {x_train.LotFrontage.max():0.2f} sq ft"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Mean: 69.61 sq ft
Max: 313.00 sq ft
</pre>
<div class="highlight">
<pre><span></span><span class="n">plot</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">hvplot</span><span class="o">.</span><span class="n">box</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="s2">"GarageYrBlt"</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"GarageYrBlt"</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">source</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"garage_year_built_box"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">source</span><span class="p">)</span>
</pre></div>
: <object data="/posts/tutorials/missing-values/garage_year_built_box.html" height="800" style="width:100%" type="text/html">:
<p>Figure Missing</p>
:</object>
<p>This also looks skewed, but the number of missing points is less so I don't know if it had as much of an effect.</p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org0e61bbe">
<h3 id="org0e61bbe">Step 4: Generate test predictions</h3>
<div class="outline-text-3" id="text-org0e61bbe">
<blockquote>
<p>In this final step, you'll use any approach of your choosing to deal with missing values. Once you've preprocessed the training and validation features, you'll train and evaluate a random forest model. Then, you'll preprocess the test data before generating predictions that can be submitted to the competition.</p>
</blockquote>
</div>
<div class="outline-4" id="outline-container-orgd37aebc">
<h4 id="orgd37aebc">Part A</h4>
<div class="outline-text-4" id="text-orgd37aebc">
<blockquote>
<p>Use the next code cell to preprocess the training and validation data. Set the preprocessed DataFrames to <code>final_X_train</code> and <code>final_X_valid</code>. <b>You can use any approach of your choosing here!</b> in order for this step to be marked as correct, you need only ensure:</p>
<ul class="org-ul">
<li>the preprocessed DataFrames have the same number of columns,</li>
<li>the preprocessed DataFrames have no missing values,</li>
<li><code>final_X_train</code> and <code>y_train</code> have the same number of rows, and</li>
<li><code>final_X_valid</code> and <code>y_valid</code> have the same number of rows.</li>
</ul>
</blockquote>
</div>
<ul class="org-ul">
<li><a id="orga189d19"></a>KNN<br>
<div class="outline-text-5" id="text-orga189d19">
<p>Let's try using K-Nearest Neighbors to estimate missing values.</p>
<div class="highlight">
<pre><span></span><span class="n">imputer</span> <span class="o">=</span> <span class="n">KNNImputer</span><span class="p">()</span>
<span class="n">final_x_train</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_train</span><span class="p">),</span>
                                 <span class="n">columns</span><span class="o">=</span><span class="n">x_train</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">final_x_validate</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">imputer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x_validate</span><span class="p">),</span>
                                 <span class="n">columns</span><span class="o">=</span><span class="n">x_validate</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
</pre></div>
</div>
<ul class="org-ul">
<li><a id="org4981c75"></a>One Last Try<br>
<div class="outline-text-6" id="text-org4981c75">
<blockquote>
<p>Run the next code cell to train and evaluate a random forest model. (<b>Note that we don't use the <code>score_dataset()</code> function above, because we will soon use the trained model to generate test predictions!</b>)</p>
</blockquote>
<p>Define and fit the model.</p>
<div class="highlight">
<pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">final_x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
<p>Get validation predictions and MAE.</p>
<div class="highlight">
<pre><span></span><span class="n">preds_valid</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">final_x_validate</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">"MAE (Your approach):"</span><span class="p">)</span>
<span class="n">final_error</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_validate</span><span class="p">,</span> <span class="n">preds_valid</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{final_error:.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Improvement Over Dropping Columns: {drop_columns_error - final_error:0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Improvement Over Mean: {impute_mean_error - final_error:0.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
MAE (Your approach):
17834.40
Improvement Over Dropping Columns: 3.43
Improvement Over Mean: 222.46
</pre>
<p>So it does a litle better than dropping the columns altogether.</p>
</div>
</li>
</ul>
</li>
<li><a id="org2958459"></a>Iterative<br>
<div class="outline-text-5" id="text-org2958459">
<p>This is an experimental imputer from sklearn based on imputation methods from R.</p>
<div class="highlight">
<pre><span></span><span class="n">imputer_2</span> <span class="o">=</span> <span class="n">IterativeImputer</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
<span class="n">final_x_train_2</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">imputer_2</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_train</span><span class="p">),</span>
                                   <span class="n">columns</span><span class="o">=</span><span class="n">x_train</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">final_x_validate_2</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">imputer_2</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x_validate</span><span class="p">),</span>
                                      <span class="n">columns</span><span class="o">=</span><span class="n">x_validate</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
</pre></div>
</div>
<ul class="org-ul">
<li><a id="org20e6bcb"></a>One Last Try<br>
<div class="outline-text-6" id="text-org20e6bcb">
<blockquote>
<p>Run the next code cell to train and evaluate a random forest model. (<b>Note that we don't use the <code>score_dataset()</code> function above, because we will soon use the trained model to generate test predictions!</b>)</p>
</blockquote>
<p>Define and fit the model.</p>
<div class="highlight">
<pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">final_x_train_2</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
<p>Get validation predictions and MAE.</p>
<div class="highlight">
<pre><span></span><span class="n">preds_valid</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">final_x_validate_2</span><span class="p">)</span>
<span class="n">final_error_2</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_validate</span><span class="p">,</span> <span class="n">preds_valid</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"MAE (Your approach): {final_error_2:0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Improvement Over Dropping Columns: {drop_columns_error - final_error:0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Improvement Over Mean: {impute_mean_error - final_error:0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Improvement over KNN: {final_error - final_error_2: 0.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
MAE (Your approach): 17812.88
Improvement Over Dropping Columns: 3.43
Improvement Over Mean: 222.46
Improvement over KNN:  21.51
</pre>
<p>There's a slight improvement once again (the imputers have hyperparameters themselves that aren't being tuned so they might be even better than what I'm getting).</p>
</div>
</li>
</ul>
</li>
<li><a id="org1d348d2"></a>Permutation Importance<br>
<div class="outline-text-5" id="text-org1d348d2">
<p>Let's look at the the features that were the most important in our model.</p>
<div class="highlight">
<pre><span></span><span class="n">permutor</span> <span class="o">=</span> <span class="n">PermutationImportance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">final_x_validate_2</span><span class="p">,</span> <span class="n">y_validate</span><span class="p">)</span>
<span class="n">ipython_html</span> <span class="o">=</span> <span class="n">eli5</span><span class="o">.</span><span class="n">show_weights</span><span class="p">(</span>
    <span class="n">permutor</span><span class="p">,</span>
    <span class="n">feature_names</span><span class="o">=</span><span class="n">final_x_validate_2</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
<span class="n">table</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_html</span><span class="p">(</span><span class="n">ipython_html</span><span class="o">.</span><span class="n">data</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="n">TABLE</span><span class="p">(</span><span class="n">table</span><span class="p">))</span>
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-left"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Weight</th>
<th class="org-left" scope="col">Feature</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">0.4717 Â± 0.0741</td>
<td class="org-left">OverallQual</td>
</tr>
<tr>
<td class="org-left">0.1163 Â± 0.0182</td>
<td class="org-left">GrLivArea</td>
</tr>
<tr>
<td class="org-left">0.0254 Â± 0.0066</td>
<td class="org-left">TotalBsmtSF</td>
</tr>
<tr>
<td class="org-left">0.0209 Â± 0.0040</td>
<td class="org-left">BsmtFinSF1</td>
</tr>
<tr>
<td class="org-left">0.0127 Â± 0.0006</td>
<td class="org-left">2ndFlrSF</td>
</tr>
<tr>
<td class="org-left">0.0112 Â± 0.0042</td>
<td class="org-left">1stFlrSF</td>
</tr>
<tr>
<td class="org-left">0.0090 Â± 0.0072</td>
<td class="org-left">YearRemodAdd</td>
</tr>
<tr>
<td class="org-left">0.0079 Â± 0.0022</td>
<td class="org-left">YearBuilt</td>
</tr>
<tr>
<td class="org-left">0.0069 Â± 0.0036</td>
<td class="org-left">LotArea</td>
</tr>
<tr>
<td class="org-left">0.0046 Â± 0.0018</td>
<td class="org-left">GarageCars</td>
</tr>
<tr>
<td class="org-left">0.0039 Â± 0.0006</td>
<td class="org-left">WoodDeckSF</td>
</tr>
<tr>
<td class="org-left">0.0034 Â± 0.0026</td>
<td class="org-left">GarageYrBlt</td>
</tr>
<tr>
<td class="org-left">0.0031 Â± 0.0009</td>
<td class="org-left">OverallCond</td>
</tr>
<tr>
<td class="org-left">0.0027 Â± 0.0032</td>
<td class="org-left">OpenPorchSF</td>
</tr>
<tr>
<td class="org-left">0.0026 Â± 0.0008</td>
<td class="org-left">LotFrontage</td>
</tr>
<tr>
<td class="org-left">0.0026 Â± 0.0011</td>
<td class="org-left">Fireplaces</td>
</tr>
<tr>
<td class="org-left">0.0016 Â± 0.0009</td>
<td class="org-left">FullBath</td>
</tr>
<tr>
<td class="org-left">0.0015 Â± 0.0010</td>
<td class="org-left">BedroomAbvGr</td>
</tr>
<tr>
<td class="org-left">0.0014 Â± 0.0028</td>
<td class="org-left">BsmtUnfSF</td>
</tr>
<tr>
<td class="org-left">0.0012 Â± 0.0025</td>
<td class="org-left">TotRmsAbvGrd</td>
</tr>
<tr>
<td class="org-left">â€¦ 16 more â€¦</td>
<td class="org-left">â€¦ 16 more â€¦</td>
</tr>
</tbody>
</table>
<p>It's interesting, but the four most important features (<i>OverallQual</i>, <i>GrLivArea</i>, <i>TotalBsmtSF</i>, and <i>BsmtFinSF1</i>) were'nt in our first models. And <i>LotFrontage</i> that we spent all that time in this post filling in is only fifteenth - but looking at our improvements the imputation made, even these seemingly lowm contributiong features helped.</p>
<div class="highlight">
<pre><span></span><span class="n">ipython_html</span> <span class="o">=</span> <span class="n">eli5</span><span class="o">.</span><span class="n">show_weights</span><span class="p">(</span>
    <span class="n">permutor</span><span class="p">,</span>
    <span class="n">top</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
    <span class="n">feature_names</span><span class="o">=</span><span class="n">final_x_validate_2</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
<span class="n">table</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_html</span><span class="p">(</span><span class="n">ipython_html</span><span class="o">.</span><span class="n">data</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">table</span><span class="p">[</span><span class="s2">"Weight"</span><span class="p">]</span> <span class="o">=</span> <span class="n">table</span><span class="o">.</span><span class="n">Weight</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">expand</span><span class="o">=</span><span class="bp">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
<span class="n">plot</span> <span class="o">=</span> <span class="n">table</span><span class="o">.</span><span class="n">hvplot</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"Feature"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"Weight"</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"Permutation Importance"</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
    <span class="n">xrotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
<span class="n">source</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"permutation_importance"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">source</span><span class="p">)</span>
</pre></div>
: <object data="/posts/tutorials/missing-values/permutation_importance.html" height="800" style="width:100%" type="text/html">:
<p>Figure Missing</p>
:</object>
<p>Looking at the plot you can see that there's a huge drop from the influence of <code>OverallQuall</code> to the influence of the rest of the features.</p>
<p>Let's look at the features that didn't contribute to the model.</p>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="s2">"| Feature | Weight|"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">"|-+-|"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">table</span><span class="p">[</span><span class="n">table</span><span class="o">.</span><span class="n">Weight</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">itertuples</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"|{row.Feature}| {row.Weight}|"</span><span class="p">)</span>
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Feature</th>
<th class="org-right" scope="col">Weight</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">MiscVal</td>
<td class="org-right">0.0</td>
</tr>
<tr>
<td class="org-left">LowQualFinSF</td>
<td class="org-right">0.0</td>
</tr>
<tr>
<td class="org-left">PoolArea</td>
<td class="org-right">0.0</td>
</tr>
<tr>
<td class="org-left">EnclosedPorch</td>
<td class="org-right">-0.0003</td>
</tr>
<tr>
<td class="org-left">HalfBath</td>
<td class="org-right">-0.0004</td>
</tr>
<tr>
<td class="org-left">YrSold</td>
<td class="org-right">-0.0005</td>
</tr>
<tr>
<td class="org-left">MasVnrArea</td>
<td class="org-right">-0.0015</td>
</tr>
<tr>
<td class="org-left">MoSold</td>
<td class="org-right">-0.0058</td>
</tr>
</tbody>
</table>
<p>So, no point enclosing that porch or expanding your pool, I guess.</p>
</div>
</li>
<li><a id="org9357569"></a>The Most Important Feature<br>
<div class="outline-text-5" id="text-org9357569">
<p>This is the <code>data_description</code> entry for <code>OverallQual</code>:</p>
<p><b>OverallQual:</b> Rates the overall material and finish of the house</p>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-right">
<col class="org-left"></colgroup>
<thead>
<tr>
<th class="org-right" scope="col">Value</th>
<th class="org-left" scope="col">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">10</td>
<td class="org-left">Very Excellent</td>
</tr>
<tr>
<td class="org-right">9</td>
<td class="org-left">Excellent</td>
</tr>
<tr>
<td class="org-right">8</td>
<td class="org-left">Very Good</td>
</tr>
<tr>
<td class="org-right">7</td>
<td class="org-left">Good</td>
</tr>
<tr>
<td class="org-right">6</td>
<td class="org-left">Above Average</td>
</tr>
<tr>
<td class="org-right">5</td>
<td class="org-left">Average</td>
</tr>
<tr>
<td class="org-right">4</td>
<td class="org-left">Below Average</td>
</tr>
<tr>
<td class="org-right">3</td>
<td class="org-left">Fair</td>
</tr>
<tr>
<td class="org-right">2</td>
<td class="org-left">Poor</td>
</tr>
<tr>
<td class="org-right">1</td>
<td class="org-left">Very Poor</td>
</tr>
</tbody>
</table>
<p>This appears to be an ordinal rather than a continuous variable, interesting how much it dominates.</p>
</div>
<ul class="org-ul">
<li><a id="orgf8de560"></a>PDP Plot<br>
<div class="outline-text-6" id="text-orgf8de560">
<p>Here's the amount that the feature changes the sales price as it changes.</p>
<div class="highlight">
<pre><span></span><span class="n">FEATURE</span> <span class="o">=</span> <span class="s2">"OverallQual"</span>
<span class="n">pdp_dist</span> <span class="o">=</span> <span class="n">pdp</span><span class="o">.</span><span class="n">pdp_isolate</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                           <span class="n">dataset</span><span class="o">=</span><span class="n">final_x_validate_2</span><span class="p">,</span>
                           <span class="n">model_features</span><span class="o">=</span><span class="n">final_x_validate_2</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span>
                           <span class="n">feature</span><span class="o">=</span><span class="n">FEATURE</span><span class="p">)</span>
<span class="n">pdp</span><span class="o">.</span><span class="n">pdp_plot</span><span class="p">(</span><span class="n">pdp_dist</span><span class="p">,</span> <span class="n">FEATURE</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">f</span><span class="s2">"{FEATURE}_pdp_plot.png"</span>
<span class="n">figure</span> <span class="o">=</span> <span class="n">pyplot</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">figure</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">top</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">figure</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">OUTPUT_PATH</span><span class="o">/</span><span class="n">output</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"[[file:{output}]]"</span><span class="p">)</span>
</pre></div>
<div class="figure">
<p><img alt="OverallQual_pdp_plot.png" src="/posts/tutorials/missing-values/OverallQual_pdp_plot.png"></p>
</div>
<p>So it looks like once you hit "Above Average" it's pretty much a linear relationship between the overall quality and the sale price.</p>
</div>
</li>
<li><a id="org870fbb5"></a>SHAP Summary<br>
<div class="outline-text-6" id="text-org870fbb5">
<p>Let's take a more visual look at the importance of each feature.</p>
<div class="highlight">
<pre><span></span><span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">TreeExplainer</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">shap_values</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">final_x_validate_2</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">shap</span><span class="o">.</span><span class="n">summary_plot</span><span class="p">(</span><span class="n">shap_values</span><span class="p">,</span> <span class="n">final_x_validate_2</span><span class="p">)</span>
<span class="n">figure</span> <span class="o">=</span> <span class="n">pyplot</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">output</span> <span class="o">=</span> <span class="s2">"shap_summary.png"</span>

<span class="n">figure</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">OUTPUT_PATH</span><span class="o">/</span><span class="n">output</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"[[file:{output}]]"</span><span class="p">)</span>
</pre></div>
<div class="figure">
<p><img alt="shap_summary.png" src="/posts/tutorials/missing-values/shap_summary.png"></p>
</div>
<p>Besides reinforcing the importance of <code>OverallQual</code>, the plot shows how much spread its influence covers. The odd bunches might reflect the fact that it's a discrete, ordinal feature, not a continuous one.</p>
</div>
</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org27deac5">
<h2 id="org27deac5">End</h2>
<div class="outline-text-2" id="text-org27deac5">
<p>Make a kaggle submission.</p>
<div class="highlight">
<pre><span></span><span class="n">final_x_test</span> <span class="o">=</span> <span class="n">imputer_2</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">preds_test</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">final_x_test</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">'Id'</span><span class="p">:</span> <span class="n">x_test</span><span class="o">.</span><span class="n">index</span><span class="p">,</span>
                           <span class="s1">'SalePrice'</span><span class="p">:</span> <span class="n">preds_test</span><span class="p">})</span>
<span class="n">output</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">DATA_PATH</span><span class="o">/</span><span class="s1">'submission.csv'</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
<p>This model gives us an error of 16,656.25822, an improvement over our previous submission where we used only a smaller subset of the features.</p>
<div class="highlight">
<pre><span></span><span class="n">introduction</span> <span class="o">=</span> <span class="mf">27217.91640</span>
<span class="n">previous</span> <span class="o">=</span> <span class="mf">20928.54621</span>
<span class="n">current</span> <span class="o">=</span> <span class="mf">16656.25822</span>

<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Latest Error: {current:,}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Improvement over the introduction ({introduction:,}): {introduction - current:,}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Improvement over the previous model ({previous:,}): {previous - current:,}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Latest Error: 16,656.25822
Improvement over the introduction (27,217.9164): 10,561.658179999999
Improvement over the previous model (20,928.54621): 4,272.287990000001
</pre>
<p>So by adding in the remaining features we were able to reduce our error by quite a bit.</p>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="/posts/tutorials/introduction-intermediate-machine-learning/">Introduction to the Kaggle Intermediate Machine Learning Tutorial</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="/posts/tutorials/introduction-intermediate-machine-learning/" rel="bookmark"><time class="published dt-published" datetime="2020-02-20T20:59:21-08:00" itemprop="datePublished" title="2020-02-20 20:59">2020-02-20 20:59</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="/posts/tutorials/introduction-intermediate-machine-learning/#orga63dcf0">Beginning</a>
<ul>
<li><a href="/posts/tutorials/introduction-intermediate-machine-learning/#orgfc609b9">Imports</a>
<ul>
<li><a href="/posts/tutorials/introduction-intermediate-machine-learning/#org1cf1ecb">Python</a></li>
<li><a href="/posts/tutorials/introduction-intermediate-machine-learning/#orgbed9e59">PyPi</a></li>
<li><a href="/posts/tutorials/introduction-intermediate-machine-learning/#org0c88ab6">Others</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/introduction-intermediate-machine-learning/#org83fd5f3">Set Up</a>
<ul>
<li><a href="/posts/tutorials/introduction-intermediate-machine-learning/#org53439df">Plottting</a></li>
<li><a href="/posts/tutorials/introduction-intermediate-machine-learning/#org2e636ef">The Timer</a></li>
<li><a href="/posts/tutorials/introduction-intermediate-machine-learning/#org9c6d29c">Environment</a></li>
<li><a href="/posts/tutorials/introduction-intermediate-machine-learning/#org649bbb7">The Data</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="/posts/tutorials/introduction-intermediate-machine-learning/#orgd5afb4d">Middle</a>
<ul>
<li><a href="/posts/tutorials/introduction-intermediate-machine-learning/#org8c1472c">Preliminary 1: Specify Prediction Target</a></li>
<li><a href="/posts/tutorials/introduction-intermediate-machine-learning/#org38546e5">Preliminary 2: Create X</a></li>
<li><a href="/posts/tutorials/introduction-intermediate-machine-learning/#org31bbcd9">Preliminary 3: Evaluate Some Models</a></li>
<li><a href="/posts/tutorials/introduction-intermediate-machine-learning/#orgdd33e46">Preliminary 4: Make Some Predictions</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/introduction-intermediate-machine-learning/#org8fdd3fe">End</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orga63dcf0">
<h2 id="orga63dcf0">Beginning</h2>
<div class="outline-text-2" id="text-orga63dcf0">
<p>This is the introduction to kaggle's intermediate machine learning tutorial.</p>
</div>
<div class="outline-3" id="outline-container-orgfc609b9">
<h3 id="orgfc609b9">Imports</h3>
<div class="outline-text-3" id="text-orgfc609b9"></div>
<div class="outline-4" id="outline-container-org1cf1ecb">
<h4 id="org1cf1ecb">Python</h4>
<div class="outline-text-4" id="text-org1cf1ecb">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgbed9e59">
<h4 id="orgbed9e59">PyPi</h4>
<div class="outline-text-4" id="text-orgbed9e59">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">train_test_split</span>

<span class="kn">import</span> <span class="nn">hvplot.pandas</span>
<span class="kn">import</span> <span class="nn">pandas</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org0c88ab6">
<h4 id="org0c88ab6">Others</h4>
<div class="outline-text-4" id="text-org0c88ab6">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">EnvironmentLoader</span><span class="p">,</span> <span class="n">Timer</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org83fd5f3">
<h3 id="org83fd5f3">Set Up</h3>
<div class="outline-text-3" id="text-org83fd5f3"></div>
<div class="outline-4" id="outline-container-org53439df">
<h4 id="org53439df">Plottting</h4>
<div class="outline-text-4" id="text-org53439df">
<div class="highlight">
<pre><span></span><span class="n">SLUG</span> <span class="o">=</span> <span class="s2">"introduction-intermediate-machine-learning"</span>
<span class="n">OUTPUT_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"../../files/posts/tutorials/"</span><span class="p">)</span><span class="o">/</span><span class="n">SLUG</span>
<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">folder_path</span><span class="o">=</span><span class="n">OUTPUT_PATH</span><span class="p">)</span>
<span class="n">Plot</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org2e636ef">
<h4 id="org2e636ef">The Timer</h4>
<div class="outline-text-4" id="text-org2e636ef">
<div class="highlight">
<pre><span></span><span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org9c6d29c">
<h4 id="org9c6d29c">Environment</h4>
<div class="outline-text-4" id="text-org9c6d29c">
<div class="highlight">
<pre><span></span><span class="n">ENVIRONMENT</span> <span class="o">=</span> <span class="n">EnvironmentLoader</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org649bbb7">
<h4 id="org649bbb7">The Data</h4>
<div class="outline-text-4" id="text-org649bbb7">
<div class="highlight">
<pre><span></span><span class="n">DATA_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">ENVIRONMENT</span><span class="p">[</span><span class="s2">"HOUSE-PRICES-IOWA"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="n">training_data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="n">DATA_PATH</span><span class="o">/</span><span class="s2">"train.csv"</span><span class="p">)</span>

<span class="n">testing_data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="n">DATA_PATH</span><span class="o">/</span><span class="s2">"test.csv"</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgd5afb4d">
<h2 id="orgd5afb4d">Middle</h2>
<div class="outline-text-2" id="text-orgd5afb4d"></div>
<div class="outline-3" id="outline-container-org8c1472c">
<h3 id="org8c1472c">Preliminary 1: Specify Prediction Target</h3>
<div class="outline-text-3" id="text-org8c1472c">
<p>Select the target variable, which corresponds to the sales price. Save this to a new variable called `y`. You'll need to print a list of the columns to find the name of the column you need.</p>
<p>Our target is <i>SalePrice</i>.</p>
<div class="highlight">
<pre><span></span><span class="n">Y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">SalePrice</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org38546e5">
<h3 id="org38546e5">Preliminary 2: Create X</h3>
<div class="outline-text-3" id="text-org38546e5">
<blockquote>
<p>Now you will create a DataFrame called `X` holding the predictive features.</p>
<p>Since you want only some columns from the original data, you'll first create a list with the names of the columns you want in `X`.</p>
<p>You'll use just the following columns in the list (you can copy and paste the whole list to save some typing, though you'll still need to add quotes):</p>
<ul class="org-ul">
<li>LotArea</li>
<li>YearBuilt</li>
<li>1stFlrSF</li>
<li>2ndFlrSF</li>
<li>FullBath</li>
<li>BedroomAbvGr</li>
<li>TotRmsAbvGrd</li>
</ul>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">Training</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">features</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">"1stFlrSF"</span><span class="p">,</span>
        <span class="s2">"2ndFlrSF"</span><span class="p">,</span>
        <span class="s2">"BedroomAbvGr"</span><span class="p">,</span>
        <span class="s2">"FullBath"</span><span class="p">,</span>
        <span class="s2">"LotArea"</span><span class="p">,</span>
        <span class="s2">"TotRmsAbvGrd"</span><span class="p">,</span>
        <span class="s2">"YearBuilt"</span><span class="p">,</span>
    <span class="p">],</span>
    <span class="n">random_seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">train_size</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">training_data</span><span class="p">[</span><span class="n">Training</span><span class="o">.</span><span class="n">features</span><span class="p">]</span>
<span class="n">x_submit</span> <span class="o">=</span> <span class="n">testing_data</span><span class="p">[</span><span class="n">Training</span><span class="o">.</span><span class="n">features</span><span class="p">]</span>
</pre></div>
<p>Split up the data into training and validation sets.</p>
<div class="highlight">
<pre><span></span><span class="n">x_train</span><span class="p">,</span> <span class="n">x_validate</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_validate</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="n">Training</span><span class="o">.</span><span class="n">random_seed</span><span class="p">,</span>
    <span class="n">train_size</span><span class="o">=</span><span class="n">Training</span><span class="o">.</span><span class="n">train_size</span><span class="p">,</span>
    <span class="n">test_size</span><span class="o">=</span><span class="n">Training</span><span class="o">.</span><span class="n">test_size</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org31bbcd9">
<h3 id="org31bbcd9">Preliminary 3: Evaluate Some Models</h3>
<div class="outline-text-3" id="text-org31bbcd9">
<div class="highlight">
<pre><span></span><span class="n">hyperparameters</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
    <span class="n">model_1</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
    <span class="n">model_2</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
    <span class="n">model_3</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s1">'mae'</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
    <span class="n">model_4</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
    <span class="n">model_5</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
    <span class="p">)</span>

<span class="n">models</span> <span class="o">=</span> <span class="p">[</span><span class="n">RandomForestRegressor</span><span class="p">(</span><span class="o">**</span><span class="n">parameters</span><span class="p">)</span> <span class="k">for</span> <span class="n">parameters</span> <span class="ow">in</span> <span class="n">hyperparameters</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">score_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_t</span><span class="o">=</span><span class="n">x_train</span><span class="p">,</span> <span class="n">X_v</span><span class="o">=</span><span class="n">x_validate</span><span class="p">,</span> <span class="n">y_t</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_v</span><span class="o">=</span><span class="n">y_validate</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span><span class="p">)</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_v</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_v</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span>

<span class="n">scores</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">([(</span><span class="n">score_model</span><span class="p">(</span><span class="n">model</span><span class="p">),</span> <span class="n">model</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span> <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">model</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">models</span><span class="p">)])</span>

<span class="k">for</span> <span class="n">score</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">scores</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Model {index} MAE: {score:0.2f}"</span><span class="p">)</span>

<span class="n">best</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
<span class="k">print</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Best Model: {best}"</span><span class="p">)</span>
<span class="n">best_model</span> <span class="o">=</span> <span class="n">f</span><span class="s2">"model_{best[2]}"</span>
<span class="n">best_hyperparameters</span> <span class="o">=</span> <span class="n">hyperparameters</span><span class="p">[</span><span class="n">best_model</span><span class="p">]</span>
</pre></div>
<pre class="example">
Model 2 MAE: 23528.78
Model 4 MAE: 23706.67
Model 1 MAE: 23740.98
Model 3 MAE: 23996.68
Model 0 MAE: 24015.49

Best Model: (23528.78421232877, RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=None,
                      max_features='auto', max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_impurity_split=None,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, n_estimators=100,
                      n_jobs=None, oob_score=False, random_state=0, verbose=0,
                      warm_start=False), 2)
</pre></div>
</div>
<div class="outline-3" id="outline-container-orgdd33e46">
<h3 id="orgdd33e46">Preliminary 4: Make Some Predictions</h3>
<div class="outline-text-3" id="text-orgdd33e46">
<div class="highlight">
<pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="o">**</span><span class="n">best_hyperparameters</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>

<span class="n">test_predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_submit</span><span class="p">)</span>

<span class="n">submission</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">Id</span><span class="o">=</span><span class="n">testing_data</span><span class="o">.</span><span class="n">Id</span><span class="p">,</span>
                                   <span class="n">SalePrice</span><span class="o">=</span><span class="n">test_predictions</span><span class="p">))</span>
<span class="n">submission</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">DATA_PATH</span><span class="o">/</span><span class="s2">"submission.csv"</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
<p>This gets a score of <b>20,928.54621</b> compared to the previous error score of <b>*27,217.91640</b>, so it looks like the error is getting better.</p>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org8fdd3fe">
<h2 id="org8fdd3fe">End</h2>
<div class="outline-text-2" id="text-org8fdd3fe">
<p>Now we're back at the point we were at the end of the introduction to machine learning tutorial, except with a slightly improved model.</p>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="/posts/tutorials/machine-learning-competitions/">Machine Learning Competitions</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="/posts/tutorials/machine-learning-competitions/" rel="bookmark"><time class="published dt-published" datetime="2020-02-18T10:16:45-08:00" itemprop="datePublished" title="2020-02-18 10:16">2020-02-18 10:16</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="/posts/tutorials/machine-learning-competitions/#orgb66dfe7">Beginning</a>
<ul>
<li><a href="/posts/tutorials/machine-learning-competitions/#org1881a5e">Imports</a>
<ul>
<li><a href="/posts/tutorials/machine-learning-competitions/#org5991af7">Python</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#org7da97dc">PyPi</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#orgbe982a1">Others</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/machine-learning-competitions/#org0fa5af7">Set Up</a>
<ul>
<li><a href="/posts/tutorials/machine-learning-competitions/#org6573138">Plottting</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#org4577f55">The Timer</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#org41960c3">Environment</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#orgd0bf968">The Data</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="/posts/tutorials/machine-learning-competitions/#orge9cd335">Middle</a>
<ul>
<li><a href="/posts/tutorials/machine-learning-competitions/#org86d331a">Preliminary 1: Specify Prediction Target</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#org0de2fbb">Preliminary 2: Create X</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#orgff37c29">Preliminary 3: Specify and Fit Model</a>
<ul>
<li><a href="/posts/tutorials/machine-learning-competitions/#org6ac5035">A Linear Regression Model</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#orgccabd11">Decision Tree</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/machine-learning-competitions/#org2f5dfde">Preliminary 4: Make Some Predictions</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#orgc683f91">Preliminary 5: Calculate the Mean Absolute Error in Validation Data</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#org3b7186f">Preliminary 6: Compare Different Tree Sizes</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#org17c74cf">Preliminary 7: Use a Random Forest</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#org37a2227">Step 1: Creating a Model For the Competition</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#orgc751fe5">Step 2: Make Predictions</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#org614be8b">Step 3: Save the Submission</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#org4f8c089">Step 4: Test Your Work</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#orgab6581e">Step 5: Continuing Your Progress</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/machine-learning-competitions/#org1f0462d">End</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orgb66dfe7">
<h2 id="orgb66dfe7">Beginning</h2>
<div class="outline-text-2" id="text-orgb66dfe7">
<blockquote>
<p>In this exercise, you will create and submit predictions for a Kaggle competition. You can then improve your model (e.g. by adding features) to improve and see how you stack up to others taking this micro-course.</p>
<p>The steps in this notebook are:</p>
<ol class="org-ol">
<li>Build a Random Forest model with all of your data (<b>X</b> and <b>y</b>)</li>
<li>Read in the "test" data, which doesn't include values for the target. Predict home values in the test data with your Random Forest model.</li>
<li>Submit those predictions to the competition and see your score.</li>
<li>Optionally, come back to see if you can improve your model by adding features or changing your model. Then you can resubmit to see how that stacks up on the competition leaderboard.</li>
</ol>
</blockquote>
</div>
<div class="outline-3" id="outline-container-org1881a5e">
<h3 id="org1881a5e">Imports</h3>
<div class="outline-text-3" id="text-org1881a5e"></div>
<div class="outline-4" id="outline-container-org5991af7">
<h4 id="org5991af7">Python</h4>
<div class="outline-text-4" id="text-org5991af7">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org7da97dc">
<h4 id="org7da97dc">PyPi</h4>
<div class="outline-text-4" id="text-org7da97dc">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>

<span class="kn">import</span> <span class="nn">hvplot.pandas</span>
<span class="kn">import</span> <span class="nn">pandas</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgbe982a1">
<h4 id="orgbe982a1">Others</h4>
<div class="outline-text-4" id="text-orgbe982a1">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">EnvironmentLoader</span><span class="p">,</span> <span class="n">Timer</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org0fa5af7">
<h3 id="org0fa5af7">Set Up</h3>
<div class="outline-text-3" id="text-org0fa5af7"></div>
<div class="outline-4" id="outline-container-org6573138">
<h4 id="org6573138">Plottting</h4>
<div class="outline-text-4" id="text-org6573138">
<div class="highlight">
<pre><span></span><span class="n">SLUG</span> <span class="o">=</span> <span class="s2">"underfitting-and-overfitting-exercise"</span>
<span class="n">OUTPUT_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"../../files/posts/tutorials/"</span><span class="p">)</span><span class="o">/</span><span class="n">SLUG</span>
<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">folder_path</span><span class="o">=</span><span class="n">OUTPUT_PATH</span><span class="p">)</span>
<span class="n">Plot</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org4577f55">
<h4 id="org4577f55">The Timer</h4>
<div class="outline-text-4" id="text-org4577f55">
<div class="highlight">
<pre><span></span><span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org41960c3">
<h4 id="org41960c3">Environment</h4>
<div class="outline-text-4" id="text-org41960c3">
<div class="highlight">
<pre><span></span><span class="n">ENVIRONMENT</span> <span class="o">=</span> <span class="n">EnvironmentLoader</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgd0bf968">
<h4 id="orgd0bf968">The Data</h4>
<div class="outline-text-4" id="text-orgd0bf968">
<div class="highlight">
<pre><span></span><span class="n">DATA_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">ENVIRONMENT</span><span class="p">[</span><span class="s2">"HOUSE-PRICES-IOWA"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="n">DATA_PATH</span><span class="o">/</span><span class="s2">"train.csv"</span><span class="p">)</span>

<span class="n">test_data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="n">DATA_PATH</span><span class="o">/</span><span class="s2">"test.csv"</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orge9cd335">
<h2 id="orge9cd335">Middle</h2>
<div class="outline-text-2" id="text-orge9cd335"></div>
<div class="outline-3" id="outline-container-org86d331a">
<h3 id="org86d331a">Preliminary 1: Specify Prediction Target</h3>
<div class="outline-text-3" id="text-org86d331a">
<p>Select the target variable, which corresponds to the sales price. Save this to a new variable called `y`. You'll need to print a list of the columns to find the name of the column you need.</p>
<p>Our target is <i>SalePrice</i>.</p>
<div class="highlight">
<pre><span></span><span class="n">Y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">SalePrice</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org0de2fbb">
<h3 id="org0de2fbb">Preliminary 2: Create X</h3>
<div class="outline-text-3" id="text-org0de2fbb">
<blockquote>
<p>Now you will create a DataFrame called `X` holding the predictive features.</p>
<p>Since you want only some columns from the original data, you'll first create a list with the names of the columns you want in `X`.</p>
<p>You'll use just the following columns in the list (you can copy and paste the whole list to save some typing, though you'll still need to add quotes):</p>
<ul class="org-ul">
<li>LotArea</li>
<li>YearBuilt</li>
<li>1stFlrSF</li>
<li>2ndFlrSF</li>
<li>FullBath</li>
<li>BedroomAbvGr</li>
<li>TotRmsAbvGrd</li>
</ul>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">FEATURES</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">"LotArea"</span><span class="p">,</span>
    <span class="s2">"YearBuilt"</span><span class="p">,</span>
    <span class="s2">"1stFlrSF"</span><span class="p">,</span>
    <span class="s2">"2ndFlrSF"</span><span class="p">,</span>
    <span class="s2">"FullBath"</span><span class="p">,</span>
    <span class="s2">"BedroomAbvGr"</span><span class="p">,</span>
    <span class="s2">"TotRmsAbvGrd"</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">FEATURES</span><span class="p">]</span>
</pre></div>
<p>Split up the data into training and validation sets.</p>
<div class="highlight">
<pre><span></span><span class="n">x_train</span><span class="p">,</span> <span class="n">x_validate</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_validate</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgff37c29">
<h3 id="orgff37c29">Preliminary 3: Specify and Fit Model</h3>
<div class="outline-text-3" id="text-orgff37c29"></div>
<div class="outline-4" id="outline-container-org6ac5035">
<h4 id="org6ac5035">A Linear Regression Model</h4>
<div class="outline-text-4" id="text-org6ac5035">
<p>As a baseline, I'll fit a simple <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html">Linear Regression</a> (ordinary-least-squares) model.</p>
<div class="highlight">
<pre><span></span><span class="n">regression</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">regression</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{scores.mean():0.2f} (+/- {2 * scores.std():0.2f})"</span><span class="p">)</span>
<span class="n">regression</span> <span class="o">=</span> <span class="n">regression</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Training R^2: {regression.score(x_train, y_train): 0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Validation R^2: {regression.score(x_validate, y_validate):0.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
0.66 (+/- 0.17)
Training R^2:  0.68
Validation R^2: 0.77
</pre></div>
</div>
<div class="outline-4" id="outline-container-orgccabd11">
<h4 id="orgccabd11">Decision Tree</h4>
<div class="outline-text-4" id="text-orgccabd11">
<blockquote>
<p>Create a <code>DecisionTreeRegressor</code> and save it as <code>iowa_model</code>. Ensure you've done the relevant import from sklearn to run this command.</p>
<p>Then fit the model you just created using the data in <code>X</code> and <code>y</code> that you saved above.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">()</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{scores.mean():0.2f} (+/- {2 * scores.std():0.2f})"</span><span class="p">)</span>

<span class="n">tree</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Training R^2: {tree.score(x_train, y_train): 0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Validation R^2: {tree.score(x_validate, y_validate):0.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
0.52 (+/- 0.34)
Training R^2:  1.00
Validation R^2: 0.75
</pre>
<p>So our linear regression actually does better than the tree does. It looks like the tree might be overfitting on the training data.</p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org2f5dfde">
<h3 id="org2f5dfde">Preliminary 4: Make Some Predictions</h3>
<div class="outline-text-3" id="text-org2f5dfde">
<div class="highlight">
<pre><span></span><span class="n">tree_predict</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_validate</span><span class="p">)</span>
<span class="n">regression_predict</span> <span class="o">=</span> <span class="n">regression</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_validate</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgc683f91">
<h3 id="orgc683f91">Preliminary 5: Calculate the Mean Absolute Error in Validation Data</h3>
<div class="outline-text-3" id="text-orgc683f91">
<div class="highlight">
<pre><span></span><span class="n">tree_mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_validate</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">tree_predict</span><span class="p">)</span>
<span class="n">regression_mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_validate</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">regression_predict</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Tree MAE: {tree_mae: 0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Regression MAE: {regression_mae: 0.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Tree MAE:  28969.44
Regression MAE:  27228.88
</pre>
<p>The tree's error is a little higher than the regression line's.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org3b7186f">
<h3 id="org3b7186f">Preliminary 6: Compare Different Tree Sizes</h3>
<div class="outline-text-3" id="text-org3b7186f">
<blockquote>
<p>Write a loop that tries the following values for <b>max_leaf_nodes</b> from a set of possible values.</p>
<p>Call the <b>get_mae</b> function on each value of max_leaf_nodes. Store the output in some way that allows you to select the value of <code>max_leaf_nodes</code> that gives the most accurate model on your data.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">get_mae</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="p">,</span> <span class="n">train_X</span><span class="o">=</span><span class="n">x_train</span><span class="p">,</span> <span class="n">val_X</span><span class="o">=</span><span class="n">x_validate</span><span class="p">,</span> <span class="n">train_y</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">val_y</span><span class="o">=</span><span class="n">y_validate</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="o">=</span><span class="n">max_leaf_nodes</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>
    <span class="n">preds_val</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">val_X</span><span class="p">)</span>
    <span class="n">mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">val_y</span><span class="p">,</span> <span class="n">preds_val</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mae</span>
</pre></div>
<blockquote>
<p>Write a loop to find the ideal tree size from <code>candidate_max_leaf_nodes</code>.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">candidate_max_leaf_nodes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">250</span><span class="p">,</span> <span class="mi">500</span><span class="p">]</span>
<span class="n">outcomes</span> <span class="o">=</span> <span class="p">[(</span><span class="n">get_mae</span><span class="p">(</span><span class="n">nodes</span><span class="p">),</span> <span class="n">nodes</span><span class="p">)</span> <span class="k">for</span> <span class="n">nodes</span> <span class="ow">in</span> <span class="n">candidate_max_leaf_nodes</span><span class="p">]</span>
<span class="n">best</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">outcomes</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">best</span><span class="p">)</span>
<span class="n">best_tree_size</span> <span class="o">=</span> <span class="n">best</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
<pre class="example">
(27282.50803885739, 100)
</pre>
<div class="highlight">
<pre><span></span><span class="n">mae</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">nodes</span><span class="o">=</span><span class="n">candidate_max_leaf_nodes</span><span class="p">,</span> <span class="n">mae</span> <span class="o">=</span> <span class="p">[</span><span class="n">outcome</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">outcome</span> <span class="ow">in</span> <span class="n">outcomes</span><span class="p">]))</span>
<span class="n">plot</span> <span class="o">=</span> <span class="n">mae</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"nodes"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"mae"</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">"Node Mean Absolute Error"</span><span class="p">,</span>
                                           <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
                                           <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">)</span>
<span class="n">source</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"node_mean_absolute_error"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">source</span><span class="p">)</span>
</pre></div>
: <object data="/posts/tutorials/machine-learning-competitions/node_mean_absolute_error.html" height="800" style="width:100%" type="text/html">:
<p>Figure Missing</p>
:</object>
<p>Looking at the plot you can see that the error drops until you hit 100 nodes and then begins to rise again as it overfits the data with more nodes.</p>
<p>Let's see how much this improves our model using \(r^2\).</p>
<div class="highlight">
<pre><span></span><span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="o">=</span><span class="n">best_tree_size</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{scores.mean():0.2f} (+/- {2 * scores.std():0.2f})"</span><span class="p">)</span>

<span class="n">tree</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Training R^2: {tree.score(x_train, y_train): 0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Validation R^2: {tree.score(x_validate, y_validate):0.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
0.58 (+/- 0.32)
Training R^2:  0.93
Validation R^2: 0.76
</pre>
<p>We've improved it slightly, it's probably still overfitting the model but not as much.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org17c74cf">
<h3 id="org17c74cf">Preliminary 7: Use a Random Forest</h3>
<div class="outline-text-3" id="text-org17c74cf">
<div class="highlight">
<pre><span></span><span class="n">forest</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">forest</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{scores.mean():0.2f} (+/- {2 * scores.std():0.2f})"</span><span class="p">)</span>

<span class="n">tree</span> <span class="o">=</span> <span class="n">forest</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Training R^2: {forest.score(x_train, y_train): 0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Validation R^2: {forest.score(x_validate, y_validate):0.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
0.76 (+/- 0.11)
Training R^2:  0.97
Validation R^2: 0.85
</pre>
<p>So the defaults already beat the regression and decision tree model.</p>
<div class="highlight">
<pre><span></span><span class="n">forest_predictions</span> <span class="o">=</span> <span class="n">forest</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_validate</span><span class="p">)</span>
<span class="n">forest_mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_validate</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">forest_predictions</span><span class="p">)</span>

<span class="n">tree_mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_validate</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">tree_predict</span><span class="p">)</span>
<span class="n">regression_mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_validate</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">regression_predict</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Tree MAE: {tree_mae: 0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Regression MAE: {regression_mae: 0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Forest MAE: {forest_mae:0.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Tree MAE:  28969.44
Regression MAE:  27228.88
Forest MAE: 21857.16
</pre>
<p>So the forest also has a much better Mean Absolute Error than the other two models.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org37a2227">
<h3 id="org37a2227">Step 1: Creating a Model For the Competition</h3>
<div class="outline-text-3" id="text-org37a2227">
<blockquote>
<p>Build a Random Forest model and train it on all of <b>X</b> and <b>y</b>.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">forest</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">forest</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgc751fe5">
<h3 id="orgc751fe5">Step 2: Make Predictions</h3>
<div class="outline-text-3" id="text-orgc751fe5">
<blockquote>
<p>Read the file of "test" data. And apply your model to make predictions. Then create test_X which comes from test_data but includes only the columns you used for prediction. The list of columns is stored in a variable called features.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">x_test</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[</span><span class="n">FEATURES</span><span class="p">]</span>
</pre></div>
<blockquote>
<p>Make predictions which we will submit.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">forest</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org614be8b">
<h3 id="org614be8b">Step 3: Save the Submission</h3>
<div class="outline-text-3" id="text-org614be8b">
<div class="highlight">
<pre><span></span><span class="n">submission</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">Id</span><span class="o">=</span><span class="n">test_data</span><span class="o">.</span><span class="n">Id</span><span class="p">,</span> <span class="n">SalePrice</span><span class="o">=</span><span class="n">predictions</span><span class="p">))</span>
<span class="n">submission</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">DATA_PATH</span><span class="o">/</span><span class="s2">"submission.csv"</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org4f8c089">
<h3 id="org4f8c089">Step 4: Test Your Work</h3>
<div class="outline-text-3" id="text-org4f8c089">
<blockquote>
<p>To test your results, you'll need to join the competition (if you haven't already). So open a new window by clicking on <a href="https://www.kaggle.com/c/home-data-for-ml-course">this link</a>. Then click on the <b>Join Competition</b> button.</p>
</blockquote>
<p><a href="https://i.imgur.com/wLmFtH3.png">join competition image</a></p>
<blockquote>
<p>Next, follow the instructions below:</p>
<ol class="org-ol">
<li>Begin by clicking on the blue <b>COMMIT</b> button in the top right corner of this window. This will generate a pop-up window.</li>
<li>After your code has finished running, click on the blue <b>Open Version</b> button in the top right of the pop-up window. This brings you into view mode of the same page. You will need to scroll down to get back to these instructions.</li>
<li>Click on the <b>Output</b> tab on the left of the screen. Then, click on the <b>Submit to Competition</b> button to submit your results to the leaderboard.</li>
</ol>
<p>You have now successfully submitted to the competition.</p>
</blockquote>
</div>
</div>
<div class="outline-3" id="outline-container-orgab6581e">
<h3 id="orgab6581e">Step 5: Continuing Your Progress</h3>
<div class="outline-text-3" id="text-orgab6581e">
<blockquote>
<p>There are many ways to improve your model, and <b>experimenting is a great way to learn at this point.</b></p>
<p>The best way to improve your model is to add features. Look at the list of columns and think about what might affect home prices. Some features will cause errors because of issues like missing values or non-numeric data types.</p>
</blockquote>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org1f0462d">
<h2 id="org1f0462d">End</h2>
<div class="outline-text-2" id="text-org1f0462d">
<p>The submission is evaluated using the Root Mean Squared Error of the logarithms of the sale prices. The logarithm makes it so the errors for the cheap houses and the expensive houses are equally bad.</p>
<p>For this model you get a score of <b>*27,217.91640</b>. The current leader has a score of 0, which would seem to imply he downloaded the original set and learned the data, the second best is <i>8,830</i>.</p>
<p>The <b><a href="https://www.kaggle.com/learn/intermediate-machine-learning">Intermediate Machine Learning</a></b> micro-course will teach you how to handle these types of features. You will also learn to use <b>xgboost</b>, a technique giving even better accuracy than Random Forest.</p>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="/posts/tutorials/random-forests/">Random Forests</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="/posts/tutorials/random-forests/" rel="bookmark"><time class="published dt-published" datetime="2020-02-18T10:14:50-08:00" itemprop="datePublished" title="2020-02-18 10:14">2020-02-18 10:14</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="/posts/tutorials/random-forests/#orgc7129bf">Beginning</a>
<ul>
<li><a href="/posts/tutorials/random-forests/#orgdae8852">Imports</a>
<ul>
<li><a href="/posts/tutorials/random-forests/#org96b5f27">Python</a></li>
<li><a href="/posts/tutorials/random-forests/#org045ba1d">PyPi</a></li>
<li><a href="/posts/tutorials/random-forests/#orgcea703a">Others</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/random-forests/#orgb246679">Set Up</a>
<ul>
<li><a href="/posts/tutorials/random-forests/#orgf7b69f0">Plottting</a></li>
<li><a href="/posts/tutorials/random-forests/#orgb088c7e">The Timer</a></li>
<li><a href="/posts/tutorials/random-forests/#org2b33f23">Environment</a></li>
<li><a href="/posts/tutorials/random-forests/#org3077c5a">The Data</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="/posts/tutorials/random-forests/#org286fbbf">Middle</a>
<ul>
<li><a href="/posts/tutorials/random-forests/#org027ffb4">Preliminary 1: Specify Prediction Target</a></li>
<li><a href="/posts/tutorials/random-forests/#orgdf0071e">Preliminary 2: Create X</a></li>
<li><a href="/posts/tutorials/random-forests/#org82eec89">Preliminary 3: Specify and Fit Model</a>
<ul>
<li><a href="/posts/tutorials/random-forests/#orgb09f960">A Linear Regression Model</a></li>
<li><a href="/posts/tutorials/random-forests/#org37df55d">Decision Tree</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/random-forests/#org32caadb">Preliminary 4: Make Some Predictions</a></li>
<li><a href="/posts/tutorials/random-forests/#org16b4b7f">Preliminary 5: Calculate the Mean Absolute Error in Validation Data</a></li>
<li><a href="/posts/tutorials/random-forests/#orgf85bb99">Preliminary 6: Compare Different Tree Sizes</a></li>
<li><a href="/posts/tutorials/random-forests/#org8a92187">Step 1: Use a Random Forest</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/random-forests/#orgead4fa9">End</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orgc7129bf">
<h2 id="orgc7129bf">Beginning</h2>
<div class="outline-text-2" id="text-orgc7129bf">
<p>This is the fourth part of kaggle's <a href="https://www.kaggle.com/learn/intro-to-machine-learning">Introduction to Machine Learning</a> tutorial - Overfitting and Underfitting.</p>
</div>
<div class="outline-3" id="outline-container-orgdae8852">
<h3 id="orgdae8852">Imports</h3>
<div class="outline-text-3" id="text-orgdae8852"></div>
<div class="outline-4" id="outline-container-org96b5f27">
<h4 id="org96b5f27">Python</h4>
<div class="outline-text-4" id="text-org96b5f27">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org045ba1d">
<h4 id="org045ba1d">PyPi</h4>
<div class="outline-text-4" id="text-org045ba1d">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>

<span class="kn">import</span> <span class="nn">hvplot.pandas</span>
<span class="kn">import</span> <span class="nn">pandas</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgcea703a">
<h4 id="orgcea703a">Others</h4>
<div class="outline-text-4" id="text-orgcea703a">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">EnvironmentLoader</span><span class="p">,</span> <span class="n">Timer</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orgb246679">
<h3 id="orgb246679">Set Up</h3>
<div class="outline-text-3" id="text-orgb246679"></div>
<div class="outline-4" id="outline-container-orgf7b69f0">
<h4 id="orgf7b69f0">Plottting</h4>
<div class="outline-text-4" id="text-orgf7b69f0">
<div class="highlight">
<pre><span></span><span class="n">SLUG</span> <span class="o">=</span> <span class="s2">"underfitting-and-overfitting-exercise"</span>
<span class="n">OUTPUT_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"../../files/posts/tutorials/"</span><span class="p">)</span><span class="o">/</span><span class="n">SLUG</span>
<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">folder_path</span><span class="o">=</span><span class="n">OUTPUT_PATH</span><span class="p">)</span>
<span class="n">Plot</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgb088c7e">
<h4 id="orgb088c7e">The Timer</h4>
<div class="outline-text-4" id="text-orgb088c7e">
<div class="highlight">
<pre><span></span><span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org2b33f23">
<h4 id="org2b33f23">Environment</h4>
<div class="outline-text-4" id="text-org2b33f23">
<div class="highlight">
<pre><span></span><span class="n">ENVIRONMENT</span> <span class="o">=</span> <span class="n">EnvironmentLoader</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org3077c5a">
<h4 id="org3077c5a">The Data</h4>
<div class="outline-text-4" id="text-org3077c5a">
<div class="highlight">
<pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="n">Path</span><span class="p">(</span><span class="n">ENVIRONMENT</span><span class="p">[</span><span class="s2">"HOUSE-PRICES-IOWA"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span><span class="o">/</span><span class="s2">"train.csv"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org286fbbf">
<h2 id="org286fbbf">Middle</h2>
<div class="outline-text-2" id="text-org286fbbf"></div>
<div class="outline-3" id="outline-container-org027ffb4">
<h3 id="org027ffb4">Preliminary 1: Specify Prediction Target</h3>
<div class="outline-text-3" id="text-org027ffb4">
<p>Select the target variable, which corresponds to the sales price. Save this to a new variable called `y`. You'll need to print a list of the columns to find the name of the column you need.</p>
<p>Our target is <i>SalePrice</i>.</p>
<div class="highlight">
<pre><span></span><span class="n">Y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">SalePrice</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgdf0071e">
<h3 id="orgdf0071e">Preliminary 2: Create X</h3>
<div class="outline-text-3" id="text-orgdf0071e">
<blockquote>
<p>Now you will create a DataFrame called `X` holding the predictive features.</p>
<p>Since you want only some columns from the original data, you'll first create a list with the names of the columns you want in `X`.</p>
<p>You'll use just the following columns in the list (you can copy and paste the whole list to save some typing, though you'll still need to add quotes):</p>
<ul class="org-ul">
<li>LotArea</li>
<li>YearBuilt</li>
<li>1stFlrSF</li>
<li>2ndFlrSF</li>
<li>FullBath</li>
<li>BedroomAbvGr</li>
<li>TotRmsAbvGrd</li>
</ul>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">FEATURES</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">"LotArea"</span><span class="p">,</span>
    <span class="s2">"YearBuilt"</span><span class="p">,</span>
    <span class="s2">"1stFlrSF"</span><span class="p">,</span>
    <span class="s2">"2ndFlrSF"</span><span class="p">,</span>
    <span class="s2">"FullBath"</span><span class="p">,</span>
    <span class="s2">"BedroomAbvGr"</span><span class="p">,</span>
    <span class="s2">"TotRmsAbvGrd"</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">FEATURES</span><span class="p">]</span>
</pre></div>
<p>Split up the data into training and validation sets.</p>
<div class="highlight">
<pre><span></span><span class="n">x_train</span><span class="p">,</span> <span class="n">x_validate</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_validate</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org82eec89">
<h3 id="org82eec89">Preliminary 3: Specify and Fit Model</h3>
<div class="outline-text-3" id="text-org82eec89"></div>
<div class="outline-4" id="outline-container-orgb09f960">
<h4 id="orgb09f960">A Linear Regression Model</h4>
<div class="outline-text-4" id="text-orgb09f960">
<p>As a baseline, I'll fit a simple <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html">Linear Regression</a> (ordinary-least-squares) model.</p>
<div class="highlight">
<pre><span></span><span class="n">regression</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">regression</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{scores.mean():0.2f} (+/- {2 * scores.std():0.2f})"</span><span class="p">)</span>
<span class="n">regression</span> <span class="o">=</span> <span class="n">regression</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Training R^2: {regression.score(x_train, y_train): 0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Validation R^2: {regression.score(x_validate, y_validate):0.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
0.66 (+/- 0.17)
Training R^2:  0.68
Validation R^2: 0.77
</pre></div>
</div>
<div class="outline-4" id="outline-container-org37df55d">
<h4 id="org37df55d">Decision Tree</h4>
<div class="outline-text-4" id="text-org37df55d">
<blockquote>
<p>Create a <code>DecisionTreeRegressor</code> and save it as <code>iowa_model</code>. Ensure you've done the relevant import from sklearn to run this command.</p>
<p>Then fit the model you just created using the data in <code>X</code> and <code>y</code> that you saved above.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">()</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{scores.mean():0.2f} (+/- {2 * scores.std():0.2f})"</span><span class="p">)</span>

<span class="n">tree</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Training R^2: {tree.score(x_train, y_train): 0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Validation R^2: {tree.score(x_validate, y_validate):0.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
0.54 (+/- 0.33)
Training R^2:  1.00
Validation R^2: 0.72
</pre>
<p>So our linear regression actually does better than the tree does. It looks like the tree might be overfitting on the training data.</p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org32caadb">
<h3 id="org32caadb">Preliminary 4: Make Some Predictions</h3>
<div class="outline-text-3" id="text-org32caadb">
<div class="highlight">
<pre><span></span><span class="n">tree_predict</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_validate</span><span class="p">)</span>
<span class="n">regression_predict</span> <span class="o">=</span> <span class="n">regression</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_validate</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org16b4b7f">
<h3 id="org16b4b7f">Preliminary 5: Calculate the Mean Absolute Error in Validation Data</h3>
<div class="outline-text-3" id="text-org16b4b7f">
<div class="highlight">
<pre><span></span><span class="n">tree_mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_validate</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">tree_predict</span><span class="p">)</span>
<span class="n">regression_mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_validate</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">regression_predict</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Tree MAE: {tree_mae: 0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Regression MAE: {regression_mae: 0.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Tree MAE:  30219.18
Regression MAE:  27228.88
</pre>
<p>The tree's error is a little higher than the regression line's.</p>
</div>
</div>
<div class="outline-3" id="outline-container-orgf85bb99">
<h3 id="orgf85bb99">Preliminary 6: Compare Different Tree Sizes</h3>
<div class="outline-text-3" id="text-orgf85bb99">
<blockquote>
<p>Write a loop that tries the following values for <b>max_leaf_nodes</b> from a set of possible values.</p>
<p>Call the <b>get_mae</b> function on each value of max_leaf_nodes. Store the output in some way that allows you to select the value of <code>max_leaf_nodes</code> that gives the most accurate model on your data.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">get_mae</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="p">,</span> <span class="n">train_X</span><span class="o">=</span><span class="n">x_train</span><span class="p">,</span> <span class="n">val_X</span><span class="o">=</span><span class="n">x_validate</span><span class="p">,</span> <span class="n">train_y</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">val_y</span><span class="o">=</span><span class="n">y_validate</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="o">=</span><span class="n">max_leaf_nodes</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>
    <span class="n">preds_val</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">val_X</span><span class="p">)</span>
    <span class="n">mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">val_y</span><span class="p">,</span> <span class="n">preds_val</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mae</span>
</pre></div>
<blockquote>
<p>Write a loop to find the ideal tree size from <code>candidate_max_leaf_nodes</code>.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">candidate_max_leaf_nodes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">250</span><span class="p">,</span> <span class="mi">500</span><span class="p">]</span>
<span class="n">outcomes</span> <span class="o">=</span> <span class="p">[(</span><span class="n">get_mae</span><span class="p">(</span><span class="n">nodes</span><span class="p">),</span> <span class="n">nodes</span><span class="p">)</span> <span class="k">for</span> <span class="n">nodes</span> <span class="ow">in</span> <span class="n">candidate_max_leaf_nodes</span><span class="p">]</span>
<span class="n">best</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">outcomes</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">best</span><span class="p">)</span>
<span class="n">best_tree_size</span> <span class="o">=</span> <span class="n">best</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
<pre class="example">
(27282.50803885739, 100)
</pre>
<div class="highlight">
<pre><span></span><span class="n">mae</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">nodes</span><span class="o">=</span><span class="n">candidate_max_leaf_nodes</span><span class="p">,</span> <span class="n">mae</span> <span class="o">=</span> <span class="p">[</span><span class="n">outcome</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">outcome</span> <span class="ow">in</span> <span class="n">outcomes</span><span class="p">]))</span>
<span class="n">plot</span> <span class="o">=</span> <span class="n">mae</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"nodes"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"mae"</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">"Node Mean Absolute Error"</span><span class="p">,</span>
                                           <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
                                           <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">)</span>
<span class="n">source</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"node_mean_absolute_error"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">source</span><span class="p">)</span>
</pre></div>
: <object data="/posts/tutorials/random-forests/node_mean_absolute_error.html" height="800" style="width:100%" type="text/html">:
<p>Figure Missing</p>
:</object>
<p>Looking at the plot you can see that the error drops until you hit 100 nodes and then begins to rise again as it overfits the data with more nodes.</p>
<p>Let's see how much this improves our model using \(r^2\).</p>
<div class="highlight">
<pre><span></span><span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="o">=</span><span class="n">best_tree_size</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{scores.mean():0.2f} (+/- {2 * scores.std():0.2f})"</span><span class="p">)</span>

<span class="n">tree</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Training R^2: {tree.score(x_train, y_train): 0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Validation R^2: {tree.score(x_validate, y_validate):0.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
0.58 (+/- 0.31)
Training R^2:  0.93
Validation R^2: 0.77
</pre>
<p>We've improved it slightly, it's probably still overfitting the model but not as much.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org8a92187">
<h3 id="org8a92187">Step 1: Use a Random Forest</h3>
<div class="outline-text-3" id="text-org8a92187">
<div class="highlight">
<pre><span></span><span class="n">forest</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">forest</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{scores.mean():0.2f} (+/- {2 * scores.std():0.2f})"</span><span class="p">)</span>

<span class="n">tree</span> <span class="o">=</span> <span class="n">forest</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Training R^2: {forest.score(x_train, y_train): 0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Validation R^2: {forest.score(x_validate, y_validate):0.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
0.76 (+/- 0.11)
Training R^2:  0.97
Validation R^2: 0.85
</pre>
<p>So the defaults already beat the regression and decision tree model.</p>
<div class="highlight">
<pre><span></span><span class="n">forest_predictions</span> <span class="o">=</span> <span class="n">forest</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_validate</span><span class="p">)</span>
<span class="n">forest_mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_validate</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">forest_predictions</span><span class="p">)</span>

<span class="n">tree_mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_validate</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">tree_predict</span><span class="p">)</span>
<span class="n">regression_mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_validate</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">regression_predict</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Tree MAE: {tree_mae: 0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Regression MAE: {regression_mae: 0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Forest MAE: {forest_mae:0.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Tree MAE:  30219.18
Regression MAE:  27228.88
Forest MAE: 21857.16
</pre>
<p>So the forest also has a much better Mean Absolute Error than the other two models.</p>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgead4fa9">
<h2 id="orgead4fa9">End</h2>
<div class="outline-text-2" id="text-orgead4fa9">
<p>This is the end of the tutorial as far as how to build models. Next is a bit on entering a kaggle competition.</p>
</div>
</div>
</div>
</article>
</div>
<ul class="pager postindexpager clearfix">
<li class="previous"><a href="/" rel="prev">Newer posts</a></li>
<li class="next"><a href="/index-6.html" rel="next">Older posts</a></li>
</ul>
<!--End of body content-->
<footer id="footer">Contents Â© 2020 <a href="mailto:necromuralist@protonmail.com">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a></footer>
</div>
</div>
<script src="/assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
</script> 
</body>
</html>
