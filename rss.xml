<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Visions, Voices, Data</title><link>https://necromuralist.github.io/Visions-Voices-Data/</link><description>Adumbrations of data.</description><atom:link href="https://necromuralist.github.io/Visions-Voices-Data/rss.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents Â© 2019 &lt;a href="mailto:necromuralist@protonmail.com"&gt;Cloistered Monkey&lt;/a&gt; </copyright><lastBuildDate>Mon, 15 Apr 2019 17:37:52 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Looking at random graphs</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/networks/looking-at-random-graphs/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/looking-at-random-graphs/#org8045147"&gt;Imports&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/looking-at-random-graphs/#orgd1b1aff"&gt;Part 1 - Random Graph Identification&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/looking-at-random-graphs/#org330469b"&gt;Load the data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/looking-at-random-graphs/#org4f6ee4a"&gt;Graph Identification&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/looking-at-random-graphs/#org2e0f798"&gt;Part 2 - Company Emails&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/looking-at-random-graphs/#orga3e3fdb"&gt;Part 2A - Salary Prediction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/looking-at-random-graphs/#orgbf39f76"&gt;Part 2B - New Connections Prediction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/looking-at-random-graphs/#org4d16011"&gt;Separate the Target and Training Sets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/looking-at-random-graphs/#org5f7a101"&gt;Scaling the Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/looking-at-random-graphs/#org39b6571"&gt;Feature Selection&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org8045147" class="outline-2"&gt;
&lt;h2 id="org8045147"&gt;Imports&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org8045147"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# python standard library
import os
import pickle

# from pypi
import networkx
import numpy
import pandas

from sklearn.linear_model import LogisticRegressionCV
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import (
    ExtraTreesClassifier,
    RandomForestClassifier,
    )
from sklearn.feature_selection import (
    RFECV,
    SelectFromModel,
)
from sklearn.model_selection import (
    GridSearchCV,
    StratifiedKFold,
    train_test_split,
    )
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;% matplotlib inline
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgd1b1aff" class="outline-2"&gt;
&lt;h2 id="orgd1b1aff"&gt;Part 1 - Random Graph Identification&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgd1b1aff"&gt;
&lt;p&gt;
For the first part of this assignment you will analyze randomly generated graphs and determine which algorithm created them.
&lt;/p&gt;
&lt;/div&gt;

&lt;div id="outline-container-org330469b" class="outline-3"&gt;
&lt;h3 id="org330469b"&gt;Load the data&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org330469b"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;part_one_graphs = pickle.load(open('A4_graphs','rb'))
print(len(part_one_graphs))
print(type(part_one_graphs[0]))
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
&lt;code&gt;part_one_graphs&lt;/code&gt; is a list containing 5 networkx graphs. Each of these graphs were generated by one of three possible algorithms:
&lt;/p&gt;

&lt;ul class="org-ul"&gt;
&lt;li&gt;Preferential Attachment (`'PA'`)&lt;/li&gt;
&lt;li&gt;Small World with low probability of rewiring (`'SW&lt;sub&gt;L&lt;/sub&gt;'`)&lt;/li&gt;
&lt;li&gt;Small World with high probability of rewiring (`'SW&lt;sub&gt;H&lt;/sub&gt;'`)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;
Analyze each of the 5 graphs and determine which of the three algorithms generated the graph.
&lt;/p&gt;

&lt;p&gt;
&lt;b&gt;The `graph&lt;sub&gt;identification&lt;/sub&gt;` function should return a list of length 5 where each element in the list is either `'PA'`, `'SW&lt;sub&gt;L&lt;/sub&gt;'`, or `'SW&lt;sub&gt;H&lt;/sub&gt;'`.&lt;/b&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org4f6ee4a" class="outline-3"&gt;
&lt;h3 id="org4f6ee4a"&gt;Graph Identification&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org4f6ee4a"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def graph_identification():
    """Identifies the type of graph each of the graphs is

    Returns:
     list: string identifiers for the type of graph
    """
    graph_types = []
    for graph in part_one_graphs:
	path = networkx.average_shortest_path_length(graph)
	coefficient = networkx.average_clustering(graph)
	if path &amp;gt; 6:
	    if coefficient &amp;lt; 0.5:
		graph_types.append("SW_L")
	    else:
		raise Exception("unexpected type")
	else:
	    if coefficient &amp;lt; 0.5:
		graph_types.append("PA")
	    else:
		graph_types.append("SW_H")
    return graph_types
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
This was marked wrong by the grader.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org2e0f798" class="outline-2"&gt;
&lt;h2 id="org2e0f798"&gt;Part 2 - Company Emails&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org2e0f798"&gt;
&lt;p&gt;
For the second part of this assignment you will be working with a company's email network where each node corresponds to a person at the company, and each edge indicates that at least one email has been sent between two people.
&lt;/p&gt;

&lt;p&gt;
The network also contains the node attributes `Department` and `ManagementSalary`.
&lt;/p&gt;

&lt;p&gt;
`Department` indicates the department in the company which the person belongs to, and `ManagementSalary` indicates whether that person is receiving a managment position salary.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;email = networkx.read_gpickle('email_prediction.txt')
print(networkx.info(email))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orga3e3fdb" class="outline-3"&gt;
&lt;h3 id="orga3e3fdb"&gt;Part 2A - Salary Prediction&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orga3e3fdb"&gt;
&lt;p&gt;
Using network `email`, identify the people in the network with missing values for the node attribute `ManagementSalary` and predict whether or not these individuals are receiving a managment position salary.
&lt;/p&gt;

&lt;p&gt;
To accomplish this, you will need to create a matrix of node features using networkx, train a sklearn classifier on nodes that have `ManagementSalary` data, and predict a probability of the node receiving a managment salary for nodes where `ManagementSalary` is missing.
&lt;/p&gt;

&lt;p&gt;
Your predictions will need to be given as the probability that the corresponding employee is receiving a managment position salary.
&lt;/p&gt;

&lt;p&gt;
The evaluation metric for this assignment is the Area Under the ROC Curve (AUC).
&lt;/p&gt;

&lt;p&gt;
Your grade will be based on the AUC score computed for your classifier. A model which with an AUC of 0.75 or higher will receive full points.
&lt;/p&gt;

&lt;p&gt;
Using your trained classifier, return a series of length 252 with the data being the probability of receiving managment salary, and the index being the node id.
&lt;/p&gt;

&lt;pre class="example"&gt;
1       1.0
2       0.0
5       0.8
8       1.0
    ...
996     0.7
1000    0.5
1001    0.0
Length: 252, dtype: float64
&lt;/pre&gt;
&lt;/div&gt;

&lt;div id="outline-container-org5cedf61" class="outline-4"&gt;
&lt;h4 id="org5cedf61"&gt;The Data Frame&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org5cedf61"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;if not os.path.isfile("email_data.h5"):
    data = pandas.DataFrame(index=email.nodes())
    data["department"] = pandas.Series(networkx.get_node_attributes(email, "Department"))
    data["management"] = pandas.Series(networkx.get_node_attributes(email, "ManagementSalary"))
    data["clustering"] = pandas.Series(networkx.clustering(email))
    data["degree"] = pandas.Series(email.degree())
    data["degree_centrality"] = pandas.Series(networkx.degree_centrality(email))
    data["closeness_centrality"] = pandas.Series(networkx.closeness_centrality(email))
    data["betweenness_centrality"] = pandas.Series(networkx.betweenness_centrality(email))
    data["pagerank"] = pandas.Series(networkx.pagerank(email))
    _, authority = networkx.hits(email)
    data["authority"] = pandas.Series(authority)
    data.to_hdf("email_data.h5","df" )
else:
    data = pandas.read_hdf('email_data.h5', "df")
print(data.head())    
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(data.management.unique())
print(data.department.unique())
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org6c03930" class="outline-4"&gt;
&lt;h4 id="org6c03930"&gt;Department Dummy Variables&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org6c03930"&gt;
&lt;p&gt;
Even though I don't think it's going to prove useful, the &lt;code&gt;department&lt;/code&gt; feature is actually categorical, despite the use of integers so we'll have to use One-Hot-Encoding to add dummy variables for it.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;dummies_data = pandas.get_dummies(data, columns=["department"])
print(dummies_data.head(1))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgb26c22f" class="outline-4"&gt;
&lt;h4 id="orgb26c22f"&gt;Separating the Training and Prediction Sets&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgb26c22f"&gt;
&lt;p&gt;
We're going to use the model to predict what the missing &lt;code&gt;management&lt;/code&gt; values are so I'm going to separate the missing and non-missing sets. 
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;training_data = dummies_data[pandas.notnull(dummies_data.management)]
prediction_data = dummies_data[pandas.isnull(dummies_data.management)]
print(training_data.shape)
print(prediction_data.shape)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
The problem description tells us that the answer should have 252 entries so this is a safe assertion.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;assert len(prediction_data) == 252
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org7ce3762" class="outline-4"&gt;
&lt;h4 id="org7ce3762"&gt;Training and Target Data&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org7ce3762"&gt;
&lt;p&gt;
To train the model we'll need to separate out the &lt;code&gt;management&lt;/code&gt; column (and remove it entirely from the &lt;code&gt;prediction&lt;/code&gt; set).
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;non_management = [column for column in training_data.columns if column != "management"]
y_train = training_data.management
x_train = training_data[non_management]
x_predict = prediction_data[non_management]
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org6efec13" class="outline-4"&gt;
&lt;h4 id="org6efec13"&gt;Scaling&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org6efec13"&gt;
&lt;p&gt;
I don't think the Random Forest model that I'm going to use needs it, but I'm going to standardize the data.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_predict = pandas.DataFrame(scaler.transform(x_predict), index=x_predict.index)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org3a5504b" class="outline-4"&gt;
&lt;h4 id="org3a5504b"&gt;Feature Selection&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org3a5504b"&gt;
&lt;p&gt;
Since we now have so many features, I'm going to do some feature selection.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(x_train.shape)
print(x_predict.shape)
trees = ExtraTreesClassifier(n_estimators=10)
eliminator = RFECV(estimator=trees, cv=StratifiedKFold(10), scoring="roc_auc")
eliminator.fit(x_train, y_train)
x_train_reduced = eliminator.transform(x_train)
x_predict_reduced = pandas.DataFrame(eliminator.transform(x_predict), index=x_predict.index)
print(x_train_reduced.shape)
print(x_predict_reduced.shape)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
When I used the train-test-split training model it left 17 columns. I wonder if using the whole training set messes it up.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org797d51b" class="outline-4"&gt;
&lt;h4 id="org797d51b"&gt;Logistic Regression&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org797d51b"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;model = LogisticRegressionCV(penalty="l1", scoring="roc_auc",
			     solver="liblinear", cv=StratifiedKFold(10))
model.fit(x_train_reduced, y_train)
print(model.scores_[1.0].mean())
print(model.scores_[1.0].std())
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
It seems to be doing much worse than when I used the train-test split.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgcc024ef" class="outline-4"&gt;
&lt;h4 id="orgcc024ef"&gt;Random Forests&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgcc024ef"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;parameter_grid = dict(n_estimators=range(10, 100, 10))
search = GridSearchCV(RandomForestClassifier(), parameter_grid,
		      cv=StratifiedKFold(10), scoring="roc_auc")
search.fit(x_train_reduced, y_train)
print(search.best_score_)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class RandomForest(object):
    """builds the random forest

    Args:
     x_train(array): data to train on
     y_train(array): targets for training
     start (int): start value for number of estimators
     stop (int): upper value for range of estimators
     step (int): increment for range of estimators
     folds (int): K-folds for cross-validation    
    """
    def __init__(self, x_train, y_train,
		 start=10, stop=100, step=10, folds=10):
	self.x_train = x_train
	self.y_train = y_train
	self.start = start
	self.stop = stop
	self.step = step
	self.folds = folds
	self._parameters = None
	self._search = None
	self._model = None
	return

    @property
    def parameters(self):
	"""parameters for the grid-search"""
	if self._parameters is None:
	    self._parameters = dict(n_estimators=range(self.start,
						       self.stop,
						       self.step))
	return self._parameters

    @property
    def search(self):
	"""fitted grid search to find hyper-parameters"""
	if self._search is None:
	    self._search = GridSearchCV(RandomForestClassifier(),
					self.parameters,
					cv=StratifiedKFold(self.folds),
					scoring="roc_auc")
	    self._search.fit(self.x_train, self.y_train)
	return self._search

    @property
    def model(self):
	"""best model found by the grid search"""
	if self._model is None:
	    self._model = self.search.best_estimator_
	return self._model
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org274ae21" class="outline-4"&gt;
&lt;h4 id="org274ae21"&gt;Data Loader&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org274ae21"&gt;
&lt;p&gt;
Since having all these org-babel things around makes things kind of hard I'm going to make a class to bundle everything together.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class DataLoader(object):
    """loads and transforms the data
    Args:
     estimators (int): number of trees to use for feature elimination
    """
    def __init__(self, estimators=10):
	self.estimators = estimators
	self._data = None
	self._dummies_data = None
	self._training_data = None
	self._prediction_data = None
	self._non_management = None
	self._y_train = None
	self._x_train = None
	self._x_predict = None
	self._scaler = None
	self._x_train_scaled = None
	self._x_predict_scaled = None
	self._eliminator = None
	self._x_train_reduced = None
	self._x_predict_reduced = None
	return

    @property
    def data(self):
	"""The initial data"""
	if self._data is None:
	    if not os.path.isfile("email_data.h5"):
		data = pandas.DataFrame(index=email.nodes())
		data["department"] = pandas.Series(networkx.get_node_attributes(email, "Department"))
		data["management"] = pandas.Series(networkx.get_node_attributes(email, "ManagementSalary"))
		data["clustering"] = pandas.Series(networkx.clustering(email))
		data["degree"] = pandas.Series(email.degree())
		data["degree_centrality"] = pandas.Series(networkx.degree_centrality(email))
		data["closeness_centrality"] = pandas.Series(networkx.closeness_centrality(email))
		data["betweenness_centrality"] = pandas.Series(networkx.betweenness_centrality(email))
		data["pagerank"] = pandas.Series(networkx.pagerank(email))
		_, authority = networkx.hits(email)
		data["authority"] = pandas.Series(authority)
		data.to_hdf("email_data.h5","df" )
		self._data = data
	    else:
		self._data = pandas.read_hdf('email_data.h5', "df")
	return self._data

    @property
    def dummies_data(self):
	"""one-hot-encoded data"""
	if self._dummies_data is None:
	    self._dummies_data = pandas.get_dummies(self.data, columns=["department"])
	return self._dummies_data

    @property
    def training_data(self):
	"""data with management information"""
	if self._training_data is None:
	    self._training_data = self.dummies_data[pandas.notnull(
		self.dummies_data.management)]
	return self._training_data

    @property
    def prediction_data(self):
	"""data missing management information"""
	if self._prediction_data is None:
	    self._prediction_data = self.dummies_data[pandas.isnull(
		self.dummies_data.management)]
	    assert len(self._prediction_data) == 252
	return self._prediction_data

    @property
    def non_management(self):
	"""list of columns minus management"""
	if self._non_management is None:
	    self._non_management = [
		column for column in self.training_data.columns
		if column != "management"]
	return self._non_management

    @property
    def y_train(self):
	"""target-data for training"""
	if self._y_train is None:
	    self._y_train = self.training_data.management
	return self._y_train

    @property
    def x_train(self):
	"""data for training"""
	if self._x_train is None:
	    self._x_train = self.training_data[self.non_management]
	return self._x_train

    @property
    def x_predict(self):
	"""set to make predictions"""
	if self._x_predict is None:
	    self._x_predict = self.prediction_data[self.non_management]
	return self._x_predict

    @property
    def scaler(self):
	"""standard scaler"""
	if self._scaler is None:
	    self._scaler = StandardScaler()
	return self._scaler

    @property
    def x_train_scaled(self):
	"""training data scaled to 1 std, 0 mean"""
	if self._x_train_scaled is None:
	    self._x_train_scaled = self.scaler.fit_transform(self.x_train)
	return self._x_train_scaled

    @property
    def x_predict_scaled(self):
	"""prediction data with mean 0, std 1

	The answer requires the index so this is a dataframe
	instead of an array

	Returns:
	 pandas.DataFrame: scaled data with index preserved
	"""
	if self._x_predict_scaled is None:
	    self._x_predict_scaled = pandas.DataFrame(
		self.scaler.transform(self.x_predict),
		index=self.x_predict.index)
	return self._x_predict_scaled

    @property
    def eliminator(self):
	"""recursive feature eliminator"""
	if self._eliminator is None:
	    trees = ExtraTreesClassifier(n_estimators=10)
	    self._eliminator = RFECV(estimator=trees, cv=StratifiedKFold(10), 
				     scoring="roc_auc")
	    self._eliminator.fit(self.x_train_scaled, self.y_train)
	return self._eliminator

    @property
    def x_train_reduced(self):
	"""training data with features eliminated"""
	if self._x_train_reduced is None:
	    self._x_train_reduced = self.eliminator.transform(
		self.x_train_scaled)
	return self._x_train_reduced

    @property
    def x_predict_reduced(self):
	"""prediction data with features eliminated"""
	if self._x_predict_reduced is None:
	    self._x_predict_reduced = pandas.DataFrame(
		self.eliminator.transform(self.x_predict_scaled),
		index=self.x_predict_scaled.index)
	return self._x_predict_reduced
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org106f04c" class="outline-4"&gt;
&lt;h4 id="org106f04c"&gt;Submission&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org106f04c"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def salary_predictions():
    """Prediction that employee is management

    Calculates the probability that an employee is management

    Returns:
     pandas.Series: Node ID, probability of node
    """
    data = DataLoader()
    forest = RandomForest(data.x_train_reduced, data.y_train)
    # probabilites is an array with rows of 
    # [&amp;lt;probability not management&amp;gt;, &amp;lt;probability management&amp;gt;]
    # see forest.model.classes_ to see what each entry represents
    probabilities = forest.model.predict_proba(data.x_predict_reduced)
    return pandas.Series(probabilities[:, 1], index=data.x_predict_reduced.index)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;output = salary_predictions()
print(output.head())
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;assert all(output.index == DataLoader().prediction_data.index)
assert len(output) == 252
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgbf39f76" class="outline-3"&gt;
&lt;h3 id="orgbf39f76"&gt;Part 2B - New Connections Prediction&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgbf39f76"&gt;
&lt;p&gt;
For the last part of this assignment, you will predict future connections between employees of the network. The future connections information has been loaded into the variable `future&lt;sub&gt;connections&lt;/sub&gt;`. The index is a tuple indicating a pair of nodes that currently do not have a connection, and the `Future Connection` column indicates if an edge between those two nodes will exist in the future, where a value of 1.0 indicates a future connection.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;future_connections = pandas.read_csv('Future_Connections.csv', index_col=0, converters={0: eval})
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(future_connections.head(10))
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(future_connections['Future Connection'].value_counts())
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;
Using network `G` and `future&lt;sub&gt;connections&lt;/sub&gt;`, identify the edges in `future&lt;sub&gt;connections&lt;/sub&gt;` with missing values and predict whether or not these edges will have a future connection.
&lt;/p&gt;

&lt;p&gt;
To accomplish this, you will need to create a matrix of features for the edges found in `future&lt;sub&gt;connections&lt;/sub&gt;` using networkx, train a sklearn classifier on those edges in `future&lt;sub&gt;connections&lt;/sub&gt;` that have `Future Connection` data, and predict a probability of the edge being a future connection for those edges in `future&lt;sub&gt;connections&lt;/sub&gt;` where `Future Connection` is missing.
&lt;/p&gt;

&lt;p&gt;
Your predictions will need to be given as the probability of the corresponding edge being a future connection.
&lt;/p&gt;

&lt;p&gt;
The evaluation metric for this assignment is the Area Under the ROC Curve (AUC).
&lt;/p&gt;

&lt;p&gt;
Your grade will be based on the AUC score computed for your classifier. A model which with an AUC of 0.75 or higher will receive full points.
&lt;/p&gt;

&lt;p&gt;
Using your trained classifier, return a series of length 122112 with the data being the probability of the edge being a future connection, and the index being the edge as represented by a tuple of nodes.
&lt;/p&gt;

&lt;pre class="example"&gt;
(107, 348)    0.35
(542, 751)    0.40
(20, 426)     0.55
(50, 989)     0.35
          ...
(939, 940)    0.15
(555, 905)    0.35
(75, 101)     0.65
Length: 122112, dtype: float64
&lt;/pre&gt;
&lt;/div&gt;
&lt;div id="outline-container-org6f9c2cf" class="outline-4"&gt;
&lt;h4 id="org6f9c2cf"&gt;Add Network Features&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org6f9c2cf"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class Futures(object):
    target = "Future Connection"
    data_file = "Future_Connections.csv"
    graph_file = "email_prediction.txt"
    networkx_data_index = 2
    folds = 10
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class DataNames(object):
    resource_allocation = 'resource_allocation'
    jaccard = 'jaccard_coefficient'
    adamic = "adamic_adar"
    preferential = "preferential_attachment"
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def add_networkx_data(adder, name, graph=email, frame=future_connections):
    """Adds networkx data to the frame

    The networkx link-prediction functions return generators of triples:
     (first-node, second-node, value)

    This will use the index of the frame that's passed in as the source of 
    node-pairs for the networkx function (called `ebunch` in the networkx
    documentation) and the add only the value we want back to the frame

    Args:
     adder: networkx function to call to get the new data
     name: column-name to add to the frame
     graph: networkx graph to pass to the function
     frame (pandas.DataFrame): frame with node-pairs as index to add data to
    """
    frame[name] = [output[Futures.networkx_data_index]
		   for output in adder(graph, frame.index)]
    return frame
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org1989e18" class="outline-5"&gt;
&lt;h5 id="org1989e18"&gt;Adding A Resource Allocation Index&lt;/h5&gt;
&lt;div class="outline-text-5" id="text-org1989e18"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;add_networkx_data(networkx.resource_allocation_index,
		  DataNames.resource_allocation)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(future_connections.head(1))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org153d3f3" class="outline-5"&gt;
&lt;h5 id="org153d3f3"&gt;Adding the Jaccard Coefficient&lt;/h5&gt;
&lt;div class="outline-text-5" id="text-org153d3f3"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;add_networkx_data(networkx.jaccard_coefficient, DataNames.jaccard)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(future_connections.head(1))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org99d650d" class="outline-5"&gt;
&lt;h5 id="org99d650d"&gt;Adamic Adar&lt;/h5&gt;
&lt;div class="outline-text-5" id="text-org99d650d"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;add_networkx_data(networkx.adamic_adar_index, DataNames.adamic)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(future_connections.head(1))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org3673c5c" class="outline-5"&gt;
&lt;h5 id="org3673c5c"&gt;Preferential Attachment&lt;/h5&gt;
&lt;div class="outline-text-5" id="text-org3673c5c"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;add_networkx_data(networkx.preferential_attachment, DataNames.preferential)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(future_connections.head(1))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgc8e8e24" class="outline-4"&gt;
&lt;h4 id="orgc8e8e24"&gt;Setup the Training and Testing Data&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgc8e8e24"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org01e822d" class="outline-5"&gt;
&lt;h5 id="org01e822d"&gt;Separating the Edges Without 'Future Connection' Values&lt;/h5&gt;
&lt;div class="outline-text-5" id="text-org01e822d"&gt;
&lt;p&gt;
We are going to train on the values in the data with predictions and then make predictions for those that don't.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;prediction_set = future_connections[future_connections[Futures.target].isnull()]
training_set = future_connections[future_connections[Futures.target].notnull()]
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(prediction_set.shape)
print(training_set.shape)
assert len(prediction_set) + len(training_set) == len(future_connections)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org4d16011" class="outline-3"&gt;
&lt;h3 id="org4d16011"&gt;Separate the Target and Training Sets&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org4d16011"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;non_target = [column for column in future_connections.columns
	      if column != Futures.target]
x_train = training_set[non_target]
y_train = training_set[Futures.target]
x_predict = prediction_set[non_target]
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;assert all(x_train.columns == x_predict.columns)
assert len(x_train) == len(x_test)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org5f7a101" class="outline-3"&gt;
&lt;h3 id="org5f7a101"&gt;Scaling the Data&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org5f7a101"&gt;
&lt;p&gt;
To enable the use of linear models I'm going to scale the data so the mean is 0 and the variance is 1.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;scaler = StandardScaler()
x_train_scaled = scaler.fit_transform(x_train)
x_predict_scaled = scaler.transform(x_predict)

x_train_frame = pandas.DataFrame(x_train_scaled, columns=x_train.columns)
x_predict_frame = pandas.DataFrame(x_predict_scaled, columns=x_predict.columns)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(training.describe())
print(predictions.describe())
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org39b6571" class="outline-3"&gt;
&lt;h3 id="org39b6571"&gt;Feature Selection&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org39b6571"&gt;
&lt;p&gt;
To reduce the dimensionality I'm going to use model-based selection with Extra Trees.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;estimator = ExtraTreesClassifier()
estimator.fit(x_train_scaled, y_train)
selector = SelectFromModel(estimator, prefit=True)
x_train_trees_sfm = selector.transform(x_train_scaled)
x_predict_sfm = selector.transform(x_predict_scaled)
print(estimator.feature_importances_)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(x_train_trees_sfm.shape)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org899fe3b" class="outline-4"&gt;
&lt;h4 id="org899fe3b"&gt;Missing Future Connections&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org899fe3b"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;model = LogisticRegressionCV(n_jobs=-1, scoring='roc_auc', solver='liblinear',
			     cv=StratifiedKFold())
model.fit(x_train_trees_sfm, y_train)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;for scores in model.scores_[1.0]:
    print(max(scores))
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(model.classes_)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def new_connections_predictions():    
    probabilities = model.predict_proba(x_predict_sfm)
    return pandas.Series(probabilities[:, 1], index=prediction_set.index)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;outcome = new_connections_predictions()
assert len(outcome) == 122112, len(outcome)
print(outcome.head())
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>networks</category><category>random graphs</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/networks/looking-at-random-graphs/</guid><pubDate>Sat, 13 Apr 2019 18:59:44 GMT</pubDate></item><item><title>Selecting the E-Mail Model</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/networks/selecting-the-e-mail-model/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/selecting-the-e-mail-model/#org865efa6"&gt;Imports&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/selecting-the-e-mail-model/#orgde06815"&gt;The Data&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/selecting-the-e-mail-model/#org52ffacc"&gt;Department&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/selecting-the-e-mail-model/#org90a3d48"&gt;Splitting the Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/selecting-the-e-mail-model/#orgaa50152"&gt;Standardizing the Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/selecting-the-e-mail-model/#org85f4993"&gt;Dummy Classifier&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/selecting-the-e-mail-model/#org90135f8"&gt;Feature Selection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/selecting-the-e-mail-model/#orgefdf2d0"&gt;Fit and Display&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/selecting-the-e-mail-model/#orgbcc56b7"&gt;Logistic Regression&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/selecting-the-e-mail-model/#org345d726"&gt;L1 Penalty&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/selecting-the-e-mail-model/#org084446e"&gt;Random Forests&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/selecting-the-e-mail-model/#org1e39d10"&gt;K Nearest Neighbors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/selecting-the-e-mail-model/#org0d80ec5"&gt;Support Vector Classifier (SVC)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org865efa6" class="outline-2"&gt;
&lt;h2 id="org865efa6"&gt;Imports&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org865efa6"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# pypi
from sklearn.ensemble import (
    ExtraTreesClassifier,
    RandomForestClassifier,
    )
from sklearn.feature_selection import (
    RFECV,
    SelectFromModel,
)
from sklearn.linear_model import LogisticRegressionCV
from sklearn.model_selection import (
    GridSearchCV,
    StratifiedKFold,
    train_test_split,
    )

from sklearn.dummy import DummyClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
import matplotlib.pyplot as pyplot
import mglearn
import numpy
import pandas
import seaborn
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;% matplotlib inline
seaborn.set_style("whitegrid")
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgde06815" class="outline-2"&gt;
&lt;h2 id="orgde06815"&gt;The Data&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgde06815"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;data = pandas.read_hdf("email_data.h5", "df")
cleaned_data = data[pandas.notnull(data.management)]
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(cleaned_data.head())
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org52ffacc" class="outline-3"&gt;
&lt;h3 id="org52ffacc"&gt;Department&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org52ffacc"&gt;
&lt;p&gt;
Even though I don't think it's going to prove useful, the &lt;code&gt;department&lt;/code&gt; feature is actually categorical, despite the use of integers so we'll have to add dummy variables for it.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;cleaned_data = pandas.get_dummies(cleaned_data, columns=["department"])
print(cleaned_data.head(1))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org90a3d48" class="outline-3"&gt;
&lt;h3 id="org90a3d48"&gt;Splitting the Data&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org90a3d48"&gt;
&lt;p&gt;
For evaluation purposes I'll use the traditional train-test split.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;x_data = cleaned_data.loc[:, cleaned_data.columns != "management"]

y_data = cleaned_data.management

print(x_data.head())
print(y_data.head())
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(y_data.value_counts())
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;seaborn.countplot(x='management', data=cleaned_data)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
It looks like the management data is unbalanced, so I'll do a stratified split.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, stratify=y_data)
print(x_train.shape)
print(y_test.shape)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;seaborn.countplot(y_train)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Looks close enough for government work.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgaa50152" class="outline-2"&gt;
&lt;h2 id="orgaa50152"&gt;Standardizing the Data&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgaa50152"&gt;
&lt;p&gt;
The linear models expect the data to be standardized, so to make the comparisons fair I'll standardize the data first. First, a look at the data before scaling.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(x_train.describe())
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Now I'll scale it.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;scaler = StandardScaler()
scaler.fit(x_train)
x_train = pandas.DataFrame(scaler.transform(x_train), columns=x_train.columns)
x_test = scaler.transform(x_test)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Now the means should be near 0 (very small) and the standard deviations should be around 1.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(x_train.describe())
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org85f4993" class="outline-2"&gt;
&lt;h2 id="org85f4993"&gt;Dummy Classifier&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org85f4993"&gt;
&lt;p&gt;
As a baseline I'll use a &lt;a href="http://scikit-learn.org/stable/modules/model_evaluation.html#dummy-estimators"&gt;Dummy Classifier&lt;/a&gt; which uses a simple rule rather than the input data to make predictions.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;parameter_grid = dict(strategy=["stratified", 'most_frequent', 'prior', 'uniform'])
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Now we'll do a grid search.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;grid_search = GridSearchCV(DummyClassifier(), parameter_grid,
			   cv=StratifiedKFold(10), scoring="roc_auc")
grid_search.fit(x_train, y_train)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;BASELINE = grid_search.score(x_test, y_test)
print(grid_search.best_params_)
print(BASELINE)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
It looks like it chose the &lt;b&gt;stratified&lt;/b&gt; strategy, which should predict that the instances are all non-managers. Our baseline AUC score is 0.5 (0.47 now?).
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;results = pandas.DataFrame(grid_search.cv_results_)
print(results.head(1))
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;figure = pyplot.figure()
axe = figure.gca()
strategies = parameter_grid["strategy"]
x = pyplot.xticks(list(range(len(strategies))), strategies)
axe.plot(range(len(strategies)), results.mean_test_score)
axe.set_title("Dummy Classifier Strategy Vs AUC")
axe.set_xlabel("strategy")
axe.set_ylabel("AUC Score")
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
So it looks like all the strategies except &lt;b&gt;stratified&lt;/b&gt; did the same - and even the stratified did basically the same if you round it off.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org90135f8" class="outline-2"&gt;
&lt;h2 id="org90135f8"&gt;Feature Selection&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org90135f8"&gt;
&lt;p&gt;
I'm going to need to do some feature reduction, but figuring out what is important and what isn't is something I'm going to have to leave to the machine. I'm going to assume that the features thrown out by logistic regression with l1 penalization are unimportant. 
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;logistic_model = LogisticRegressionCV(penalty='l1',
				      solver='liblinear', scoring="roc_auc")
logistic_model.fit(x_train, y_train)
model = SelectFromModel(logistic_model, prefit=True)

x_train_positive = model.transform(x_train)
x_test_positive = model.transform(x_test)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(logistic_model.score(x_test, y_test))
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Logistic Regression with &lt;code&gt;L1&lt;/code&gt; penalty seems to do reasonably well even without feature selection.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;logistic_model.fit(x_train_positive, y_train)
print(logistic_model.score(x_test_positive, y_test))
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
It looks like feature selection didn't really help here.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(x_train.shape)
print(x_train_positive.shape)
print(model.ranking_)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
As a double-check I'll use a tree-based, recursive feature-elimination version.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;trees = ExtraTreesClassifier(n_estimators=10)
eliminator = RFECV(estimator=trees, cv=StratifiedKFold(10), scoring="roc_auc")
eliminator.fit(x_train, y_train)
x_train_trees = eliminator.transform(x_train)
x_test_trees = eliminator.transform(x_test)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(x_train_trees.shape)
print(eliminator.ranking_)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
This eliminated many more columns than the Logistic Regression version did.
&lt;/p&gt;

&lt;p&gt;
&lt;b&gt;warning&lt;/b&gt; this seem to change every time you run it - the randomness changes it. Only the elimination of the first column seems to do as well as not running it at all.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgefdf2d0" class="outline-2"&gt;
&lt;h2 id="orgefdf2d0"&gt;Fit and Display&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgefdf2d0"&gt;
&lt;p&gt;
This is a convenience function so I can fit and display the scores for the models.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def fit_and_display(model, identifier):
    """Fit and display the scores

    Args:
     model: The instantiated model to fit
     identifier (str): something to output at the beginning
    """
    print(identifier)
    print("=" * len(identifier))
    model.fit(x_train, y_train)
    print("\nX-train")
    print("Score: {:.2f}".format(model.score(x_test, y_test)))
    print("\nX-Train Positive")
    model.fit(x_train_positive, y_train)
    print("Score: {:.2f}".format(model.score(x_test_positive, y_test)))
    print("\nX-Train Trees")
    model.fit(x_train_trees, y_train)
    print("Score: {:.2f}".format(model.score(x_test_trees, y_test)))
    print("\nBest Training Score: {}".format(search.best_score_))
    return
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgbcc56b7" class="outline-2"&gt;
&lt;h2 id="orgbcc56b7"&gt;Logistic Regression&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgbcc56b7"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org345d726" class="outline-3"&gt;
&lt;h3 id="org345d726"&gt;L1 Penalty&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org345d726"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;model = LogisticRegressionCV(penalty="l1", scoring="roc_auc", solver="liblinear")
fit_and_display(model, "Logistic Regression L1")
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
I've already run the Logistic Regression using a 'l1' but I'll try it again with 'l2' to see if it improved.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;model = LogisticRegressionCV(scoring="roc_auc", solver="liblinear")
fit_and_display(model, "LogisticRegression")
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
L1 seems to do better than L1 overall, although it doesn't do as well with the recursively data form some reason.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org084446e" class="outline-2"&gt;
&lt;h2 id="org084446e"&gt;Random Forests&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org084446e"&gt;
&lt;p&gt;
I'll try a &lt;a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"&gt;Random Forest&lt;/a&gt; classifier next.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;parameter_grid = dict(n_estimators=range(10, 100, 10))
search = GridSearchCV(RandomForestClassifier(), parameter_grid,
		      cv=StratifiedKFold(10), scoring="roc_auc")
fit_and_display(search, "Random Forest")
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
This seems to have done much better than the logistic regression did. My logistic-regression feature reduction doesn't seem to help.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class RandomForest(object):
    """trains a random forest on the x-test-trees set

    Args:
     start (int): first n-estimators value to use
     stop (int): last n-estimators value (minus step)
     step (int): amount to increment estimators
     folds (int): Cross-validation-folds to usen

    Returns:
     GridSearchCV: grid-search with the best estimator
    """

    def __init__(self, start, stop, step, folds=10):
	self.start = start
	self.stop = stop
	self.step = step
	self.folds = folds
	self._search = None
	self._parameter_grid = None
	return

    @property
    def parameter_grid(self):
	"""dict of the number of estimators to use"""
	if self._parameter_grid is None:
	    self._parameter_grid = dict(n_estimators=list(range(self.start,
								self.stop,
								self.step)))
	return self._parameter_grid

    @property
    def search(self):
	"""grid-search cv object"""
	if self._search is None:
	    self._search = GridSearchCV(RandomForestClassifier(),
					self.parameter_grid,
					cv=StratifiedKFold(self.folds),
					scoring="roc_auc")
	return self._search    

    def fit(self):
	"""fits the model to the tree-based reduced-feature data"""
	self.search.fit(x_train_trees, y_train)
	print(self.search.score(x_test_trees, y_test))
	print(self.search.best_estimator_.feature_importances_)
	print(self.search.best_params_)
	return

    def plot(self):
	"""Plots estimators vs AUC scores"""
	figure = pyplot.figure()
	axe = figure.gca()
	axe.plot(self.parameter_grid["n_estimators"],
		 self.search.cv_results_["mean_test_score"])
	axe.set_title("Estimator Count vs AUC")
	axe.set_xlabel("Number of estimators (trees)")
	axe.set_ylabel("Mean AUC Score")
	return
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;search = RandomForest(10, 100, 10)
search.fit()
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Not a lot of variance in the importance of the features.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;search.plot()
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Would things get better with more trees?
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;search = RandomForest(150, 250, 10)
search.fit()
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;search.plot()
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
In this case the test-score was better, although the training scores don't look much better. I guess it's the randomness coming into play again. I'll try a long run instead.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;search = RandomForest(10, 500, 10)
search.fit()
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;search.plot()
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
The test-score for the best estimator is actually a little worse than it was for the previous case, although it's qute a small difference.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org1e39d10" class="outline-2"&gt;
&lt;h2 id="org1e39d10"&gt;K Nearest Neighbors&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org1e39d10"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;parameters = dict(n_neighbors=range(10, 20),
		  weights=["uniform", "distance"],
		  p=[1, 2],
		  leaf_size=range(10, 50, 10))

search = GridSearchCV(KNeighborsClassifier(), parameters, scoring="roc_auc")
search.fit(x_train_trees, y_train)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(search.score(x_test_trees, y_test))
print(search.best_params_)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
This doesn't seem to do so well, although I'm not as experienced at using it so I might be using bad parameters.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org0d80ec5" class="outline-2"&gt;
&lt;h2 id="org0d80ec5"&gt;Support Vector Classifier (SVC)&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org0d80ec5"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;parameters = dict(C=numpy.arange(.1, 1, 0.1), gamma=range(1, 10, 1),
		  kernel=["linear", 'rbf', 'sigmoid'])
search = GridSearchCV(SVC(class_weight='balanced'), parameters, scoring='roc_auc')
fit_and_display(search, "SVC")
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(search.score(x_test_trees, y_test))
print(search.best_params_)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Now that the data is scaled, the svc does much better, alhough still not as well as the random forest.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>model selection</category><category>networks</category><category>sklearn</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/networks/selecting-the-e-mail-model/</guid><pubDate>Sat, 13 Apr 2019 18:57:42 GMT</pubDate></item><item><title>Future E-Mail</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org10af2bc"&gt;Tangle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org88839ab"&gt;Imports&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org4c24dc7"&gt;Constants&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#orgd68ccc3"&gt;The Email-Graph&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#orgc65bc7c"&gt;The Data&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org227f2c0"&gt;The Given Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org4df48cf"&gt;Adding networkx features&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org362fc1d"&gt;Add Networkx Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#orgc7f6164"&gt;Adding A Resource Allocation Index&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org08b797f"&gt;Adding the Jaccard Coefficient&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org4349331"&gt;Adamic Adar&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org9a00030"&gt;Preferential Attachment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org86e225d"&gt;Community-Based Link Prediction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org3e02e6a"&gt;Saving the Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#orgea7fdb5"&gt;Setup the Training and Testing Data&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org94f8192"&gt;Separating the Edges Without 'Future Connection' Values&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org1907c92"&gt;Separate the Target and Training Sets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org9a710d6"&gt;Setting Up the Testing and Training Sets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org88f4562"&gt;Scaling the Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org8223efe"&gt;Feature Selection&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org7df20bc"&gt;Fitting the Models&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org5efc44b"&gt;Persistent Storage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org6538dc8"&gt;Logistic Regression&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#orgb86926e"&gt;Fit Grid Search&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#orgd9f102b"&gt;Random Forests&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org64e3526"&gt;Extra Trees&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
This will select a model to predict whether an edge in the email-network that currently doesn't have an edge will have one in the future.
&lt;/p&gt;
&lt;div id="outline-container-org10af2bc" class="outline-2"&gt;
&lt;h2 id="org10af2bc"&gt;Tangle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org10af2bc"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;imports&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;futures&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;names&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;files&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;future&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;networkx&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;future&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;connections&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;jaccard&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;coefficient&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;adamic&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;adar&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;preferential&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;attachment&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;future&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;connections&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;future&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;connections&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;scaled&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;pickle&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;it&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;unpickle&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;it&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;lr&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;rfs&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;trees&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;rfs&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;lr&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;sfm&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;trees&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;fsm&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;scores&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;identifiers&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="ow"&gt;and&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;sets&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;by&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="ow"&gt;and&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nb"&gt;all&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;logistic&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;grid&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;search&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;grid&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;searches&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;forests&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;extra&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;trees&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org88839ab" class="outline-2"&gt;
&lt;h2 id="org88839ab"&gt;Imports&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org88839ab"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# python standard library
import os
import pickle

# pypi
import networkx
import pandas
import seaborn

from numba import jit

from sklearn.ensemble import (
    ExtraTreesClassifier,
    RandomForestClassifier,
    )
from sklearn.feature_selection import (
    RFECV,
    SelectFromModel,
    )
from sklearn.linear_model import LogisticRegressionCV
from sklearn.model_selection import (
    train_test_split,
    GridSearchCV,
    StratifiedKFold,
    )
from sklearn.preprocessing import StandardScaler
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;% matplotlib inline
seaborn.set_style("whitegrid")
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org4c24dc7" class="outline-2"&gt;
&lt;h2 id="org4c24dc7"&gt;Constants&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org4c24dc7"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class Futures(object):
    target = "Future Connection"
    data_file = "Future_Connections.csv"
    graph_file = "email_prediction.txt"
    networkx_data_index = 2
    folds = 10
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class DataNames(object):
    resource_allocation = 'resource_allocation'
    jaccard = 'jaccard_coefficient'
    adamic = "adamic_adar"
    preferential = "preferential_attachment"
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class Files(object):
    """File-names for data persistence"""
    future_training_data = 'future_training_data.csv'
    future_selection_outcomes = 'future_selection_outcomes.pkl'
    future_model_selection = "future_model_cvs.pkl"
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class Training(object):
    """data-pickles"""
    x_train_lr_rfs = "x_train_lr_rfs.pkl"
    x_test_lr_rfs = "x_test_lr_rfs.pkl"
    x_train_trees_rfs = "x_train_trees_rfs.pkl"
    x_test_trees_rfs = "x_test_trees_rfs.pkl"
    x_train_lr_sfm = "x_train_lr_sfm.pkl"
    x_test_lr_sfm = "x_test_lr_sfm.pkl"
    x_train_trees_sfm = "x_train_trees_sfm.pkl"
    x_test_trees_sfm = "x_test_trees_sfm.pkl"
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgd68ccc3" class="outline-2"&gt;
&lt;h2 id="orgd68ccc3"&gt;The Email-Graph&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgd68ccc3"&gt;
&lt;p&gt;
To get the features for the models we'll need to use the email-graph.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;email = networkx.read_gpickle(Futures.graph_file)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgc65bc7c" class="outline-2"&gt;
&lt;h2 id="orgc65bc7c"&gt;The Data&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgc65bc7c"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org227f2c0" class="outline-3"&gt;
&lt;h3 id="org227f2c0"&gt;The Given Data&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org227f2c0"&gt;
&lt;p&gt;
We're given a csv file with the training and prediction data in it ('Future&lt;sub&gt;Connections.csv&lt;/sub&gt;').
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;head Future_Connections.csv
&lt;span class="nb"&gt;echo&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Org-mode converted it to a table, but it's actually a CSV. The first line of data looks like this.
&lt;/p&gt;

&lt;pre class="example"&gt;
"(6, 840)",0.0
&lt;/pre&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;future_connections_pre_loaded = os.path.isfile(Files.future_training_data)
if future_connections_pre_loaded:
    future_connections = pandas.read_csv(Files.future_training_data,
					 index_col=0)
else:
    future_connections = pandas.read_csv(Futures.data_file,
					 index_col=0,
					 converters={0: eval})
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
So, we're loading the node-pairs (edges) as the index of the data-frame and explicitly telling pandas that the Future Connection values should be converted , which I don't think is necessary, but this came with the problem statement so I'll just leave it in in case there's some side-effect I'm not aware of.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(future_connections[Futures.target].value_counts())
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
This is a fairly big (and lopsided) data-set.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;seaborn.countplot(x=Futures.target, data=future_connections)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org4df48cf" class="outline-2"&gt;
&lt;h2 id="org4df48cf"&gt;Adding networkx features&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org4df48cf"&gt;
&lt;p&gt;
To create features to train the model and make predictions, I'm going to use the networkx &lt;a href="https://networkx.github.io/documentation/networkx-1.10/reference/algorithms.link_prediction.html"&gt;link prediction&lt;/a&gt; algorithms.
&lt;/p&gt;
&lt;/div&gt;

&lt;div id="outline-container-org362fc1d" class="outline-3"&gt;
&lt;h3 id="org362fc1d"&gt;Add Networkx Data&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org362fc1d"&gt;
&lt;p&gt;
This is a function to get networkx data and add it to the data-frame. It won't work for the community-based algorithms.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def add_networkx_data(adder, name, graph=email, frame=future_connections):
    """Adds networkx data to the frame

    The networkx link-prediction functions return generators of triples:
     (first-node, second-node, value)

    This will use the index of the frame that's passed in as the source of 
    node-pairs for the networkx function (called `ebunch` in the networkx
    documentation) and the add only the value we want back to the frame

    Args:
     adder: networkx function to call to get the new data
     name: column-name to add to the frame
     graph: networkx graph to pass to the function
     frame (pandas.DataFrame): frame with node-pairs as index to add data to
    """
    frame[name] = [output[Futures.networkx_data_index]
		   for output in adder(graph, frame.index)]
    return frame
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgc7f6164" class="outline-3"&gt;
&lt;h3 id="orgc7f6164"&gt;Adding A Resource Allocation Index&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgc7f6164"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;if not future_connections_pre_loaded:
    add_networkx_data(networkx.resource_allocation_index,
		      DataNames.resource_allocation)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(future_connections.head(1))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org08b797f" class="outline-3"&gt;
&lt;h3 id="org08b797f"&gt;Adding the Jaccard Coefficient&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org08b797f"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;if not future_connections_pre_loaded:
    add_networkx_data(networkx.jaccard_coefficient, DataNames.jaccard)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(future_connections.head(1))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org4349331" class="outline-3"&gt;
&lt;h3 id="org4349331"&gt;Adamic Adar&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org4349331"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;if not future_connections_pre_loaded:
    add_networkx_data(networkx.adamic_adar_index, DataNames.adamic)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(future_connections.head(1))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org9a00030" class="outline-3"&gt;
&lt;h3 id="org9a00030"&gt;Preferential Attachment&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org9a00030"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;if not future_connections_pre_loaded:
    add_networkx_data(networkx.preferential_attachment, DataNames.preferential)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(future_connections.head(1))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org86e225d" class="outline-3"&gt;
&lt;h3 id="org86e225d"&gt;Community-Based Link Prediction&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org86e225d"&gt;
&lt;p&gt;
This requires identifying 'communities' first, so I'll defer it for now.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;#add_networkx_data(networkx.cn_soundarajan_hopcroft, DataNames.common_neighbors)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
These three all require communities for them to work (so I'm skipping them):
&lt;/p&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;cn&lt;sub&gt;soundarajan&lt;/sub&gt;&lt;sub&gt;hopcroft&lt;/sub&gt;&lt;/li&gt;
&lt;li&gt;ra&lt;sub&gt;index&lt;/sub&gt;&lt;sub&gt;soundarajan&lt;/sub&gt;&lt;sub&gt;hopcroft&lt;/sub&gt;&lt;/li&gt;
&lt;li&gt;within&lt;sub&gt;inter&lt;/sub&gt;&lt;sub&gt;cluster&lt;/sub&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org3e02e6a" class="outline-3"&gt;
&lt;h3 id="org3e02e6a"&gt;Saving the Data&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org3e02e6a"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;future_connections.to_csv(Files.future_training_data)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgea7fdb5" class="outline-2"&gt;
&lt;h2 id="orgea7fdb5"&gt;Setup the Training and Testing Data&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgea7fdb5"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org94f8192" class="outline-3"&gt;
&lt;h3 id="org94f8192"&gt;Separating the Edges Without 'Future Connection' Values&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org94f8192"&gt;
&lt;p&gt;
We are going to train on the values in the data with predictions and then make predictions for those that don't. For model selection we don't need the set missing predictions, but I'll separate it out anyway to be complete.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;prediction_set = future_connections[future_connections[Futures.target].isnull()]
training_set = future_connections[future_connections[Futures.target].notnull()]
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(prediction_set.shape)
print(training_set.shape)
assert len(prediction_set) + len(training_set) == len(future_connections)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org1907c92" class="outline-3"&gt;
&lt;h3 id="org1907c92"&gt;Separate the Target and Training Sets&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org1907c92"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;non_target = [column for column in future_connections.columns
	      if column != Futures.target]
training = training_set[non_target]
testing = training_set[Futures.target]
predictions = prediction_set[non_target]
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;assert all(training.columns == predictions.columns)
assert len(training) == len(testing)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org9a710d6" class="outline-3"&gt;
&lt;h3 id="org9a710d6"&gt;Setting Up the Testing and Training Sets&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org9a710d6"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;x_train, x_test, y_train, y_test = train_test_split(training, testing, stratify=testing)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(x_train.shape)
print(x_test.shape)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;seaborn.countplot(y_train)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;seaborn.countplot(y_test)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org88f4562" class="outline-3"&gt;
&lt;h3 id="org88f4562"&gt;Scaling the Data&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org88f4562"&gt;
&lt;p&gt;
To enable the use of linear models I'm going to scale the data so the mean is 0 and the variance is 1.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)

x_train = pandas.DataFrame(x_train, columns=training.columns)
x_test = pandas.DataFrame(x_test, columns=training.columns)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(x_train.describe())
print(x_test.describe())
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org8223efe" class="outline-3"&gt;
&lt;h3 id="org8223efe"&gt;Feature Selection&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org8223efe"&gt;
&lt;p&gt;
To reduce the dimensionality I'm going to use recursive feature selection and model-based selection.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def pickle_it(thing, name):
    """saves the thing as a pickle"""
    with open(name, "wb") as writer:
	pickle.dump(thing, writer)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def unpickle_it(name):
    """loads the object from the file-name

    Args:
     name (str): name of binary pickle file

    Returns:
     obj: unpickled object
    """
    with open(name, 'rb') as reader:
	thing = pickle.load(reader)
    return thing
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org3f61885" class="outline-4"&gt;
&lt;h4 id="org3f61885"&gt;RFECV with Logistic Regression&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org3f61885"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;if os.path.isfile(Training.x_train_lr_rfs):
    x_train_lr_rfs = unpickle_it(Training.x_train_lr_rfs)
    x_test_lr_rfs = unpickle_it(Training.x_test_lr_rfs)
else:
    estimator = LogisticRegressionCV(n_jobs=-1)
    selector = RFECV(estimator, scoring='roc_auc',
		     n_jobs=-1,
		     cv=StratifiedKFold(Futures.folds))
    x_train_lr_rfs = selector.fit_transform(x_train, y_train)
    x_test_lr_rfs = selector.transform(x_test)
    pickle_it(x_train_lr_rfs, Training.x_train_lr_rfs)
    pickle_it(x_test_lr_rfs, Training.x_test_lr_rfs)
    print(selector.ranking_)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
It looks like it only discarded preferential attachment.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgc921490" class="outline-4"&gt;
&lt;h4 id="orgc921490"&gt;RFECV with Extra Trees&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgc921490"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;if os.path.isfile(Training.x_train_trees_rfs):
    x_train_trees_rfs = unpickle_it(Training.x_train_trees_rfs)
    x_test_trees_rfs = unpickle_it(Training.x_test_trees_rfs)
else:
    estimator = ExtraTreesClassifier()
    selector = RFECV(estimator, scoring='roc_auc', n_jobs=-1, cv=StratifiedKFold(Futures.folds))
    x_train_trees_rfs = selector.fit_transform(x_train, y_train)
    x_test_trees_rfs = selector.transform(x_test)
    pickle_it(x_train_trees_rfs, Training.x_train_trees_rfs)
    pickle_it(x_test_trees_rfs, Training.x_test_trees_rfs)
    print(selector.ranking_)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Strangely, the Extra Trees Classifier didn't remove any columnsâ¦
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgec5dc38" class="outline-4"&gt;
&lt;h4 id="orgec5dc38"&gt;Select Model Logistic Regression&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgec5dc38"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;if os.path.isfile(Training.x_train_lr_sfm):
    x_train_lr_sfm = unpickle_it(Training.x_train_lr_sfm)
    x_test_lr_sfm = unpickle_it(Training.x_test_lr_sfm)
else:
    estimator = LogisticRegressionCV(
	n_jobs=-1, scoring='roc_auc',
	cv=StratifiedKFold(Futures.folds)).fit(x_train,
					       y_train)
    selector = SelectFromModel(estimator, prefit=True)
    x_train_lr_sfm = selector.transform(x_train)
    x_test_lr_sfm = selector.transform(x_test)
    pickle_it(x_train_lr_sfm, Training.x_train_lr_sfm)
    pickle_it(x_test_lr_sfm, Training.x_test_lr_sfm)
    print(estimator.coef_)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(x_train_lr_sfm.shape)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
This was more aggressive, cutting out half the features. It looks like it kept &lt;b&gt;Jaccard Coefficient&lt;/b&gt; and &lt;b&gt;Adamic Adar&lt;/b&gt; and got rid of &lt;b&gt;Resource Allocation&lt;/b&gt; and &lt;b&gt;Preferential Attachment&lt;/b&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orga5faba0" class="outline-4"&gt;
&lt;h4 id="orga5faba0"&gt;Select Model Extra Trees&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orga5faba0"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;if os.path.isfile(Training.x_train_trees_sfm):
    x_train_trees_sfm = unpickle_it(Training.x_train_trees_sfm)
    x_test_trees_sfm = unpickle_it(Training.x_test_trees_sfm)
else:
    estimator = ExtraTreesClassifier()
    estimator.fit(x_train, y_train)
    selector = SelectFromModel(estimator, prefit=True)
    x_train_trees_sfm = selector.transform(x_train)
    x_test_trees_sfm = selector.transform(x_test)
    pickle_it(x_train_trees_sfm, Training.x_train_trees_sfm)
    pickle_it(x_test_trees_sfm, Training.x_test_trees_sfm)
    print(estimator.feature_importances_)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(x_train_trees_sfm.shape)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
This is sometimes more aggressive, keeping only the &lt;b&gt;Adamic Adar&lt;/b&gt; featureâ¦ But maybe that's all you need, we'll see. Then again, other times it isn't as aggressive, only trimming two columns, and this tiem it only trimmed oneâ¦
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org7df20bc" class="outline-2"&gt;
&lt;h2 id="org7df20bc"&gt;Fitting the Models&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org7df20bc"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org5efc44b" class="outline-3"&gt;
&lt;h3 id="org5efc44b"&gt;Persistent Storage&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org5efc44b"&gt;
&lt;p&gt;
The outcomes will be stored in a dictionary called &lt;code&gt;scores&lt;/code&gt; with descriptions of the best model and feature-selection mapped to their testing-score.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;if os.path.isfile(Files.future_model_selection):
    with open(Files.future_model_selection, 'rb') as pkl:
	scores = pickle.load(pkl)
else:
    scores = {}
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def fit_and_print(estimator, x_train, x_test):
    """fits the estimator to the data

    Args:
     estimator: model to fit
     x_train: scaled data to fit model to
     x_test: data to test the model with

    Returns:
     tuple: model fit to the data, test score
    """
    model = estimator.fit(x_train, y_train)
    test_score = model.score(x_test, y_test)
    print("Mean Cross-Validation Score: {:.2f}".format(model.scores_[1].mean()))
    print("Testing Score: {:.2f}".format(test_score))
    return model, test_score
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;data_sets = {("extra trees", 'select from model') : (x_train_trees_sfm, x_test_trees_sfm),
	     ("extra trees", 'recursive feature selection') : (x_train_trees_rfs, x_test_trees_rfs),
	     ('logistic regression', "recursive feature selection") : (x_train_lr_rfs, x_test_lr_rfs),
	     ('logistic regression', "select from model") : (x_train_lr_sfm, x_test_lr_sfm)}
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def key_by_value(source, search_value):
    """Find the key in a dict that matches a value

    Args:
     source (dict): dictionary with value to search for
     search_value: value to search for

    Returns:
     object: key in source that matched value
    """
    for key, value in source.items():
	if value == search_value:
	    return key
    return
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def fit_and_print_all(model, model_name):
    """Fits the model against all data instances

    Args:
     model: model to fit to the data sets
     model_name: identifier for the outcomes
    """
    for data_set, x in data_sets.items():
	selector, method = data_set
	train, test = x
	key = ','.join([model_name, selector, method])
	print("Training Shape: {}".format(train.shape))
	if key not in scores:
	    print(key)
	    fitted, score = fit_and_print(model, train, test)
	    scores[key] = score
	else:
	    score = scores[key]
	    print("{}: {:.3f}".format(key, score))
	print()

    best_score = max(scores.values())
    best_key = key_by_value(scores, best_score)
    print("Best Model So Far: {}, Score={:.2f}".format(
	best_key,
	best_score))
    with open(Files.future_model_selection, 'wb') as writer:
	pickle.dump(scores, writer)
    return
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org6538dc8" class="outline-3"&gt;
&lt;h3 id="org6538dc8"&gt;Logistic Regression&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org6538dc8"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;logistic_model = LogisticRegressionCV(n_jobs=-1, scoring="roc_auc",
				      solver='liblinear',
				      cv=StratifiedKFold(Futures.folds))
fit_and_print_all(logistic_model, "Logistic Regression")
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgb86926e" class="outline-3"&gt;
&lt;h3 id="orgb86926e"&gt;Fit Grid Search&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgb86926e"&gt;
&lt;p&gt;
Since the Logistic Regression had its own cross-validation I didn't use a grid search, but for the forests I'll use one to figure out the best number of estimators. I'll have to look into what the other parameters do to figure out whether they're going to be useful.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def fit_grid_search(estimator, parameters, x_train, x_test):
    """Fits the estimator using grid search

    Args:
     estimator: Model to fit
     parameters (dict): hyper-parameters for the grid search
     x_train (array): the training data input
     x_test (array): data to evaluate the best model with

    Returns: 
     tuple: Best Model, best model score
    """
    search = GridSearchCV(estimator, parameters, n_jobs=-1, scoring='roc_auc',
			  cv=StratifiedKFold(Futures.folds))
    search.fit(x_train, y_train)
    best_model = search.best_estimator_
    test_score = best_model.score(x_test, y_test)
    print("Mean of Mean Cross-Validation Scores: {:.2f}".format(
	search.cv_results_["mean_train_score"].mean()))
    print("Mean of Cross-Validation Score STDs: {:.2f}".format(
	search.cv_results_["std_train_score"].mean()))
    print("Testing Score: {:.2f}".format(test_score))
    return best_model, test_score
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def fit_grid_searches(estimator, parameters, name, data_sets=data_sets):
    """Fits the estimator against all the data-sets

    Args:
     estimator: instance of model to test
     parameters: dict of grid-search parameters
     name: identifier for the model
    """
    for data_set, x in data_sets.items():
	selector, method = data_set
	train, test = x
	key = ",".join([name, selector, method])
	if key not in scores:
	    print(key)
	    fitted, score = fit_grid_search(estimator, parameters, train, test)
	    scores[key] = score
	else:
	    score = scores[key]
	    print("{}: {:.2f}".format(key, score))
	print()
    best = max(scores.values())
    best_key = key_by_value(scores, best)
    print("Best Model So Far: {}, Score={:.2f}".format(best_key, best))
    with open(Files.future_model_selection, 'wb') as writer:
	pickle.dump(scores, writer)
    return
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgd9f102b" class="outline-3"&gt;
&lt;h3 id="orgd9f102b"&gt;Random Forests&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgd9f102b"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;parameters = dict(n_estimators = list(range(10, 200, 10)))
forest = RandomForestClassifier()
fit_grid_searches(forest, parameters, "Random Forest")
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org64e3526" class="outline-3"&gt;
&lt;h3 id="org64e3526"&gt;Extra Trees&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org64e3526"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;scores = {k:v for k,v in scores.items() if not k.startswith('Extra Trees,extra trees')}
parameters = dict(n_estimators = list(range(10, 200, 10)))
trees = ExtraTreesClassifier()
fit_grid_searches(trees, parameters, "Extra Trees")
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>networks</category><category>prediction</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/</guid><pubDate>Sat, 13 Apr 2019 18:52:40 GMT</pubDate></item><item><title>Friends and Politics</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/networks/friends-and-politics/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/friends-and-politics/#org98e6c3c"&gt;Part 1 - Friendships&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/friends-and-politics/#org018afc4"&gt;Imports&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/friends-and-politics/#org732ccfd"&gt;Friendships data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/friends-and-politics/#orgf25f1e3"&gt;Degree, Closeness, and Normalized Betweenness Centrality&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/friends-and-politics/#org4768f6e"&gt;Most Connected Friend&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/friends-and-politics/#org30c7f27"&gt;Fewest Hops&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/friends-and-politics/#org8bd5234"&gt;Most Important Connection&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/friends-and-politics/#orgdc438ba"&gt;Part 2 - Political Blogs&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/friends-and-politics/#org0ea3edb"&gt;Scaled Page Rank of &lt;i&gt;realclearpolitics.com&lt;/i&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/friends-and-politics/#org8bd71a4"&gt;Top Five Blogs by Page Rank&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/friends-and-politics/#org207f51f"&gt;HITS Score for Real Clear Politics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/friends-and-politics/#orga5d2d87"&gt;Top 5 Blogs by Hub Score&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/friends-and-politics/#orga24c551"&gt;Top Five Blogs By Authority&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
&lt;a href="https://en.wikipedia.org/wiki/Centrality"&gt;Node Centrality&lt;/a&gt; is a measure of the importance of a node to a network. This will explore measures of centrality using two networks, a friendship network, and a blog network.
&lt;/p&gt;

&lt;div id="outline-container-org98e6c3c" class="outline-2"&gt;
&lt;h2 id="org98e6c3c"&gt;Part 1 - Friendships&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org98e6c3c"&gt;
&lt;p&gt;
This will look at a network of friendships at a university department. Each node corresponds to a person (identified by an integer node label), and an edge indicates friendship. 
&lt;/p&gt;
&lt;/div&gt;

&lt;div id="outline-container-org018afc4" class="outline-3"&gt;
&lt;h3 id="org018afc4"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org018afc4"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;import networkx
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org732ccfd" class="outline-3"&gt;
&lt;h3 id="org732ccfd"&gt;Friendships data&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org732ccfd"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;friendships = networkx.read_gml('friendships.gml')
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(len(friendships))
print(networkx.is_connected(friendships))
print(networkx.is_directed(friendships))
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
There are 1,133 people in the friendship network, which is a connected, undirected graph.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgf25f1e3" class="outline-3"&gt;
&lt;h3 id="orgf25f1e3"&gt;Degree, Closeness, and Normalized Betweenness Centrality&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgf25f1e3"&gt;
&lt;p&gt;
Find the degree centrality, closeness centrality, and normalized betweenness centrality (excluding endpoints) of node 100.
&lt;/p&gt;

&lt;ul class="org-ul"&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Centrality#Degree_centrality"&gt;Degree Centrality&lt;/a&gt; scores the nodes based on the number of links they have to other nose. The assumption is that a node with more connections should be more important.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Closeness_centrality"&gt;Closeness Centrality&lt;/a&gt; uses the lengths of shortest paths to decide importance. The less distance there is between a node and the other nodes the more important it is.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Betweenness_centrality"&gt;Betweenness Centrality&lt;/a&gt; counts the number of shortest paths between pairs of nodes that pass through a node.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;DEGREE_CENTRALITY = networkx.degree_centrality(friendships)
CLOSENESS_CENTRALITY = networkx.closeness_centrality(friendships)
BETWEENNESS_CENTRALITY = networkx.betweenness_centrality(friendships)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def node_centrality(node=100):
    """gets measures of centrality for node

    Args:
     node (int): the number (key) for the node

    Returns:
     tuple: 
      - float: degree centrality
      - float: closeness centrality
      - float: normalized betweeness centrality
    """
    return (DEGREE_CENTRALITY[node],
	    CLOSENESS_CENTRALITY[node], BETWEENNESS_CENTRALITY[node])
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print("Node 101:")
degree, closeness, betweenness = node_centrality()
print("Degree Centrality: {0:.4f}".format(degree))
print("Closeness Centrality: {0:.2f}".format(closeness))
print("Normalized Betweenness Centrality: {0:.6f}".format(betweenness))
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def largest_node(centrality):
    """gets the node with the best (largest) score

    Args:
     centrality (dict): one of the centrality score dicts

    Returns:
     int: name of the node with the best score
    """
    return list(
	reversed(sorted((value, node)
			for (node, value) in centrality.items())))[0][1]
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org4768f6e" class="outline-3"&gt;
&lt;h3 id="org4768f6e"&gt;Most Connected Friend&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org4768f6e"&gt;
&lt;p&gt;
We want to contact one person in our friendship network and have him or her contact all his or her immediate friends. To have the greatest impact, this person should have the most links in the network. Which node is this?
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def most_connected_friend():
    """returns the node with the best degree centrality"""
    return largest_node(DEGREE_CENTRALITY)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;MOST_CONNECTED = most_connected_friend()
print("Most Connected Friend: {}".format(MOST_CONNECTED))
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;connected = networkx.Graph()
friends = friendships[MOST_CONNECTED]
for friend in friends:
    connected.add_edge(MOST_CONNECTED, friend)
positions = networkx.spring_layout(connected)
networkx.draw(connected, positions, with_labels=False, node_color='b', node_size=50)
networkx.draw(connected, positions, nodelist=[MOST_CONNECTED], node_color="r")
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Node 105 does appear to be well connected.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org30c7f27" class="outline-3"&gt;
&lt;h3 id="org30c7f27"&gt;Fewest Hops&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org30c7f27"&gt;
&lt;p&gt;
We want to reach everyone in the network by having one person passing messages to his friends who can then pass it on and so forth (a six-degrees of separation type scenario) but we want the fewest number of transfers. &lt;i&gt;Which friend is closest to all the people in the friendship network?&lt;/i&gt;
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def closest_friend():
    """the node with the best closeness centrality

    Returns:
     int: Identifier for the node closest to all the other nodes
    """
    return largest_node(CLOSENESS_CENTRALITY)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;CLOSEST_FRIEND = closest_friend()
print("Closest Friend: {}".format(CLOSEST_FRIEND))
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;positions = networkx.spring_layout(friendships)
networkx.draw(friendships, positions, node_size=1, alpha=0.25, node_color='b')
networkx.draw_networkx_nodes(friendships, positions, nodelist=[CLOSEST_FRIEND],
			     node_color='r', node_size=50)
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;
Interesting to look at, if not the most informative.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org8bd5234" class="outline-3"&gt;
&lt;h3 id="org8bd5234"&gt;Most Important Connection&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org8bd5234"&gt;
&lt;p&gt;
Although the graph is connected, if you took out one persion from the network, which one would cause the most disruption (which person is in the path of the most shortest paths)?
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def betweenness_centrality():
    """the node with the highest betweenness centrality

    Returns:
     int: ID of the person who sits on the most shortest paths
    """
    return largest_node(BETWEENNESS_CENTRALITY)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;MOST_BETWEEN = betweenness_centrality()
print("Most Between Friend: {}".format(MOST_BETWEEN))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgdc438ba" class="outline-2"&gt;
&lt;h2 id="orgdc438ba"&gt;Part 2 - Political Blogs&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgdc438ba"&gt;
&lt;p&gt;
Now we're going to use &lt;a href="https://en.wikipedia.org/wiki/PageRank"&gt;PageRank&lt;/a&gt; and &lt;a href="https://en.wikipedia.org/wiki/HITS_algorithm"&gt;Hyperlink-Induced Topic Search (HITS)&lt;/a&gt;  to look at a directed network of political blogs, where nodes correspond to a blog and edges correspond to links between blogs.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;blogs = networkx.read_gml('blogs.gml')
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(len(blogs))
print(networkx.is_directed(blogs))
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;networkx.draw(blogs, alpha=0.5, node_size=1, node_color='r')
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org0ea3edb" class="outline-3"&gt;
&lt;h3 id="org0ea3edb"&gt;Scaled Page Rank of &lt;i&gt;realclearpolitics.com&lt;/i&gt;&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org0ea3edb"&gt;
&lt;p&gt;
&lt;i&gt;PageRank&lt;/i&gt; scores web-pages by the number of important nodes that link directly to them. It is possible for the algorithm to get stuck if there are no edges leading out from a directed subgraph, producing erroneous page-ranks so the &lt;i&gt;Scaled Page Rank&lt;/i&gt; uses a random-restart do decide when to occasionally jump to a new node, an idea similar to the way Stochastic Gradient Descent avoids being stuck in local minima. The &lt;a href="https://networkx.github.io/documentation/networkx-1.10/reference/generated/networkx.algorithms.link_analysis.pagerank_alg.pagerank.html"&gt;Networkx pagerank&lt;/a&gt; uses a default of 0.85, which I will use, so it will do a random-restart about 15% of the time.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;PAGE_RANK = networkx.pagerank(blogs)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def real_clear_politics_page_rank():
    """Page Rank of realclearpolitics.com

    Returns:
     float: The PageRank for the realclearpolitics blog.
    """
    return PAGE_RANK['realclearpolitics.com']
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print("Real Clear Politics Page Rank: {0:.4f}".format(real_clear_politics_page_rank()))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org8bd71a4" class="outline-3"&gt;
&lt;h3 id="org8bd71a4"&gt;Top Five Blogs by Page Rank&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org8bd71a4"&gt;
&lt;p&gt;
This time the PageRank scores will be used to find what it thinks are the most important blogs.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def top_five(ranks, count=5):
    """gets the top-five blogs by rank

    Args:
     count (int): number to return

    Returns:
     list [str]: names of the top blogs - most to least important
    """
    top = list(reversed(sorted((rank, node)
			       for node, rank in ranks.items())))[:count]
    return [node for rank, node in top]
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def top_five_page_rank():
    """Top 5 nodes by page rank

    Returns:
     list [str]: top-five blogs by page-rank
    """
    return top_five(PAGE_RANK)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print("Top Five Blogs by PageRank")

for blog in top_five_page_rank():
    print("  - {}".format(blog))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org207f51f" class="outline-3"&gt;
&lt;h3 id="org207f51f"&gt;HITS Score for Real Clear Politics&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org207f51f"&gt;
&lt;p&gt;
This uses the HITS algorithm to find the authority and hub scores for &lt;i&gt;realclearpolitics.com&lt;/i&gt;. This algorithm tries to identify &lt;code&gt;hubs&lt;/code&gt;, collections of links that directed users to important pages, and &lt;code&gt;authoratative&lt;/code&gt; pages, pages that are deemed important because of their relevant content (as identified by the fact that they are linked to by &lt;code&gt;hubs&lt;/code&gt;).
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;HUBS, AUTHORITIES = networkx.hits(blogs)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def real_clear_politics_hits():
    """HITS score for realclearpolitics.com

    Returns:
     tuple (float, float): hub score, authority score
    """
    return HUBS['realclearpolitics.com'], AUTHORITIES['realclearpolitics.com']
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;hub, authority = real_clear_politics_hits()
print("Real Clear Politics")
print("Hub: {0:.5f}\nAuthority: {0:.5f}".format(hub, authority))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orga5d2d87" class="outline-3"&gt;
&lt;h3 id="orga5d2d87"&gt;Top 5 Blogs by Hub Score&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orga5d2d87"&gt;
&lt;p&gt;
This will find the top five blogs based on their hub scores (meaning they are the ones who link to the most authoratative sites).
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def top_five_hubs():
    """Top five blogs by hub scores

    Returns:
     list (str): Names of top-five hub blogs
    """
    return top_five(HUBS)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;top_five_hub_blogs = top_five_hubs()
print('Top Five Hub Blogs')
for blog in top_five_hub_blogs:
    print(" - {}".format(blog))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orga24c551" class="outline-3"&gt;
&lt;h3 id="orga24c551"&gt;Top Five Blogs By Authority&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orga24c551"&gt;
&lt;p&gt;
This will find the top five political blogs based on how many of the hub-blogs link to them.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def top_five_authorities():
    """the top 5 blogs by authorities score

    Returns:
     list (str): names of the most authoratative blogs
    """
    return top_five(AUTHORITIES)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print("Top Five Authoratative Blogs")
authoratative_blogs = top_five_authorities()
for blog in authoratative_blogs:
    print(" - {}".format(blog))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>centrality</category><category>networks</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/networks/friends-and-politics/</guid><pubDate>Sat, 13 Apr 2019 18:40:48 GMT</pubDate></item><item><title>Company E-Mail</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/networks/company-e-mail/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/company-e-mail/#orga8da806"&gt;Tangle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/company-e-mail/#org2c451b2"&gt;Imports&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/company-e-mail/#orga9e6ed6"&gt;1 - Load the Directed Multigraph&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/company-e-mail/#orgec38d94"&gt;Number of employees and emails&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/company-e-mail/#org752a5e2"&gt;Information Routes&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/company-e-mail/#org8839161"&gt;Part 1. Assume that information in this company can only be exchanged through email.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/company-e-mail/#org5e6c549"&gt;Part 2. Now assume that a communication channel established by an email allows information to be exchanged both ways.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/company-e-mail/#org024ed72"&gt;Largest Weakly Connected Component&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
This will go through the process of importing and analyzing an internal email communication network between employees of a mid-sized manufacturing company. 
Each node represents an employee and each directed edge between two nodes represents an individual email. The left node represents the sender and the right node represents the recipient.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;+------+      +--------+
|Sender| --&amp;gt;  |Receiver|
+------+      +--------+
&lt;/pre&gt;&lt;/div&gt;

&lt;div id="outline-container-orga8da806" class="outline-2"&gt;
&lt;h2 id="orga8da806"&gt;Tangle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orga8da806"&gt;
&lt;p&gt;
This is for troubleshooting.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;imports&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;answer&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;one&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org2c451b2" class="outline-2"&gt;
&lt;h2 id="org2c451b2"&gt;Imports&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org2c451b2"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;import networkx
import pandas
import seaborn
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;% matplotlib inline
seaborn.set_style("whitegrid")
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
This line must be commented out when submitting to the autograder
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;email_network = pandas.read_table('email_network.txt', dtype={"#Sender": str, "Recipient": str})
print(email_network.head())
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orga9e6ed6" class="outline-2"&gt;
&lt;h2 id="orga9e6ed6"&gt;1 - Load the Directed Multigraph&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orga9e6ed6"&gt;
&lt;p&gt;
Using networkx, load up the directed multigraph from `email&lt;sub&gt;network.txt&lt;/sub&gt;`. Make sure the node names are strings.
&lt;/p&gt;

&lt;p&gt;
&lt;b&gt;This function should return a directed multigraph networkx graph.&lt;/b&gt;
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def answer_one():
    """Loads the email-network graph

    Returns:
     networkx.MultiDiGraph: the graph of the email network
    """
    # there's a bug in networkx loading MultiDiGraphs from pandas data-frames
    # so this is a work-around
    graph = networkx.MultiDiGraph()
    tuples = [(sender, recipient, {"time": time})
	      for (sender, recipient, time) in email_network.values]
    graph.add_edges_from(tuples)
    return graph
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;one = answer_one()
networkx.draw_networkx(one)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgec38d94" class="outline-2"&gt;
&lt;h2 id="orgec38d94"&gt;Number of employees and emails&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgec38d94"&gt;
&lt;p&gt;
How many employees and emails are represented in the graph from Question 1?
&lt;/p&gt;

&lt;p&gt;
&lt;b&gt;This function should return a tuple (#employees, #emails).&lt;/b&gt;
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def answer_two():
    """Counts the number of employees and emails

    Returns:
     tuple: count of employees, count of emails
    """
    one = answer_one()
    return (one.order(), one.size())
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(answer_two())
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org752a5e2" class="outline-2"&gt;
&lt;h2 id="org752a5e2"&gt;Information Routes&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org752a5e2"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org8839161" class="outline-3"&gt;
&lt;h3 id="org8839161"&gt;Part 1. Assume that information in this company can only be exchanged through email.&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org8839161"&gt;
&lt;p&gt;
When an employee sends an email to another employee, a communication channel has been created, allowing the sender to provide information to the receiver, but not vice versa. 
&lt;/p&gt;

&lt;p&gt;
Based on the emails sent in the data, is it possible for information to go from every employee to every other employee?
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org5e6c549" class="outline-3"&gt;
&lt;h3 id="org5e6c549"&gt;Part 2. Now assume that a communication channel established by an email allows information to be exchanged both ways.&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org5e6c549"&gt;
&lt;p&gt;
Based on the emails sent in the data, is it possible for information to go from every employee to every other employee?
&lt;/p&gt;

&lt;p&gt;
&lt;b&gt;This function should return a tuple of bools (part1, part2).&lt;/b&gt;
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def answer_three():
    """decides connectivity based on emails

    First: Assume communication is not necessarily allowed both ways - 
    based on data, can every employee contact each other?

    Second: Assume any contact means there's two way communication. 
    Can every employee be contacted?

    Returns:
     tuple: (every employee contacted every other employee, every employee contacted once)
    """
    emails = answer_one()
    nodes = emails.nodes()
    other_nodes = len(nodes) - 1
    fully_connected = all((len(emails.neighbors(node)) == other_nodes for node in nodes))
    undirected = emails.to_undirected()
    all_connected = True
    for left_node in nodes:
	for right_node in nodes:
	    if left_node != right_node and not undirected.has_edge(left_node, right_node):
		all_connected = False
		break
	if not all_connected:
	    break
    return fully_connected, all_connected
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(answer_three())
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org024ed72" class="outline-2"&gt;
&lt;h2 id="org024ed72"&gt;Largest Weakly Connected Component&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org024ed72"&gt;
&lt;p&gt;
How many nodes are in the largest (in terms of nodes) weakly connected component?
&lt;/p&gt;

&lt;p&gt;
&lt;b&gt;This function should return an int.&lt;/b&gt;
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def answer_four():
    """Count of nodes in the largest weakly connected component"""
    one = answer_one()
    return len(max(networkx.weakly_connected_component_subgraphs(one), key=len).nodes())
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
According to &lt;a href="https://en.wikipedia.org/wiki/Connectivity_(graph_theory)#Definitions_of_components.2C_cuts_and_connectivity"&gt;Wikipedia&lt;/a&gt;, a directed graph is weakly connected if replacing every directed edge with an undirected one creates a connected graph, so if the undirected graph in the next section is a connected graph, then the entire email graph is weakly connected.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(answer_four())
undirected = one.to_undirected()
print(networkx.is_connected(undirected))
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;
def answer&lt;sub&gt;five&lt;/sub&gt;():
&lt;/p&gt;

&lt;p&gt;
return # Your Answer Here
&lt;/p&gt;


&lt;p&gt;
def answer&lt;sub&gt;six&lt;/sub&gt;():
&lt;/p&gt;

&lt;p&gt;
return # Your Answer Here
&lt;/p&gt;


&lt;p&gt;
def answer&lt;sub&gt;seven&lt;/sub&gt;():
&lt;/p&gt;

&lt;p&gt;
return # Your Answer Here
&lt;/p&gt;


&lt;p&gt;
def answer&lt;sub&gt;eight&lt;/sub&gt;():
&lt;/p&gt;

&lt;p&gt;
return # Your Answer Here
&lt;/p&gt;


&lt;p&gt;
def answer&lt;sub&gt;nine&lt;/sub&gt;():
&lt;/p&gt;

&lt;p&gt;
return # Your Answer Here
&lt;/p&gt;


&lt;p&gt;
def answer&lt;sub&gt;ten&lt;/sub&gt;():
&lt;/p&gt;

&lt;p&gt;
return # Your Answer Here
&lt;/p&gt;


&lt;p&gt;
def answer&lt;sub&gt;eleven&lt;/sub&gt;():
&lt;/p&gt;

&lt;p&gt;
return # Your Answer Here
&lt;/p&gt;


&lt;p&gt;
def answer&lt;sub&gt;twelve&lt;/sub&gt;():
&lt;/p&gt;

&lt;p&gt;
return # Your Answer Here
&lt;/p&gt;


&lt;p&gt;
def answer&lt;sub&gt;thirteen&lt;/sub&gt;():
&lt;/p&gt;

&lt;p&gt;
return # Your Answer Here
&lt;/p&gt;


&lt;p&gt;
def answer&lt;sub&gt;fourteen&lt;/sub&gt;():
&lt;/p&gt;

&lt;p&gt;
return # Your Answer Here
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>networks</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/networks/company-e-mail/</guid><pubDate>Sat, 13 Apr 2019 18:34:37 GMT</pubDate></item><item><title>Some Networkx Examples</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/networks/some-networkx-examples/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/some-networkx-examples/#org87f7995"&gt;The Departure&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/some-networkx-examples/#org14675b2"&gt;Imports&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/some-networkx-examples/#orgc5bc91b"&gt;Set Up&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/some-networkx-examples/#orgea00c44"&gt;The Initiation&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/some-networkx-examples/#org89e016d"&gt;Different Ways to Create Network Graphs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/some-networkx-examples/#org463b0af"&gt;A Chess Example&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/some-networkx-examples/#orgc3bb999"&gt;The Return&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org87f7995" class="outline-2"&gt;
&lt;h2 id="org87f7995"&gt;The Departure&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org87f7995"&gt;
&lt;p&gt;
This is a look at different ways of creating and manipulating graphs using &lt;a href="https://networkx.github.io"&gt;NetworkX&lt;/a&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-org14675b2" class="outline-3"&gt;
&lt;h3 id="org14675b2"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org14675b2"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgbdcbb4a" class="outline-4"&gt;
&lt;h4 id="orgbdcbb4a"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgbdcbb4a"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from functools import partial
from pathlib import Path
import os
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org56144b4" class="outline-4"&gt;
&lt;h4 id="org56144b4"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org56144b4"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from bokeh.models import HoverTool
import holoviews
import hvplot.pandas
import networkx
import numpy
import pandas
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgfb165c9" class="outline-4"&gt;
&lt;h4 id="orgfb165c9"&gt;My Stuff&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgfb165c9"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from graeae.visualization import EmbedHoloview
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgc5bc91b" class="outline-3"&gt;
&lt;h3 id="orgc5bc91b"&gt;Set Up&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgc5bc91b"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;SLUG = "some-networkx-examples"
OUTPUT_PATH = Path("../../files/posts/networks/" + SLUG)
Embed = partial(EmbedHoloview, folder_path=OUTPUT_PATH)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgea00c44" class="outline-2"&gt;
&lt;h2 id="orgea00c44"&gt;The Initiation&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgea00c44"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org89e016d" class="outline-3"&gt;
&lt;h3 id="org89e016d"&gt;Different Ways to Create Network Graphs&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org89e016d"&gt;
&lt;p&gt;
&lt;b&gt;NetworkX&lt;/b&gt; has a few different ways to create graphs, some more flexible than others. This is a non-exhaustive showing of some of them.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-org80f975a" class="outline-4"&gt;
&lt;h4 id="org80f975a"&gt;Adding Edges To An Existing Graph&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org80f975a"&gt;
&lt;p&gt;
You can create a graph using the graph constructors. This is an example of an undirected &lt;a href="https://networkx.github.io/documentation/stable/reference/classes/graph.html"&gt;Graph&lt;/a&gt;.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;graph_1 = networkx.Graph()
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;G1.add_edges_from([(0, 1),
		   (0, 2),
		   (0, 3),
		   (0, 5),
		   (1, 3),
		   (1, 6),
		   (3, 4),
		   (4, 5),
		   (4, 7),
		   (5, 8),
		   (8, 9)])

networkx.draw_networkx(G1)
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="file:///tmp/graph_one.png" alt="graph_one.png"&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org105c70a" class="outline-4"&gt;
&lt;h4 id="org105c70a"&gt;Adjacency List&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org105c70a"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;with open("G_adjlist.txt") as reader:
    print(reader.read())
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;G2 = networkx.read_adjlist('G_adjlist.txt', nodetype=int)
G2.edges()
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org71b7368" class="outline-4"&gt;
&lt;h4 id="org71b7368"&gt;Adjacency Matrix&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org71b7368"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;G_mat = numpy.array([[0, 1, 1, 1, 0, 1, 0, 0, 0, 0],
		     [1, 0, 0, 1, 0, 0, 1, 0, 0, 0],
		     [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
		     [1, 1, 0, 0, 1, 0, 0, 0, 0, 0],
		     [0, 0, 0, 1, 0, 1, 0, 1, 0, 0],
		     [1, 0, 0, 0, 1, 0, 0, 0, 1, 0],
		     [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
		     [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
		     [0, 0, 0, 0, 0, 1, 0, 0, 0, 1],
		     [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]])
G_mat
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;G3 = networkx.Graph(G_mat)
G3.edges()
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org6d639c7" class="outline-4"&gt;
&lt;h4 id="org6d639c7"&gt;Edgelist&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org6d639c7"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;with open('G_edgelist.txt') as reader:
    print(reader.read())
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;G4 = networkx.read_edgelist('G_edgelist.txt', data=[('Weight', int)])

G4.edges(data=True)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org6ded988" class="outline-4"&gt;
&lt;h4 id="org6ded988"&gt;Pandas DataFrame&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org6ded988"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;G_df = pandas.read_csv('G_edgelist.txt', delim_whitespace=True, 
		       header=None, names=['n1', 'n2', 'weight'])
G_df
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;G5 = networkx.from_pandas_dataframe(G_df, 'n1', 'n2', edge_attr='weight')
G5.edges(data=True)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org463b0af" class="outline-3"&gt;
&lt;h3 id="org463b0af"&gt;A Chess Example&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org463b0af"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;with open('chess_graph.txt') as reader:
    count = 0
    for line in reader:
	print(line.strip())
	count += 1
	if count == 5:
	    break
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;chess = networkx.read_edgelist('chess_graph.txt', data=[('outcome', int), ('timestamp', float)], 
			 create_using=networkx.MultiDiGraph())
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;chess.is_directed(), chess.is_multigraph()
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;chess.edges(data=True)[:5]
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;games_played = chess.degree()
games_played
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;max_value = max(games_played.values())
max_key, = [i for i in games_played.keys() if games_played[i] == max_value]

print('player {}\n{} games'.format(max_key, max_value))
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;df = pd.DataFrame(chess.edges(data=True), columns=['white', 'black', 'outcome'])
df.head()
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;df['outcome'] = df['outcome'].map(lambda x: x['outcome'])
df.head()
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;won_as_white = df[df['outcome']==1].groupby('white').sum()
won_as_black = df[df['outcome']==-1].groupby('black').sum()
win_count = won_as_white.add(won_as_black, fill_value=0)
print(win_count.head())
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;win_count.nlargest(5, 'outcome')
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgc3bb999" class="outline-2"&gt;
&lt;h2 id="orgc3bb999"&gt;The Return&lt;/h2&gt;
&lt;/div&gt;</description><category>networks</category><category>networkx</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/networks/some-networkx-examples/</guid><pubDate>Fri, 12 Apr 2019 20:12:58 GMT</pubDate></item><item><title>Company Movie Night</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/networks/company-moving-night/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/company-moving-night/#org2bc9d7e"&gt;The Departure&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/company-moving-night/#org23b5893"&gt;Imports&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/company-moving-night/#orgb5dd9c8"&gt;Set Up&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/company-moving-night/#org3d59bef"&gt;The Plotting&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/company-moving-night/#orgca2c334"&gt;The Initiation&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/company-moving-night/#org682623f"&gt;The Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/company-moving-night/#org9acb9d3"&gt;Plot Graph&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/company-moving-night/#org80c0970"&gt;The Employee Movie Choices Graph&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/company-moving-night/#org73e9f2c"&gt;Question 2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/company-moving-night/#org4934d2c"&gt;Question 3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/company-moving-night/#orgf0d4a96"&gt;Question 4&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/company-moving-night/#orgb72da45"&gt;The Return&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org2bc9d7e" class="outline-2"&gt;
&lt;h2 id="org2bc9d7e"&gt;The Departure&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org2bc9d7e"&gt;
&lt;p&gt;
This is a look at working with networks using &lt;a href="https://networkx.github.io"&gt;networkx&lt;/a&gt;. Our scene - eight employees are trying to choose three movies to watch. We have two sources of data - the candidate movies and the &lt;i&gt;relationship&lt;/i&gt; between pairs of employees. The relationships are on a scale from -100 to 100, with -100 being the strongest of enemies and 100 meaning they are best of friends. Zero either means they have no relationship (don't interact) or are indifferent about the other person.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-org23b5893" class="outline-3"&gt;
&lt;h3 id="org23b5893"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org23b5893"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgc8c8630" class="outline-4"&gt;
&lt;h4 id="orgc8c8630"&gt;From Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgc8c8630"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from functools import partial
from pathlib import Path
import os
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org561316d" class="outline-4"&gt;
&lt;h4 id="org561316d"&gt;From PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org561316d"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from dotenv import load_dotenv
from bokeh.models import HoverTool
import holoviews
import hvplot.pandas
import networkx
import pandas
import numpy
from networkx.algorithms import bipartite
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7479a5f" class="outline-4"&gt;
&lt;h4 id="org7479a5f"&gt;My Stuff&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org7479a5f"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from graeae.visualization import EmbedHoloview
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgb5dd9c8" class="outline-3"&gt;
&lt;h3 id="orgb5dd9c8"&gt;Set Up&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgb5dd9c8"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgd00db63" class="outline-4"&gt;
&lt;h4 id="orgd00db63"&gt;Load Dotenv&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgd00db63"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;load_dotenv(".env", override=True)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org3d59bef" class="outline-3"&gt;
&lt;h3 id="org3d59bef"&gt;The Plotting&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org3d59bef"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;SLUG = 'company-movie-night'
OUTPUT = Path("../../files/posts/networks/" + SLUG)
Embed = partial(EmbedHoloview, folder_path=OUTPUT)
holoviews.extension("bokeh")
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgca2c334" class="outline-2"&gt;
&lt;h2 id="orgca2c334"&gt;The Initiation&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgca2c334"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org682623f" class="outline-3"&gt;
&lt;h3 id="org682623f"&gt;The Data&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org682623f"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgbc5dc1e" class="outline-4"&gt;
&lt;h4 id="orgbc5dc1e"&gt;This Is the Set Of Employee-Relationships&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgbc5dc1e"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;employee_relationships_path = Path(os.environ.get("EMPLOYEE_RELATIONSHIPS"))
relationships_data = pandas.read_csv(
    employee_relationships_path, 
    delimiter="\t", 
    header=None,
    names="employee_1 employee_2 relationship".split())
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;table = holoviews.Table(relationships_data)
Embed(plot=table, file_name="relationships_data")()
&lt;/pre&gt;&lt;/div&gt;

&lt;object type="text/html" data="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/company-moving-night/relationships_data.html" style="width:100%" height="800"&gt;
  &lt;p&gt;Figure Missing&lt;/p&gt;
&lt;/object&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;employees = set(relationships_data.employee_1.unique()) | set(relationships_data.employee_2.unique())
print(employees)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
{'Claude', 'Pablo', 'Lee', 'Andy', 'Vincent', 'Joan', 'Frida', 'Georgia'}

&lt;/pre&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(len(employees))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
8

&lt;/pre&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(len(relationships_data))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
28

&lt;/pre&gt;

&lt;p&gt;
We have eight employees and twenty-eight links. Is this a fully connected graph? The handshake problem says that the amount of links in a fully-connected network is:
&lt;/p&gt;

&lt;p&gt;
\[
 links = \frac{n(n-1)}{2}
\]
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(len(employees) * (len(employees) - 1)/2)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
28.0

&lt;/pre&gt;

&lt;p&gt;
It looks like our relationships data creates a fully-connected network (unless there is a duplicate which would be an error).
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org05df5ff" class="outline-4"&gt;
&lt;h4 id="org05df5ff"&gt;This Is the Movie Choices&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org05df5ff"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;employee_movies_path = Path(os.environ.get("EMPLOYEE_MOVIE_CHOICES"))
movies_data = pandas.read_csv(
    employee_movies_path, 
    delimiter="\t", 
    header=None,
    skiprows=1,
    names="employee movie".split())
print(movies_data.head())
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
  employee                            movie
0     Andy                         Anaconda
1     Andy                       Mean Girls
2     Andy                       The Matrix
3   Claude                         Anaconda
4   Claude  Monty Python and the Holy Grail

&lt;/pre&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;movies = set(movies_data.movie.unique())
print(movies)
print(len(movies))
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
The eight employees chose 11 movies between them.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org9acb9d3" class="outline-3"&gt;
&lt;h3 id="org9acb9d3"&gt;Plot Graph&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org9acb9d3"&gt;
&lt;p&gt;
You can use the following function to plot graphs.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def plot_graph(graph, file_name, plot_title, weight_name=None, directed=False):
    """Plots an interactive graph using the spring-layout

    Args:
     graph: a networkx graph
     file_name: name to store the plot (without extension)
     plot_title: name to give the plot
     weight_name: name of the attribute for plotting edge weights (if G is weighted)
     directed: whether it is a directed graph
    """
    plot = holoviews.Graph.from_networkx(graph,
					 networkx.spring_layout).opts(
					     cmap="Set1",                                             
					     fontsize=Plot.fontsize,
					     width=Plot.width,
					     height=Plot.height,
					     edge_line_color=Plot.edge_color,
					     title=plot_title,
					     xaxis=None, yaxis=None, directed=directed)
    Embed(plot=plot, file_name=file_name)()
    return
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org80c0970" class="outline-3"&gt;
&lt;h3 id="org80c0970"&gt;The Employee Movie Choices Graph&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org80c0970"&gt;
&lt;p&gt;
The employee-movie network consists of employees and movies as nodes and the edges indicate an employee chose a movie. Not every movie is chosen by every employee, so it isn't a complete graph.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;expected_edges = len(movies_data)
expected_nodes = len(employees) + len(movies)
print("Expected Edges: {}".format(expected_edges))
print("Expected Nodes: {}".format(expected_nodes))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Expected Edges: 24
Expected Nodes: 19

&lt;/pre&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;plot = holoviews.Graph.from_networkx(friendship_graph,
				     networkx.circular_layout).opts(
					 node_color=dim("gender"), cmap="Set1",
					 tools=[hover],
					 fontsize=Plot.fontsize,
					 width=800,
					 height=800,
					 edge_line_color=Plot.edge_color,
					 title="Friendship Network by Gender",
					 xaxis=None, yaxis=None, directed=True)
Embed(plot=plot, file_name="employee_movie_choices_plot")()
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def answer_one():
    """Loads the Employee Movie Choices

    Returns:
     Graph: graph with movie and employees as nodes
    """
    movie_choices = pandas.read_table('Employee_Movie_Choices.txt')
    movie_choices = networkx.from_pandas_dataframe(movie_choices, "#Employee", "Movie")
    return movie_choices
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;movie_choices = answer_one()
edges = movie_choices.edges()
assert len(edges) == 24
assert len(movie_choices.nodes()) == 19
assert networkx.is_bipartite(movie_choices)
positions = networkx.spring_layout(movie_choices)

networkx.draw_networkx(movie_choices, positions, edges=edges)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org73e9f2c" class="outline-3"&gt;
&lt;h3 id="org73e9f2c"&gt;Question 2&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org73e9f2c"&gt;
&lt;p&gt;
Using the graph from the previous question, add nodes attributes named `'type'` where movies have the value `'movie'` and employees have the value `'employee'` and return that graph.
&lt;/p&gt;

&lt;p&gt;
&lt;b&gt;This function should return a networkx graph with node attributes `{'type': 'movie'}` or `{'type': 'employee'}`&lt;/b&gt;
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def answer_two():
    """Adds 'type' to nodes from movie-graph

    Returns:
     Graph: answer_one with 'type' attribute added (employee or movie)
    """
    graph = answer_one()
    new_graph = networkx.Graph()
    nodes = graph.nodes()
    employee_nodes = [node for node in nodes if node in employees]
    movie_nodes = [node for node in nodes if node in movies]
    new_graph.add_nodes_from(employee_nodes, bipartite=0, type='employee')
    new_graph.add_nodes_from(movie_nodes, bipartite=1, type="movie")
    new_graph.add_edges_from(graph.edges())
    return new_graph
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;two = answer_two()
two.nodes(data=True)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;plot_graph(two)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org4934d2c" class="outline-3"&gt;
&lt;h3 id="org4934d2c"&gt;Question 3&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org4934d2c"&gt;
&lt;p&gt;
Find a weighted projection of the graph from `answer&lt;sub&gt;two&lt;/sub&gt;` which tells us how many movies different pairs of employees have in common.
&lt;/p&gt;

&lt;p&gt;
&lt;b&gt;This function should return a weighted projected graph.&lt;/b&gt;
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def answer_three():
    graph = answer_two()
    assert networkx.is_bipartite(graph)
    return bipartite.weighted_projected_graph(graph, employees)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;three = answer_three()
plot_graph(three)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgf0d4a96" class="outline-3"&gt;
&lt;h3 id="orgf0d4a96"&gt;Question 4&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgf0d4a96"&gt;
&lt;p&gt;
Suppose you'd like to find out if people that have a high relationship score also like the same types of movies.
&lt;/p&gt;

&lt;p&gt;
Find the Pearson correlation ( using `DataFrame.corr()` ) between employee relationship scores and the number of movies they have in common. If two employees have no movies in common it should be treated as a 0, not a missing value, and should be included in the correlation calculation.
&lt;/p&gt;

&lt;p&gt;
&lt;b&gt;This function should return a float.&lt;/b&gt;
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def answer_four():
    """calculates the pearson correlation for data

    Returns:
     float: Pearson correlation for weight and relationship_score
    """
    three = answer_three()
    relationships = pandas.read_table(
	"Employee_Relationships.txt",
	names="employee_left employee_right relationship_score".split())
    relationships["employees"] = relationships.apply(
	lambda row: tuple(sorted((row["employee_left"],
				  row['employee_right']))), axis=1)

    weights = pandas.DataFrame(
	three.edges(data=True),
	columns="employee_left employee_right weight".split())
    weights["weight"] = weights.weight.map(lambda row: row["weight"])
    weights["employees"] = weights.apply(lambda row: tuple(sorted(
	(row["employee_left"],
	 row["employee_right"]))),
					 axis=1)

    joined = pandas.merge(relationships, weights, how="outer", 
			  on=['employees'])
    assert len(joined) == len(relationships)
    joined['weight'] = joined["weight"].fillna(0)

    data = joined[["relationship_score", "weight"]]
    correlation = data.corr()
    return correlation.relationship_score.weight
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(answer_four())
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgb72da45" class="outline-2"&gt;
&lt;h2 id="orgb72da45"&gt;The Return&lt;/h2&gt;
&lt;/div&gt;</description><category>networks</category><category>networkx</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/networks/company-moving-night/</guid><pubDate>Thu, 11 Apr 2019 20:04:23 GMT</pubDate></item><item><title>Getting Started With Prophet</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/prophet/getting-started-with-prophet/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/prophet/getting-started-with-prophet/#org60746f0"&gt;The Departure&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/prophet/getting-started-with-prophet/#orgd5c6a3c"&gt;Imports&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/prophet/getting-started-with-prophet/#org05ebdeb"&gt;Setup&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/prophet/getting-started-with-prophet/#orgf8599f6"&gt;The Initiation&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/prophet/getting-started-with-prophet/#orgf70637c"&gt;Load The Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org60746f0" class="outline-2"&gt;
&lt;h2 id="org60746f0"&gt;The Departure&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org60746f0"&gt;
&lt;p&gt;
This is a first look at &lt;a href="https://facebook.github.io/prophet/"&gt;Prophet&lt;/a&gt; a time-series forecasting library. It depends on &lt;code&gt;pystan&lt;/code&gt;, a Bayesian modelling platform, which in turn depends on &lt;code&gt;numpy&lt;/code&gt; and &lt;code&gt;cython&lt;/code&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgd5c6a3c" class="outline-3"&gt;
&lt;h3 id="orgd5c6a3c"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgd5c6a3c"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orge1d6939" class="outline-4"&gt;
&lt;h4 id="orge1d6939"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orge1d6939"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from pathlib import Path
import os
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgca8ceb5" class="outline-4"&gt;
&lt;h4 id="orgca8ceb5"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgca8ceb5"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from dotenv import load_dotenv
import modin.pandas as pandas
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgcafcba7" class="outline-4"&gt;
&lt;h4 id="orgcafcba7"&gt;My Stuff&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgcafcba7"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from graeae.timers import Timer
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org05ebdeb" class="outline-3"&gt;
&lt;h3 id="org05ebdeb"&gt;Setup&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org05ebdeb"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org30fd0f5" class="outline-4"&gt;
&lt;h4 id="org30fd0f5"&gt;The Paths&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org30fd0f5"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;load_dotenv(".env", override=True)
DATA = Path(os.environ.get("PEYTON_MANNING_WIKIPEDIA_VIEWS")).expanduser()
assert DATA.is_file()
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgd569bf6" class="outline-4"&gt;
&lt;h4 id="orgd569bf6"&gt;The Timer&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgd569bf6"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;TIMER = Timer()
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgf8599f6" class="outline-2"&gt;
&lt;h2 id="orgf8599f6"&gt;The Initiation&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgf8599f6"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgf70637c" class="outline-3"&gt;
&lt;h3 id="orgf70637c"&gt;Load The Data&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgf70637c"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;with TIMER:
    data = pandas.read_csv(DATA)
print(data.shape)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
WARNING: Falling back to serializing objects of type &amp;lt;class 'pathlib.PosixPath'&amp;gt; by using pickle. This may be inefficient.
Started: 2019-04-05 15:23:56.038686
Ended: 2019-04-05 15:23:56.236422
Elapsed: 0:00:00.197736
(2905, 2)

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>prophet</category><category>timeseries</category><category>tutorial</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/prophet/getting-started-with-prophet/</guid><pubDate>Fri, 05 Apr 2019 21:53:40 GMT</pubDate></item><item><title>High School Contact Networks</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/networks/high-school-contact-networks/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/high-school-contact-networks/#org774e9d9"&gt;The Departure&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/high-school-contact-networks/#org8416791"&gt;Setup The Plotting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/high-school-contact-networks/#orgd45eb7b"&gt;Load The Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/high-school-contact-networks/#org819fb51"&gt;The Descent&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/high-school-contact-networks/#org27ca107"&gt;End&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/high-school-contact-networks/#org2e3db1d"&gt;Citations&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org774e9d9" class="outline-2"&gt;
&lt;h2 id="org774e9d9"&gt;The Departure&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org774e9d9"&gt;
&lt;p&gt;
This looks at data provided by &lt;a href="http://www.sociopatterns.org"&gt;SocioPatterns&lt;/a&gt; that looks a the interactions between students at a High School in Marseilles, France, in December of 2013.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-org66ddbd0" class="outline-4"&gt;
&lt;h4 id="org66ddbd0"&gt;Imports&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org66ddbd0"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgfeca3d8" class="outline-5"&gt;
&lt;h5 id="orgfeca3d8"&gt;From Python&lt;/h5&gt;
&lt;div class="outline-text-5" id="text-orgfeca3d8"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from collections import Counter
from functools import partial
from pathlib import Path
import os
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org08c7377" class="outline-5"&gt;
&lt;h5 id="org08c7377"&gt;From PyPi&lt;/h5&gt;
&lt;div class="outline-text-5" id="text-org08c7377"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from bokeh.models import HoverTool
from dotenv import load_dotenv
from holoviews import dim, opts
from holoviews.operation.datashader import datashade, bundle_graph
import holoviews
import hvplot.pandas
import networkx
import pandas as pandas
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org271ec56" class="outline-5"&gt;
&lt;h5 id="org271ec56"&gt;My Stuff&lt;/h5&gt;
&lt;div class="outline-text-5" id="text-org271ec56"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from graeae.timers import Timer
from graeae.visualization import EmbedHoloview
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org3ef45c5" class="outline-4"&gt;
&lt;h4 id="org3ef45c5"&gt;Load the Dotenv&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org3ef45c5"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;load_dotenv(".env")
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org500ba9a" class="outline-4"&gt;
&lt;h4 id="org500ba9a"&gt;Build the Timer&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org500ba9a"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;TIMER = Timer()
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org8416791" class="outline-3"&gt;
&lt;h3 id="org8416791"&gt;Setup The Plotting&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org8416791"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;holoviews.extension("bokeh")
SLUG = "high-school-contact-networks/"
output = Path("../../files/posts/networks/" + SLUG)
Embed = partial(EmbedHoloview, folder_path=output)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class Plot:
    """Constants for plotting"""
    width = 1000
    height = 800
    fontsize = 18
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgd45eb7b" class="outline-3"&gt;
&lt;h3 id="orgd45eb7b"&gt;Load The Data&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgd45eb7b"&gt;
&lt;p&gt;
Let's take a look at the data before loading it into pandas.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;HIGH_SCHOOL = Path(os.environ.get("HIGH_SCHOOL")).expanduser()
assert HIGH_SCHOOL.is_dir()

#+begin_src ipython :session highschool :results none
class Files:
    metadata = "metadata_2013.txt"
    contact_diaries = "Contact-diaries-network_data_2013.csv"
    facebook = "Facebook-known-pairs_data_2013.csv"
    friendship = "Friendship-network_data_2013.csv"
    high_school = "High-School_data_2013.csv"
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orge6f14c4" class="outline-4"&gt;
&lt;h4 id="orge6f14c4"&gt;MetaData&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orge6f14c4"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;metadata_path = HIGH_SCHOOL.joinpath(Files.metadata)
assert metadata_path.is_file()
with metadata_path.open() as reader:
    for line in range(5):
	print(reader.readline(), end="")
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
650	2BIO1	F
498	2BIO1	F
627	2BIO1	F
857	2BIO1	F
487	2BIO1	F

&lt;/pre&gt;

&lt;p&gt;
This first file has the meta-data for the students. The three columns are the student's ID, class, and gender.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;meta_data = pandas.read_csv(metadata_path, sep="\t", 
			    names=["id", "class", "gender"])
meta_data.loc[:, "class"] = meta_data["class"].astype("category")
meta_data.loc[:, "gender"] = meta_data.gender.astype("category")
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orga3eb430" class="outline-5"&gt;
&lt;h5 id="orga3eb430"&gt;Classes&lt;/h5&gt;
&lt;div class="outline-text-5" id="text-orga3eb430"&gt;
&lt;p&gt;
First a bar-plot to look at how the classes are distributed.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;grouped = meta_data.groupby(["class", "gender"]).agg(
    {"class": "count", "gender": "count"})
grouped.columns = ["class_count", "gender_count"]
grouped = grouped.reset_index()
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;plot = grouped.hvplot.bar(title="Class Counts by Gender", 
			  x="class", y="class_count", 
			  stacked=True,
			  by="gender", height=Plot.height, 
			  width=Plot.width,
			  ylabel="Count",
			  xlabel="Class",
			  tools=["hover"],
			  fontsize=Plot.fontsize).opts(xrotation=90)
Embed(plot=plot, file_name="gender_counts_stacked", height_in_pixels=Plot.height)()
&lt;/pre&gt;&lt;/div&gt;

&lt;object type="text/html" data="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/high-school-contact-networks/gender_counts_stacked.html" style="width:100%" height="800"&gt;
  &lt;p&gt;Figure Missing&lt;/p&gt;
&lt;/object&gt;

&lt;p&gt;
&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/high-school-contact-networks/gender_counts_stacked.html"&gt;Link to Plot&lt;/a&gt;
&lt;/p&gt;

&lt;p&gt;
This is a look at the same thing except not stacked.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;plot = grouped.hvplot.bar(title="Class Counts by Gender", x="class", 
			  y="class_count",
			  xlabel="Class",
			  ylabel="Count",
			  by="gender", height=Plot.height, width=Plot.width, 
			  tools=["hover"],
			  fontsize=Plot.fontsize).opts(xrotation=90)
Embed(plot=plot, file_name="gender_counts", height_in_pixels=Plot.height)()
&lt;/pre&gt;&lt;/div&gt;

&lt;object type="text/html" data="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/high-school-contact-networks/gender_counts.html" style="width:100%" height="800"&gt;
  &lt;p&gt;Figure Missing&lt;/p&gt;
&lt;/object&gt;

&lt;p&gt;
&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/high-school-contact-networks/gender_counts.html"&gt;Link to Plot&lt;/a&gt;
&lt;/p&gt;

&lt;p&gt;
Strangely, the classes that start with &lt;code&gt;2BIO&lt;/code&gt; are more female while the others are more male.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgb76cbdd" class="outline-5"&gt;
&lt;h5 id="orgb76cbdd"&gt;Gender&lt;/h5&gt;
&lt;div class="outline-text-5" id="text-orgb76cbdd"&gt;
&lt;p&gt;
A stacked bar plot to get a sense of not just the distribution among genders but among classes.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;plot = grouped.hvplot.bar(title="Gender Counts", x="gender", y="gender_count",
			  stacked=True,
			  by="class", 
			  xlabel="Count",
			  ylabel="Gender",
			  fontsize=Plot.fontsize,
			  width=Plot.width,
			  height=Plot.height).opts(
			      xrotation=90, 
			      xlabel="Gender and Class")
Embed(plot=plot, file_name="class_counts_stacked", height_in_pixels=Plot.height)()
&lt;/pre&gt;&lt;/div&gt;

&lt;object type="text/html" data="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/high-school-contact-networks/class_counts_stacked.html" style="width:100%" height="800"&gt;
  &lt;p&gt;Figure Missing&lt;/p&gt;
&lt;/object&gt;

&lt;p&gt;
&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/high-school-contact-networks/class_counts_stacked.html"&gt;Link to Plot&lt;/a&gt;
&lt;/p&gt;

&lt;p&gt;
A non-stacked bar plot to get a better sense of how the genders fill the different classes.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;plot = grouped.hvplot.bar(title="Gender Counts", x="gender", y="gender_count",
			  xlabel="Gender",
			  ylabel="Count",
			  by="class", 
			  height=Plot.height,
			  width=Plot.width,
			  fontsize=Plot.fontsize).opts(
			      xrotation=90, xlabel="Gender and Class")
Embed(plot=plot, file_name="class_counts", height_in_pixels=Plot.height)()
&lt;/pre&gt;&lt;/div&gt;

&lt;object type="text/html" data="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/high-school-contact-networks/class_counts.html" style="width:100%" height="800"&gt;
  &lt;p&gt;Figure Missing&lt;/p&gt;
&lt;/object&gt;

&lt;p&gt;
&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/high-school-contact-networks/class_counts.html"&gt;Link to Plot&lt;/a&gt;
&lt;/p&gt;

&lt;p&gt;
It looks like there were a little more males than females, but not a whole lot more.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org819fb51" class="outline-2"&gt;
&lt;h2 id="org819fb51"&gt;The Descent&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org819fb51"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org9c05dcc" class="outline-4"&gt;
&lt;h4 id="org9c05dcc"&gt;The Contact Network&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org9c05dcc"&gt;
&lt;p&gt;
This is a dataset that shows whether a student logged contact with another student.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;contact_path = HIGH_SCHOOL.joinpath(Files.contact_diaries)
assert contact_path.is_file()
with contact_path.open() as reader:
    for line in range(5):
	print(reader.readline(), end="")
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
3 28 2
3 106 1
3 147 4
3 177 1
3 295 4

&lt;/pre&gt;

&lt;p&gt;
The columns are the person who was making the report, the person that was identified as a contact, and the time spent ecoded into one of four values.
&lt;/p&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-right"&gt;Code&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Lower Limit (minutes)&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Upper Limit (minutes)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-right"&gt;5&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;2&lt;/td&gt;
&lt;td class="org-right"&gt;5&lt;/td&gt;
&lt;td class="org-right"&gt;15&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;3&lt;/td&gt;
&lt;td class="org-right"&gt;15&lt;/td&gt;
&lt;td class="org-right"&gt;60&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;4&lt;/td&gt;
&lt;td class="org-right"&gt;60&lt;/td&gt;
&lt;td class="org-right"&gt;infinity&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;contact_data = pandas.read_csv(contact_path, delimiter=" ", 
				  names=["reporter", "contact", "time"])
contact_data = contact_data.dropna()
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org27ca107" class="outline-2"&gt;
&lt;h2 id="org27ca107"&gt;End&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org27ca107"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org2e3db1d" class="outline-3"&gt;
&lt;h3 id="org2e3db1d"&gt;Citations&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org2e3db1d"&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;R. Mastrandrea, J. Fournet, A. Barrat,&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
Contact patterns in a high school: a comparison between data collected using wearable sensors, contact diaries and friendship surveys.
PLoS ONE 10(9): e0136497 (2015)
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>exploration</category><category>networks</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/networks/high-school-contact-networks/</guid><pubDate>Thu, 28 Mar 2019 00:38:17 GMT</pubDate></item><item><title>High School Facebook Networks</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/networks/high-school-facebook-networks/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/high-school-facebook-networks/#org8b5d508"&gt;The Departure&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/high-school-facebook-networks/#orgf7ed5a0"&gt;Setup The Plotting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/high-school-facebook-networks/#org000ad90"&gt;Load The Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/high-school-facebook-networks/#orgb5d79df"&gt;The Descent&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/high-school-facebook-networks/#orgcd266b3"&gt;The Descent&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/high-school-facebook-networks/#org7b00256"&gt;Looking at the Friendship Network&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/high-school-facebook-networks/#org2c55dc1"&gt;End&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/high-school-facebook-networks/#org509ea5e"&gt;Citations&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org8b5d508" class="outline-2"&gt;
&lt;h2 id="org8b5d508"&gt;The Departure&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org8b5d508"&gt;
&lt;p&gt;
This looks at data provided by &lt;a href="http://www.sociopatterns.org"&gt;SocioPatterns&lt;/a&gt; that looks a the interactions between students at a High School in Marseilles, France, in December of 2013.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-org11891c6" class="outline-4"&gt;
&lt;h4 id="org11891c6"&gt;Imports&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org11891c6"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgbab260a" class="outline-5"&gt;
&lt;h5 id="orgbab260a"&gt;From Python&lt;/h5&gt;
&lt;div class="outline-text-5" id="text-orgbab260a"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from collections import Counter
from functools import partial
from pathlib import Path
import os
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org6adb087" class="outline-5"&gt;
&lt;h5 id="org6adb087"&gt;From PyPi&lt;/h5&gt;
&lt;div class="outline-text-5" id="text-org6adb087"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from bokeh.models import HoverTool
from dotenv import load_dotenv
from holoviews import dim, opts
from holoviews.operation.datashader import datashade, bundle_graph
import holoviews
import hvplot.pandas
import networkx
import pandas as pandas
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org6478d6c" class="outline-5"&gt;
&lt;h5 id="org6478d6c"&gt;My Stuff&lt;/h5&gt;
&lt;div class="outline-text-5" id="text-org6478d6c"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from graeae.timers import Timer
from graeae.visualization import EmbedBokeh, EmbedHoloview
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgaaef694" class="outline-4"&gt;
&lt;h4 id="orgaaef694"&gt;Load the Dotenv&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgaaef694"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;load_dotenv(".env")
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orga41344f" class="outline-4"&gt;
&lt;h4 id="orga41344f"&gt;Build the Timer&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orga41344f"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;TIMER = Timer()
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgf7ed5a0" class="outline-3"&gt;
&lt;h3 id="orgf7ed5a0"&gt;Setup The Plotting&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgf7ed5a0"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;holoviews.extension("bokeh")
SLUG = "high-school-contact-and-friendship-networks/"
output = Path("../../files/posts/networks/" + SLUG)
Embed = partial(EmbedHoloview, folder_path=output)
EmbedB = partial(EmbedBokeh, folder_path=output)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class Plot:
    """Constants for plotting"""
    width = 1000
    height = 800
    fontsize = 18
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org000ad90" class="outline-3"&gt;
&lt;h3 id="org000ad90"&gt;Load The Data&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org000ad90"&gt;
&lt;p&gt;
Let's take a look at the data before loading it into pandas.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;HIGH_SCHOOL = Path(os.environ.get("HIGH_SCHOOL")).expanduser()
assert HIGH_SCHOOL.is_dir()

#+begin_src ipython :session highschool :results none
class Files:
    metadata = "metadata_2013.txt"
    contact_diaries = "Contact-diaries-network_data_2013.csv"
    facebook = "Facebook-known-pairs_data_2013.csv"
    friendship = "Friendship-network_data_2013.csv"
    high_school = "High-School_data_2013.csv"
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org33b0740" class="outline-4"&gt;
&lt;h4 id="org33b0740"&gt;MetaData&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org33b0740"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;metadata_path = HIGH_SCHOOL.joinpath(Files.metadata)
assert metadata_path.is_file()
with metadata_path.open() as reader:
    for line in range(5):
	print(reader.readline(), end="")
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
650	2BIO1	F
498	2BIO1	F
627	2BIO1	F
857	2BIO1	F
487	2BIO1	F

&lt;/pre&gt;

&lt;p&gt;
This first file has the meta-data for the students. The three columns are the student's ID, class, and gender.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;meta_data = pandas.read_csv(metadata_path, sep="\t", 
			    names=["id", "class", "gender"])
meta_data.loc[:, "class"] = meta_data["class"].astype("category")
meta_data.loc[:, "gender"] = meta_data.gender.astype("category")
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgbe1437a" class="outline-5"&gt;
&lt;h5 id="orgbe1437a"&gt;Classes&lt;/h5&gt;
&lt;div class="outline-text-5" id="text-orgbe1437a"&gt;
&lt;p&gt;
First a bar-plot to look at how the classes are distributed.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;grouped = meta_data.groupby(["class", "gender"]).agg(
    {"class": "count", "gender": "count"})
grouped.columns = ["class_count", "gender_count"]
grouped = grouped.reset_index()
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;plot = grouped.hvplot.bar(title="Class Counts by Gender", 
			  x="class", y="class_count", 
			  stacked=True,
			  by="gender", height=Plot.height, 
			  width=Plot.width,
			  ylabel="Count",
			  xlabel="Class",
			  tools=["hover"],
			  fontsize=Plot.fontsize).opts(xrotation=90)
Embed(plot=plot, file_name="gender_counts_stacked", height_in_pixels=Plot.height)()
&lt;/pre&gt;&lt;/div&gt;

&lt;object type="text/html" data="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/high-school-facebook-networks/gender_counts_stacked.html" style="width:100%" height="800"&gt;
  &lt;p&gt;Figure Missing&lt;/p&gt;
&lt;/object&gt;

&lt;p&gt;
This is a look at the same thing except not stacked.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;plot = grouped.hvplot.bar(title="Class Counts by Gender", x="class", 
			  y="class_count",
			  xlabel="Class",
			  ylabel="Count",
			  by="gender", height=Plot.height, width=Plot.width, 
			  tools=["hover"],
			  fontsize=Plot.fontsize).opts(xrotation=90)
Embed(plot=plot, file_name="gender_counts", height_in_pixels=Plot.height)()
&lt;/pre&gt;&lt;/div&gt;

&lt;object type="text/html" data="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/high-school-facebook-networks/gender_counts.html" style="width:100%" height="800"&gt;
  &lt;p&gt;Figure Missing&lt;/p&gt;
&lt;/object&gt;

&lt;p&gt;
Strangely, the classes that start with &lt;code&gt;2BIO&lt;/code&gt; are more female while the others are more male.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org68df08d" class="outline-5"&gt;
&lt;h5 id="org68df08d"&gt;Gender&lt;/h5&gt;
&lt;div class="outline-text-5" id="text-org68df08d"&gt;
&lt;p&gt;
A stacked bar plot to get a sense of not just the distribution among genders but among classes.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;plot = grouped.hvplot.bar(title="Gender Counts", x="gender", y="gender_count",
			  stacked=True,
			  by="class", 
			  xlabel="Count",
			  ylabel="Gender",
			  fontsize=Plot.fontsize,
			  width=Plot.width,
			  height=Plot.height).opts(
			      xrotation=90, 
			      xlabel="Gender and Class")
Embed(plot=plot, file_name="class_counts_stacked", height_in_pixels=Plot.height)()
&lt;/pre&gt;&lt;/div&gt;

&lt;object type="text/html" data="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/high-school-facebook-networks/class_counts_stacked.html" style="width:100%" height="800"&gt;
  &lt;p&gt;Figure Missing&lt;/p&gt;
&lt;/object&gt;

&lt;p&gt;
A non-stacked bar plot to get a better sense of how the genders fill the different classes.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;plot = grouped.hvplot.bar(title="Gender Counts", x="gender", y="gender_count",
			  xlabel="Gender",
			  ylabel="Count",
			  by="class", 
			  height=Plot.height,
			  width=Plot.width,
			  fontsize=Plot.fontsize).opts(
			      xrotation=90, xlabel="Gender and Class")
Embed(plot=plot, file_name="class_counts", height_in_pixels=Plot.height)()
&lt;/pre&gt;&lt;/div&gt;

&lt;object type="text/html" data="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/high-school-facebook-networks/class_counts.html" style="width:100%" height="800"&gt;
  &lt;p&gt;Figure Missing&lt;/p&gt;
&lt;/object&gt;

&lt;p&gt;
It looks like there were a little more males than females, but not a whole lot more.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgb5d79df" class="outline-2"&gt;
&lt;h2 id="orgb5d79df"&gt;The Descent&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgb5d79df"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org1889f86" class="outline-4"&gt;
&lt;h4 id="org1889f86"&gt;The Facebook Network&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org1889f86"&gt;
&lt;p&gt;
This is a dataset that shows whether a student was &lt;i&gt;facebook&lt;/i&gt; friends with another student.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;facebook_path = HIGH_SCHOOL.joinpath(Files.facebook)
assert facebook_path.is_file()
with facebook_path.open() as reader:
    for line in range(5):
	print(reader.readline(), end="")
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
1 984 0
1 883 1
1 941 0
1 650 0
1 132 1

&lt;/pre&gt;

&lt;p&gt;
The columns are &lt;i&gt;one student&lt;/i&gt;, &lt;i&gt;next student&lt;/i&gt;, &lt;i&gt;facebook friends&lt;/i&gt;.
&lt;/p&gt;

&lt;p&gt;
The third column is &lt;i&gt;0&lt;/i&gt; if they aren't facebook friends and &lt;i&gt;1&lt;/i&gt; if they are.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;facebook_data = pandas.read_csv(facebook_path, delimiter=" ", 
				names=["reporter", "other", "friend"])
facebook_data = facebook_data.dropna()
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgcd266b3" class="outline-2"&gt;
&lt;h2 id="orgcd266b3"&gt;The Descent&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgcd266b3"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7b00256" class="outline-3"&gt;
&lt;h3 id="org7b00256"&gt;Looking at the Friendship Network&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org7b00256"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;with TIMER:
    facebook_graph = networkx.convert_matrix.from_pandas_edgelist(
	facebook_data, "reporter", "other", 
	create_using=networkx.DiGraph)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Started: 2019-03-27 23:05:04.495114
Ended: 2019-03-27 23:05:04.499622
Elapsed: 0:00:00.004508

&lt;/pre&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;genders = dict(zip(meta_data.id, meta_data.gender))
classes = dict(zip(meta_data.id, meta_data["class"]))
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;for node in facebook_graph.nodes:
    facebook_graph.nodes[node]["gender"] = genders[node]
    facebook_graph.nodes[node]["class"] = classes[node]
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;hover = HoverTool(
    tooltips = [
	 ("Gender", "@gender"),
	 ("Class", "@class"),
    ],
)

plot = holoviews.Graph.from_networkx(facebook_graph,
				     networkx.circular_layout).opts(
					 node_color=dim("gender"), cmap="Set1",
					 tools=[hover],
					 fontsize=Plot.fontsize,
					 width=800,
					 height=800,                                        
					 title="Facebook Network by Gender",
					 xaxis=None, yaxis=None, directed=True)
Embed(plot=plot, file_name="facebook_network_circular")()
&lt;/pre&gt;&lt;/div&gt;

&lt;object type="text/html" data="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/high-school-facebook-networks/facebook_network_circular.html" style="width:100%" height="800"&gt;
  &lt;p&gt;Figure Missing&lt;/p&gt;
&lt;/object&gt;

&lt;p&gt;
It's a little hard to see what's going on here, other than to note that you can see some people are more popular than others.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;hover = HoverTool(
    tooltips = [
	 ("Gender", "@gender"),
	 ("Class", "@class"),
    ],
)

plot = holoviews.Graph.from_networkx(facebook_graph,
				     networkx.circular_layout).opts(
					 node_color=dim("class"), cmap="Set1",
					 tools=[hover],
					 fontsize=Plot.fontsize,
					 width=800,
					 height=800,                                        
					 title="Facebook Network by Class",
					 xaxis=None, yaxis=None, directed=True)
Embed(plot=plot, file_name="facebook_network_circular_class")()
&lt;/pre&gt;&lt;/div&gt;

&lt;object type="text/html" data="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/high-school-facebook-networks/facebook_network_circular_class.html" style="width:100%" height="800"&gt;
  &lt;p&gt;Figure Missing&lt;/p&gt;
&lt;/object&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;plot = holoviews.Graph.from_networkx(facebook_graph, networkx.spring_layout, ).opts(
					 node_color=dim("class"), cmap="Set1",
					 tools=["hover"],
					 width=800,
					 height=800,
					 title="Facebook Network By Class",
					 xaxis=None, yaxis=None, directed=True)
Embed(plot=plot, file_name="facebook_network_class_spring", height_in_pixels=810)()
&lt;/pre&gt;&lt;/div&gt;

&lt;object type="text/html" data="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/high-school-facebook-networks/facebook_network_class_spring.html" style="width:100%" height="810"&gt;
  &lt;p&gt;Figure Missing&lt;/p&gt;
&lt;/object&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;plot = holoviews.Graph.from_networkx(facebook_graph, networkx.spring_layout, ).opts(
					 node_color=dim("gender"), cmap="Set1",
					 tools=["hover"],
					 width=800,
					 height=800,
					 title="Facebook Network By Gender",
					 xaxis=None, yaxis=None, directed=True)
Embed(plot=plot, file_name="facebook_network_gender_spring", height_in_pixels=810)()
&lt;/pre&gt;&lt;/div&gt;

&lt;object type="text/html" data="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/high-school-facebook-networks/facebook_network_gender_spring.html" style="width:100%" height="810"&gt;
  &lt;p&gt;Figure Missing&lt;/p&gt;
&lt;/object&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org2c55dc1" class="outline-2"&gt;
&lt;h2 id="org2c55dc1"&gt;End&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org2c55dc1"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org509ea5e" class="outline-3"&gt;
&lt;h3 id="org509ea5e"&gt;Citations&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org509ea5e"&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;R. Mastrandrea, J. Fournet, A. Barrat,&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
Contact patterns in a high school: a comparison between data collected using wearable sensors, contact diaries and friendship surveys.
PLoS ONE 10(9): e0136497 (2015)
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>exploration</category><category>networks</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/networks/high-school-facebook-networks/</guid><pubDate>Thu, 28 Mar 2019 00:38:17 GMT</pubDate></item></channel></rss>