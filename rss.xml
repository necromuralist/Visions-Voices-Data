<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Visions, Voices, Data</title><link>https://necromuralist.github.io/Visions-Voices-Data/</link><description>Adumbrations of data.</description><atom:link href="https://necromuralist.github.io/Visions-Voices-Data/rss.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents Â© 2020 &lt;a href="mailto:necromuralist@protonmail.com"&gt;Cloistered Monkey&lt;/a&gt; </copyright><lastBuildDate>Sun, 16 Feb 2020 19:27:09 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Advanced Uses Of SHAP Exercise</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap-exercise/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap-exercise/#orgdc3c9b8"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap-exercise/#org9e83025"&gt;Imports&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap-exercise/#orga589cce"&gt;Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap-exercise/#org437020e"&gt;PyPi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap-exercise/#org8fcfc85"&gt;Others&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap-exercise/#orgd8ea0c0"&gt;Set Up&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap-exercise/#org868e469"&gt;Plotting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap-exercise/#org79ce9ef"&gt;The Timer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap-exercise/#org561bed3"&gt;The Environment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap-exercise/#orgee3d425"&gt;The Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap-exercise/#orgc09f422"&gt;Middle&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap-exercise/#orgbb9b8bc"&gt;Build the Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap-exercise/#org7bd49a3"&gt;Shap Values&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap-exercise/#org084c5da"&gt;Summary Plot&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap-exercise/#orge57fb88"&gt;Question 1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap-exercise/#org829bd06"&gt;Question 2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap-exercise/#org02183bd"&gt;Question 3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap-exercise/#org51c0829"&gt;Question 4&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap-exercise/#orgf2f1892"&gt;Question 5&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap-exercise/#org95d8519"&gt;Question 6&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap-exercise/#org2b97967"&gt;End&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgdc3c9b8" class="outline-2"&gt;
&lt;h2 id="orgdc3c9b8"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgdc3c9b8"&gt;
&lt;p&gt;
This is my notes on the Advanced Uses of SHAP Exercise that's part of the &lt;a href="https://www.kaggle.com/learn/machine-learning-explainability"&gt;Machine Learning Explainability&lt;/a&gt; tutorial on kaggle.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-org9e83025" class="outline-3"&gt;
&lt;h3 id="org9e83025"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org9e83025"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orga589cce" class="outline-4"&gt;
&lt;h4 id="orga589cce"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orga589cce"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pathlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org437020e" class="outline-4"&gt;
&lt;h4 id="org437020e"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org437020e"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;matplotlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;pyplot&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.ensemble&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;RandomForestClassifier&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.model_selection&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;RandomizedSearchCV&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;seaborn&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;shap&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org8fcfc85" class="outline-4"&gt;
&lt;h4 id="org8fcfc85"&gt;Others&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org8fcfc85"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;graeae&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;EnvironmentLoader&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Timer&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgd8ea0c0" class="outline-3"&gt;
&lt;h3 id="orgd8ea0c0"&gt;Set Up&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgd8ea0c0"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org868e469" class="outline-4"&gt;
&lt;h4 id="org868e469"&gt;Plotting&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org868e469"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;SLUG&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"advanced-uses-of-shap-exercise"&lt;/span&gt;
&lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"../../files/posts/tutorials"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;SLUG&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;is_dir&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mkdir&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;get_ipython&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run_line_magic&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'matplotlib'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'inline'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;get_ipython&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run_line_magic&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'config'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"InlineBackend.figure_format = 'retina'"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;FIGURE_SIZE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;seaborn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;style&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"whitegrid"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	    &lt;span class="n"&gt;rc&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;"axes.grid"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
		&lt;span class="s2"&gt;"font.family"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"sans-serif"&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
		&lt;span class="s2"&gt;"font.sans-serif"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"Open Sans"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"Latin Modern Sans"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"Lato"&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
		&lt;span class="s2"&gt;"font.size"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
		&lt;span class="s2"&gt;"figure.figsize"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;FIGURE_SIZE&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;
	    &lt;span class="n"&gt;font_scale&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org79ce9ef" class="outline-4"&gt;
&lt;h4 id="org79ce9ef"&gt;The Timer&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org79ce9ef"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;TIMER&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Timer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org561bed3" class="outline-4"&gt;
&lt;h4 id="org561bed3"&gt;The Environment&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org561bed3"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;ENVIRONMENT&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;EnvironmentLoader&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgee3d425" class="outline-4"&gt;
&lt;h4 id="orgee3d425"&gt;The Data&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgee3d425"&gt;
&lt;p&gt;
Once again we're going to use the &lt;a href="https://www.kaggle.com/dansbecker/hospital-readmissions"&gt;Medical Data and Hospital Readmissions&lt;/a&gt; dataset from kaggle.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ENVIRONMENT&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"HOSPITAL-READMISSIONS"&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expanduser&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
We are only going to use a subset of the features.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;FEATURES&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
    &lt;span class="s1"&gt;'A1Cresult_None'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'diabetesMed_Yes'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'diag_1_414'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
    &lt;span class="s1"&gt;'diag_1_428'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'gender_Female'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'medical_specialty_?'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'num_lab_procedures'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
    &lt;span class="s1"&gt;'num_medications'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'num_procedures'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'number_diagnoses'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'number_emergency'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
    &lt;span class="s1"&gt;'number_inpatient'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'number_outpatient'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'payer_code_?'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="s1"&gt;'time_in_hospital'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Now we'll split up the features and the target. According to the notebook some versions of shap don't work when you combine numeric and boolean types so we'll convert all the features to floats.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;FEATURES&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;readmitted&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;
Now the training and validation split.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x_validation&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_validation&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgc09f422" class="outline-2"&gt;
&lt;h2 id="orgc09f422"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgc09f422"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgbb9b8bc" class="outline-3"&gt;
&lt;h3 id="orgbb9b8bc"&gt;Build the Model&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgbb9b8bc"&gt;
&lt;p&gt;
For some reason the notebook switches from a classifier to a regressor, even though this seems to be a classification problem. Since I don't have an explanation for it I'll try it using a classifier instead.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# model = RandomForestRegressor()&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RandomForestClassifier&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;estimators&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;30&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;300&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;max_depth&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;grid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;dict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_estimators&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;estimators&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	    &lt;span class="n"&gt;max_depth&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;max_depth&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;search&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RandomizedSearchCV&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;estimator&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			    &lt;span class="n"&gt;param_distributions&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;grid&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			    &lt;span class="n"&gt;n_iter&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			    &lt;span class="n"&gt;n_jobs&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			    &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;TIMER&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;search&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;search&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;best_estimator_&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"CV Training Accuracy: &lt;/span&gt;&lt;span class="si"&gt;{search.best_score_:0.2f}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Training Accuracy: {model.score(x_train, y_train): 0.2f}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Validation Accuracy: {model.score(x_validation, y_validation):0.2f}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;search&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;best_params_&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
CV Training Accuracy: 0.63
Training Accuracy:  0.70
Validation Accuracy: 0.63
{'n_estimators': 140, 'max_depth': 10}
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7bd49a3" class="outline-3"&gt;
&lt;h3 id="org7bd49a3"&gt;Shap Values&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org7bd49a3"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;READMITTED&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="n"&gt;explainer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;shap&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TreeExplainer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;shap_values&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;explainer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shap_values&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_validation&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org084c5da" class="outline-3"&gt;
&lt;h3 id="org084c5da"&gt;Summary Plot&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org084c5da"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;shap&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;summary_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;shap_values&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;READMITTED&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;x_validation&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;figure&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pyplot&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gcf&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"shap_summary.png"&lt;/span&gt;
&lt;span class="c1"&gt;#figure.subplots_adjust(left=0.3)&lt;/span&gt;
&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;savefig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"[[file:&lt;/span&gt;&lt;span class="si"&gt;{output}&lt;/span&gt;&lt;span class="s2"&gt;]]"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap-exercise/shap_summary.png" alt="shap_summary.png"&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orge57fb88" class="outline-3"&gt;
&lt;h3 id="orge57fb88"&gt;Question 1&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orge57fb88"&gt;
&lt;blockquote&gt;
&lt;p&gt;
Which of the following features has a bigger range of effects on predictions (i.e. larger difference between most positive and most negative effect)
&lt;/p&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;&lt;code&gt;diag_1_428&lt;/code&gt; or&lt;/li&gt;
&lt;li&gt;&lt;code&gt;payer_code_?&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;
&lt;code&gt;diag_1_428&lt;/code&gt; appears to have a bigger spread than &lt;code&gt;payer_code&lt;/code&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org829bd06" class="outline-3"&gt;
&lt;h3 id="org829bd06"&gt;Question 2&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org829bd06"&gt;
&lt;blockquote&gt;
&lt;p&gt;
Do you believe the range of effects sizes (distance between smallest effect and largest effect) is a good indication of which feature will have a higher permutation importance? Why or why not?  
&lt;/p&gt;

&lt;p&gt;
If the &lt;b&gt;&lt;b&gt;range of effect sizes&lt;/b&gt;&lt;/b&gt; measures something different from &lt;b&gt;&lt;b&gt;permutation importance&lt;/b&gt;&lt;/b&gt;: which is a better answer for the question "Which of these two features does the model say is more important for us to understand when discussing readmission risks in the population?"
&lt;/p&gt;

&lt;p&gt;
Run the following line after you've decided your answer.
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;
I don't think that the range of effect size is a good indication of which feature will have a higher permutation importance, because it just indicates the spread of the values, not their overall effect.
&lt;/p&gt;

&lt;p&gt;
I think that &lt;code&gt;diag_1_428&lt;/code&gt; is more important because it has a higher &lt;i&gt;Feature Value&lt;/i&gt; than &lt;code&gt;payer_code_?&lt;/code&gt;.
&lt;/p&gt;

&lt;p&gt;
&lt;b&gt;&lt;b&gt;Note:&lt;/b&gt;&lt;/b&gt; Although the question says "which of these two features does the model say is more important", the answer given is that permutation importance is a better measure of what's important to the model, since it's a robust measurement, while the range of effects is influenced by outliers.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org02183bd" class="outline-3"&gt;
&lt;h3 id="org02183bd"&gt;Question 3&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org02183bd"&gt;
&lt;blockquote&gt;
&lt;p&gt;
Both &lt;code&gt;diag_1_428&lt;/code&gt; and &lt;code&gt;payer_code_?&lt;/code&gt; are binary variables, taking values of 0 or 1.
&lt;/p&gt;

&lt;p&gt;
From the graph, which do you think would typically have a bigger impact on predicted readmission risk:
&lt;/p&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;Changing &lt;code&gt;diag_1_428&lt;/code&gt; from 0 to 1&lt;/li&gt;
&lt;li&gt;Changing &lt;code&gt;payer_code_?&lt;/code&gt; from 0 to 1&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;
I think that changing &lt;code&gt;diag_1_428&lt;/code&gt; to 1 would have a bigger impact, since the dots are more heavily right skewed for it than is the case with &lt;code&gt;payer_code_?&lt;/code&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org51c0829" class="outline-3"&gt;
&lt;h3 id="org51c0829"&gt;Question 4&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org51c0829"&gt;
&lt;blockquote&gt;
&lt;p&gt;
Some features (like &lt;code&gt;number_inpatient&lt;/code&gt;) have reasonably clear separation between the blue and pink dots. Other variables like &lt;code&gt;num_lab_procedures&lt;/code&gt; have blue and pink dots jumbled together, even though the SHAP values (or impacts on prediction) aren't all 0.
&lt;/p&gt;

&lt;p&gt;
What do you think you learn from the fact that &lt;code&gt;num_lab_procedures&lt;/code&gt; has blue and pink dots jumbled together? Once you have your answer, run the line below to verify your solution.
&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;
I think that this means that it is more difficult to make predictions based on the &lt;code&gt;num_lab_procedures&lt;/code&gt; - there isn't a clear separation of outcomes based on the value of &lt;code&gt;num_lab_procedures&lt;/code&gt;. The feature probably has interacting effects with other features.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgf2f1892" class="outline-3"&gt;
&lt;h3 id="orgf2f1892"&gt;Question 5&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgf2f1892"&gt;
&lt;blockquote&gt;
&lt;p&gt;
Consider the following SHAP contribution dependence plot. 
&lt;/p&gt;

&lt;p&gt;
The x-axis shows &lt;code&gt;feature_of_interest&lt;/code&gt; and the points are colored based on &lt;code&gt;other_feature&lt;/code&gt;.
&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://i.imgur.com/zFdHneM.png" alt="zFdHneM.png"&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;
Is there an interaction between &lt;code&gt;feature_of_interest&lt;/code&gt; and &lt;code&gt;other_feature&lt;/code&gt;?  
&lt;/p&gt;

&lt;p&gt;
If so, does &lt;code&gt;feature_of_interest&lt;/code&gt; have a more positive impact on predictions when &lt;code&gt;other_feature&lt;/code&gt; is high or when &lt;code&gt;other_feature&lt;/code&gt; is low?
&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;
It looks like &lt;code&gt;feature_of_interest&lt;/code&gt; has a more positive impart on predictions when the &lt;code&gt;other_feature&lt;/code&gt; is high.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org95d8519" class="outline-3"&gt;
&lt;h3 id="org95d8519"&gt;Question 6&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org95d8519"&gt;
&lt;blockquote&gt;
&lt;p&gt;
Both &lt;b&gt;&lt;b&gt;num_medications&lt;/b&gt;&lt;/b&gt; and &lt;b&gt;&lt;b&gt;num_lab_procedures&lt;/b&gt;&lt;/b&gt; share that jumbling of pink and blue dots.
&lt;/p&gt;

&lt;p&gt;
Aside from &lt;code&gt;num_medications&lt;/code&gt; having effects of greater magnitude (both more positive and more negative), it's hard to see a meaningful difference between how these two features affect readmission risk.  Create the SHAP dependence contribution plots for each variable, and describe what you think is different between how these two variables affect predictions.
&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axe&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pyplot&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplots&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;FIGURE_SIZE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"num_medications.png"&lt;/span&gt;
&lt;span class="n"&gt;shap&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dependence_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"num_medications"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shap_values&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;READMITTED&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;x_validation&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
		     &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;axe&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;savefig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"[[file:&lt;/span&gt;&lt;span class="si"&gt;{output}&lt;/span&gt;&lt;span class="s2"&gt;]]"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap-exercise/num_medications.png" alt="num_medications.png"&gt;
&lt;/p&gt;
&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axe&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pyplot&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplots&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;FIGURE_SIZE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"num_lab_procedures.png"&lt;/span&gt;
&lt;span class="n"&gt;shap&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dependence_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"num_lab_procedures"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shap_values&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;READMITTED&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;x_validation&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
		     &lt;span class="n"&gt;interaction_index&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"num_medications"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;axe&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;savefig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"[[file:&lt;/span&gt;&lt;span class="si"&gt;{output}&lt;/span&gt;&lt;span class="s2"&gt;]]"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap-exercise/num_lab_procedures.png" alt="num_lab_procedures.png"&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;
The &lt;code&gt;num_medications&lt;/code&gt; value appears to peak at 20 and then after that the SHAP value starts to go down as &lt;code&gt;num_medications&lt;/code&gt; goes up, while &lt;code&gt;num_lab_procedures&lt;/code&gt; makes a more gradual climb but appears to not have this inverted-curve shape.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org2b97967" class="outline-2"&gt;
&lt;h2 id="org2b97967"&gt;End&lt;/h2&gt;
&lt;/div&gt;</description><category>machine learning interpretability</category><category>shap</category><category>tutorial</category><category>visualization</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap-exercise/</guid><pubDate>Sat, 15 Feb 2020 04:03:29 GMT</pubDate></item><item><title>Advanced Uses Of SHAP</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap/#orgd13e527"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap/#org9f60c90"&gt;Imports&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap/#orgd2c9c17"&gt;Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap/#org903eb6b"&gt;PyPi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap/#org890ab4c"&gt;Others&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap/#org7d04a9a"&gt;Set Up&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap/#org4445d13"&gt;Plotting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap/#orgcad1fb1"&gt;The Environment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap/#org7a5f0ef"&gt;The Dataset&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap/#orgeea29c5"&gt;Middle&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap/#orgd0c61a7"&gt;Setup the SHAP Values&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap/#org8983047"&gt;Summary Plots&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap/#orge519499"&gt;SHAP Dependence Contribution Plots&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap/#orgc3b182e"&gt;End&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgd13e527" class="outline-2"&gt;
&lt;h2 id="orgd13e527"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgd13e527"&gt;
&lt;p&gt;
This is a re-do of the Kaggle tutorial on &lt;a href="https://www.kaggle.com/dansbecker/advanced-uses-of-shap-values"&gt;Advanced Uses of SHAP Values&lt;/a&gt;. SHAP values let us see how much a given feature changed our prediction for a given row of data, but it can also be used to look at groups of features to get a bigger picture look at our model. 
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-org9f60c90" class="outline-3"&gt;
&lt;h3 id="org9f60c90"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org9f60c90"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgd2c9c17" class="outline-4"&gt;
&lt;h4 id="orgd2c9c17"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgd2c9c17"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pathlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org903eb6b" class="outline-4"&gt;
&lt;h4 id="org903eb6b"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org903eb6b"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;matplotlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;pyplot&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.model_selection&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.ensemble&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;RandomForestClassifier&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;seaborn&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;shap&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org890ab4c" class="outline-4"&gt;
&lt;h4 id="org890ab4c"&gt;Others&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org890ab4c"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;graeae&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;EnvironmentLoader&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7d04a9a" class="outline-3"&gt;
&lt;h3 id="org7d04a9a"&gt;Set Up&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org7d04a9a"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org4445d13" class="outline-4"&gt;
&lt;h4 id="org4445d13"&gt;Plotting&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org4445d13"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;SLUG&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"advanced-uses-of-shap"&lt;/span&gt;
&lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"../../files/posts/tutorials"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;SLUG&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;is_dir&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mkdir&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;get_ipython&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run_line_magic&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'matplotlib'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'inline'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;get_ipython&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run_line_magic&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'config'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"InlineBackend.figure_format = 'retina'"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;FIGURE_SIZE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;seaborn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;style&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"whitegrid"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	    &lt;span class="n"&gt;rc&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;"axes.grid"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
		&lt;span class="s2"&gt;"font.family"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"sans-serif"&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
		&lt;span class="s2"&gt;"font.sans-serif"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"Open Sans"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"Latin Modern Sans"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"Lato"&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
		&lt;span class="s2"&gt;"font.size"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;22&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
		&lt;span class="s2"&gt;"figure.figsize"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;FIGURE_SIZE&lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;
	    &lt;span class="n"&gt;font_scale&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgcad1fb1" class="outline-4"&gt;
&lt;h4 id="orgcad1fb1"&gt;The Environment&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgcad1fb1"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;ENVIRONMENT&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;EnvironmentLoader&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7a5f0ef" class="outline-4"&gt;
&lt;h4 id="org7a5f0ef"&gt;The Dataset&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org7a5f0ef"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ENVIRONMENT&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"FIFA-2018"&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expanduser&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"Man of the Match"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;"Yes"&lt;/span&gt;

&lt;span class="n"&gt;FEATURES&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;column&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;column&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;
	    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;column&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dtype&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int64&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;FEATURES&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x_validation&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_validation&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RandomForestClassifier&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgeea29c5" class="outline-2"&gt;
&lt;h2 id="orgeea29c5"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgeea29c5"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgd0c61a7" class="outline-3"&gt;
&lt;h3 id="orgd0c61a7"&gt;Setup the SHAP Values&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgd0c61a7"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;explainer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;shap&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TreeExplainer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;shap_values&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;explainer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shap_values&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_validation&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org8983047" class="outline-3"&gt;
&lt;h3 id="org8983047"&gt;Summary Plots&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org8983047"&gt;
&lt;p&gt;
Like Permutation Importance, SHAP Summary Plots show you the relative importance of different features for your model, but unlike Permutation Importance, Summary Plots can show you how much more each feature influences the predictions.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;MAN_OF_THE_MATCH&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="n"&gt;shap&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;summary_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;shap_values&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;MAN_OF_THE_MATCH&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;x_validation&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;figure&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pyplot&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gcf&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="c1"&gt;# figure.set_size_inches(FIGURE_SIZE)&lt;/span&gt;
&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"shap_summary.png"&lt;/span&gt;
&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplots_adjust&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;left&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;savefig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"[[file:&lt;/span&gt;&lt;span class="si"&gt;{output}&lt;/span&gt;&lt;span class="s2"&gt;]]"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap/shap_summary.png" alt="shap_summary.png"&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;
As with permutation importance, Goal Scored was the most important feature, with a greater impact on not being the man of the match than being the man of the match. This looks sort of like a combination of Permutation importance and Partial Dependence Plots (PDP) except all in one place.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orge519499" class="outline-3"&gt;
&lt;h3 id="orge519499"&gt;SHAP Dependence Contribution Plots&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orge519499"&gt;
&lt;p&gt;
Dependence Contribution Plots work much like PDP plots except with more detail. Rather than showing you the means the Dependence Contribution Plot shows you the individual rows so you can get a sense of the shape of the outcomes.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axe&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pyplot&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplots&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;figsize&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;FIGURE_SIZE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"ball_possession_dcp.png"&lt;/span&gt;
&lt;span class="n"&gt;shap&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dependence_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Ball Possession %"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;shap_values&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;MAN_OF_THE_MATCH&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;x_validation&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
		     &lt;span class="n"&gt;interaction_index&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"Goal Scored"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ax&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;axe&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;savefig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"[[file:&lt;/span&gt;&lt;span class="si"&gt;{output}&lt;/span&gt;&lt;span class="s2"&gt;]]"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap/ball_possession_dcp.png" alt="ball_possession_dcp.png"&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;
Interestingly, our plot doesn't look like the one in the tutorial, we appear to have much fewer points and less spread in the values. But, anyway, the way to interpret this is as you move from left to right you are increasing the percentage of the time that a team had the ball, and as you move up, you are increasing the likelihood that the team had a man of the match. Additionally, the colors tell you how many goals the team scored. 
&lt;/p&gt;

&lt;p&gt;
Looking closer, it looks like the tutorial went with the entire dataset rather than just the validation set, probably because there are so few data points. While that does reveal a more interesting pattern, I'm not sure that that's what you would do, normally. 
&lt;/p&gt;

&lt;p&gt;
Anyway, this plot shows that having a very low ball possession percentage decreases the likelihood that you would have the man of the match and generally speaking as it goes up, so does the likelihood of having man of the match, although it seems to level off around 45%.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgc3b182e" class="outline-2"&gt;
&lt;h2 id="orgc3b182e"&gt;End&lt;/h2&gt;
&lt;/div&gt;</description><category>machine learning</category><category>shap</category><category>tutorial</category><category>visualization</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/advanced-uses-of-shap/</guid><pubDate>Sat, 15 Feb 2020 00:09:16 GMT</pubDate></item><item><title>SHAP Values Exercise</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values-exercise/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values-exercise/#org1b3e8d2"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values-exercise/#org94dbf4e"&gt;The Scenario&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values-exercise/#orgc39f53a"&gt;Imports&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values-exercise/#org1d5082d"&gt;Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values-exercise/#org2a818db"&gt;PyPi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values-exercise/#orgd42f25e"&gt;Others&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values-exercise/#org593c60d"&gt;Set Up&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values-exercise/#orgbb4231f"&gt;Plotting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values-exercise/#org816ccfc"&gt;The Table Printer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values-exercise/#orga4c7787"&gt;The Timer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values-exercise/#org562e01a"&gt;The Environment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values-exercise/#orgd29ae47"&gt;The Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values-exercise/#org1b26e3e"&gt;Middle&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values-exercise/#org35cb59d"&gt;Looking At the Data&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values-exercise/#org41d77ba"&gt;Set Up X and Y&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values-exercise/#org95ce5e0"&gt;Split the Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values-exercise/#orgb922b1a"&gt;A Simple Model&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values-exercise/#org357d174"&gt;Train the Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values-exercise/#org38ec7a7"&gt;Permutation Importance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values-exercise/#orgc3e8edd"&gt;Partial Dependence Plot&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values-exercise/#org584934e"&gt;SHAP Values&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values-exercise/#orgf567bab"&gt;Time In Hospital&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values-exercise/#org0bce611"&gt;Raw Readmissions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values-exercise/#orga510ac2"&gt;SHAP Creator&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values-exercise/#org4e6ba93"&gt;End&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values-exercise/#org9d12e7b"&gt;Sources&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org1b3e8d2" class="outline-2"&gt;
&lt;h2 id="org1b3e8d2"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org1b3e8d2"&gt;
&lt;p&gt;
This is the SHAP Exercise from the kaggle &lt;a href="https://www.kaggle.com/learn/machine-learning-explainability"&gt;Machine Learing Explainability Tutorial&lt;/a&gt;. It's using the kaggle &lt;a href="https://www.kaggle.com/dansbecker/hospital-readmissions"&gt;Hospital Readmissions&lt;/a&gt; dataset (I think).
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-org94dbf4e" class="outline-3"&gt;
&lt;h3 id="org94dbf4e"&gt;The Scenario&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org94dbf4e"&gt;
&lt;blockquote&gt;
&lt;p&gt;
A hospital has struggled with "readmissions," where they release a patient before the patient has recovered enough, and the patient returns with health complications. 
&lt;/p&gt;

&lt;p&gt;
The hospital wants your help identifying patients at highest risk of being readmitted. Doctors (rather than your model) will make the final decision about when to release each patient; but they hope your model will highlight issues the doctors should consider when releasing a patient.
&lt;/p&gt;

&lt;p&gt;
The hospital has given you relevant patient medical information.
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgc39f53a" class="outline-3"&gt;
&lt;h3 id="orgc39f53a"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgc39f53a"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org1d5082d" class="outline-4"&gt;
&lt;h4 id="org1d5082d"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org1d5082d"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;argparse&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Namespace&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;functools&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;partial&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pathlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;random&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org2a818db" class="outline-4"&gt;
&lt;h4 id="org2a818db"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org2a818db"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;eli5.sklearn&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;PermutationImportance&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;matplotlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;pyplot&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pdpbox&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;pdp&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.ensemble&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;RandomForestClassifier&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.model_selection&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;RandomizedSearchCV&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;tabulate&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;tabulate&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;eli5&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;hvplot.pandas&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;shap&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgd42f25e" class="outline-4"&gt;
&lt;h4 id="orgd42f25e"&gt;Others&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgd42f25e"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;graeae&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;EmbedHoloviews&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;EnvironmentLoader&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Timer&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org593c60d" class="outline-3"&gt;
&lt;h3 id="org593c60d"&gt;Set Up&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org593c60d"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgbb4231f" class="outline-4"&gt;
&lt;h4 id="orgbb4231f"&gt;Plotting&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgbb4231f"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;SLUG&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"shap-values-exercise"&lt;/span&gt;
&lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"../../files/posts/tutorials/"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;SLUG&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;is_dir&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mkdir&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;Plot&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Namespace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;800&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Embed&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;partial&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;EmbedHoloviews&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;folder_path&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org816ccfc" class="outline-4"&gt;
&lt;h4 id="org816ccfc"&gt;The Table Printer&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org816ccfc"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;TABLE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;partial&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tabulate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tablefmt&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"orgtbl"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;headers&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"keys"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;showindex&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orga4c7787" class="outline-4"&gt;
&lt;h4 id="orga4c7787"&gt;The Timer&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orga4c7787"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;TIMER&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Timer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org562e01a" class="outline-4"&gt;
&lt;h4 id="org562e01a"&gt;The Environment&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org562e01a"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;ENVIRONMENT&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;EnvironmentLoader&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgd29ae47" class="outline-4"&gt;
&lt;h4 id="orgd29ae47"&gt;The Data&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgd29ae47"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;PATH&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ENVIRONMENT&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"HOSPITAL-READMISSIONS"&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expanduser&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;PATH&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;is_file&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;PATH&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org1b26e3e" class="outline-2"&gt;
&lt;h2 id="org1b26e3e"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org1b26e3e"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org35cb59d" class="outline-3"&gt;
&lt;h3 id="org35cb59d"&gt;Looking At the Data&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org35cb59d"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;column&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;" - &lt;/span&gt;&lt;span class="si"&gt;{column}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;ul class="org-ul"&gt;
&lt;li&gt;A1Cresult_None&lt;/li&gt;
&lt;li&gt;acarbose_No&lt;/li&gt;
&lt;li&gt;acetohexamide_No&lt;/li&gt;
&lt;li&gt;age_[40-50)&lt;/li&gt;
&lt;li&gt;age_[50-60)&lt;/li&gt;
&lt;li&gt;age_[60-70)&lt;/li&gt;
&lt;li&gt;age_[70-80)&lt;/li&gt;
&lt;li&gt;age_[80-90)&lt;/li&gt;
&lt;li&gt;change_No&lt;/li&gt;
&lt;li&gt;chlorpropamide_No&lt;/li&gt;
&lt;li&gt;citoglipton_No&lt;/li&gt;
&lt;li&gt;diabetesMed_Yes&lt;/li&gt;
&lt;li&gt;diag_1_414&lt;/li&gt;
&lt;li&gt;diag_1_428&lt;/li&gt;
&lt;li&gt;diag_1_786&lt;/li&gt;
&lt;li&gt;diag_2_250&lt;/li&gt;
&lt;li&gt;diag_2_276&lt;/li&gt;
&lt;li&gt;diag_2_427&lt;/li&gt;
&lt;li&gt;diag_2_428&lt;/li&gt;
&lt;li&gt;diag_3_250&lt;/li&gt;
&lt;li&gt;diag_3_276&lt;/li&gt;
&lt;li&gt;diag_3_401&lt;/li&gt;
&lt;li&gt;diag_3_428&lt;/li&gt;
&lt;li&gt;examide_No&lt;/li&gt;
&lt;li&gt;gender_Female&lt;/li&gt;
&lt;li&gt;glimepiride-pioglitazone_No&lt;/li&gt;
&lt;li&gt;glimepiride_No&lt;/li&gt;
&lt;li&gt;glipizide-metformin_No&lt;/li&gt;
&lt;li&gt;glipizide_No&lt;/li&gt;
&lt;li&gt;glyburide-metformin_No&lt;/li&gt;
&lt;li&gt;glyburide_No&lt;/li&gt;
&lt;li&gt;insulin_No&lt;/li&gt;
&lt;li&gt;max_glu_serum_None&lt;/li&gt;
&lt;li&gt;medical_specialty_?&lt;/li&gt;
&lt;li&gt;medical_specialty_Cardiology&lt;/li&gt;
&lt;li&gt;medical_specialty_Emergency/Trauma&lt;/li&gt;
&lt;li&gt;medical_specialty_Family/GeneralPractice&lt;/li&gt;
&lt;li&gt;medical_specialty_InternalMedicine&lt;/li&gt;
&lt;li&gt;metformin-pioglitazone_No&lt;/li&gt;
&lt;li&gt;metformin-rosiglitazone_No&lt;/li&gt;
&lt;li&gt;metformin_No&lt;/li&gt;
&lt;li&gt;miglitol_No&lt;/li&gt;
&lt;li&gt;nateglinide_No&lt;/li&gt;
&lt;li&gt;num_lab_procedures&lt;/li&gt;
&lt;li&gt;num_medications&lt;/li&gt;
&lt;li&gt;num_procedures&lt;/li&gt;
&lt;li&gt;number_diagnoses&lt;/li&gt;
&lt;li&gt;number_emergency&lt;/li&gt;
&lt;li&gt;number_inpatient&lt;/li&gt;
&lt;li&gt;number_outpatient&lt;/li&gt;
&lt;li&gt;payer_code_?&lt;/li&gt;
&lt;li&gt;payer_code_BC&lt;/li&gt;
&lt;li&gt;payer_code_HM&lt;/li&gt;
&lt;li&gt;payer_code_MC&lt;/li&gt;
&lt;li&gt;payer_code_SP&lt;/li&gt;
&lt;li&gt;pioglitazone_No&lt;/li&gt;
&lt;li&gt;race_AfricanAmerican&lt;/li&gt;
&lt;li&gt;race_Caucasian&lt;/li&gt;
&lt;li&gt;readmitted&lt;/li&gt;
&lt;li&gt;repaglinide_No&lt;/li&gt;
&lt;li&gt;rosiglitazone_No&lt;/li&gt;
&lt;li&gt;time_in_hospital&lt;/li&gt;
&lt;li&gt;tolazamide_No&lt;/li&gt;
&lt;li&gt;tolbutamide_No&lt;/li&gt;
&lt;li&gt;troglitazone_No&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;
So there are a lot of columns.
&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;
Here are some quick hints at interpreting the field names:
&lt;/p&gt;

&lt;ul class="org-ul"&gt;
&lt;li&gt;Your prediction target is &lt;code&gt;readmitted&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Columns with the word &lt;code&gt;diag&lt;/code&gt; indicate the diagnostic code of the illness or illnesses the patient was admitted with. For example, &lt;code&gt;diag_1_428&lt;/code&gt; means the doctor said their first illness diagnosis is number "428".  What illness does 428 correspond to? You could look it up in a codebook, but without more medical background it wouldn't mean anything to you anyway.&lt;/li&gt;
&lt;li&gt;A column names like &lt;code&gt;glimepiride_No&lt;/code&gt; mean the patient did not have the medicine &lt;code&gt;glimepiride&lt;/code&gt;. If this feature had a value of False, then the patient did take the drug &lt;code&gt;glimepiride&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Features whose names begin with &lt;code&gt;medical_specialty&lt;/code&gt; describe the specialty of the doctor seeing the patient. The values in these fields are all &lt;code&gt;True&lt;/code&gt; or &lt;code&gt;False&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div id="outline-container-org41d77ba" class="outline-4"&gt;
&lt;h4 id="org41d77ba"&gt;Set Up X and Y&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org41d77ba"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;readmitted&lt;/span&gt;
&lt;span class="n"&gt;TARGET&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"readmitted"&lt;/span&gt;
&lt;span class="n"&gt;FEATURES&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;TARGET&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;FEATURES&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org95ce5e0" class="outline-4"&gt;
&lt;h4 id="org95ce5e0"&gt;Split the Data&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org95ce5e0"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_validate&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
							    &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgb922b1a" class="outline-3"&gt;
&lt;h3 id="orgb922b1a"&gt;A Simple Model&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgb922b1a"&gt;
&lt;blockquote&gt;
&lt;p&gt;
You have built a simple model, but the doctors say they don't know how to evaluate a model, and they'd like you to show them some evidence the model is doing something in line with their medical intuition. Create any graphics or tables that will show them a quick overview of what the model is doing?
&lt;/p&gt;

&lt;p&gt;
They are very busy. So they want you to condense your model overview into just 1 or 2 graphics, rather than a long string of graphics.
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div id="outline-container-org357d174" class="outline-4"&gt;
&lt;h4 id="org357d174"&gt;Train the Model&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org357d174"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;TIMER&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;model_1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RandomForestClassifier&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_estimators&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;30&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
	&lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Training R^2: {model_1.score(x_train, y_train): 0.2f}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Validation R^2: {model_1.score(x_validate, y_validate):0.2f}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
2020-02-14 14:02:08,392 graeae.timers.timer start: Started: 2020-02-14 14:02:08.391737
2020-02-14 14:02:09,011 graeae.timers.timer end: Ended: 2020-02-14 14:02:09.011136
2020-02-14 14:02:09,011 graeae.timers.timer end: Elapsed: 0:00:00.619399
Training R^2:  1.00
Validation R^2: 0.60
&lt;/pre&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;model_2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RandomForestClassifier&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;estimators&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;300&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;max_depth&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;grid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;dict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_estimators&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;estimators&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	    &lt;span class="n"&gt;max_depth&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;max_depth&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;search&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RandomizedSearchCV&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;estimator&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;model_2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			    &lt;span class="n"&gt;param_distributions&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;grid&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			    &lt;span class="n"&gt;n_iter&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			    &lt;span class="n"&gt;n_jobs&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			    &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;TIMER&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;search&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;first_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;search&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;best_estimator_&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"CV Training R^2: &lt;/span&gt;&lt;span class="si"&gt;{search.best_score_:0.2f}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Training R^2: {first_model.score(x_train, y_train): 0.2f}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Validation R^2: {first_model.score(x_validate, y_validate):0.2f}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;search&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;best_params_&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
2020-02-14 14:02:10,418 graeae.timers.timer start: Started: 2020-02-14 14:02:10.418784
2020-02-14 14:04:09,802 graeae.timers.timer end: Ended: 2020-02-14 14:04:09.802077
2020-02-14 14:04:09,802 graeae.timers.timer end: Elapsed: 0:01:59.383293
CV Training R^2: 0.63
Training R^2:  0.70
Validation R^2: 0.63
{'n_estimators': 90, 'max_depth': 10}
&lt;/pre&gt;


&lt;p&gt;
We get a slight improvement with a much more complex model, but not a lot. Our validation \(r^2\) is nearly as good as the training \(r^2\) so it looks like we aren't overfitting.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org38ec7a7" class="outline-4"&gt;
&lt;h4 id="org38ec7a7"&gt;Permutation Importance&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org38ec7a7"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;permutor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PermutationImportance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
	&lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_validate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;ipython_html&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;eli5&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show_weights&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;permutor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
				 &lt;span class="n"&gt;feature_names&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tolist&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="n"&gt;table&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_html&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ipython_html&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;TABLE&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;table&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-left"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Weight&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Feature&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;0.0640  Â± 0.0071&lt;/td&gt;
&lt;td class="org-left"&gt;number_inpatient&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0108  Â± 0.0046&lt;/td&gt;
&lt;td class="org-left"&gt;number_emergency&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0084  Â± 0.0058&lt;/td&gt;
&lt;td class="org-left"&gt;number_outpatient&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0025  Â± 0.0034&lt;/td&gt;
&lt;td class="org-left"&gt;number_diagnoses&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0021  Â± 0.0010&lt;/td&gt;
&lt;td class="org-left"&gt;diabetesMed_Yes&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0020  Â± 0.0017&lt;/td&gt;
&lt;td class="org-left"&gt;payer_code_?&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0019  Â± 0.0015&lt;/td&gt;
&lt;td class="org-left"&gt;race_AfricanAmerican&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0015  Â± 0.0015&lt;/td&gt;
&lt;td class="org-left"&gt;num_lab_procedures&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0013  Â± 0.0008&lt;/td&gt;
&lt;td class="org-left"&gt;age_[80-90)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0011  Â± 0.0030&lt;/td&gt;
&lt;td class="org-left"&gt;diag_1_428&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0011  Â± 0.0023&lt;/td&gt;
&lt;td class="org-left"&gt;medical_specialty_?&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0010  Â± 0.0012&lt;/td&gt;
&lt;td class="org-left"&gt;payer_code_HM&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0008  Â± 0.0043&lt;/td&gt;
&lt;td class="org-left"&gt;num_procedures&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0008  Â± 0.0012&lt;/td&gt;
&lt;td class="org-left"&gt;payer_code_BC&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0008  Â± 0.0008&lt;/td&gt;
&lt;td class="org-left"&gt;age_[40-50)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0008  Â± 0.0010&lt;/td&gt;
&lt;td class="org-left"&gt;max_glu_serum_None&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0008  Â± 0.0015&lt;/td&gt;
&lt;td class="org-left"&gt;race_Caucasian&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0005  Â± 0.0032&lt;/td&gt;
&lt;td class="org-left"&gt;num_medications&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0005  Â± 0.0022&lt;/td&gt;
&lt;td class="org-left"&gt;diag_2_250&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0004  Â± 0.0006&lt;/td&gt;
&lt;td class="org-left"&gt;rosiglitazone_No&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;â¦ 44 more â¦&lt;/td&gt;
&lt;td class="org-left"&gt;â¦ 44 more â¦&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;
The most important features weren't in the data description. What is &lt;code&gt;number_inpatient&lt;/code&gt;?
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgc3e8edd" class="outline-4"&gt;
&lt;h4 id="orgc3e8edd"&gt;Partial Dependence Plot&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgc3e8edd"&gt;
&lt;p&gt;
Since the most important feature is the "number_inpatient" let's see how much it changes the re-admissions.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;FEATURE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"number_inpatient"&lt;/span&gt;
&lt;span class="n"&gt;pdp_dist&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pdp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pdp_isolate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;first_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			   &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			   &lt;span class="n"&gt;model_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;FEATURES&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			   &lt;span class="n"&gt;feature&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;FEATURE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;pdp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pdp_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pdp_dist&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;FEATURE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="si"&gt;{FEATURE}&lt;/span&gt;&lt;span class="s2"&gt;_pdp_plot.png"&lt;/span&gt;
&lt;span class="n"&gt;figure&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pyplot&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;gcf&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplots_adjust&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;top&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;savefig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"[[file:&lt;/span&gt;&lt;span class="si"&gt;{output}&lt;/span&gt;&lt;span class="s2"&gt;]]"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values-exercise/number_inpatient_pdp_plot.png" alt="number_inpatient_pdp_plot.png"&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;


&lt;div id="outline-container-org584934e" class="outline-4"&gt;
&lt;h4 id="org584934e"&gt;SHAP Values&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org584934e"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;seed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ROW&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randrange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;row_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;ROW&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;row_data_matrix&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;row_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first_model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;classes_&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first_model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict_proba&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row_data_matrix&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
[0 1]
[[0.49342394 0.50657606]]
&lt;/pre&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;explainer = shap.TreeExplainer(first_model)
shap_values = explainer.shap_values(row_data_matrix)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;READMIT = 1
figure = shap.force_plot(explainer.expected_value[READMIT],
			 shap_values[READMIT],
			 row_data_matrix,
			 feature_names=FEATURES,
			 matplotlib=True, show=False)
filename = "shap_zero.png"

figure.savefig(OUTPUT_PATH/filename)
print(f"[[file:{filename}]]")
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values-exercise/shap_zero.png" alt="shap_zero.png"&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;ul class="org-ul"&gt;
&lt;li&gt;&lt;a id="orgeaef7e1"&gt;&lt;/a&gt;Try one where num_inpatients was 1&lt;br&gt;
&lt;div class="outline-text-5" id="text-orgeaef7e1"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;row_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;number_inpatient&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;row_data_matrix&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;row_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first_model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;classes_&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first_model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict_proba&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row_data_matrix&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
[0 1]
[[0.36731038 0.63268962]]
&lt;/pre&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;explainer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;shap&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TreeExplainer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first_model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;shap_values&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;explainer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shap_values&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row_data_matrix&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;figure&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;shap&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;force_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;explainer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expected_value&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;READMIT&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
			 &lt;span class="n"&gt;shap_values&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;READMIT&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
			 &lt;span class="n"&gt;row_data_matrix&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			 &lt;span class="n"&gt;feature_names&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;FEATURES&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			 &lt;span class="n"&gt;matplotlib&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;filename&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"shap_one.png"&lt;/span&gt;

&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;savefig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"[[file:&lt;/span&gt;&lt;span class="si"&gt;{filename}&lt;/span&gt;&lt;span class="s2"&gt;]]"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values-exercise/shap_one.png" alt="shap_one.png"&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;

&lt;li&gt;&lt;a id="org2c3a677"&gt;&lt;/a&gt;Try one where num_inpatients was 2&lt;br&gt;
&lt;div class="outline-text-5" id="text-org2c3a677"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;INPATIENTS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="n"&gt;row_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;number_inpatient&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="n"&gt;INPATIENTS&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;row_data_matrix&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;row_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first_model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;classes_&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first_model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict_proba&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row_data_matrix&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
[0 1]
[[0.38485607 0.61514393]]
&lt;/pre&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;explainer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;shap&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TreeExplainer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first_model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;shap_values&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;explainer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shap_values&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row_data_matrix&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;figure&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;shap&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;force_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;explainer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expected_value&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;READMIT&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
			 &lt;span class="n"&gt;shap_values&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;READMIT&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
			 &lt;span class="n"&gt;row_data_matrix&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			 &lt;span class="n"&gt;feature_names&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;FEATURES&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			 &lt;span class="n"&gt;matplotlib&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;filename&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"shap_two.png"&lt;/span&gt;

&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;savefig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"[[file:&lt;/span&gt;&lt;span class="si"&gt;{filename}&lt;/span&gt;&lt;span class="s2"&gt;]]"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values-exercise/shap_two.png" alt="shap_two.png"&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;

&lt;li&gt;&lt;a id="org68b3fe8"&gt;&lt;/a&gt;Try one where num_inpatients was 3&lt;br&gt;
&lt;div class="outline-text-5" id="text-org68b3fe8"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;INPATIENTS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;
&lt;span class="n"&gt;row_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;number_inpatient&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="n"&gt;INPATIENTS&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;row_data_matrix&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;row_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first_model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;classes_&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first_model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict_proba&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row_data_matrix&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
[0 1]
[[0.47141351 0.52858649]]
&lt;/pre&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;explainer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;shap&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TreeExplainer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first_model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;shap_values&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;explainer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shap_values&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row_data_matrix&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;figure&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;shap&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;force_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;explainer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expected_value&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;READMIT&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
			 &lt;span class="n"&gt;shap_values&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;READMIT&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
			 &lt;span class="n"&gt;row_data_matrix&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			 &lt;span class="n"&gt;feature_names&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;FEATURES&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			 &lt;span class="n"&gt;matplotlib&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;filename&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"shap_three.png"&lt;/span&gt;

&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;savefig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"[[file:&lt;/span&gt;&lt;span class="si"&gt;{filename}&lt;/span&gt;&lt;span class="s2"&gt;]]"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values-exercise/shap_three.png" alt="shap_three.png"&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;

&lt;li&gt;&lt;a id="orgdcf41f3"&gt;&lt;/a&gt;Try one where num_inpatients was the Maximum&lt;br&gt;
&lt;div class="outline-text-5" id="text-orgdcf41f3"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;INPATIENTS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;number_inpatient&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;max&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;row_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;number_inpatient&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="n"&gt;INPATIENTS&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;row_data_matrix&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;row_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first_model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;classes_&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first_model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict_proba&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row_data_matrix&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
[0 1]
[[0.19208238 0.80791762]]
&lt;/pre&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;explainer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;shap&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TreeExplainer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first_model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;shap_values&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;explainer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shap_values&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row_data_matrix&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;figure&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;shap&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;force_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;explainer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expected_value&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;READMIT&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
			 &lt;span class="n"&gt;shap_values&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;READMIT&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
			 &lt;span class="n"&gt;row_data_matrix&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			 &lt;span class="n"&gt;feature_names&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;FEATURES&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			 &lt;span class="n"&gt;matplotlib&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;filename&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"shap_max.png"&lt;/span&gt;

&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;savefig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"[[file:&lt;/span&gt;&lt;span class="si"&gt;{filename}&lt;/span&gt;&lt;span class="s2"&gt;]]"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values-exercise/shap_max.png" alt="shap_max.png"&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;
So it seems to be that the greater &lt;code&gt;number_inpatient&lt;/code&gt; the more it contributes to re-admission (although note that since we're only using one row the cases with small values doesn't always look like what I plotted above - it depends on the patient).
&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgf567bab" class="outline-4"&gt;
&lt;h4 id="orgf567bab"&gt;Time In Hospital&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgf567bab"&gt;
&lt;blockquote&gt;
&lt;p&gt;
The doctors think it's a good sign that increasing the number of inpatient procedures leads to increased predictions.  But they can't tell from this plot whether that change in the plot is big or small. They'd like you to create something similar for &lt;code&gt;time_in_hospital&lt;/code&gt; to see how that compares.
&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;FEATURE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"time_in_hospital"&lt;/span&gt;
&lt;span class="n"&gt;pdp_dist&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pdp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pdp_isolate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;first_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			   &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			   &lt;span class="n"&gt;model_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;FEATURES&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			   &lt;span class="n"&gt;feature&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;FEATURE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;pdp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pdp_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pdp_dist&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;FEATURE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="si"&gt;{FEATURE}&lt;/span&gt;&lt;span class="s2"&gt;_pdp_plot.png"&lt;/span&gt;
&lt;span class="n"&gt;pyplot&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;savefig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"[[file:&lt;/span&gt;&lt;span class="si"&gt;{output}&lt;/span&gt;&lt;span class="s2"&gt;]]"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values-exercise/time_in_hospital_pdp_plot.png" alt="time_in_hospital_pdp_plot.png"&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;TIME_IN_HOSPITAL&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;

&lt;span class="n"&gt;row_data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;time_in_hospital&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="n"&gt;TIME_IN_HOSPITAL&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;row_data_matrix&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;row_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first_model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;classes_&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first_model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict_proba&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row_data_matrix&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
[0 1]
[[0.39445183 0.60554817]]
&lt;/pre&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;explainer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;shap&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TreeExplainer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first_model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;shap_values&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;explainer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shap_values&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row_data_matrix&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;figure&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;shap&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;force_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;explainer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expected_value&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;READMIT&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
			 &lt;span class="n"&gt;shap_values&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;READMIT&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
			 &lt;span class="n"&gt;row_data_matrix&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			 &lt;span class="n"&gt;feature_names&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;FEATURES&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			 &lt;span class="n"&gt;matplotlib&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;filename&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"shap_hospital_one.png"&lt;/span&gt;

&lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;savefig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"[[file:&lt;/span&gt;&lt;span class="si"&gt;{filename}&lt;/span&gt;&lt;span class="s2"&gt;]]"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values-exercise/shap_hospital_one.png" alt="shap_hospital_one.png"&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;
It looks like time in hospital has an effect - but it is a small one.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org0bce611" class="outline-4"&gt;
&lt;h4 id="org0bce611"&gt;Raw Readmissions&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org0bce611"&gt;
&lt;blockquote&gt;
&lt;p&gt;
Whoa!  It seems like &lt;code&gt;time_in_hospital&lt;/code&gt; doesn't matter at all.  The difference between the lowest value on the partial dependence plot and the highest value is about 5%.
&lt;/p&gt;

&lt;p&gt;
If that is what your model concluded, the doctors will believe it. But it seems so low. Could  the data be wrong, or is your model doing something more complex than they expect?  
&lt;/p&gt;

&lt;p&gt;
They'd like you to show them the raw readmission rate for each value of &lt;code&gt;time_in_hospital&lt;/code&gt; to see how it compares to the partial dependence plot.
&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;training&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;concat&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"columns"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;grouped&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;groupby&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s2"&gt;"time_in_hospital"&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;agg&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s2"&gt;"readmitted"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"mean"&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
&lt;span class="n"&gt;plot&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;grouped&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hvplot&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bar&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;opts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"Readmission Rates for time_in_hospital"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;Plot&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;Plot&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;source&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Embed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;file_name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"time_in_hospital_readmission_rates"&lt;/span&gt;&lt;span class="p"&gt;)()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;source&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

: &lt;object type="text/html" data="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values-exercise/time_in_hospital_readmission_rates.html" style="width:100%" height="800"&gt;
:   &lt;p&gt;Figure Missing&lt;/p&gt;
: &lt;/object&gt;

&lt;p&gt;
It sort of looks like &lt;code&gt;time_in_hospital&lt;/code&gt; does affect readmission rates, just not as much as the number of admissions, I guess.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orga510ac2" class="outline-3"&gt;
&lt;h3 id="orga510ac2"&gt;SHAP Creator&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orga510ac2"&gt;
&lt;blockquote&gt;
&lt;p&gt;
Now the doctors are convinced you have the right data, and the model overview looked reasonable.  It's time to turn this into a finished product they can use. Specifically, the hospital wants you to create a function &lt;code&gt;patient_risk_factors&lt;/code&gt; that does the following
&lt;/p&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;Takes a single row with patient data (of the same format you as your raw data)&lt;/li&gt;
&lt;li&gt;Creates a visualization showing what features of that patient increased their risk of readmission, what features decreased it, and how much those features mattered.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;
It's not important to show every feature with every miniscule impact on the readmission risk.  It's fine to focus on only the most important features for that patient.
&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;patient_risk_factors&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row_data&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Series&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tag&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;row_data_matrix&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;row_data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;explainer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;shap&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;TreeExplainer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first_model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;shap_values&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;explainer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shap_values&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row_data_matrix&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;figure&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;shap&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;force_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;explainer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expected_value&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;READMIT&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
			     &lt;span class="n"&gt;shap_values&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;READMIT&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;
			     &lt;span class="n"&gt;row_data_matrix&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			     &lt;span class="n"&gt;feature_names&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;FEATURES&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			     &lt;span class="n"&gt;matplotlib&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;filename&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"shap_&lt;/span&gt;&lt;span class="si"&gt;{tag}&lt;/span&gt;&lt;span class="s2"&gt;.png"&lt;/span&gt;
    &lt;span class="n"&gt;figure&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;savefig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;filename&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"[[file:&lt;/span&gt;&lt;span class="si"&gt;{filename}&lt;/span&gt;&lt;span class="s2"&gt;]]"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;row_data_matrix&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;row_matrix&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;patient_risk_factors&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"random_one"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values-exercise/shap_random_one.png" alt="shap_random_one.png"&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first_model&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict_proba&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row_matrix&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
[[0.70043997 0.29956003]]
&lt;/pre&gt;


&lt;p&gt;
In this case it looks like the number of diagnoses was the most important - having many diagnoses with no hospital admissions predicts you won't be readmitted. Should people who were never admitted be considered? Perhaps "readmission" just means admitted later.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org4e6ba93" class="outline-2"&gt;
&lt;h2 id="org4e6ba93"&gt;End&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org4e6ba93"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org9d12e7b" class="outline-3"&gt;
&lt;h3 id="org9d12e7b"&gt;Sources&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org9d12e7b"&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;Lundberg, S.M., Erion, G., Chen, H. et al. From local explanations to global understanding with explainable AI for trees. Nat Mach Intell 2, 56â67 (2020). &lt;a href="https://doi.org/10.1038/s42256-019-0138-9"&gt;https://doi.org/10.1038/s42256-019-0138-9&lt;/a&gt; (&lt;a href="https://www.nature.com/articles/s42256-019-0138-9"&gt;TreeExplainer&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Lundberg, S.M., Nair, B., Vavilala, M.S. et al. Explainable machine-learning predictions for the prevention of hypoxaemia during surgery. Nat Biomed Eng 2, 749â760 (2018). &lt;a href="https://doi.org/10.1038/s41551-018-0304-0"&gt;https://doi.org/10.1038/s41551-018-0304-0&lt;/a&gt; (&lt;a href="https://www.nature.com/articles/s41551-018-0304-0"&gt;&lt;code&gt;force_plot&lt;/code&gt;&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values-exercise/</guid><pubDate>Tue, 11 Feb 2020 15:06:57 GMT</pubDate></item><item><title>SHAP Values</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values/#org6bf9a85"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values/#org7deee69"&gt;Imports&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values/#org98968d4"&gt;Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values/#orgd54892f"&gt;PyPi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values/#orga29719e"&gt;Others&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values/#org246bc96"&gt;Set Up&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values/#orge93544f"&gt;Plotting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values/#org663ea8b"&gt;The Timer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values/#org664d413"&gt;Environment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values/#orga9aac4a"&gt;The Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values/#org855984d"&gt;Middle&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values/#org2ab88be"&gt;A Single Row&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values/#org52953ea"&gt;End&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values/#org43f2023"&gt;See Also&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org6bf9a85" class="outline-2"&gt;
&lt;h2 id="org6bf9a85"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org6bf9a85"&gt;
&lt;p&gt;
SHAP values interpret the impact of a certain value for a given feature when compared to the prediction you'd make if that feature instead took a baseline value. This helps us interpret predictions given specific values for our features. We'll do this using the &lt;a href="https://github.com/slundberg/shap"&gt;SHAP&lt;/a&gt; library, naturally.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7deee69" class="outline-3"&gt;
&lt;h3 id="org7deee69"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org7deee69"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org98968d4" class="outline-4"&gt;
&lt;h4 id="org98968d4"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org98968d4"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from argparse import Namespace
from pathlib import Path
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgd54892f" class="outline-4"&gt;
&lt;h4 id="orgd54892f"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgd54892f"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from matplotlib import pyplot
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier

import numpy
import pandas
import seaborn
import shap
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orga29719e" class="outline-4"&gt;
&lt;h4 id="orga29719e"&gt;Others&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orga29719e"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from graeae import EnvironmentLoader, Timer
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org246bc96" class="outline-3"&gt;
&lt;h3 id="org246bc96"&gt;Set Up&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org246bc96"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orge93544f" class="outline-4"&gt;
&lt;h4 id="orge93544f"&gt;Plotting&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orge93544f"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;SLUG = "shap-values"
OUTPUT_PATH = Path("../../files/posts/tutorials/")/SLUG
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;get_ipython().run_line_magic('matplotlib', 'inline')
get_ipython().run_line_magic('config', "InlineBackend.figure_format = 'retina'")
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org663ea8b" class="outline-4"&gt;
&lt;h4 id="org663ea8b"&gt;The Timer&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org663ea8b"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;TIMER = Timer()
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org664d413" class="outline-4"&gt;
&lt;h4 id="org664d413"&gt;Environment&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org664d413"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ENVIRONMENT = EnvironmentLoader()
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orga9aac4a" class="outline-4"&gt;
&lt;h4 id="orga9aac4a"&gt;The Data&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orga9aac4a"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;data = pandas.read_csv(Path(ENVIRONMENT["FIFA-2018"]).expanduser())
y = data["Man of the Match"] == "Yes"
FEATURES = [column for column in data.columns if data[column].dtype == numpy.int64]
X = data[FEATURES]
x_train, x_validate, y_train, y_validate = train_test_split(X, y, random_state=1)


model = RandomForestClassifier()

estimators = list(range(50, 200, 10))
max_depth = list(range(10, 100, 10)) + [None]

grid = dict(n_estimators=estimators,
	    max_depth=max_depth)
search = RandomizedSearchCV(estimator=model,
			    param_distributions=grid,
			    n_iter=40,
			    n_jobs=-1,
			    random_state=1)
with TIMER:
    search.fit(x_train, y_train)
first_model = search.best_estimator_
print(f"CV Training R^2: {search.best_score_:0.2f}")
print(f"Training R^2: {first_model.score(x_train, y_train): 0.2f}")
print(f"Validation R^2: {first_model.score(x_validate, y_validate):0.2f}")
print(search.best_params_)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
2020-02-10 18:09:33,716 graeae.timers.timer start: Started: 2020-02-10 18:09:33.716565
The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.
2020-02-10 18:09:36,830 graeae.timers.timer end: Ended: 2020-02-10 18:09:36.830883
2020-02-10 18:09:36,832 graeae.timers.timer end: Elapsed: 0:00:03.114318
CV Training R^2: 0.70
Training R^2:  1.00
Validation R^2: 0.69
{'n_estimators': 100, 'max_depth': 30}
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org855984d" class="outline-2"&gt;
&lt;h2 id="org855984d"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org855984d"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org2ab88be" class="outline-3"&gt;
&lt;h3 id="org2ab88be"&gt;A Single Row&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org2ab88be"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ROW = 5
row_data = x_validate.iloc[ROW]
row_data_matrix = row_data.values.reshape(1, -1)
print(first_model.classes_)
print(first_model.predict_proba(row_data_matrix))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
[False  True]
[[0.25 0.75]]
&lt;/pre&gt;


&lt;p&gt;
The &lt;a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.predict_proba"&gt;&lt;code&gt;predict_proba&lt;/code&gt;&lt;/a&gt; method tells us the probability for the data for each class. So this team has a 70% chance that they do have a man of the match.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;explainer = shap.TreeExplainer(first_model)
shap_values = explainer.shap_values(row_data_matrix)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(explainer.shap_values.__doc__)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Estimate the SHAP values for a set of samples.

       Parameters
       ----------
       X : numpy.array, pandas.DataFrame or catboost.Pool (for catboost)
           A matrix of samples (# samples x # features) on which to explain the model's output.

       y : numpy.array
           An array of label values for each sample. Used when explaining loss functions.

       tree_limit : None (default) or int
           Limit the number of trees used by the model. By default None means no use the limit of the
           original model, and -1 means no limit.

       approximate : bool
           Run fast, but only roughly approximate the Tree SHAP values. This runs a method
           previously proposed by Saabas which only considers a single feature ordering. Take care
           since this does not have the consistency guarantees of Shapley values and places too
           much weight on lower splits in the tree.

       check_additivity : bool
           Run a validation check that the sum of the SHAP values equals the output of the model. This
           check takes only a small amount of time, and will catch potential unforeseen errors.
           Note that this check only runs right now when explaining the margin of the model.

       Returns
       -------
       For models with a single output this returns a matrix of SHAP values
       (# samples x # features). Each row sums to the difference between the model output for that
       sample and the expected value of the model output (which is stored in the expected_value
       attribute of the explainer when it is constant). For models with vector outputs this returns
       a list of such matrices, one for each output.

&lt;/pre&gt;

&lt;p&gt;
The array returned by the &lt;code&gt;shap_values&lt;/code&gt; method has two rows - one for each of our target classes. In this case we're asking if a team had a man of the match so we'll just look at the second array.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;shap.initjs()
figure = shap.force_plot(explainer.expected_value[1],
			 shap_values[1],
			 row_data_matrix,
			 feature_names=FEATURES,
			 matplotlib=True, show=False)
filename = "shap_one.png"

figure.savefig(OUTPUT_PATH/filename)
print(f"[[file:{filename}]]")
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values/shap_one.png" alt="shap_one.png"&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;
Our predicted probability that this team had a man of the match was 0.7, but the base-value for the set as a whole is 0.4979 (you can't see it in this plot for some reason), so our team is more likely to have one than most teams. The pink section of the plot shows the features that increased the probability and the part in blue shows the features that decreased the probability. The size of each feature's block is proportional to the amount the feature contributed, so the biggest block (&lt;i&gt;Goal Scored&lt;/i&gt;) contributed the most. The greatest negative feature was &lt;i&gt;Ball Possession %&lt;/i&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org52953ea" class="outline-2"&gt;
&lt;h2 id="org52953ea"&gt;End&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org52953ea"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org43f2023" class="outline-3"&gt;
&lt;h3 id="org43f2023"&gt;See Also&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org43f2023"&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;The &lt;a href="https://shap.readthedocs.io/en/latest/"&gt;SHAP&lt;/a&gt; Documentation&lt;/li&gt;
&lt;li&gt;The &lt;a href="https://github.com/slundberg/shap"&gt;SHAP github repository&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Lundberg SM, Lee SI. A unified approach to interpreting model predictions. InAdvances in neural information processing systems 2017 (pp. 4765-4774). (&lt;a href="https://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predicti"&gt;PDF Available Here&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>interpret</category><category>machine learning</category><category>tutorial</category><category>visualization</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values/</guid><pubDate>Mon, 10 Feb 2020 01:07:12 GMT</pubDate></item><item><title>Exercise In Partial Dependence Plots</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/#orgc4b9b92"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/#org28397e7"&gt;Imports&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/#orge120f44"&gt;Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/#orgc68d7c1"&gt;PyPi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/#orge329a31"&gt;Others&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/#org8755954"&gt;Set Up&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/#org11946ee"&gt;The Environment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/#org77f0ad0"&gt;The Timer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/#org29ef8e6"&gt;Plotting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/#org2cdbde9"&gt;The Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/#orgc1a78ad"&gt;Middle&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/#org9e2af56"&gt;The First Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/#orgc97feb3"&gt;Question 1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/#org617fc19"&gt;Question 2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/#orgfc819a7"&gt;Question 3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/#orga8ada38"&gt;Question 4&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/#org8fba01a"&gt;Question 5&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgc4b9b92" class="outline-2"&gt;
&lt;h2 id="orgc4b9b92"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgc4b9b92"&gt;
&lt;p&gt;
This is my re-working of the Kaggle &lt;a href="https://www.kaggle.com/learn/machine-learning-explainability"&gt;Machine Learning Explainability&lt;/a&gt; exercise in Partial Dependece Plots. It uses data from the &lt;a href="https://www.kaggle.com/c/new-york-city-taxi-fare-prediction"&gt;Taxi Fare Prediction&lt;/a&gt; competition.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-org28397e7" class="outline-3"&gt;
&lt;h3 id="org28397e7"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org28397e7"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orge120f44" class="outline-4"&gt;
&lt;h4 id="orge120f44"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orge120f44"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from pathlib import Path
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgc68d7c1" class="outline-4"&gt;
&lt;h4 id="orgc68d7c1"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgc68d7c1"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from matplotlib import pyplot
from matplotlib.pyplot import rcParams
from pdpbox import pdp
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split, RandomizedSearchCV

import pandas
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orge329a31" class="outline-4"&gt;
&lt;h4 id="orge329a31"&gt;Others&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orge329a31"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from graeae import EnvironmentLoader, Timer
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org8755954" class="outline-3"&gt;
&lt;h3 id="org8755954"&gt;Set Up&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org8755954"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org11946ee" class="outline-4"&gt;
&lt;h4 id="org11946ee"&gt;The Environment&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org11946ee"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ENVIRONMENT = EnvironmentLoader()
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org77f0ad0" class="outline-4"&gt;
&lt;h4 id="org77f0ad0"&gt;The Timer&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org77f0ad0"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;TIMER = Timer()
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org29ef8e6" class="outline-4"&gt;
&lt;h4 id="org29ef8e6"&gt;Plotting&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org29ef8e6"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;SLUG = "exercise-in-partial-dependence-plots"
OUTPUT_PATH = Path("../../files/posts/tutorials/")/SLUG

rcParams["figure.figsize"] = (6, 4)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org2cdbde9" class="outline-4"&gt;
&lt;h4 id="org2cdbde9"&gt;The Data&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org2cdbde9"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ROWS = 5 * 10**4
data = pandas.read_csv(Path(ENVIRONMENT["NY-TAXI"]).expanduser()/"train.csv",
		       nrows=ROWS)
data = data.query('pickup_latitude &amp;gt; 40.7 and pickup_latitude &amp;lt; 40.8 and ' +
		  'dropoff_latitude &amp;gt; 40.7 and dropoff_latitude &amp;lt; 40.8 and ' +
		  'pickup_longitude &amp;gt; -74 and pickup_longitude &amp;lt; -73.9 and ' +
		  'dropoff_longitude &amp;gt; -74 and dropoff_longitude &amp;lt; -73.9 and ' +
		  'fare_amount &amp;gt; 0'
		  )
y = data.fare_amount
base_features = ['pickup_longitude',
		 'pickup_latitude',
		 'dropoff_longitude',
		 'dropoff_latitude']

X = data[base_features]

x_train, x_validate, y_train, y_validate = train_test_split(X, y, random_state=1)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgc1a78ad" class="outline-2"&gt;
&lt;h2 id="orgc1a78ad"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgc1a78ad"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org9e2af56" class="outline-3"&gt;
&lt;h3 id="org9e2af56"&gt;The First Model&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org9e2af56"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;first_model = RandomForestRegressor(n_estimators=180,
				    max_depth=50, random_state=1).fit(x_train, y_train)
print(f"Training R^2: {first_model.score(x_train, y_train):0.2f}")
print(f"Validation R^2: {first_model.score(x_validate, y_validate):0.2f}")
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Training R^2: 0.92
Validation R^2: 0.43
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgc97feb3" class="outline-3"&gt;
&lt;h3 id="orgc97feb3"&gt;Question 1&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgc97feb3"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;FEATURE = 'pickup_longitude'
pdp_dist = pdp.pdp_isolate(model=first_model,
			   dataset=x_validate,
			   model_features=base_features,
			   feature=FEATURE)
pdp.pdp_plot(pdp_dist, FEATURE)
output = f"{FEATURE}_pdp_plot.png"
pyplot.savefig(OUTPUT_PATH/output)
print(f"[[file:{output}]]")
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
[[file:pickup_longitude_pdp_plot.png]]
&lt;/pre&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/.ob-jupyter/eb446225f180346680b332c924342792de7e5135.png" alt="eb446225f180346680b332c924342792de7e5135.png"&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;
&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/pickup_longitude_pdp_plot.png" alt="pickup_longitude_pdp_plot.png"&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/.ob-jupyter/eb446225f180346680b332c924342792de7e5135.png" alt="eb446225f180346680b332c924342792de7e5135.png"&gt;
&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;
Why does the partial dependence plot have this U-shape?
&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;
At the extremes you have the locations that can potentially travel the furthest, creating the biggest fairs, but as you move to the center you reduce the amount you can possibly travel - although the change isn't symmetric so this isn't the only explanation, otherwise if it were then you would expect the two ends to have the highest values and the nadir to be at the halfway point (-73.95).
&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;
Does your explanation suggest what shape to expect in the partial dependence plots for the other features?
&lt;/p&gt;

&lt;p&gt;
Create all other partial plots.
&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;for FEATURE in base_features:
    pdp_dist = pdp.pdp_isolate(model=first_model,
			       dataset=x_validate,
			       model_features=base_features,
			       feature=FEATURE)
    pdp.pdp_plot(pdp_dist, FEATURE)
    output = f"{FEATURE}_pdp_plot.png"
    pyplot.savefig(OUTPUT_PATH/output)
    print(f"[[file:{output}]]")
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
[[file:pickup_longitude_pdp_plot.png]]
[[file:pickup_latitude_pdp_plot.png]]
[[file:dropoff_longitude_pdp_plot.png]]
[[file:dropoff_latitude_pdp_plot.png]]
&lt;/pre&gt;

&lt;p&gt;
&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/.ob-jupyter/eb446225f180346680b332c924342792de7e5135.png" alt="eb446225f180346680b332c924342792de7e5135.png"&gt;
&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/.ob-jupyter/f2c9b641a0b8f044729d15efd208f672e3ecb7c1.png" alt="f2c9b641a0b8f044729d15efd208f672e3ecb7c1.png"&gt;
&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/.ob-jupyter/6334156ec3931ff43161785fde6f1f27a460bccd.png" alt="6334156ec3931ff43161785fde6f1f27a460bccd.png"&gt;
&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/.ob-jupyter/4417e1dcc2d023ce83c886e006ce5de690bfe97b.png" alt="4417e1dcc2d023ce83c886e006ce5de690bfe97b.png"&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/pickup_latitude_pdp_plot.png" alt="pickup_latitude_pdp_plot.png"&gt;
&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/dropoff_longitude_pdp_plot.png" alt="dropoff_longitude_pdp_plot.png"&gt;
&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/dropoff_latitude_pdp_plot.png" alt="dropoff_latitude_pdp_plot.png"&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/.ob-jupyter/eb446225f180346680b332c924342792de7e5135.png" alt="eb446225f180346680b332c924342792de7e5135.png"&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org617fc19" class="outline-3"&gt;
&lt;h3 id="org617fc19"&gt;Question 2&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org617fc19"&gt;
&lt;p&gt;
Now you will run a 2D partial dependence plot.  As a reminder, here is the code from the tutorial.  
&lt;/p&gt;

&lt;p&gt;
Create a 2D plot for the features &lt;code&gt;pickup_longitude&lt;/code&gt; and &lt;code&gt;dropoff_longitude&lt;/code&gt;.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;FEATURES = "pickup_longitude dropoff_longitude".split()
interaction  =  pdp.pdp_interact(model=first_model,
				 dataset=x_validate,
				 model_features=base_features,
				 features=FEATURES)
pdp.pdp_interact_plot(pdp_interact_out=interaction,
		      feature_names=FEATURES, plot_type='contour')
output = "longitude_interaction.png"
pyplot.savefig(OUTPUT_PATH/output)
print(f"[[file:{output}]]")
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
[[file:longitude_interaction.png]]
&lt;/pre&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/.ob-jupyter/744ca56de862b725f3b5132f1c80c9bf41837026.png" alt="744ca56de862b725f3b5132f1c80c9bf41837026.png"&gt;
&lt;/p&gt;
&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/longitude_interaction.png" alt="longitude_interaction.png"&gt;
&lt;/p&gt;
&lt;/div&gt;


&lt;p&gt;
Our plot shows that the fares are highest at the top-left and bottom-right corners, as you might expect, since this would be the furthest distance from pickup to dropoff.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgfc819a7" class="outline-3"&gt;
&lt;h3 id="orgfc819a7"&gt;Question 3&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgfc819a7"&gt;
&lt;blockquote&gt;
&lt;p&gt;
Consider a ride starting at longitude -73.92 and ending at longitude -74. Using the graph from the last question, estimate how much money the rider would have saved if they'd started the ride at longitude -73.98 instead?
&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;
I don't exactly agree with the interpretation given by the kaggle notebook. Looking at the plot, -73.92 to -74 appears to cost 27, while a -73.92 to -74 would cost 9 - but the notebook says that -73.92 to -74 costs 24. So I would say there would be a saving of 18 while the given answer is 15. To reconcile the difference (kind of) we might say that -73.92 to -74 costs 12, not 9 - it's not really easy to tell by the plot, in which case I would also say the savings is 15.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orga8ada38" class="outline-3"&gt;
&lt;h3 id="orga8ada38"&gt;Question 4&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orga8ada38"&gt;
&lt;blockquote&gt;
&lt;p&gt;
In the PDP's you've seen so far, location features have primarily served as a proxy to capture distance traveled. In the permutation importance lessons, you added the features `abs_lon_change` and `abs_lat_change` as a more direct measure of distance.
&lt;/p&gt;

&lt;p&gt;
Create these features again here.
&lt;/p&gt;

&lt;p&gt;
After you run it, identify the most important difference between this partial dependence plot and the one you got without absolute value features. The code to generate the PDP without absolute value features is at the top of this code cell.
&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;FEATURE = 'pickup_longitude'
pdp_dist_original = pdp.pdp_isolate(model=first_model,
				    dataset=x_validate,
				    model_features=base_features,
				    feature=FEATURE)
pdp.pdp_plot(pdp_dist_original, FEATURE)
output = "pre_distance.png"
pyplot.savefig(OUTPUT_PATH/output)
print(f"[[file:{output}]]")
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/pre_distance.png" alt="pre_distance.png"&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/.ob-jupyter/eb446225f180346680b332c924342792de7e5135.png" alt="eb446225f180346680b332c924342792de7e5135.png"&gt;
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;data['abs_lon_change'] = abs(data.pickup_longitude - data.dropoff_longitude)
data['abs_lat_change'] = abs(data.pickup_latitude - data.dropoff_longitude)

features_2  = ['pickup_longitude',
	       'pickup_latitude',
	       'dropoff_longitude',
	       'dropoff_latitude',
	       'abs_lat_change',
	       'abs_lon_change']

X = data[features_2]
new_x_train, new_x_validate, new_y_train, new_y_validate = train_test_split(X, y, random_state=1)

estimators = list(range(50, 200, 10))
max_depth = list(range(10, 100, 10)) + [None]

grid = dict(n_estimators=estimators,
	    max_depth=max_depth)

model = RandomForestRegressor()
search = RandomizedSearchCV(estimator=model,
			    param_distributions=grid,
			    n_iter=40,
			    n_jobs=-1,
			    random_state=1)
with TIMER:
    search.fit(new_x_train, new_y_train)
second_model = search.best_estimator_
print(f"CV Training R^2: {search.best_score_:0.2f}")
print(f"Training R^2: {first_model.score(x_train, y_train): 0.2f}")
print(f"Validation R^2: {first_model.score(x_validate, y_validate):0.2f}")
print(search.best_params_)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
2020-02-09 17:36:14,915 graeae.timers.timer start: Started: 2020-02-09 17:36:14.915123
2020-02-09 17:43:16,053 graeae.timers.timer end: Ended: 2020-02-09 17:43:16.053011
2020-02-09 17:43:16,053 graeae.timers.timer end: Elapsed: 0:07:01.137888
CV Training R^2: 0.46
Training R^2:  0.92
Validation R^2: 0.43
{'n_estimators': 190, 'max_depth': 30}
&lt;/pre&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;FEATURE = 'pickup_longitude'
pdp_dist = pdp.pdp_isolate(model=second_model,
			   dataset=new_x_validate,
			   model_features=features_2,
			   feature=FEATURE)

pdp.pdp_plot(pdp_dist, FEATURE)
output = "pickup_longitude_with_distance_added.png"
pyplot.savefig(OUTPUT_PATH/output)
print(f"[[file:{output}]]")
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/pickup_longitude_with_distance_added.png" alt="pickup_longitude_with_distance_added.png"&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/.ob-jupyter/98c17657a972a412bc6d33619b6e23ee5818b884.png" alt="98c17657a972a412bc6d33619b6e23ee5818b884.png"&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org8fba01a" class="outline-3"&gt;
&lt;h3 id="org8fba01a"&gt;Question 5&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org8fba01a"&gt;
&lt;blockquote&gt;
&lt;p&gt;
Consider a scenario where you have only 2 predictive features, which we will call `feat_A` and `feat_B`. Both features have minimum values of -1 and maximum values of 1.  The partial dependence plot for `feat_A` increases steeply over its whole range, whereas the partial dependence plot for feature B increases at a slower rate (less steeply) over its whole range.
Does this guarantee that `feat_A` will have a higher permutation importance than `feat_B`.  Why or why not?
&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;
It doesn't - the partial dependence plot shows how the predictions change based on the inputs, but it isn't the same thing as the feature importance - it might be the case that a few inputs create a large difference but most points don't, in which case the feature importance won't be very large.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>interpret</category><category>machine learning</category><category>tutorial</category><category>visualization</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/</guid><pubDate>Sun, 09 Feb 2020 21:26:37 GMT</pubDate></item><item><title>Partial Dependence Plots</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/#org76bc05f"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/#orgb5fee0d"&gt;What is this about?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/#org7f4c222"&gt;How does it work?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/#org690f6dd"&gt;Imports&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/#org7f2de4b"&gt;Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/#org17afb66"&gt;PyPi&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/#org98f74df"&gt;Set Up&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/#org2097968"&gt;Plotting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/#orgde6fbc0"&gt;The Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/#orgeba0831"&gt;Middle&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/#org0425cac"&gt;A Decision Tree Model&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/#orgcfb4b30"&gt;Visualizing the Decision Tree&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/#org19b8ecc"&gt;Partial Dependency Plot&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/#org23b0729"&gt;Distance Covered&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/#org96647d3"&gt;A Random Forest Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/#org4a9192a"&gt;2D Partial Dependence Plots&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/#orga122c95"&gt;Forest From the Trees&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/#org99692f6"&gt;End&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org76bc05f" class="outline-2"&gt;
&lt;h2 id="org76bc05f"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org76bc05f"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgb5fee0d" class="outline-3"&gt;
&lt;h3 id="orgb5fee0d"&gt;What is this about?&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgb5fee0d"&gt;
&lt;p&gt;
These are my notes/re-write of the &lt;a href="https://www.kaggle.com/dansbecker/partial-plots"&gt;Partial Dependence Plots&lt;/a&gt; tutorial on kaggle. Partial Dependence Plots are a complement to Permutation Importance in that Permutation Importance can tell you which features are contributing to the model but don't tell you how features change with different inputs. Given that they have the word "Plot" in their name you can guess that this is a visualization method and since humans have a hard time visualizing things with more than three dimensions, using them requires selecting a subset of features (or maybe just one feature) to visualize at a time, so the fact that Permutation Importance ranks features by their contribution might come in handy in deciding which features to use.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7f4c222" class="outline-3"&gt;
&lt;h3 id="org7f4c222"&gt;How does it work?&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org7f4c222"&gt;
&lt;p&gt;
In a simplistic view we might say that it takes input data and then repeatedly alters the values in our feature of choice, freezing the other values so that we can see how varying the feature changes the prediction. You can then repeat this for multiple rows of data and take the average prediction for each value of our feature.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org690f6dd" class="outline-3"&gt;
&lt;h3 id="org690f6dd"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org690f6dd"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7f2de4b" class="outline-4"&gt;
&lt;h4 id="org7f2de4b"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org7f2de4b"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pathlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org17afb66" class="outline-4"&gt;
&lt;h4 id="org17afb66"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org17afb66"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;dotenv&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;load_dotenv&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;matplotlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;pyplot&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pdpbox&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;pdp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;get_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;info_plots&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.model_selection&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.ensemble&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;RandomForestClassifier&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.tree&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;DecisionTreeClassifier&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;tree&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;graphviz&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org98f74df" class="outline-3"&gt;
&lt;h3 id="org98f74df"&gt;Set Up&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org98f74df"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org2097968" class="outline-4"&gt;
&lt;h4 id="org2097968"&gt;Plotting&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org2097968"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;SLUG&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"partial-dependence-plots"&lt;/span&gt;
&lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"../../files/posts/tutorials/"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;SLUG&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgde6fbc0" class="outline-4"&gt;
&lt;h4 id="orgde6fbc0"&gt;The Data&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgde6fbc0"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"~/.env"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expanduser&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;load_dotenv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;override&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getenv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"FIFA-2018"&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expanduser&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgeba0831" class="outline-2"&gt;
&lt;h2 id="orgeba0831"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgeba0831"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org0425cac" class="outline-3"&gt;
&lt;h3 id="org0425cac"&gt;A Decision Tree Model&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org0425cac"&gt;
&lt;p&gt;
The data is the same set from the Permutation Importance exercise (team data to predict whether one of them would become the &lt;i&gt;Budweiser Man of the Match&lt;/i&gt;). Out initial model will be a shallow decision tree so that we can compare its structure to the plots.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"Man of the Match"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;"Yes"&lt;/span&gt;
&lt;span class="n"&gt;features&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;column&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;column&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;column&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dtype&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int64&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_validate&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;tree_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;DecisionTreeClassifier&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;max_depth&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;min_samples_split&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgcfb4b30" class="outline-4"&gt;
&lt;h4 id="orgcfb4b30"&gt;Visualizing the Decision Tree&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgcfb4b30"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;tree_graph&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tree&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;export_graphviz&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tree_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;out_file&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;feature_names&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;graph&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;graphviz&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Source&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tree_graph&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"decision_tree.dot"&lt;/span&gt;
&lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;render&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;format&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"png"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"[[file:&lt;/span&gt;&lt;span class="si"&gt;{output}&lt;/span&gt;&lt;span class="s2"&gt;.png]]"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/decision_tree.dot.png" alt="decision_tree.dot.png"&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org19b8ecc" class="outline-4"&gt;
&lt;h4 id="org19b8ecc"&gt;Partial Dependency Plot&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org19b8ecc"&gt;
&lt;p&gt;
To create the plot we can use the &lt;a href="https://pdpbox.readthedocs.io/en/latest/"&gt;PDPBox library&lt;/a&gt;.
&lt;/p&gt;
&lt;/div&gt;

&lt;ul class="org-ul"&gt;
&lt;li&gt;&lt;a id="org4efa272"&gt;&lt;/a&gt;Create the Data to Plot&lt;br&gt;
&lt;div class="outline-text-5" id="text-org4efa272"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;FEATURE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"Goal Scored"&lt;/span&gt;
&lt;span class="n"&gt;pdp_goals&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pdp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pdp_isolate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tree_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			    &lt;span class="n"&gt;model_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;feature&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;FEATURE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;

&lt;li&gt;&lt;a id="org5606093"&gt;&lt;/a&gt;Plot It&lt;br&gt;
&lt;div class="outline-text-5" id="text-org5606093"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;pdp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pdp_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pdp_goals&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;FEATURE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"pdp_goals_scored.png"&lt;/span&gt;
&lt;span class="n"&gt;pyplot&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;savefig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"[[file:&lt;/span&gt;&lt;span class="si"&gt;{output}&lt;/span&gt;&lt;span class="s2"&gt;]]"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/pdp_goals_scored.png" alt="pdp_goals_scored.png"&gt;
&lt;/p&gt;
&lt;/div&gt;


&lt;p&gt;
Looking at the plot we can interpret it as saying that scoring that first goal is helpful in getting someone on the team the Man of the Match, but after that, more goals doesn't help. The PDPBox documentation has no real information about interpreting the output (or anything they provide, really), but according to the Kaggle tutorial the y-axis is the change in the prediction from the baseline as x changes.
&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id="outline-container-org23b0729" class="outline-4"&gt;
&lt;h4 id="org23b0729"&gt;Distance Covered&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org23b0729"&gt;
&lt;p&gt;
We can also look at how much the distance the players cover on the field matters.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;FEATURE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"Distance Covered (Kms)"&lt;/span&gt;
&lt;span class="n"&gt;pdp_distance&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pdp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pdp_isolate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tree_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			       &lt;span class="n"&gt;model_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;feature&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;FEATURE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;pdp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pdp_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pdp_distance&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;FEATURE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"pdp_distance.png"&lt;/span&gt;
&lt;span class="n"&gt;pyplot&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;savefig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"[[file:&lt;/span&gt;&lt;span class="si"&gt;{output}&lt;/span&gt;&lt;span class="s2"&gt;]]"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/pdp_distance.png" alt="pdp_distance.png"&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;
It looks like there's one distance at which the probabilities increase and then going further doesn't matter.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pdp_distance&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;feature_grids&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
102.0
&lt;/pre&gt;


&lt;p&gt;
So you want your team to cover at least 102 Kilometers, but covering more won't help you.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org96647d3" class="outline-3"&gt;
&lt;h3 id="org96647d3"&gt;A Random Forest Model&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org96647d3"&gt;
&lt;p&gt;
The Decision Tree was useful because the simplicity made it easy to interpret, but an ensemble method like a Random Forest probably makes a better model so let's see what it reveals.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;forest&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RandomForestClassifier&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;FEATURE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"Goal Scored"&lt;/span&gt;
&lt;span class="n"&gt;pdp_goals&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pdp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pdp_isolate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;forest&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			    &lt;span class="n"&gt;model_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;feature&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;FEATURE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;pdp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pdp_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pdp_goals&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;FEATURE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"pdp_forest_goals_scored.png"&lt;/span&gt;
&lt;span class="n"&gt;pyplot&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;savefig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"[[file:&lt;/span&gt;&lt;span class="si"&gt;{output}&lt;/span&gt;&lt;span class="s2"&gt;]]"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/pdp_forest_goals_scored.png" alt="pdp_forest_goals_scored.png"&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;
So, our random forest says that the greatest gain comes from the first goal, but there is in fact a greater probability as you increase the number of goals scored.
&lt;/p&gt;

&lt;p&gt;
What about distance covered?
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;FEATURE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"Distance Covered (Kms)"&lt;/span&gt;
&lt;span class="n"&gt;pdp_distance&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pdp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pdp_isolate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;forest&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			       &lt;span class="n"&gt;model_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;feature&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;FEATURE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;pdp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pdp_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pdp_distance&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;FEATURE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"pdp_forest_distance.png"&lt;/span&gt;
&lt;span class="n"&gt;pyplot&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;savefig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"[[file:&lt;/span&gt;&lt;span class="si"&gt;{output}&lt;/span&gt;&lt;span class="s2"&gt;]]"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/pdp_forest_distance.png" alt="pdp_forest_distance.png"&gt;
&lt;/p&gt;
&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pdp_distance&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;feature_grids&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;pdp_distance&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pdp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmax&lt;/span&gt;&lt;span class="p"&gt;()])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
102.0
&lt;/pre&gt;


&lt;p&gt;
Our forest says that, once again, covering 102 kilometers maximizes the probability, but in this case it appears that going beyond that actually decreases the probability that your team would have the man of the match.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org4a9192a" class="outline-3"&gt;
&lt;h3 id="org4a9192a"&gt;2D Partial Dependence Plots&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org4a9192a"&gt;
&lt;p&gt;
Rather than plot a single feature against the probability of becoming the man of the match you can plot how two features interact to affect the probability.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;FEATURES&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"Goal Scored"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"Distance Covered (Kms)"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;interaction&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pdp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pdp_interact&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tree_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			       &lt;span class="n"&gt;model_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			       &lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;FEATURES&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;pdp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pdp_interact_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pdp_interact_out&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;interaction&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;feature_names&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;FEATURES&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
		      &lt;span class="n"&gt;plot_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"contour"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"goals_vs_distance.png"&lt;/span&gt;
&lt;span class="n"&gt;pyplot&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;savefig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"[[file:&lt;/span&gt;&lt;span class="si"&gt;{output}&lt;/span&gt;&lt;span class="s2"&gt;]]"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/goals_vs_distance.png" alt="goals_vs_distance.png"&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;
&lt;b&gt;Note:&lt;/b&gt; The version of PDPBox on pypi currently has a bug (as of February 8, 2020) that won't let you create the previous plot, install it from github instead.
&lt;/p&gt;

&lt;p&gt;
The plot shows a more succinct version of the two plots we had seen before - the optimal point for these two features is 1 goal and 102 Kms covered.
&lt;/p&gt;
&lt;/div&gt;

&lt;div id="outline-container-orga122c95" class="outline-4"&gt;
&lt;h4 id="orga122c95"&gt;Forest From the Trees&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orga122c95"&gt;
&lt;p&gt;
Let's re-run the same plot using the Random Forest instead of the Decision Tree.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;FEATURES&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"Goal Scored"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"Distance Covered (Kms)"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;interaction&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pdp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pdp_interact&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;forest&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			       &lt;span class="n"&gt;model_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			       &lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;FEATURES&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;pdp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pdp_interact_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pdp_interact_out&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;interaction&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;feature_names&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;FEATURES&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
		      &lt;span class="n"&gt;plot_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"contour"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"forest_goals_vs_distance.png"&lt;/span&gt;
&lt;span class="n"&gt;pyplot&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;savefig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"[[file:&lt;/span&gt;&lt;span class="si"&gt;{output}&lt;/span&gt;&lt;span class="s2"&gt;]]"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/forest_goals_vs_distance.png" alt="forest_goals_vs_distance.png"&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;
The random forest suggests a slightly different scenario - here you want 2 gooalds and between 100 and 110 Kms (or thereabouts) covered to get the best probability.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org99692f6" class="outline-2"&gt;
&lt;h2 id="org99692f6"&gt;End&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org99692f6"&gt;
&lt;p&gt;
This showed how to use the PDPBox library to create Partial Dependence Plots to look at how input values for features affects the predicted outcomes. Unfortunately it looks like PDPBox might have been abandoned, but while it works it's a nice library.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>interpret</category><category>machine learning</category><category>tutorial</category><category>visualization</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/</guid><pubDate>Sat, 08 Feb 2020 20:48:50 GMT</pubDate></item><item><title>Exercise in Permutation Importance</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-permutation-importance/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-permutation-importance/#orgff4f4b1"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-permutation-importance/#org8d90b27"&gt;Imports&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-permutation-importance/#orgd41ba19"&gt;From Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-permutation-importance/#org7dcac24"&gt;From PyPi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-permutation-importance/#org07d0ef7"&gt;Others&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-permutation-importance/#orgc1edd76"&gt;Set Up&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-permutation-importance/#org5655ebb"&gt;A Timer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-permutation-importance/#org7ddc042"&gt;Plotting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-permutation-importance/#orgd21c70f"&gt;The Environment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-permutation-importance/#org7511931"&gt;Table Printer&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-permutation-importance/#org7cd1f31"&gt;Middle&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-permutation-importance/#org867a504"&gt;The Dataset&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-permutation-importance/#org7332599"&gt;Set Up the Training and Test Sets&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-permutation-importance/#org26c4252"&gt;Build and Train the Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-permutation-importance/#org3197a2f"&gt;Questions&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-permutation-importance/#orgac1e9b9"&gt;Question 1&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-permutation-importance/#org43e2099"&gt;A New Model&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-permutation-importance/#org93e0df7"&gt;Question 4&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-permutation-importance/#org885887f"&gt;Feature Engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-permutation-importance/#org2c476b2"&gt;The Permutation Importance&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-permutation-importance/#org5c8c6e8"&gt;Question 5&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-permutation-importance/#orgfd92676"&gt;Question 6&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-permutation-importance/#org596b4cd"&gt;Euclidean Distance&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-permutation-importance/#org678d685"&gt;End&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgff4f4b1" class="outline-2"&gt;
&lt;h2 id="orgff4f4b1"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgff4f4b1"&gt;
&lt;p&gt;
This is my re-do of the &lt;a href="https://www.kaggle.com/learn/machine-learning-explainability"&gt;Machine Learning Explainability&lt;/a&gt; Permutation Importance exercise on kaggle. It uses the data from the &lt;a href="https://www.kaggle.com/c/new-york-city-taxi-fare-prediction/data"&gt;New York City Taxi Fare Prediction&lt;/a&gt; dataset on kaggle.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-org8d90b27" class="outline-3"&gt;
&lt;h3 id="org8d90b27"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org8d90b27"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgd41ba19" class="outline-4"&gt;
&lt;h4 id="orgd41ba19"&gt;From Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgd41ba19"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;argparse&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Namespace&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;functools&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;partial&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pathlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7dcac24" class="outline-4"&gt;
&lt;h4 id="org7dcac24"&gt;From PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org7dcac24"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;eli5.sklearn&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;PermutationImportance&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.ensemble&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;RandomForestRegressor&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.linear_model&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;LinearRegression&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.model_selection&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;RandomizedSearchCV&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;tabulate&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;tabulate&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;eli5&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;hvplot.pandas&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org07d0ef7" class="outline-4"&gt;
&lt;h4 id="org07d0ef7"&gt;Others&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org07d0ef7"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;graeae&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;EmbedHoloviews&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;EnvironmentLoader&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Timer&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgc1edd76" class="outline-3"&gt;
&lt;h3 id="orgc1edd76"&gt;Set Up&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgc1edd76"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org5655ebb" class="outline-4"&gt;
&lt;h4 id="org5655ebb"&gt;A Timer&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org5655ebb"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;TIMER&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Timer&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7ddc042" class="outline-4"&gt;
&lt;h4 id="org7ddc042"&gt;Plotting&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org7ddc042"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;SLUG&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"exercise-in-permutation-importance"&lt;/span&gt;
&lt;span class="n"&gt;PATH&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"../../files/posts/tutorials/"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;SLUG&lt;/span&gt;
&lt;span class="n"&gt;Plot&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Namespace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;800&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Embed&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;partial&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;EmbedHoloviews&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;folder_path&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;PATH&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgd21c70f" class="outline-4"&gt;
&lt;h4 id="orgd21c70f"&gt;The Environment&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgd21c70f"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;ENVIRONMENT&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;EnvironmentLoader&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7511931" class="outline-4"&gt;
&lt;h4 id="org7511931"&gt;Table Printer&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org7511931"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;TABLE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;partial&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tabulate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tablefmt&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"orgtbl"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;headers&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"keys"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;showindex&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7cd1f31" class="outline-2"&gt;
&lt;h2 id="org7cd1f31"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org7cd1f31"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org867a504" class="outline-4"&gt;
&lt;h4 id="org867a504"&gt;The Dataset&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org867a504"&gt;
&lt;p&gt;
Since this is about permutation importance we're just going to load a subset (there are over five million rows in the dataset) and use previously discovered values to get rid of outliers.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;ROWS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;
&lt;span class="n"&gt;PATH&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ENVIRONMENT&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"NY-TAXI"&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expanduser&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;PATH&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;is_dir&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;PATH&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="s2"&gt;"train.csv"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;nrows&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;ROWS&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;TABLE&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reset_index&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rename&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="s2"&gt;"index"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"Column"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;"Value"&lt;/span&gt;&lt;span class="p"&gt;})))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Column&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;key&lt;/td&gt;
&lt;td class="org-right"&gt;2009-06-15 17:26:21.0000001&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;fare_amount&lt;/td&gt;
&lt;td class="org-right"&gt;4.5&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;pickup_datetime&lt;/td&gt;
&lt;td class="org-right"&gt;2009-06-15 17:26:21 UTC&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;pickup_longitude&lt;/td&gt;
&lt;td class="org-right"&gt;-73.844311&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;pickup_latitude&lt;/td&gt;
&lt;td class="org-right"&gt;40.721319&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;dropoff_longitude&lt;/td&gt;
&lt;td class="org-right"&gt;-73.84161&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;dropoff_latitude&lt;/td&gt;
&lt;td class="org-right"&gt;40.712278000000005&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;passenger_count&lt;/td&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;ul class="org-ul"&gt;
&lt;li&gt;&lt;a id="org4ad6cb1"&gt;&lt;/a&gt;Trim Outliers&lt;br&gt;
&lt;div class="outline-text-5" id="text-org4ad6cb1"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;TABLE&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;describe&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;showindex&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Â &lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;fare_amount&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;pickup_longitude&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;pickup_latitude&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;dropoff_longitude&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;dropoff_latitude&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;passenger_count&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;count&lt;/td&gt;
&lt;td class="org-right"&gt;50000&lt;/td&gt;
&lt;td class="org-right"&gt;50000&lt;/td&gt;
&lt;td class="org-right"&gt;50000&lt;/td&gt;
&lt;td class="org-right"&gt;50000&lt;/td&gt;
&lt;td class="org-right"&gt;50000&lt;/td&gt;
&lt;td class="org-right"&gt;50000&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;mean&lt;/td&gt;
&lt;td class="org-right"&gt;11.3642&lt;/td&gt;
&lt;td class="org-right"&gt;-72.5098&lt;/td&gt;
&lt;td class="org-right"&gt;39.9338&lt;/td&gt;
&lt;td class="org-right"&gt;-72.5046&lt;/td&gt;
&lt;td class="org-right"&gt;39.9263&lt;/td&gt;
&lt;td class="org-right"&gt;1.66784&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;std&lt;/td&gt;
&lt;td class="org-right"&gt;9.68556&lt;/td&gt;
&lt;td class="org-right"&gt;10.3939&lt;/td&gt;
&lt;td class="org-right"&gt;6.22486&lt;/td&gt;
&lt;td class="org-right"&gt;10.4076&lt;/td&gt;
&lt;td class="org-right"&gt;6.01474&lt;/td&gt;
&lt;td class="org-right"&gt;1.28919&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;min&lt;/td&gt;
&lt;td class="org-right"&gt;-5&lt;/td&gt;
&lt;td class="org-right"&gt;-75.4238&lt;/td&gt;
&lt;td class="org-right"&gt;-74.0069&lt;/td&gt;
&lt;td class="org-right"&gt;-84.6542&lt;/td&gt;
&lt;td class="org-right"&gt;-74.0064&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;25%&lt;/td&gt;
&lt;td class="org-right"&gt;6&lt;/td&gt;
&lt;td class="org-right"&gt;-73.9921&lt;/td&gt;
&lt;td class="org-right"&gt;40.7349&lt;/td&gt;
&lt;td class="org-right"&gt;-73.9912&lt;/td&gt;
&lt;td class="org-right"&gt;40.7344&lt;/td&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;50%&lt;/td&gt;
&lt;td class="org-right"&gt;8.5&lt;/td&gt;
&lt;td class="org-right"&gt;-73.9818&lt;/td&gt;
&lt;td class="org-right"&gt;40.7527&lt;/td&gt;
&lt;td class="org-right"&gt;-73.9801&lt;/td&gt;
&lt;td class="org-right"&gt;40.7534&lt;/td&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;75%&lt;/td&gt;
&lt;td class="org-right"&gt;12.5&lt;/td&gt;
&lt;td class="org-right"&gt;-73.9671&lt;/td&gt;
&lt;td class="org-right"&gt;40.7674&lt;/td&gt;
&lt;td class="org-right"&gt;-73.9636&lt;/td&gt;
&lt;td class="org-right"&gt;40.7682&lt;/td&gt;
&lt;td class="org-right"&gt;2&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;max&lt;/td&gt;
&lt;td class="org-right"&gt;200&lt;/td&gt;
&lt;td class="org-right"&gt;40.7835&lt;/td&gt;
&lt;td class="org-right"&gt;401.083&lt;/td&gt;
&lt;td class="org-right"&gt;40.851&lt;/td&gt;
&lt;td class="org-right"&gt;43.4152&lt;/td&gt;
&lt;td class="org-right"&gt;6&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;to_plot&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="n"&gt;column&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;column&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;
		&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="s2"&gt;"latitude"&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;column&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="s2"&gt;"longitude"&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;column&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;
&lt;span class="n"&gt;plot&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;to_plot&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hvplot&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;box&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;opts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"Column Box-Plots"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
				 &lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;Plot&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
				 &lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;Plot&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Embed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;file_name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"column_box_plots"&lt;/span&gt;&lt;span class="p"&gt;)()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;object type="text/html" data="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-permutation-importance/column_box_plots.html" style="width:100%" height="800"&gt;
  &lt;p&gt;Figure Missing&lt;/p&gt;
&lt;/object&gt;

&lt;p&gt;
So you can see that there are negative fares, which seems wrong, and some outliers.
&lt;/p&gt;

&lt;p&gt;
This uses the pandas &lt;a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.query.html"&gt;query&lt;/a&gt; method which let's you write slightly more readable code for boolean slicing.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"{len(data):,}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;query&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"pickup_latitude &amp;gt; 40.7 and pickup_latitude &amp;lt; 40.8 and "&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
		  &lt;span class="s2"&gt;"dropoff_latitude &amp;gt; 40.7 and dropoff_latitude &amp;lt; 40.8 and "&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
		  &lt;span class="s2"&gt;"pickup_longitude &amp;gt; -74 and pickup_longitude &amp;lt; -73.9 and "&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
		  &lt;span class="s2"&gt;"dropoff_longitude &amp;gt; -74 and dropoff_longitude &amp;lt; -73.9 and "&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
		  &lt;span class="s2"&gt;"fare_amount &amp;gt; 0"&lt;/span&gt;
		  &lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"{len(data):,}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
50,000
31,289
&lt;/pre&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id="outline-container-org7332599" class="outline-4"&gt;
&lt;h4 id="org7332599"&gt;Set Up the Training and Test Sets&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org7332599"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fare_amount&lt;/span&gt;
&lt;span class="n"&gt;base_features&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'pickup_longitude'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
		 &lt;span class="s1"&gt;'pickup_latitude'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
		 &lt;span class="s1"&gt;'dropoff_longitude'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
		 &lt;span class="s1"&gt;'dropoff_latitude'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
		 &lt;span class="s1"&gt;'passenger_count'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;base_features&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_validate&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"{len(x_train):,}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"{len(x_validate):,}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
23,466
7,823
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org26c4252" class="outline-3"&gt;
&lt;h3 id="org26c4252"&gt;Build and Train the Model&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org26c4252"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;estimators&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;max_depth&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;grid&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;dict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_estimators&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;estimators&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	    &lt;span class="n"&gt;max_depth&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;max_depth&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RandomForestRegressor&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;search&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RandomizedSearchCV&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;estimator&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			    &lt;span class="n"&gt;param_distributions&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;grid&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			    &lt;span class="n"&gt;n_iter&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			    &lt;span class="n"&gt;n_jobs&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			    &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;TIMER&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;search&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;first_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;search&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;best_estimator_&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"CV Training R^2: &lt;/span&gt;&lt;span class="si"&gt;{search.best_score_:0.2f}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Training R^2: {first_model.score(x_train, y_train): 0.2f}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Validation R^2: {first_model.score(x_validate, y_validate):0.2f}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;search&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;best_params_&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
2020-02-10 13:40:59,617 graeae.timers.timer start: Started: 2020-02-10 13:40:59.616742
/home/brunhilde/.virtualenvs/Visions-Voices-Data/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.
  warnings.warn(CV_WARNING, FutureWarning)
/home/brunhilde/.virtualenvs/Visions-Voices-Data/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  "timeout or by a memory leak.", UserWarning
2020-02-10 13:42:04,387 graeae.timers.timer end: Ended: 2020-02-10 13:42:04.387425
2020-02-10 13:42:04,390 graeae.timers.timer end: Elapsed: 0:01:04.770683
CV Training R^2: 0.45
Training R^2:  0.92
Validation R^2: 0.42
{'n_estimators': 170, 'max_depth': 70}
&lt;/pre&gt;

&lt;p&gt;
So it isn't really a great model, but we'll ignore that for now.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org3197a2f" class="outline-3"&gt;
&lt;h3 id="org3197a2f"&gt;Questions&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org3197a2f"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgac1e9b9" class="outline-4"&gt;
&lt;h4 id="orgac1e9b9"&gt;Question 1&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgac1e9b9"&gt;
&lt;blockquote&gt;
&lt;p&gt;
The first model uses the following features:
&lt;/p&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;pickup_longitude&lt;/li&gt;
&lt;li&gt;pickup_latitude&lt;/li&gt;
&lt;li&gt;dropoff_longitude&lt;/li&gt;
&lt;li&gt;dropoff_latitude&lt;/li&gt;
&lt;li&gt;passenger_count&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;
Before running any codeâ¦ which variables seem potentially useful for predicting taxi fares? Do you think permutation importance will necessarily identify these features as important?
&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;
I think that pickup and dropoff latitude might be important, since this would reflect where in the city the person was and wanted to go. Passenger count might make a difference as well, but I don't know if there's a greater charge for more people. Longitude might also be useful, but my guess would be that the North-South location is more indicative of the type of place you are in (uptown or downtown) and thus how far you have to travel (I have a vague notion that New York City is longer vertically than horizontally, but I don't know if this is true). This would be even more important if the fares change by location, but I don't know if that's the case.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;TIMER&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;permutor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PermutationImportance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;first_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
	&lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_validate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;ipython_html&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;eli5&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show_weights&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;permutor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
				 &lt;span class="n"&gt;feature_names&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tolist&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="n"&gt;table&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_html&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ipython_html&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;TABLE&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;table&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-left"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Weight&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Feature&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;0.8413  Â± 0.0171&lt;/td&gt;
&lt;td class="org-left"&gt;dropoff_latitude&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.8135  Â± 0.0223&lt;/td&gt;
&lt;td class="org-left"&gt;pickup_latitude&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.5723  Â± 0.0370&lt;/td&gt;
&lt;td class="org-left"&gt;pickup_longitude&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.5324  Â± 0.0257&lt;/td&gt;
&lt;td class="org-left"&gt;dropoff_longitude&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;-0.0014  Â± 0.0015&lt;/td&gt;
&lt;td class="org-left"&gt;passenger_count&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;
So it looks like latitude and longitude are important, with latitude a little more important than longitude and passenger count isn't important.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org43e2099" class="outline-3"&gt;
&lt;h3 id="org43e2099"&gt;A New Model&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org43e2099"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org93e0df7" class="outline-4"&gt;
&lt;h4 id="org93e0df7"&gt;Question 4&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org93e0df7"&gt;
&lt;blockquote&gt;
&lt;p&gt;
Without detailed knowledge of New York City, it's difficult to rule out most hypotheses about why latitude features matter more than longitude.
&lt;/p&gt;

&lt;p&gt;
A good next step is to disentangle the effect of being in certain parts of the city from the effect of total distance traveled.  
&lt;/p&gt;

&lt;p&gt;
The code below creates new features for longitudinal and latitudinal distance. It then builds a model that adds these new features to those you already had.
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org885887f" class="outline-4"&gt;
&lt;h4 id="org885887f"&gt;Feature Engineering&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org885887f"&gt;
&lt;p&gt;
We're going to estimate the distance traveled by using the differences in latitude and longitude from the pickup to the dropoff. This should give us a taxicab-distance estimate.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'absolute_change_longitude'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropoff_longitude&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pickup_longitude&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'absolute_change_latitude'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dropoff_latitude&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pickup_latitude&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;features_2&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'pickup_longitude'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	       &lt;span class="s1"&gt;'pickup_latitude'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	       &lt;span class="s1"&gt;'dropoff_longitude'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	       &lt;span class="s1"&gt;'dropoff_latitude'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	       &lt;span class="s1"&gt;'absolute_change_latitude'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	       &lt;span class="s1"&gt;'absolute_change_longitude'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;features_2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;new_x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;new_x_validate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;new_y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;new_y_validate&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;estimators&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;250&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;max_depth&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RandomForestRegressor&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;search&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RandomizedSearchCV&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;estimator&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			    &lt;span class="n"&gt;param_distributions&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;grid&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			    &lt;span class="n"&gt;n_jobs&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			    &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;TIMER&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;search&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;new_x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;new_y_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;second_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;search&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;best_estimator_&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Mean Cross-Validation Training R^2: &lt;/span&gt;&lt;span class="si"&gt;{search.best_score_:0.2f}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Training R^2: {second_model.score(new_x_train, new_y_train): 0.2f}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Validation R^2: "&lt;/span&gt;
      &lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"{second_model.score(new_x_validate, new_y_validate):0.2f}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;search&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;best_params_&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
2020-02-10 13:42:52,104 graeae.timers.timer start: Started: 2020-02-10 13:42:52.104493
/home/brunhilde/.virtualenvs/Visions-Voices-Data/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.
  warnings.warn(CV_WARNING, FutureWarning)
2020-02-10 13:43:24,554 graeae.timers.timer end: Ended: 2020-02-10 13:43:24.554581
2020-02-10 13:43:24,556 graeae.timers.timer end: Elapsed: 0:00:32.450088
Mean Cross-Validation Training R^2: 0.48
Training R^2:  0.70
Validation R^2: 0.47
{'n_estimators': 190, 'max_depth': 10}
&lt;/pre&gt;


&lt;p&gt;
Still a pretty bad model, but that's not the point, I guess.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org2c476b2" class="outline-4"&gt;
&lt;h4 id="org2c476b2"&gt;The Permutation Importance&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org2c476b2"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;permutor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PermutationImportance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;second_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;new_x_validate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;new_y_validate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ipython_html&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;eli5&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show_weights&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;permutor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
				 &lt;span class="n"&gt;feature_names&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;new_x_validate&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tolist&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="n"&gt;table&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_html&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ipython_html&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;TABLE&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;table&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-left"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Weight&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Feature&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;0.5976  Â± 0.0306&lt;/td&gt;
&lt;td class="org-left"&gt;absolute_change_latitude&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.4429  Â± 0.0496&lt;/td&gt;
&lt;td class="org-left"&gt;absolute_change_longitude&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0339  Â± 0.0216&lt;/td&gt;
&lt;td class="org-left"&gt;pickup_latitude&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0232  Â± 0.0032&lt;/td&gt;
&lt;td class="org-left"&gt;dropoff_latitude&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0214  Â± 0.0068&lt;/td&gt;
&lt;td class="org-left"&gt;dropoff_longitude&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0159  Â± 0.0055&lt;/td&gt;
&lt;td class="org-left"&gt;pickup_longitude&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;
The distance traveled seems to be the most important feature for the fare, even more than the actual locations, probably because taxis charge by distance.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org5c8c6e8" class="outline-4"&gt;
&lt;h4 id="org5c8c6e8"&gt;Question 5&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org5c8c6e8"&gt;
&lt;p&gt;
This question is about the scale of the parameters. Here's a sample.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;TABLE&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;new_x_train&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reset_index&lt;/span&gt;&lt;span class="p"&gt;()))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;index&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;31975&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;pickup_longitude&lt;/td&gt;
&lt;td class="org-right"&gt;-73.9706&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;pickup_latitude&lt;/td&gt;
&lt;td class="org-right"&gt;40.7613&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;dropoff_longitude&lt;/td&gt;
&lt;td class="org-right"&gt;-73.9806&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;dropoff_latitude&lt;/td&gt;
&lt;td class="org-right"&gt;40.7483&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;absolute_change_latitude&lt;/td&gt;
&lt;td class="org-right"&gt;0.01302&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;absolute_change_longitude&lt;/td&gt;
&lt;td class="org-right"&gt;0.010067&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;
And here's some statistics about each.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;new_x_validate&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;describe&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
       pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \
count       7823.000000      7823.000000        7823.000000       7823.000000   
mean         -73.976957        40.756877         -73.975293         40.757591   
std            0.014663         0.018064           0.015877          0.018669   
min          -73.999977        40.700400         -73.999992         40.700293   
25%          -73.988180        40.745044         -73.987078         40.746345   
50%          -73.979933        40.757881         -73.978427         40.758602   
75%          -73.968008        40.769486         -73.966296         40.770561   
max          -73.900123        40.799865         -73.901790         40.799984   

       absolute_change_latitude  absolute_change_longitude  
count               7823.000000                7823.000000  
mean                   0.015091                   0.013029  
std                    0.012508                   0.011554  
min                    0.000000                   0.000000  
25%                    0.006089                   0.004968  
50%                    0.011745                   0.010110  
75%                    0.020781                   0.017798  
max                    0.084413                   0.087337  
&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;
A colleague observes that the values for &lt;code&gt;absolute_change_longitude&lt;/code&gt; and &lt;code&gt;absolute_change_latitude&lt;/code&gt; are pretty small (all values are between -0.1 and 0.1), whereas other variables have larger values.  Do you think this could explain why those coordinates had larger permutation importance values in this case?  
&lt;/p&gt;

&lt;p&gt;
Consider an alternative where you created and used a feature that was 100X as large for these features, and used that larger feature for training and importance calculations. Would this change the outputted permutation importance values?
&lt;/p&gt;

&lt;p&gt;
Why or why not?
&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;column&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"pickup_longitude pickup_latitude dropoff_longitude "&lt;/span&gt;
	       &lt;span class="s2"&gt;"dropoff_latitude absolute_change_latitude "&lt;/span&gt;
	       &lt;span class="s2"&gt;"absolute_change_longitude"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="si"&gt;{column}&lt;/span&gt;&lt;span class="s2"&gt;: {new_x_validate[column].max() - new_x_validate[column].min():0.3f}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
pickup_longitude: 0.100
pickup_latitude: 0.099
dropoff_longitude: 0.098
dropoff_latitude: 0.100
absolute_change_latitude: 0.084
absolute_change_longitude: 0.087
&lt;/pre&gt;


&lt;p&gt;
Intuitively I would think that the difference in the scales would make a difference.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"bigger_pickup_longitude"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pickup_longitude&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"bigger_absolute_change_longitude"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;absolute_change_longitude&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;
&lt;span class="n"&gt;features_3&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'pickup_longitude'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	       &lt;span class="s1"&gt;'pickup_latitude'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	       &lt;span class="s1"&gt;'dropoff_longitude'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	       &lt;span class="s1"&gt;'dropoff_latitude'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	       &lt;span class="s1"&gt;'absolute_change_latitude'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	       &lt;span class="s1"&gt;'absolute_change_longitude'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	       &lt;span class="s1"&gt;'bigger_pickup_longitude'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	       &lt;span class="s1"&gt;'bigger_absolute_change_longitude'&lt;/span&gt;
	       &lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;features_3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;big_x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;big_x_validate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;big_y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;big_y_validate&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RandomForestRegressor&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;search&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RandomizedSearchCV&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;estimator&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			    &lt;span class="n"&gt;param_distributions&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;grid&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			    &lt;span class="n"&gt;n_jobs&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			    &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;TIMER&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;search&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;big_x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;big_y_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;big_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;search&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;best_estimator_&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Mean Cross-Validation Training R^2: &lt;/span&gt;&lt;span class="si"&gt;{search.best_score_:0.2f}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Training R^2: {big_model.score(big_x_train, big_y_train): 0.2f}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Validation R^2: "&lt;/span&gt;
      &lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"{big_model.score(big_x_validate, big_y_validate):0.2f}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;search&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;best_params_&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
2020-02-09 15:06:45,693 graeae.timers.timer start: Started: 2020-02-09 15:06:45.693742
/home/athena/.virtualenvs/Visions-Voices-Data/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  "timeout or by a memory leak.", UserWarning
2020-02-09 15:09:15,559 graeae.timers.timer end: Ended: 2020-02-09 15:09:15.559561
2020-02-09 15:09:15,560 graeae.timers.timer end: Elapsed: 0:02:29.865819
Mean Cross-Validation Training R^2: 0.49
Training R^2:  0.70
Validation R^2: 0.47
{'n_estimators': 190, 'max_depth': 10}
&lt;/pre&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;permutor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PermutationImportance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;big_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;big_x_validate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;big_y_validate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ipython_html&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;eli5&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show_weights&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;permutor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
				 &lt;span class="n"&gt;feature_names&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;big_x_validate&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tolist&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="n"&gt;table&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_html&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ipython_html&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;TABLE&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;table&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-left"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Weight&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Feature&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;0.6034  Â± 0.0436&lt;/td&gt;
&lt;td class="org-left"&gt;absolute_change_latitude&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.1794  Â± 0.0126&lt;/td&gt;
&lt;td class="org-left"&gt;bigger_absolute_change_longitude&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.1366  Â± 0.0062&lt;/td&gt;
&lt;td class="org-left"&gt;absolute_change_longitude&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0326  Â± 0.0217&lt;/td&gt;
&lt;td class="org-left"&gt;pickup_latitude&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0242  Â± 0.0040&lt;/td&gt;
&lt;td class="org-left"&gt;dropoff_latitude&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0194  Â± 0.0083&lt;/td&gt;
&lt;td class="org-left"&gt;dropoff_longitude&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0188  Â± 0.0085&lt;/td&gt;
&lt;td class="org-left"&gt;pickup_longitude&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0116  Â± 0.0018&lt;/td&gt;
&lt;td class="org-left"&gt;bigger_pickup_longitude&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;
Making the pickup longitude  didn't change its ranking relative to the other features so I wouldn't say that the scale had an effect.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgfd92676" class="outline-4"&gt;
&lt;h4 id="orgfd92676"&gt;Question 6&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgfd92676"&gt;
&lt;blockquote&gt;
&lt;p&gt;
You've seen that the feature importance for latitudinal distance is greater than the importance of longitudinal distance. From this, can we conclude whether travelling a fixed latitudinal distance tends to be more expensive than traveling the same longitudinal distance?
&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;
No, the feature importance indicates that it is useful in predicting fares, but it doesn't automatically mean that the fares will increase with the change in latitude. It might be the case that the change in longitude affects the cost of a change in latitude as well, so a fixed latitude distance might change depending on the longitude or latitude + longitude combination.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org596b4cd" class="outline-3"&gt;
&lt;h3 id="org596b4cd"&gt;Euclidean Distance&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org596b4cd"&gt;
&lt;p&gt;
Instead of keeping latitudinal and longitudinal distances separate, what if we used the euclidean distance?
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"euclidean_distance"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;absolute_change_latitude&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;
					&lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;absolute_change_longitude&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;features&lt;/span&gt;  &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'pickup_longitude'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	       &lt;span class="s1"&gt;'pickup_latitude'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	       &lt;span class="s1"&gt;'dropoff_longitude'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	       &lt;span class="s1"&gt;'dropoff_latitude'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	       &lt;span class="s1"&gt;'absolute_change_latitude'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	       &lt;span class="s1"&gt;'absolute_change_longitude'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	       &lt;span class="s2"&gt;"euclidean_distance"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
	       &lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;euclid_x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;euclid_x_validate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;euclid_y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;euclid_y_validate&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RandomForestRegressor&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;search&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RandomizedSearchCV&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;estimator&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			    &lt;span class="n"&gt;param_distributions&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;grid&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			    &lt;span class="n"&gt;n_jobs&lt;/span&gt;&lt;span class="o"&gt;=-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			    &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="n"&gt;TIMER&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;search&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;euclid_x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;euclid_y_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;euclidean_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;search&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;best_estimator_&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Mean Cross-Validation Training R^2: &lt;/span&gt;&lt;span class="si"&gt;{search.best_score_:0.2f}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Training R^2: {euclidean_model.score(euclid_x_train, euclid_y_train): 0.2f}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Validation R^2: "&lt;/span&gt;
      &lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"{euclidean_model.score(euclid_x_validate, euclid_y_validate):0.2f}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;search&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;best_params_&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
2020-02-10 14:23:41,605 graeae.timers.timer start: Started: 2020-02-10 14:23:41.605310
/home/brunhilde/.virtualenvs/Visions-Voices-Data/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.
  warnings.warn(CV_WARNING, FutureWarning)
2020-02-10 14:24:20,385 graeae.timers.timer end: Ended: 2020-02-10 14:24:20.385580
2020-02-10 14:24:20,388 graeae.timers.timer end: Elapsed: 0:00:38.780270
Mean Cross-Validation Training R^2: 0.48
Training R^2:  0.74
Validation R^2: 0.48
{'n_estimators': 190, 'max_depth': 10}
&lt;/pre&gt;


&lt;p&gt;
Interestingly, the training \(R^2\) score went down although there was a slight improvement in the validation \(R^2\).
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;permutor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PermutationImportance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;euclidean_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;euclid_x_validate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;euclid_y_validate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ipython_html&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;eli5&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show_weights&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;permutor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;feature_names&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;euclid_x_validate&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tolist&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="n"&gt;table&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_html&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ipython_html&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;TABLE&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;table&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-left"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Weight&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Feature&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;1.3370  Â± 0.0469&lt;/td&gt;
&lt;td class="org-left"&gt;euclidean_distance&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.3031  Â± 0.0076&lt;/td&gt;
&lt;td class="org-left"&gt;absolute_change_latitude&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.1179  Â± 0.0046&lt;/td&gt;
&lt;td class="org-left"&gt;absolute_change_longitude&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0261  Â± 0.0045&lt;/td&gt;
&lt;td class="org-left"&gt;dropoff_latitude&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0224  Â± 0.0140&lt;/td&gt;
&lt;td class="org-left"&gt;dropoff_longitude&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0219  Â± 0.0041&lt;/td&gt;
&lt;td class="org-left"&gt;pickup_longitude&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0183  Â± 0.0051&lt;/td&gt;
&lt;td class="org-left"&gt;pickup_latitude&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;
According to the permutation importance, euclidean distance is much more important than the separate distances.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org678d685" class="outline-2"&gt;
&lt;h2 id="org678d685"&gt;End&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org678d685"&gt;
&lt;p&gt;
The suggested next tutorial is about &lt;a href="https://www.kaggle.com/dansbecker/partial-plots"&gt;Partial Dependence Plots&lt;/a&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>feature selection</category><category>permutation importance</category><category>tutorial</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-permutation-importance/</guid><pubDate>Thu, 06 Feb 2020 18:45:53 GMT</pubDate></item><item><title>Permutation Importance</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/#org6d9288b"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/#org1b02db6"&gt;Imports&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/#org3b23d35"&gt;Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/#orgf135ffb"&gt;PyPi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/#orgda3f5c0"&gt;Others&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/#org58df24c"&gt;Set Up&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/#org94ead59"&gt;Plotting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/#org3617fbc"&gt;The Environment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/#orga64ee47"&gt;The Table Printer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/#orgf35ea90"&gt;The Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/#orgdea3d2d"&gt;Middle&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/#org20cb4d5"&gt;Looking at the Dataset&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/#orgd3c05ef"&gt;The Target&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/#orgb15040b"&gt;The Features&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/#org39f8931"&gt;Build and Train the Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/#org8e4f2b9"&gt;Permutation Importance&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/#orgaca3b2d"&gt;Plotting the Importance&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/#org67cb970"&gt;End&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org6d9288b" class="outline-2"&gt;
&lt;h2 id="org6d9288b"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org6d9288b"&gt;
&lt;p&gt;
This is some notes on the kaggle tutorial on &lt;a href="https://www.kaggle.com/dansbecker/permutation-importance"&gt;Permutation Importance&lt;/a&gt;. &lt;i&gt;Permutation Importance&lt;/i&gt; is a form of feature selection where you ask - &lt;i&gt;If you randomly shuffle the values one column in the dataset and leave the others in place, how does this affect the performance of the model?&lt;/i&gt;. The idea is that if the column is important, then shuffling the values should make the model perform worse, so you can measure how much it degrades after you shuffle each column and figure out which columns are contributing to the model. Here's the rough process:
&lt;/p&gt;

&lt;ol class="org-ol"&gt;
&lt;li&gt;Start with a trained model and a labeled dataset.&lt;/li&gt;
&lt;li&gt;Shuffle a single column&lt;/li&gt;
&lt;li&gt;Measure how much worse the model does predicting the target.&lt;/li&gt;
&lt;li&gt;Restore the column and move on to the next column, repeating the steps until you have covered all the columns.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id="outline-container-org1b02db6" class="outline-3"&gt;
&lt;h3 id="org1b02db6"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org1b02db6"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org3b23d35" class="outline-4"&gt;
&lt;h4 id="org3b23d35"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org3b23d35"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;functools&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;partial&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pathlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgf135ffb" class="outline-4"&gt;
&lt;h4 id="orgf135ffb"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgf135ffb"&gt;
&lt;/div&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;&lt;a id="org4cda133"&gt;&lt;/a&gt;eli5&lt;br&gt;
&lt;div class="outline-text-5" id="text-org4cda133"&gt;
&lt;p&gt;
&lt;a href="https://eli5.readthedocs.io/en/latest/"&gt;eli5&lt;/a&gt; (which is presumably short for &lt;a href="https://www.dictionary.com/e/slang/eli5/"&gt;explain it like I'm five&lt;/a&gt;) is a library to help with machine learning model debugging and visualization. You can read about the PermutationImportance class &lt;a href="https://eli5.readthedocs.io/en/latest/autodocs/sklearn.html#eli5.sklearn.permutation_importance.PermutationImportance"&gt;here&lt;/a&gt;.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;eli5.sklearn&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;PermutationImportance&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;eli5&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a id="orge399d29"&gt;&lt;/a&gt;sklearn&lt;br&gt;
&lt;div class="outline-text-5" id="text-orge399d29"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.model_selection&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.ensemble&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;RandomForestClassifier&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;tabulate&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;tabulate&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;hvplot.pandas&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgda3f5c0" class="outline-4"&gt;
&lt;h4 id="orgda3f5c0"&gt;Others&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgda3f5c0"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;graeae&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;CountPercentage&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;EmbedHoloviews&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;EnvironmentLoader&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org58df24c" class="outline-3"&gt;
&lt;h3 id="org58df24c"&gt;Set Up&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org58df24c"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org94ead59" class="outline-4"&gt;
&lt;h4 id="org94ead59"&gt;Plotting&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org94ead59"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;SLUG&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"permutation-importance"&lt;/span&gt;
&lt;span class="n"&gt;PATH&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"../../files/posts/tutorials/"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;SLUG&lt;/span&gt;
&lt;span class="n"&gt;Embed&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;partial&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;EmbedHoloviews&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;folder_path&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;PATH&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org3617fbc" class="outline-4"&gt;
&lt;h4 id="org3617fbc"&gt;The Environment&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org3617fbc"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;ENVIRONMENT&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;EnvironmentLoader&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orga64ee47" class="outline-4"&gt;
&lt;h4 id="orga64ee47"&gt;The Table Printer&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orga64ee47"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;TABLE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;partial&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tabulate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tablefmt&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"orgtbl"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;headers&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"keys"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;showindex&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgf35ea90" class="outline-4"&gt;
&lt;h4 id="orgf35ea90"&gt;The Data&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgf35ea90"&gt;
&lt;p&gt;
The dataset here is the &lt;a href="https://www.kaggle.com/mathan/fifa-2018-match-statistics"&gt;Predict FIFA 2018 Man of the Match&lt;/a&gt; dataset from kaggle.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ENVIRONMENT&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"FIFA-2018"&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expanduser&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgdea3d2d" class="outline-2"&gt;
&lt;h2 id="orgdea3d2d"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgdea3d2d"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org20cb4d5" class="outline-3"&gt;
&lt;h3 id="org20cb4d5"&gt;Looking at the Dataset&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org20cb4d5"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;TABLE&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sample&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iloc&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reset_index&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;headers&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"Column Value"&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;()))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Column&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;Date&lt;/td&gt;
&lt;td class="org-right"&gt;20-06-2018&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Team&lt;/td&gt;
&lt;td class="org-right"&gt;Uruguay&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Opponent&lt;/td&gt;
&lt;td class="org-right"&gt;Saudi Arabia&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Goal Scored&lt;/td&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Ball Possession %&lt;/td&gt;
&lt;td class="org-right"&gt;47&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Attempts&lt;/td&gt;
&lt;td class="org-right"&gt;13&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;On-Target&lt;/td&gt;
&lt;td class="org-right"&gt;4&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Off-Target&lt;/td&gt;
&lt;td class="org-right"&gt;6&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Blocked&lt;/td&gt;
&lt;td class="org-right"&gt;3&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Corners&lt;/td&gt;
&lt;td class="org-right"&gt;3&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Offsides&lt;/td&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Free Kicks&lt;/td&gt;
&lt;td class="org-right"&gt;15&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Saves&lt;/td&gt;
&lt;td class="org-right"&gt;3&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Pass Accuracy %&lt;/td&gt;
&lt;td class="org-right"&gt;88&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Passes&lt;/td&gt;
&lt;td class="org-right"&gt;521&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Distance Covered (Kms)&lt;/td&gt;
&lt;td class="org-right"&gt;101&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Fouls Committed&lt;/td&gt;
&lt;td class="org-right"&gt;10&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Yellow Card&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Yellow &amp;amp; Red&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Red&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Man of the Match&lt;/td&gt;
&lt;td class="org-right"&gt;Yes&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;1st Goal&lt;/td&gt;
&lt;td class="org-right"&gt;23.0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Round&lt;/td&gt;
&lt;td class="org-right"&gt;Group Stage&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;PSO&lt;/td&gt;
&lt;td class="org-right"&gt;No&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Goals in PSO&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Own goals&lt;/td&gt;
&lt;td class="org-right"&gt;nan&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Own goal Time&lt;/td&gt;
&lt;td class="org-right"&gt;nan&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;
#+end_example
&lt;/p&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgd3c05ef" class="outline-4"&gt;
&lt;h4 id="orgd3c05ef"&gt;The Target&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgd3c05ef"&gt;
&lt;p&gt;
The target is "Man of the Match".
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;CountPercentage&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"Man of the Match"&lt;/span&gt;&lt;span class="p"&gt;])()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Value&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Count&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Percent (%)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;No&lt;/td&gt;
&lt;td class="org-right"&gt;64&lt;/td&gt;
&lt;td class="org-right"&gt;50.00&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Yes&lt;/td&gt;
&lt;td class="org-right"&gt;64&lt;/td&gt;
&lt;td class="org-right"&gt;50.00&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;
Not a particularly large dataset, but we aren't really interested in it per-se but rather how to use permutation importance with it.
&lt;/p&gt;

&lt;p&gt;
We want it to be a True/False value rather than a string value so let's change it.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loc&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="s2"&gt;"Man of the Match"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"Man of the Match"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;"Yes"&lt;/span&gt;
&lt;span class="n"&gt;CountPercentage&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"Man of the Match"&lt;/span&gt;&lt;span class="p"&gt;])()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Value&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Count&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Percent (%)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;True&lt;/td&gt;
&lt;td class="org-right"&gt;64&lt;/td&gt;
&lt;td class="org-right"&gt;50.00&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;False&lt;/td&gt;
&lt;td class="org-right"&gt;64&lt;/td&gt;
&lt;td class="org-right"&gt;50.00&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgb15040b" class="outline-3"&gt;
&lt;h3 id="orgb15040b"&gt;The Features&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgb15040b"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;info&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
&amp;lt;class 'pandas.core.frame.DataFrame'&amp;gt;
RangeIndex: 128 entries, 0 to 127
Data columns (total 27 columns):
Date                      128 non-null object
Team                      128 non-null object
Opponent                  128 non-null object
Goal Scored               128 non-null int64
Ball Possession %         128 non-null int64
Attempts                  128 non-null int64
On-Target                 128 non-null int64
Off-Target                128 non-null int64
Blocked                   128 non-null int64
Corners                   128 non-null int64
Offsides                  128 non-null int64
Free Kicks                128 non-null int64
Saves                     128 non-null int64
Pass Accuracy %           128 non-null int64
Passes                    128 non-null int64
Distance Covered (Kms)    128 non-null int64
Fouls Committed           128 non-null int64
Yellow Card               128 non-null int64
Yellow &amp;amp; Red              128 non-null int64
Red                       128 non-null int64
Man of the Match          128 non-null bool
1st Goal                  94 non-null float64
Round                     128 non-null object
PSO                       128 non-null object
Goals in PSO              128 non-null int64
Own goals                 12 non-null float64
Own goal Time             12 non-null float64
dtypes: bool(1), float64(3), int64(18), object(5)
memory usage: 26.2+ KB
None
&lt;/pre&gt;

&lt;p&gt;
As you can see there's both numeric and non-numeric columns. For illustration purposes let's use just the integer columns.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;column&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;column&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;column&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dtype&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int64&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;column&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;sorted&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;" * &lt;/span&gt;&lt;span class="si"&gt;{column}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_validate&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"Man of the Match"&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
* Attempts
* Ball Possession %
* Blocked
* Corners
* Distance Covered (Kms)
* Fouls Committed
* Free Kicks
* Goal Scored
* Goals in PSO
* Off-Target
* Offsides
* On-Target
* Pass Accuracy %
* Passes
* Red
* Saves
* Yellow &amp;amp; Red
* Yellow Card
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org39f8931" class="outline-3"&gt;
&lt;h3 id="org39f8931"&gt;Build and Train the Model&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org39f8931"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RandomForestClassifier&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;n_estimators&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Training Accuracy: {model.score(x_train, y_train)}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Validation Accuracy: {model.score(x_validate, y_validate)}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Training Accuracy: 1.0
Validation Accuracy: 0.6875
&lt;/pre&gt;


&lt;p&gt;
It didn't do particularly well on the validation set.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org8e4f2b9" class="outline-3"&gt;
&lt;h3 id="org8e4f2b9"&gt;Permutation Importance&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org8e4f2b9"&gt;
&lt;p&gt;
As I noted previously, you can read about the &lt;code&gt;PermutationImportance&lt;/code&gt; class &lt;a href="https://eli5.readthedocs.io/en/latest/autodocs/sklearn.html#eli5.sklearn.permutation_importance.PermutationImportance"&gt;here&lt;/a&gt;. If you read the documentation you'll see that you don't have to pass it a prefit model, and in some cases you don't want to but for our purposes we will.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;permutor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PermutationImportance&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_validate&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Now we can print out a table of the outcome.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;ipython_html&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;eli5&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show_weights&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;permutor&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;feature_names&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tolist&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="n"&gt;table&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_html&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;jupyter&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;python_html&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;TABLE&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;table&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-left"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Weight&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Feature&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;0.1750  Â± 0.0848&lt;/td&gt;
&lt;td class="org-left"&gt;Goal Scored&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0500  Â± 0.0637&lt;/td&gt;
&lt;td class="org-left"&gt;Distance Covered (Kms)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0437  Â± 0.0637&lt;/td&gt;
&lt;td class="org-left"&gt;Yellow Card&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0187  Â± 0.0500&lt;/td&gt;
&lt;td class="org-left"&gt;Off-Target&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0187  Â± 0.0637&lt;/td&gt;
&lt;td class="org-left"&gt;Free Kicks&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0187  Â± 0.0637&lt;/td&gt;
&lt;td class="org-left"&gt;Fouls Committed&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0125  Â± 0.0637&lt;/td&gt;
&lt;td class="org-left"&gt;Pass Accuracy %&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0125  Â± 0.0306&lt;/td&gt;
&lt;td class="org-left"&gt;Blocked&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0063  Â± 0.0612&lt;/td&gt;
&lt;td class="org-left"&gt;Saves&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0063  Â± 0.0250&lt;/td&gt;
&lt;td class="org-left"&gt;Ball Possession %&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0  Â± 0.0000&lt;/td&gt;
&lt;td class="org-left"&gt;Red&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0  Â± 0.0000&lt;/td&gt;
&lt;td class="org-left"&gt;Yellow &amp;amp; Red&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0000  Â± 0.0559&lt;/td&gt;
&lt;td class="org-left"&gt;On-Target&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;-0.0063  Â± 0.0729&lt;/td&gt;
&lt;td class="org-left"&gt;Offsides&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;-0.0063  Â± 0.0919&lt;/td&gt;
&lt;td class="org-left"&gt;Corners&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;-0.0063  Â± 0.0250&lt;/td&gt;
&lt;td class="org-left"&gt;Goals in PSO&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;-0.0187  Â± 0.0306&lt;/td&gt;
&lt;td class="org-left"&gt;Attempts&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;-0.0500  Â± 0.0637&lt;/td&gt;
&lt;td class="org-left"&gt;Passes&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;
The table is ranked from most important feature to least important (based on the accuracy after shuffling the column). Anything with 0 or less essenttially contributed nothing to the model - although that doesn't mean that they might not be useful for more feature engineering.
&lt;/p&gt;

&lt;p&gt;
The data is for the team as a whole, not an individual, so the "Man of the Match" column is telling you if any player on the team was awarded the "Budweiser Man of the Match".
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgaca3b2d" class="outline-4"&gt;
&lt;h4 id="orgaca3b2d"&gt;Plotting the Importance&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgaca3b2d"&gt;
&lt;p&gt;
The numbers are okay, but let's take a look at a plot of the weights.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;weights&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;table&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Weight&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;str&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;expand&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;astype&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;table&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"weights"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;weights&lt;/span&gt;
&lt;span class="n"&gt;plot&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;table&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;hvplot&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"Feature"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"weights"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;opts&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"Permutation Importance (by Accuracy)"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;width&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;height&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;800&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;xrotation&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;45&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;Embed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;file_name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"permutation_importance"&lt;/span&gt;&lt;span class="p"&gt;)()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;object type="text/html" data="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/permutation_importance.html" style="width:100%" height="800"&gt;
  &lt;p&gt;Figure Missing&lt;/p&gt;
&lt;/object&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org67cb970" class="outline-2"&gt;
&lt;h2 id="org67cb970"&gt;End&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org67cb970"&gt;
&lt;p&gt;
So that's a quick look at getting a sense of the importance of a feature using &lt;code&gt;eli5&lt;/code&gt; and permutation importance. There's a more in-depth look at it on their site, but next is another look at it with a different data set.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>feature importance</category><category>kaggle</category><category>tutorial</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/</guid><pubDate>Wed, 05 Feb 2020 20:33:20 GMT</pubDate></item><item><title>Decision Trees</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/machine-learning/decision-trees/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/machine-learning/decision-trees/#orgbcddfe2"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/machine-learning/decision-trees/#orgdf6db35"&gt;Imports&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/machine-learning/decision-trees/#orgfe107b3"&gt;Set Up&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/machine-learning/decision-trees/#orga28221a"&gt;Splitting A Node&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/machine-learning/decision-trees/#orgd006346"&gt;Entropy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/machine-learning/decision-trees/#org7d9e0c9"&gt;Binary Splitting of Qualitative Attributes Using the Gini Index&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgbcddfe2" class="outline-2"&gt;
&lt;h2 id="orgbcddfe2"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgbcddfe2"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgdf6db35" class="outline-3"&gt;
&lt;h3 id="orgdf6db35"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgdf6db35"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7b1dcbf" class="outline-4"&gt;
&lt;h4 id="org7b1dcbf"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org7b1dcbf"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from functools import partial
from typing import Any
from math import log2
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org9bd7238" class="outline-4"&gt;
&lt;h4 id="org9bd7238"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org9bd7238"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from expects import (
    be_within,
    expect,
)
from tabulate import tabulate
import attr
import pandas
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgfe107b3" class="outline-3"&gt;
&lt;h3 id="orgfe107b3"&gt;Set Up&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgfe107b3"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;TABLE = partial(tabulate, headers="keys", tablefmt="orgtbl")
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orga28221a" class="outline-2"&gt;
&lt;h2 id="orga28221a"&gt;Splitting A Node&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orga28221a"&gt;
&lt;p&gt;
We choose which is the next node to split by checking the amount of information we would gain for each candidate node and picking the one that gives us the highest gain. We do this by measuring the &lt;b&gt;&lt;b&gt;impurity&lt;/b&gt;&lt;/b&gt; of the nodes, which is a measurement of how dissimilar the class labels are for a node.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgd006346" class="outline-3"&gt;
&lt;h3 id="orgd006346"&gt;Entropy&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgd006346"&gt;
&lt;p&gt;
One measure of "impurity" is &lt;a href="https://www.wikiwand.com/en/Entropy_(information_theory)"&gt;entropy&lt;/a&gt;, a measurement of the information associated with our nodes.
&lt;/p&gt;
&lt;/div&gt;

&lt;div id="outline-container-org199cb66" class="outline-4"&gt;
&lt;h4 id="org199cb66"&gt;Node Entropy&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org199cb66"&gt;
&lt;p&gt;
Here's where we'll calculate the entropy for a node.
&lt;/p&gt;

&lt;p&gt;
\[
Entropy = - \sum_{i=0}^{c-1} p_i(t)log_2 p_i(t)
\]
&lt;/p&gt;

&lt;p&gt;
Where \(p_1(t)\) is the fraction of training data (&lt;i&gt;t&lt;/i&gt;) that has the classification &lt;i&gt;i&lt;/i&gt;. We can translate that to a python function.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; def node_entropy(data: pandas.Series, debug: bool=False) -&amp;gt; float:
     """Calculate the entropy for a child node

     Args:
      data: target data filtered to match the child-node's class
      debug: emit values

     Returns:
      entropy for this node
     """
     if debug:
	 print("calculating node-entropy")
     total = len(data)
     accumulated = 0
     for classification in data.unique():
	 p = len(data[data == classification])/total
	 if debug:
	     print(f"\tclass: {classification}, p: {p} entropy: {p * log2(p)}")
	 accumulated += p * log2(p)
     if debug:
	 print(f"Node Entropy: {accumulated}")
     return -accumulated
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org5daa6c7" class="outline-4"&gt;
&lt;h4 id="org5daa6c7"&gt;Entropy of a Node's Children&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org5daa6c7"&gt;
&lt;p&gt;
We'll use the entropy formula to get the entropy for an indivdual node but to get the total contribution from the possible splits we'll take a weighted sum of the node entropies.
&lt;/p&gt;

&lt;p&gt;
\[
I(children) = \sum_{j=1}^k \frac{N(v_j)}{N} I(v_j)
\]
&lt;/p&gt;

&lt;p&gt;
Where \(\frac{N(v_j)}{N}\) is the fraction of the child data in node &lt;i&gt;j&lt;/i&gt; and \(I(v_j)\) is the entropy (Impurity) of node &lt;i&gt;j&lt;/i&gt;.
&lt;/p&gt;

&lt;p&gt;
Once again, in python.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def children_impurity(data: pandas.DataFrame, column: str, target: str,
		      impurity: object=node_entropy,
	    debug: bool=False) -&amp;gt; float:
    """Calculate the entropy for the parent of child nodes

    Args:
     data: the container for the values to check
     column: the column to get the entropy
     target: the target column
     impurity: the function to calculate the impurity of the child
     debug: whether to print some intermediate values

    Returns:
     entropy for the data
    """
    if debug:
	print("Calculating entropy for child nodes")
    total = len(data)
    accumulator = 0
    for classification in data[column].unique():
	child = data[data[column] == classification][target]
	if debug:
	    print(f"\tI_({classification}) = ({len(child)}/{total}) "
		  f"x {impurity(child)}")
	accumulator += (len(child)/total) * impurity(child)
    if debug:
	print(f"Child node entropy: {accumulator}")
    return accumulator
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org82a3430" class="outline-4"&gt;
&lt;h4 id="org82a3430"&gt;Information Gain&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org82a3430"&gt;
&lt;p&gt;
The measurement of how much is gained is the difference between a parent node and its children.
\[
\Delta = I(parent) - I(children)
\]
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; def information_gain(data: pandas.Series, column: str, target: str,
		      debug: bool=False) -&amp;gt; float:
     """See how much entropy is removed using this node

     Args:
      data: source to check
      column: name of the column representing the parent node
      target: name of the column we are trying to predict
      debug: emit messages
     """
     return node_entropy(data[target], debug=debug) - children_impurity(
	 data, column=column, target=target, debug=debug)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org53f16d8" class="outline-4"&gt;
&lt;h4 id="org53f16d8"&gt;Home Loans&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org53f16d8"&gt;
&lt;p&gt;
To make this concrete we can look at a small dataset of people applying for a loan. We want to know if they are likely to default and we need to decide if we want our first split to be on whether they own a home or are married (we'll ignore income for this check because it's meant to illustrate splitting qualitative data).
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; @attr.s(auto_attribs=True, slots=True, frozen=True)
 class LoanColumns:
     owner: str = "Home Owner"
     married: str = "Marital Status"
     income: str = "Annual Income"
     defaulted: str = "Defaulted"

 LOANS = LoanColumns()
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; loans = pandas.DataFrame({
     LOANS.owner: [True, False, False, True, False, False, True, False, False, False],
     LOANS.married: ["Single", "Married", "Single", "Married", "Divorced", "Single", "Divorced", "Single", "Married", "Single"],
     LOANS.income: [125000, 100000, 70000, 120000, 95000, 60000, 220000, 85000, 75000, 90000],
     LOANS.defaulted: [False, False, False, False, True, False, False, True, False, True],
 })
 print(TABLE(loans))
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-right"&gt;

&lt;col class="org-left"&gt;

&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-left"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-right"&gt;Â &lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Home Owner&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Marital Status&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Annual Income&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Defaulted&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-left"&gt;True&lt;/td&gt;
&lt;td class="org-left"&gt;Single&lt;/td&gt;
&lt;td class="org-right"&gt;125000&lt;/td&gt;
&lt;td class="org-left"&gt;False&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;td class="org-left"&gt;False&lt;/td&gt;
&lt;td class="org-left"&gt;Married&lt;/td&gt;
&lt;td class="org-right"&gt;100000&lt;/td&gt;
&lt;td class="org-left"&gt;False&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;2&lt;/td&gt;
&lt;td class="org-left"&gt;False&lt;/td&gt;
&lt;td class="org-left"&gt;Single&lt;/td&gt;
&lt;td class="org-right"&gt;70000&lt;/td&gt;
&lt;td class="org-left"&gt;False&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;3&lt;/td&gt;
&lt;td class="org-left"&gt;True&lt;/td&gt;
&lt;td class="org-left"&gt;Married&lt;/td&gt;
&lt;td class="org-right"&gt;120000&lt;/td&gt;
&lt;td class="org-left"&gt;False&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;4&lt;/td&gt;
&lt;td class="org-left"&gt;False&lt;/td&gt;
&lt;td class="org-left"&gt;Divorced&lt;/td&gt;
&lt;td class="org-right"&gt;95000&lt;/td&gt;
&lt;td class="org-left"&gt;True&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;5&lt;/td&gt;
&lt;td class="org-left"&gt;False&lt;/td&gt;
&lt;td class="org-left"&gt;Single&lt;/td&gt;
&lt;td class="org-right"&gt;60000&lt;/td&gt;
&lt;td class="org-left"&gt;False&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;6&lt;/td&gt;
&lt;td class="org-left"&gt;True&lt;/td&gt;
&lt;td class="org-left"&gt;Divorced&lt;/td&gt;
&lt;td class="org-right"&gt;220000&lt;/td&gt;
&lt;td class="org-left"&gt;False&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;7&lt;/td&gt;
&lt;td class="org-left"&gt;False&lt;/td&gt;
&lt;td class="org-left"&gt;Single&lt;/td&gt;
&lt;td class="org-right"&gt;85000&lt;/td&gt;
&lt;td class="org-left"&gt;True&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;8&lt;/td&gt;
&lt;td class="org-left"&gt;False&lt;/td&gt;
&lt;td class="org-left"&gt;Married&lt;/td&gt;
&lt;td class="org-right"&gt;75000&lt;/td&gt;
&lt;td class="org-left"&gt;False&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;9&lt;/td&gt;
&lt;td class="org-left"&gt;False&lt;/td&gt;
&lt;td class="org-left"&gt;Single&lt;/td&gt;
&lt;td class="org-right"&gt;90000&lt;/td&gt;
&lt;td class="org-left"&gt;True&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;
The first step is to calculate the entropy for the entire set using whether they defaulted or not as our classification.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; impurity_parent = node_entropy(loans[LOANS.defaulted])
 print(f"I_parent: {impurity_parent:0.3f}")

 expect(impurity_parent).to(be_within(0.8812, 0.8813))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
I_parent: 0.881
&lt;/pre&gt;


&lt;p&gt;
The next step is to figure out which of our two chosen attributes gives us the most information gain- whether the person was a Home Owner or their Marital Status. We could just look at which has a lower entropy, but the problem is stated so that we want to find the greatest difference between the class' entropy and the parent entropy instead.
&lt;/p&gt;
&lt;/div&gt;

&lt;ul class="org-ul"&gt;
&lt;li&gt;&lt;a id="org4eeda5d"&gt;&lt;/a&gt;Home Owners&lt;br&gt;
&lt;div class="outline-text-5" id="text-org4eeda5d"&gt;
&lt;p&gt;
We have two child nodes - one for homeowners and one for non-homeowners.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; print(loans[loans[LOANS.owner]][LOANS.defaulted].value_counts())
 print()
 print(loans[~loans[LOANS.owner]][LOANS.defaulted].value_counts())
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
False    3
Name: Defaulted, dtype: int64

False    4
True     3
Name: Defaulted, dtype: int64
&lt;/pre&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; impurity_home_owner = children_entropy(loans,
					column=LOANS.owner,
					target=LOANS.defaulted, debug=True)
 print(f"{impurity_home_owner: 0.3f}")
 expect(impurity_home_owner).to(be_within(0.689, 0.691))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Calculating entropy for child nodes
	I_(True) = (3/10) x -0.0
	I_(False) = (7/10) x 0.9852281360342515
Child node entropy: 0.6896596952239761
 0.690
&lt;/pre&gt;


&lt;p&gt;
Odd that python allows negative zero-valuesâ¦ Now we can see what the information gain will be.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; gain_home_owner = information_gain(loans, LOANS.owner, LOANS.defaulted)
 print(f"Delta Home-Owner: {gain_home_owner: 0.3}")
 expect(gain_home_owner).to(be_within(0.190, 0.19165))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Delta Home-Owner:  0.192
&lt;/pre&gt;


&lt;p&gt;
I seem to have precision differences with the bookâ¦
&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a id="org55384e0"&gt;&lt;/a&gt;Married Applicants&lt;br&gt;
&lt;div class="outline-text-5" id="text-org55384e0"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; gain_married = information_gain(loans, LOANS.married, LOANS.defaulted, debug=True)
 print(f"Delta Married: {gain_married: 0.3f}")
 expect(gain_married).to(be_within(0.194, 0.196))
 choice = max(((gain_home_owner, LOANS.owner),
	       (gain_married, LOANS.married)))
 print(f"Next Node: {choice}")
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
calculating node-entropy
        class: False, p: 0.7 entropy: -0.3602012209808308
        class: True, p: 0.3 entropy: -0.5210896782498619
Node Entropy: -0.8812908992306927
Calculating entropy for child nodes
        I_(Single) = (5/10) x 0.9709505944546686
        I_(Married) = (3/10) x -0.0
        I_(Divorced) = (2/10) x 1.0
Child node entropy: 0.6854752972273344
Delta Married:  0.196
Next Node: (0.19581560200335835, 'Marital Status')
&lt;/pre&gt;

&lt;p&gt;
Since we gain more information from checking whether someone was married or not, that would be the next node we would choose to split.
&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7d9e0c9" class="outline-3"&gt;
&lt;h3 id="org7d9e0c9"&gt;Binary Splitting of Qualitative Attributes Using the Gini Index&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org7d9e0c9"&gt;
&lt;p&gt;
\[
\textit{Gini Index} = 1 - \sum_{i=0}^{c - 1}
\]
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def gini(data: pandas.Series) -&amp;gt; float:
    """Calculate the gini index for the data"""
    total = len(data)
    accumulator = 0
    for classification in data.unique():
	accumulator += (len(data[data==classification])/total)**2
    return 1 - accumulator
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org5ec7157" class="outline-4"&gt;
&lt;h4 id="org5ec7157"&gt;Parent Impurity&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org5ec7157"&gt;
&lt;p&gt;
First we get the gini index for the overall data.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;parent_gini = gini(loans[LOANS.defaulted])
print(f"I_parent = {parent_gini: 0.3f}")
expect(parent_gini).to(be_within(0.420, 0.421))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
I_parent =  0.420
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org1454491" class="outline-4"&gt;
&lt;h4 id="org1454491"&gt;Home Owner Impurity&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org1454491"&gt;
&lt;p&gt;
Now the homeowner attribute.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;homeowner_gini = children_impurity(loans, LOANS.owner, LOANS.defaulted, gini, debug=True)
expect(homeowner_gini).to(be_within(0.342, 0.344))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Calculating entropy for child nodes
	I_(True) = (3/10) x 0.0
	I_(False) = (7/10) x 0.48979591836734704
Child node entropy: 0.3428571428571429
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org4ddb355" class="outline-4"&gt;
&lt;h4 id="org4ddb355"&gt;Married Impurity&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org4ddb355"&gt;
&lt;p&gt;
This is different from the entropy case because we want to do binary splits but the marital status attribute has three values (&lt;i&gt;Single&lt;/i&gt;, &lt;i&gt;Married&lt;/i&gt;, and &lt;i&gt;Divorced&lt;/i&gt;) so we need to use a different function that does each attribute against the other (or we could add columns which turn the marital status into a binary attribute, but this seems simpler).
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def binary_gini(data: pandas.Series, column: str, target: str,
		classification: object, debug: bool=False) -&amp;gt; float:
    """Calculate the gini value for the data using one against many

    Args:
     data: source with qualitative values
     column: column with the classifications to test
     target: column with the classifications to predict
     classification: the classification to compare
     debug: whether to emit messages
    """
    total = len(data)
    classified = data[data[column] == classification]
    others = data[data[column] != classification]
    if debug:
	print(f"N({classification}/N) I({classification}) = {len(classified)/total * gini(classified[target]):0.3f}")
	print(f"N(!{classification}/N) I!({classification}) = {len(others)/total * gini(others[target]):0.3f}")
	print(f"I({classification}) = {((len(classified)/total) * gini(classified[target]) + (len(others)/total) * gini(others[target])):0.3f}")
    return ((len(classified)/total) * gini(classified[target])
	    + (len(others)/total) * gini(others[target]))
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;@attr.s(auto_attribs=True, slots=True, frozen=True)
class MaritalStatus:
    single: str="Single"
    married: str="Married"
    divorced: str="Divorced"

status = MaritalStatus()
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;i_single = binary_gini(loans, LOANS.married, LOANS.defaulted, status.single,
		       debug=True)
print()
i_married = binary_gini(loans, LOANS.married, LOANS.defaulted, status.married,
			debug=True)
print()
i_divorced = binary_gini(loans, LOANS.married, LOANS.defaulted,
			 status.divorced, debug=True)
expect(i_single).to(be_within(0.39, 0.41))
expect(i_divorced).to(be_within(0.39, 0.41))
expect(i_married).to(be_within(0.342, 0.344))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
N(Single/N) I(Single) = 0.240
N(!Single/N) I!(Single) = 0.160
I(Single) = 0.400

N(Married/N) I(Married) = 0.000
N(!Married/N) I!(Married) = 0.343
I(Married) = 0.343

N(Divorced/N) I(Divorced) = 0.100
N(!Divorced/N) I!(Divorced) = 0.300
I(Divorced) = 0.400
&lt;/pre&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;best = 0
best_split = None
for candidate, label in ((homeowner_gini, "Homeowner"),
			 (i_single, "Single"),
			 (i_married, "Married"),
			 (i_divorced, "Divorced")):
    delta = parent_gini - candidate
    if delta &amp;gt; best:
	best = delta
	best_split = label
    print(f"Delta {label} = {delta:0.3f}")
print(f"Best Split: {best_split}")
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Delta Homeowner = 0.077
Delta Single = 0.020
Delta Married = 0.077
Delta Divorced = 0.020
Best Split: Homeowner
&lt;/pre&gt;


&lt;p&gt;
Either using Home Ownership or Whether someone is married would be the best candidates for the next split.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>trees</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/machine-learning/decision-trees/</guid><pubDate>Sun, 26 Jan 2020 00:31:40 GMT</pubDate></item><item><title>Snorkel Data Labeling</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-data-labeling/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-data-labeling/#org06927e3"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-data-labeling/#org7f8d1ae"&gt;Imports&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-data-labeling/#orgfad0ccd"&gt;Set Up&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-data-labeling/#org1bd75e8"&gt;Middle&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-data-labeling/#org45a8226"&gt;Finding Labeling Functions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-data-labeling/#org0eb4199"&gt;Using TextBlob with a Preprocessor&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-data-labeling/#orgba3195b"&gt;More Labeling Functions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-data-labeling/#org4575456"&gt;Adding a Spacy Preprocessor&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org06927e3" class="outline-2"&gt;
&lt;h2 id="org06927e3"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org06927e3"&gt;
&lt;p&gt;
This is a walk-through of the Snorkel &lt;a href="https://www.snorkel.org/use-cases/01-spam-tutorial"&gt;Snorkel Data Labeling&lt;/a&gt; tutorial.It uses the &lt;a href="http://www.dt.fee.unicamp.br/~tiago//youtubespamcollection/"&gt;YouTube Spam Collection&lt;/a&gt; data set (downloaded from the &lt;a href="https://archive.ics.uci.edu/ml/datasets/YouTube+Spam+Collection"&gt;UCI Machine Learning Repository&lt;/a&gt;). The data was collected in 2015 and represents comments from five of the ten most popular videos on YouTube. It is a tabular dataset with the columns &lt;code&gt;COMMENT_ID&lt;/code&gt;, &lt;code&gt;AUTHOR&lt;/code&gt;, &lt;code&gt;DATE&lt;/code&gt;, &lt;code&gt;CONTENT&lt;/code&gt;, &lt;code&gt;CLASS&lt;/code&gt;. The tag represents whether it was considered &lt;i&gt;Spam&lt;/i&gt; or not, so we'll pretend it isn't there for most of this walk-through.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7f8d1ae" class="outline-3"&gt;
&lt;h3 id="org7f8d1ae"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org7f8d1ae"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org9173448" class="outline-4"&gt;
&lt;h4 id="org9173448"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org9173448"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from argparse import Namespace
from functools import partial
from pathlib import Path
import re
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7d6ca41" class="outline-4"&gt;
&lt;h4 id="org7d6ca41"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org7d6ca41"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from snorkel.analysis import get_label_buckets
from snorkel.labeling import labeling_function, LabelingFunction, LFAnalysis, PandasLFApplier
from snorkel.preprocess import preprocessor
from snorkel.labeling.lf.nlp import nlp_labeling_function
from sklearn.model_selection import train_test_split
from tabulate import tabulate
from textblob import TextBlob

import pandas
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgfad0ccd" class="outline-3"&gt;
&lt;h3 id="orgfad0ccd"&gt;Set Up&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgfad0ccd"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org4daa77b" class="outline-4"&gt;
&lt;h4 id="org4daa77b"&gt;The Tabulate Table&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org4daa77b"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;TABLE = partial(tabulate, tablefmt="orgtbl", headers="keys")
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org1d35b54" class="outline-4"&gt;
&lt;h4 id="org1d35b54"&gt;Some Constants&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org1d35b54"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Comment = Namespace(
    is_ambiguous = -1,
    is_ham = 0,
    is_spam = 1
)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Data = Namespace(
    test_artist = "Shakira",
    development_size = 200,
    validation_size = 0.5,
    random_seed = 666,
)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Columns = Namespace(
    comment = "CONTENT",
    classification = "CLASS",
    artist = "artist",
)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org1bd75e8" class="outline-2"&gt;
&lt;h2 id="org1bd75e8"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org1bd75e8"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org5cff5f4" class="outline-4"&gt;
&lt;h4 id="org5cff5f4"&gt;The Dataset&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org5cff5f4"&gt;
&lt;p&gt;
The data is split up into separate files - one for each artist/video (they are named after the artist and each only appears to have one entry) so I'm going to smash them back together and add a &lt;code&gt;artist&lt;/code&gt; column.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;path = Path("~/data/datasets/texts/you_tube_comments/").expanduser()
sets = []
for name in path.glob("*.csv"):
    artist = name.stem.split()[-1]
    data = pandas.read_csv(name)
    data["artist"] = artist
    sets.append(data)
    print(artist)
data = pandas.concat(sets)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
KatyPerry
LMFAO
Eminem
Shakira
Psy
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgd0f4285" class="outline-4"&gt;
&lt;h4 id="orgd0f4285"&gt;Splitting the Set&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgd0f4285"&gt;
&lt;p&gt;
The tutorial takes a slightly different approach from the one I previously took. Here's their four data-set splits:
&lt;/p&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;&lt;i&gt;train&lt;/i&gt;: Comments from the first four videos&lt;/li&gt;
&lt;li&gt;&lt;i&gt;dev&lt;/i&gt;: 200 comments taken from &lt;i&gt;train&lt;/i&gt;&lt;/li&gt;
&lt;li&gt;&lt;i&gt;valid &amp;amp; test&lt;/i&gt;: A 50-50 split of the last video (actually &lt;i&gt;Shakira&lt;/i&gt;, not &lt;i&gt;Psy&lt;/i&gt; as listed above)&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;test = data[data.artist==Data.test_artist]
train = data[data.artist != Data.test_artist]
train, development = train_test_split(train, test_size=Data.development_size)

validation, test = train_test_split(test, test_size=Data.validation_size)
print(f"Training: {train.shape}")
print(f"Development: {development.shape}")
print(f"Validation: {validation.shape}")
print(f"Testing: {test.shape}")
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Training: (1386, 6)
Development: (200, 6)
Validation: (185, 6)
Testing: (185, 6)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org45a8226" class="outline-3"&gt;
&lt;h3 id="org45a8226"&gt;Finding Labeling Functions&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org45a8226"&gt;
&lt;p&gt;
The place to start is with the development set - it's labeled (although in this case the training set is as well, but pretend it isn't) and we can inspect it to get ideas.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(development.sample(random_state=Data.random_seed)[[Columns.comment, Columns.classification]])
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
                                               CONTENT  CLASS
216  Lol...I dunno how this joke gets a lot of like...      0
&lt;/pre&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;spam = development[development[Columns.classification]==Comment.is_spam]
for count in range(10):
    print(spam.sample(random_state=count).iloc[0][Columns.comment])
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
I #votekatyperry for the 2014 MTV #VMA Best Lyric Video! See who's in the  lead and vote:  http://on.mtv.com/Ut15kXï»¿
LIKE AND SUBSCRIB IF YOU WATCH IN 2015 ;)ï»¿
 HI IM 14 YEAR RAPPER SUPPORT ME GUY AND CHECK OUT MY CHANNEL AND CHECK OUT MY SONG YOU MIGHT LIKE IT ALSO FOLLOW ME IN TWITTER @McAshim for follow back.
LIKE AND SUBSCRIB IF YOU WATCH IN 2015 ;)ï»¿
HAPPY BIRTHDAY KATY :) http://giphy.com/gifs/birthday-flowers-happy-gw3JY2uqiaXKaQXS/fullscreen  (ThatÂ´s not me)ï»¿
plz check out fablife / welcome to fablife for diys and challenges so plz  subscribe thx!ï»¿
CHECK OUT MY CHANNEL BOYS AND GIRLS ;)
HAPPY BIRTHDAY KATY :) http://giphy.com/gifs/birthday-flowers-happy-gw3JY2uqiaXKaQXS/fullscreen  (ThatÂ´s not me)ï»¿
*for 90&amp;amp;#39;s rap fans*  check out my Big Pun - &amp;amp;#39;Beware&amp;amp;#39; cover!  Likes n comments very much appreciated!
Who&amp;amp;#39;s watching in 2015 Subscribe for me !ï»¿
&lt;/pre&gt;

&lt;p&gt;
You can already see that the spam has people asking viewers to check out their sites.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-org823bb24" class="outline-4"&gt;
&lt;h4 id="org823bb24"&gt;Check vs Check Out&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org823bb24"&gt;
&lt;p&gt;
Let's see which one of the strings (&lt;i&gt;check&lt;/i&gt; or &lt;i&gt;check out&lt;/i&gt;) does better for us.
&lt;/p&gt;
&lt;/div&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;&lt;a id="org648df57"&gt;&lt;/a&gt;The Labeling Functions&lt;br&gt;
&lt;div class="outline-text-5" id="text-org648df57"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;@labeling_function()
def check(row: pandas.Series) -&amp;gt; int:
    """sees if the word 'check' is in the comment"""
    return Comment.is_spam if "check" in row.CONTENT.lower() else Comment.is_ambiguous
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;@labeling_function()
def check_out(row: pandas.Series) -&amp;gt; int:
    """looks for phrase 'check out'"""
    return Comment.is_spam if "check out" in row.CONTENT.lower() else Comment.is_ambiguous
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a id="orgcf84922"&gt;&lt;/a&gt;Applying the Functions&lt;br&gt;
&lt;div class="outline-text-5" id="text-orgcf84922"&gt;
&lt;p&gt;
The next step is to create some Labeling Matrices using our labeling functions by applying them to our training and development sets. Since our data is stored using pandas, we'll use the &lt;code&gt;PandasLFApplier&lt;/code&gt;, but there are &lt;a href="https://snorkel.readthedocs.io/en/master/packages/labeling.html"&gt;other types available&lt;/a&gt; as well.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;labeling_functions = [check, check_out]

applier = PandasLFApplier(lfs=labeling_functions)
train_labeling_matrix = applier.apply(df=train, progress_bar=False)
development_labeling_matrix = applier.apply(df=development, progress_bar=False)
print(f"Training Labeling Matrix: {train_labeling_matrix.shape}")
print(f"Development Labeling Matrix: {development_labeling_matrix.shape}")
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Training Labeling Matrix: (1386, 2)
Development Labeling Matrix: (200, 2)
&lt;/pre&gt;


&lt;p&gt;
Each matrix has one column for each of our labeling functions (so two in this case) and one row for each of the rows in the set that the functions were applied to.
&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;

&lt;li&gt;&lt;a id="org6359522"&gt;&lt;/a&gt;Evaluating the Labeling Functions&lt;br&gt;
&lt;div class="outline-text-5" id="text-org6359522"&gt;
&lt;p&gt;
Snorkel provides a &lt;a href="https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.LFAnalysis.html"&gt;LFAnalysis&lt;/a&gt; class to help you see how well the labeling functions do.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;analysis = LFAnalysis(L=train_labeling_matrix, lfs=labeling_functions)
print(TABLE(analysis.lf_summary()))
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Â &lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;j&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Polarity&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Coverage&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Overlaps&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Conflicts&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;check&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-left"&gt;[1]&lt;/td&gt;
&lt;td class="org-right"&gt;0.257576&lt;/td&gt;
&lt;td class="org-right"&gt;0.212843&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;check_out&lt;/td&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;td class="org-left"&gt;[1]&lt;/td&gt;
&lt;td class="org-right"&gt;0.212843&lt;/td&gt;
&lt;td class="org-right"&gt;0.212843&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;
This is what the table is giving us for each of the labeling functions:
&lt;/p&gt;

&lt;ul class="org-ul"&gt;
&lt;li&gt;&lt;i&gt;j&lt;/i&gt; : I think this is just an index&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Polarity&lt;/i&gt;: The number of unique values the function puts out (other than -1, which is interpreted as an un-labeled row)&lt;/li&gt;
&lt;li&gt;/Coverage: The fraction of the data-set that the function labeled&lt;/li&gt;
&lt;li&gt;/Overlaps: The fraction of the data that the function labeled and at least one other function also labeled&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Conflicts&lt;/i&gt;: The fraction of the data that the function labeled something different from at least one other function&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;
So it looks like &lt;code&gt;check&lt;/code&gt; covers slightly more than &lt;code&gt;check_out&lt;/code&gt;, and they don't disagree with each other at all. This makes sense when you consider that &lt;code&gt;check&lt;/code&gt; is a sub-string of &lt;code&gt;check out&lt;/code&gt; - we can guess that all the overlaps are cases where &lt;code&gt;check out&lt;/code&gt; were found in the comment.
&lt;/p&gt;

&lt;p&gt;
We can also pass it a set of labels and it will see how well the functions did. In this case we have labels for all the rows, but in most cases we won't just for the development set so we'll use it here.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(TABLE(LFAnalysis(
    L=development_labeling_matrix,
    lfs=labeling_functions).lf_summary(Y=development.CLASS.values)))
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Â &lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;j&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Polarity&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Coverage&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Overlaps&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Conflicts&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Correct&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Incorrect&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Emp. Acc.&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;check&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-left"&gt;[1]&lt;/td&gt;
&lt;td class="org-right"&gt;0.26&lt;/td&gt;
&lt;td class="org-right"&gt;0.225&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-right"&gt;49&lt;/td&gt;
&lt;td class="org-right"&gt;3&lt;/td&gt;
&lt;td class="org-right"&gt;0.942308&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;check_out&lt;/td&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;td class="org-left"&gt;[1]&lt;/td&gt;
&lt;td class="org-right"&gt;0.225&lt;/td&gt;
&lt;td class="org-right"&gt;0.225&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-right"&gt;45&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;
&lt;b&gt;&lt;b&gt;Note:&lt;/b&gt;&lt;/b&gt; The &lt;code&gt;LFAnalysis&lt;/code&gt; class works with &lt;code&gt;numpy&lt;/code&gt; arrays, so when I called the &lt;code&gt;lf_summary&lt;/code&gt; method I had to pass in the &lt;code&gt;values&lt;/code&gt; and not the &lt;code&gt;CLASS&lt;/code&gt; Series.
&lt;/p&gt;

&lt;p&gt;
With our development set, the functions cover slightly less than before (as a fraction of the total), and although &lt;code&gt;check&lt;/code&gt; covers slightly more that &lt;code&gt;check_out&lt;/code&gt;, it also has some false-postives, so we'd have to decide if we care about getting all the spam or not accidentally labeling non-spam as spam.
&lt;/p&gt;

&lt;p&gt;
We can also check which ones were mis-labeled to get a better idea of how off they were.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;buckets = get_label_buckets(development.CLASS.values, development_labeling_matrix[:, 0])
for key, value in buckets.items():
    print(key)
    print(value)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
(0, -1)
[  0   1   2   3   4   7   9  10  11  12  13  15  16  17  19  22  27  28
  33  34  35  39  41  43  44  46  48  49  50  51  52  53  55  57  58  61
  62  65  66  68  78  79  81  82  86  88  89  92  94  95  98  99 100 103
 104 105 107 108 112 113 114 120 121 122 123 124 125 128 129 131 133 135
 141 142 144 146 148 150 153 154 155 162 165 166 167 168 171 173 174 179
 182 183 184 190 191 195 196 197]
(1, 1)
[  5  14  23  25  29  36  40  42  45  59  67  69  71  73  74  75  76  77
  80  83  87  90  91  93 101 109 110 116 117 126 127 134 138 139 140 143
 149 151 157 160 163 164 169 172 186 189 192 193 198]
(1, -1)
[  6   8  18  20  21  24  26  30  31  32  38  47  54  56  60  63  64  70
  72  84  85  96  97 102 106 111 115 119 130 132 136 137 145 147 152 156
 158 159 161 175 176 177 178 180 181 185 187 188 194 199]
(0, 1)
[ 37 118 170]
&lt;/pre&gt;

&lt;p&gt;
Buckets is a dict whose keys are tuples of (actual classes, predicted classes) and whose values are the indices of the rows matching the keys (so the key &lt;code&gt;(0, 1)&lt;/code&gt; returns the indices for rows where we labeled the comment as spam but it wasn't). Looking at the output you can see that the last key (0, 1) has the cases that we labeled as spam when they weren't, let's take a look at them.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;for comment in development.iloc[buckets[(Comment.is_ham, Comment.is_spam)]]["CONTENT"]:
    print(comment)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
i turned it on mute as soon is i came on i just wanted to check the  views...ï»¿
i check back often to help reach 2x10^9 views and I avoid watching Babyï»¿
Admit it you just came here to check the number of viewers ï»¿
&lt;/pre&gt;


&lt;p&gt;
It's not obvious to me how you should handle those.
&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a id="orgb1175e3"&gt;&lt;/a&gt;Check Out But Not Check&lt;br&gt;
&lt;div class="outline-text-5" id="text-orgb1175e3"&gt;
&lt;p&gt;
What are some training examples that &lt;code&gt;check&lt;/code&gt; labels but &lt;code&gt;check_out&lt;/code&gt; doesn't? We can check by feeding the columns from the labeling matrix for the &lt;code&gt;check&lt;/code&gt; and &lt;code&gt;check_out&lt;/code&gt; functions and see where &lt;code&gt;check_out&lt;/code&gt; abstained and &lt;code&gt;check&lt;/code&gt; didn't. I said earlier that the first argument to &lt;code&gt;get_label_buckets&lt;/code&gt; is the actual label, but really you can feed any two arrays and it will find give you the indices for the permutations of their row-values.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;buckets = get_label_buckets(train_labeling_matrix[:, 0], train_labeling_matrix[:, 1])
sampled = train.iloc[buckets[(Comment.is_spam, Comment.is_ambiguous)]].sample(10, random_state=Data.random_seed)
for sample in sampled.itertuples():
    print(sample.CONTENT)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Lil m !!!!! Check hi out!!!!! Does live the way you lie and many more ! Check it out!!! And subscribe
https://soundcloud.com/artady please check my stuff; and make some feedbackï»¿
Hey guys can you check my channel out plz. I do mine craft videos. Let's  shoot for 20 subsï»¿
ââââââââââââââââââââââââââ  ââââââââââââââââââââââââââ  âââââââââââââââââââââââââ  âââââââââââââââââââââââââ  ââââââââââââââââââââââââ  ââââââââââââââââââââââââ CHECK MY VIDEOS AND SUBSCRIBE AND LIKE PLZZ
if you like raw talent, raw lyrics, straight real hip hop Everyone check my newest sound  Dizzy X - Got the Juice (Prod by. Drugs the Model Citizen)   COMMENT TELL ME WHAT YOU THINK  DONT BE LAZY!!!!  - 1/7 Prophetzï»¿
check it out free stuff for watching videos and filling surveys&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;&amp;lt;a href="http://www.prizerebel.com/index.php?r=1446084"&amp;gt;http://www.prizerebel.com/index.php?r=1446084&amp;lt;/a&amp;gt;ï»¿
Hey! I'm NERDY PEACH and I'm a new youtuber and it would mean THE ABSOLUTE  world to me if you could check 'em out! &amp;amp;lt;3  Hope you like them! =Dï»¿
Check my first video outï»¿
http://tankionline.com#friend=cd92db3f4 great game check it out!ï»¿
hi beaties! i made a new channel please go check it out and subscribe and  enjoy!ï»¿
&lt;/pre&gt;

&lt;p&gt;
I'm going to deviate from the tutorial a little and create a regular expression to match any comment with "check" and not "view" to avoid cases where the commenter is saying that they're checking out how many views the video had.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;EXPRESSION = re.compile(r"check(?!.*view)")

assert EXPRESSION.search("everyone please come check our newest song in memories of Martin Luther  King Jr.ï»¿")
assert EXPRESSION.search("and u should.d check my channel and tell me what I should do next!ï»¿")
assert not EXPRESSION.search("Admit it you just came here to check the number of viewers ï»¿")

@labeling_function()
def re_check_out(row: pandas.Series) -&amp;gt; int:
    """match cases with 'check' but not view"""
    return Comment.is_spam if EXPRESSION.search(row.CONTENT.lower()) else Comment.is_ambiguous
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;labeling_functions = [check, check_out, re_check_out]
applier = PandasLFApplier(lfs=labeling_functions)
train_labeling_matrix = applier.apply(df=train, progress_bar=False)
development_labeling_matrix = applier.apply(df=development, progress_bar=False)
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;analysis = LFAnalysis(L=train_labeling_matrix, lfs=labeling_functions)
print(TABLE(analysis.lf_summary()))
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Â &lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;j&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Polarity&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Coverage&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Overlaps&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Conflicts&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;check&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-left"&gt;[1]&lt;/td&gt;
&lt;td class="org-right"&gt;0.257576&lt;/td&gt;
&lt;td class="org-right"&gt;0.248196&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;check_out&lt;/td&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;td class="org-left"&gt;[1]&lt;/td&gt;
&lt;td class="org-right"&gt;0.212843&lt;/td&gt;
&lt;td class="org-right"&gt;0.212843&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;re_check_out&lt;/td&gt;
&lt;td class="org-right"&gt;2&lt;/td&gt;
&lt;td class="org-left"&gt;[1]&lt;/td&gt;
&lt;td class="org-right"&gt;0.243146&lt;/td&gt;
&lt;td class="org-right"&gt;0.243146&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;
Our &lt;code&gt;re_check_out&lt;/code&gt; function has a little less coverage than &lt;code&gt;check&lt;/code&gt; as we'd expect, since it excludes reviews with "view" in them but it also covers a little more than &lt;code&gt;check_out&lt;/code&gt;.
&lt;/p&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(TABLE(LFAnalysis(
    L=development_labeling_matrix,
    lfs=labeling_functions).lf_summary(Y=development.CLASS.values)))
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Â &lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;j&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Polarity&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Coverage&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Overlaps&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Conflicts&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Correct&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Incorrect&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Emp. Acc.&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;check&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-left"&gt;[1]&lt;/td&gt;
&lt;td class="org-right"&gt;0.26&lt;/td&gt;
&lt;td class="org-right"&gt;0.245&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-right"&gt;49&lt;/td&gt;
&lt;td class="org-right"&gt;3&lt;/td&gt;
&lt;td class="org-right"&gt;0.942308&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;check_out&lt;/td&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;td class="org-left"&gt;[1]&lt;/td&gt;
&lt;td class="org-right"&gt;0.225&lt;/td&gt;
&lt;td class="org-right"&gt;0.225&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-right"&gt;45&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;re_check_out&lt;/td&gt;
&lt;td class="org-right"&gt;2&lt;/td&gt;
&lt;td class="org-left"&gt;[1]&lt;/td&gt;
&lt;td class="org-right"&gt;0.245&lt;/td&gt;
&lt;td class="org-right"&gt;0.245&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-right"&gt;49&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;
It looks like we were able to avoid the false-positives by adding our regular expression.
&lt;/p&gt;



&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;buckets = get_label_buckets(development_labeling_matrix[:, 0], development_labeling_matrix[:,2])
for comment in development.iloc[buckets[(Comment.is_spam, Comment.is_ambiguous)]]["CONTENT"]:
    print(comment)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
i turned it on mute as soon is i came on i just wanted to check the  views...ï»¿
i check back often to help reach 2x10^9 views and I avoid watching Babyï»¿
Admit it you just came here to check the number of viewers ï»¿
&lt;/pre&gt;


&lt;p&gt;
So it looks like we got rid of some false positives but also missed some spam by using the regular expression. We could probably grab more by searching for "my" as well.
&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org0eb4199" class="outline-3"&gt;
&lt;h3 id="org0eb4199"&gt;Using TextBlob with a Preprocessor&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org0eb4199"&gt;
&lt;p&gt;
Here we'll use text-blobs sentiment scorer to find comments that aren't spam. To do this we'll need to use snorkel's Preprocessor, which maps data using black-box functions.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;@preprocessor(memoize=True)
def textblob_sentiment(row: pandas.Series) -&amp;gt; pandas.Series:
    """Add the polarity and subjectivity of the comment's sentiment

    This adds two columns ('polarity' and 'subjectivity') based on the comment

    """
    blob = TextBlob(row.CONTENT)
    row["polarity"] = blob.sentiment.polarity
    row["subjectivity"] = blob.sentiment.subjectivity
    return row
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
The &lt;code&gt;polarity&lt;/code&gt; is a value from -1.0 to 1.0 which reflects how negative or positive the text is believed to be. The &lt;code&gt;subjectivity&lt;/code&gt; is a value from 0.0 to 1.0 which reflects whether the text is objective or subjective - whether it is a statement of fact or opinion.
&lt;/p&gt;

&lt;p&gt;
Now that we have the pre-processor we can use it with a labeling function.
&lt;/p&gt;
&lt;/div&gt;

&lt;div id="outline-container-org3f9b491" class="outline-4"&gt;
&lt;h4 id="org3f9b491"&gt;Polarity&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org3f9b491"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;@labeling_function(pre=[textblob_sentiment])
def textblob_polarity(row: pandas.Series) -&amp;gt; int:
    """decides if the comment is ham based on the polarity of the sentiment"""
    return Comment.is_ham if row.polarity &amp;gt; 0.9 else Comment.is_ambiguous
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgfe2eafc" class="outline-4"&gt;
&lt;h4 id="orgfe2eafc"&gt;Subjectivity&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgfe2eafc"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;@labeling_function(pre=[textblob_sentiment])
def textblob_subjectivity(row: pandas.Series) -&amp;gt; int:
    """decides if the comment is ham based on the subjectivity"""
    return Comment.is_ham if row.subjectivity &amp;gt; 0.5 else Comment.is_ambiguous
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org76d0eee" class="outline-4"&gt;
&lt;h4 id="org76d0eee"&gt;Analyzing the Performance&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org76d0eee"&gt;
&lt;p&gt;
Once again, now that we have labeling functions we need to analyze how well they do.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;labeling_functions = [textblob_polarity, textblob_subjectivity]
applier = PandasLFApplier(lfs=labeling_functions)
train_label_matrix = applier.apply(train, progress_bar=False)
development_label_matrix = applier.apply(development, progress_bar=False)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(TABLE(LFAnalysis(train_label_matrix, labeling_functions).lf_summary()))
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Â &lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;j&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Polarity&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Coverage&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Overlaps&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Conflicts&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;textblob_polarity&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-left"&gt;[0]&lt;/td&gt;
&lt;td class="org-right"&gt;0.033189&lt;/td&gt;
&lt;td class="org-right"&gt;0.0122655&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;textblob_subjectivity&lt;/td&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;td class="org-left"&gt;[0]&lt;/td&gt;
&lt;td class="org-right"&gt;0.32684&lt;/td&gt;
&lt;td class="org-right"&gt;0.0122655&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(TABLE(LFAnalysis(development_label_matrix, labeling_functions).lf_summary(Y=development.CLASS.values)))
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Â &lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;j&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Polarity&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Coverage&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Overlaps&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Conflicts&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Correct&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Incorrect&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Emp. Acc.&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;textblob_polarity&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-left"&gt;[0]&lt;/td&gt;
&lt;td class="org-right"&gt;0.05&lt;/td&gt;
&lt;td class="org-right"&gt;0.025&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-right"&gt;9&lt;/td&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;td class="org-right"&gt;0.9&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;textblob_subjectivity&lt;/td&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;td class="org-left"&gt;[0]&lt;/td&gt;
&lt;td class="org-right"&gt;0.3&lt;/td&gt;
&lt;td class="org-right"&gt;0.025&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-right"&gt;32&lt;/td&gt;
&lt;td class="org-right"&gt;28&lt;/td&gt;
&lt;td class="org-right"&gt;0.533333&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;
Subjectivity seems to have much better coverage, but it was also fairly inaccurate.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgba3195b" class="outline-3"&gt;
&lt;h3 id="orgba3195b"&gt;More Labeling Functions&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgba3195b"&gt;
&lt;p&gt;
We previously created a keyword-based labeling function for "check". Because using keywords is such a common thing Snorkel has a way to create them with a little less work than creating the labeling functions individually.
&lt;/p&gt;

&lt;p&gt;
First we make a function that checks if any of a collection of keywords is in the comment.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def lookup_keyword(row: pandas.Series, keywords: list, label: int) -&amp;gt; int:
    """check if any of the keywords are in the comment

    Args:
     row: the series with the Comment
     keywords: collection of keywords indicating spam
     label: what to return if the keyword is in the comment

    Returns:
     label if keyword in comment else -1
    """
    return label if any(keyword in row.CONTENT.lower() for keyword in keywords) else Comment.is_ambiguous
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Now we make the labeling-function creator that uses the &lt;code&gt;lookup_keyword&lt;/code&gt;.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def make_keyword_labeling_function(keywords: list, label: int=Comment.is_spam) -&amp;gt; LabelingFunction:
    """Makes LabelingFunction objects that check keywords"""
    return LabelingFunction(
	name=f"keyword_{keywords[0]}",
	f=lookup_keyword,
	resources=dict(keywords=keywords, label=label)
    )
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;keyword_my = make_keyword_labeling_function(keywords=["my"])
keyword_subscribe = make_keyword_labeling_function(keywords=["subscribe"])
keyword_link = make_keyword_labeling_function(keywords=["http"])
keyword_please = make_keyword_labeling_function(keywords=["please", "plz"])
keyword_song = make_keyword_labeling_function(keywords=["song"], label=Comment.is_ham)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;labeling_functions = [
    keyword_my,
    keyword_subscribe,
    keyword_link,
    keyword_please,
    keyword_song,
]
applier = PandasLFApplier(lfs=labeling_functions)
train_label_matrix = applier.apply(train, progress_bar=False)
development_label_matrix = applier.apply(development, progress_bar=False)
print(TABLE(LFAnalysis(development_label_matrix, labeling_functions).lf_summary(Y=development.CLASS.values)))
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Â &lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;j&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Polarity&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Coverage&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Overlaps&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Conflicts&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Correct&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Incorrect&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Emp. Acc.&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;keyword_my&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-left"&gt;[1]&lt;/td&gt;
&lt;td class="org-right"&gt;0.18&lt;/td&gt;
&lt;td class="org-right"&gt;0.115&lt;/td&gt;
&lt;td class="org-right"&gt;0.05&lt;/td&gt;
&lt;td class="org-right"&gt;33&lt;/td&gt;
&lt;td class="org-right"&gt;3&lt;/td&gt;
&lt;td class="org-right"&gt;0.916667&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;keyword_subscribe&lt;/td&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;td class="org-left"&gt;[1]&lt;/td&gt;
&lt;td class="org-right"&gt;0.125&lt;/td&gt;
&lt;td class="org-right"&gt;0.075&lt;/td&gt;
&lt;td class="org-right"&gt;0.015&lt;/td&gt;
&lt;td class="org-right"&gt;25&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;keyword_http&lt;/td&gt;
&lt;td class="org-right"&gt;2&lt;/td&gt;
&lt;td class="org-left"&gt;[1]&lt;/td&gt;
&lt;td class="org-right"&gt;0.09&lt;/td&gt;
&lt;td class="org-right"&gt;0.03&lt;/td&gt;
&lt;td class="org-right"&gt;0.005&lt;/td&gt;
&lt;td class="org-right"&gt;16&lt;/td&gt;
&lt;td class="org-right"&gt;2&lt;/td&gt;
&lt;td class="org-right"&gt;0.888889&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;keyword_please&lt;/td&gt;
&lt;td class="org-right"&gt;3&lt;/td&gt;
&lt;td class="org-left"&gt;[1]&lt;/td&gt;
&lt;td class="org-right"&gt;0.095&lt;/td&gt;
&lt;td class="org-right"&gt;0.08&lt;/td&gt;
&lt;td class="org-right"&gt;0.02&lt;/td&gt;
&lt;td class="org-right"&gt;19&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;keyword_song&lt;/td&gt;
&lt;td class="org-right"&gt;4&lt;/td&gt;
&lt;td class="org-left"&gt;[0]&lt;/td&gt;
&lt;td class="org-right"&gt;0.16&lt;/td&gt;
&lt;td class="org-right"&gt;0.06&lt;/td&gt;
&lt;td class="org-right"&gt;0.06&lt;/td&gt;
&lt;td class="org-right"&gt;20&lt;/td&gt;
&lt;td class="org-right"&gt;12&lt;/td&gt;
&lt;td class="org-right"&gt;0.625&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;
There are varying degrees of coveragen and accuracy with these. Interestingly, the &lt;code&gt;subscribe&lt;/code&gt; keyword was completely accurate and had pretty good coverage (compared to our check-out labelers).
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org4575456" class="outline-3"&gt;
&lt;h3 id="org4575456"&gt;Adding a Spacy Preprocessor&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org4575456"&gt;
&lt;p&gt;
The purpose of the pre-processors is to do a little feature engineering to add features that aren't in the original dataset but which can be derived from it. Becaues SpaCY is used so much for this, snorkel comes with a labeling function that adds a &lt;code&gt;doc&lt;/code&gt; attribute (you can also create it manually to get more control).
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;@nlp_labeling_function()
def short_with_person(row: pandas.Series) -&amp;gt; int:
    """Check if the comment is short and mentions a person"""
    return (Comment.is_ham if (len(row.CONTENT) &amp;lt; 20 and any((entity.label_=="PERSON" for entity in row.dot.ents)))
			       else Comment.is_ambiguous)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>data</category><category>exploration</category><category>snorkel</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-data-labeling/</guid><pubDate>Fri, 10 Jan 2020 01:07:33 GMT</pubDate></item></channel></rss>