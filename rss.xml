<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Visions, Voices, Data</title><link>https://necromuralist.github.io/Visions-Voices-Data/</link><description>Adumbrations of data.</description><atom:link href="https://necromuralist.github.io/Visions-Voices-Data/rss.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2019 &lt;a href="mailto:necromuralist@protonmail.com"&gt;Cloistered Monkey&lt;/a&gt; </copyright><lastBuildDate>Sat, 03 Aug 2019 19:41:48 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Web Scraping Assignment 1</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#org352760d"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#orgfe04f84"&gt;Imports&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#orge2145f2"&gt;Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#org04feb6f"&gt;PyPi&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#orgaa63aee"&gt;Setup&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#org640bff9"&gt;The URLs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#org4102cd8"&gt;The Expected&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#org0ba3141"&gt;Middle&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#org284d163"&gt;The Sample&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#org143fc40"&gt;The Way I Would Do It&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#org6b8841a"&gt;The Assignment Way&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#org2e101c6"&gt;The Assignment&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#orgd60f7b6"&gt;Requests HTML&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#org9d4bed2"&gt;Urllib&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#org772756e"&gt;End&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org352760d" class="outline-2"&gt;
&lt;h2 id="org352760d"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org352760d"&gt;
&lt;p&gt;
The goal of this exercise is to find all the &lt;code&gt;&amp;lt;span&amp;gt;&lt;/code&gt; tags on a page and sum the numbers they contain.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgfe04f84" class="outline-3"&gt;
&lt;h3 id="orgfe04f84"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgfe04f84"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orge2145f2" class="outline-4"&gt;
&lt;h4 id="orge2145f2"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orge2145f2"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;import urllib
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org04feb6f" class="outline-4"&gt;
&lt;h4 id="org04feb6f"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org04feb6f"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from bs4 import BeautifulSoup
from expects import (
    equal,
    expect,
    be_true,
)
from requests_html import HTMLSession
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgaa63aee" class="outline-3"&gt;
&lt;h3 id="orgaa63aee"&gt;Setup&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgaa63aee"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org640bff9" class="outline-4"&gt;
&lt;h4 id="org640bff9"&gt;The URLs&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org640bff9"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;SAMPLE_URL = " http://py4e-data.dr-chuck.net/comments_42.html"
ACTUAL_URL = "http://py4e-data.dr-chuck.net/comments_260442.html"
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org4102cd8" class="outline-4"&gt;
&lt;h4 id="org4102cd8"&gt;The Expected&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org4102cd8"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;SAMPLE_EXPECTED = 2553
ACTUAL_EXPECTED_LAST_DIGIT = 5
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org0ba3141" class="outline-2"&gt;
&lt;h2 id="org0ba3141"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org0ba3141"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org284d163" class="outline-3"&gt;
&lt;h3 id="org284d163"&gt;The Sample&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org284d163"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org143fc40" class="outline-4"&gt;
&lt;h4 id="org143fc40"&gt;The Way I Would Do It&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org143fc40"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def using_requests(url: str) -&amp;gt; int:
    """get the span total

    Args:
     url: The URL for the page

    Returns:
     the total sum
    """
    session = HTMLSession()
    response = session.get(url)
    expect(response.ok).to(be_true)
    total = 0

    for count, span in enumerate(response.html.find("span")):
	total += int(span.text)

    print(f"Count: {count + 1}")
    print(f"Sum: {total}")
    return total
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;total = using_requests(SAMPLE_URL)
expect(total).to(equal(SAMPLE_EXPECTED))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Count: 50
Sum: 2553

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org6b8841a" class="outline-4"&gt;
&lt;h4 id="org6b8841a"&gt;The Assignment Way&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org6b8841a"&gt;
&lt;p&gt;
For this kind of thing, using urllib isn't really much more work, I'm used to the older python 2 version which (maybe only seemed at the time) was more complicated to use.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def using_urllib(url: str) -&amp;gt; int:
    """get the span total with urllib and beautiful soup

    Args:
     url: the URL for the page

    Returns:
     the total of the span contents
    """
    response = urllib.request.urlopen(url)
    soup = BeautifulSoup(response.read(), "html.parser")
    total = 0
    for count, span in enumerate(soup.find_all("span")):
	total += int(span.text)

    print(f"Count: {count + 1}")
    print(f"Sum: {total}")
    return total
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;total = using_urllib(SAMPLE_URL)
expect(total).to(equal(SAMPLE_EXPECTED))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Count: 50
Sum: 2553

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org2e101c6" class="outline-3"&gt;
&lt;h3 id="org2e101c6"&gt;The Assignment&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org2e101c6"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgd60f7b6" class="outline-4"&gt;
&lt;h4 id="orgd60f7b6"&gt;Requests HTML&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgd60f7b6"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;total = using_requests(ACTUAL_URL)
expect(int(str(total)[-1])).to(equal(ACTUAL_EXPECTED_LAST_DIGIT))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Count: 50
Sum: 2305

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org9d4bed2" class="outline-4"&gt;
&lt;h4 id="org9d4bed2"&gt;Urllib&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org9d4bed2"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;total = using_urllib(ACTUAL_URL)
expect(int(str(total)[-1])).to(equal(ACTUAL_EXPECTED_LAST_DIGIT))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Count: 50
Sum: 2305

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org772756e" class="outline-2"&gt;
&lt;h2 id="org772756e"&gt;End&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org772756e"&gt;
&lt;p&gt;
Although I normally use &lt;code&gt;requests&lt;/code&gt; or &lt;code&gt;requests-html&lt;/code&gt;, I must say that the &lt;code&gt;urllib&lt;/code&gt; version with &lt;a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/"&gt;BeautifulSoup&lt;/a&gt; for this particular exercise wasn't much different.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>web-scraping</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/</guid><pubDate>Sat, 03 Aug 2019 19:07:56 GMT</pubDate></item><item><title>Web Scraping Assignment 2</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-2/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-2/#orge963253"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-2/#org8433374"&gt;Imports&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-2/#org04e5580"&gt;Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-2/#org264839a"&gt;PyPi&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-2/#orgff32d65"&gt;Setup&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-2/#org89ae143"&gt;The URL&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-2/#orgabe8dd0"&gt;Middle&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-2/#orgcc42471"&gt;The Sample Exercise&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-2/#org83df5a1"&gt;The Easy Way&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-2/#org19809c4"&gt;The Slightly Less Easy Way&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-2/#org45d41f3"&gt;The Real One&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-2/#org71f3761"&gt;The Easy Way&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-2/#org82ae5d5"&gt;The Assignment Way&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-2/#org3222b0a"&gt;End&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orge963253" class="outline-2"&gt;
&lt;h2 id="orge963253"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orge963253"&gt;
&lt;p&gt;
The goal of this exercise is to crawl through a set of anchor links to get a particular name stored in the &lt;i&gt;nth&lt;/i&gt; anchor tag. The assignment specifically says to use &lt;a href="https://docs.python.org/3/library/urllib.html"&gt;urllib&lt;/a&gt; but, if you go to the documentation for &lt;a href="https://docs.python.org/3/library/urllib.request.html#module-urllib.request"&gt;urllib.request&lt;/a&gt; it tells you to use to use &lt;a href="https://2.python-requests.org/en/master/"&gt;requests&lt;/a&gt;, which, if you go to its documentation says that it's in maintenance mode while work is being done on &lt;a href="https://3.python-requests.org/"&gt;Requests III&lt;/a&gt;… anyway, I like using &lt;a href="https://html.python-requests.org/"&gt;Requests-HTML&lt;/a&gt; so I'll use that and urllib side-by-side.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-org8433374" class="outline-3"&gt;
&lt;h3 id="org8433374"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org8433374"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org04e5580" class="outline-4"&gt;
&lt;h4 id="org04e5580"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org04e5580"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;re&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;urllib&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org264839a" class="outline-4"&gt;
&lt;h4 id="org264839a"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org264839a"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;bs4&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;requests_html&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;HTMLSession&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgff32d65" class="outline-3"&gt;
&lt;h3 id="orgff32d65"&gt;Setup&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgff32d65"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org89ae143" class="outline-4"&gt;
&lt;h4 id="org89ae143"&gt;The URL&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org89ae143"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;BASE_URL&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"http://py4e-data.dr-chuck.net/known_by_"&lt;/span&gt;
&lt;span class="n"&gt;SAMPLE_URL&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"{BASE_URL}Fikret.html"&lt;/span&gt;
&lt;span class="n"&gt;ASSIGNMENT_URL&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"{BASE_URL}Abdalroof.html"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgabe8dd0" class="outline-2"&gt;
&lt;h2 id="orgabe8dd0"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgabe8dd0"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgcc42471" class="outline-3"&gt;
&lt;h3 id="orgcc42471"&gt;The Sample Exercise&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgcc42471"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org83df5a1" class="outline-4"&gt;
&lt;h4 id="org83df5a1"&gt;The Easy Way&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org83df5a1"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;session&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;HTMLSession&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;SAMPLE_URL&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ok&lt;/span&gt;

&lt;span class="n"&gt;expression&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"_(?P&amp;lt;name&amp;gt;[^_.]+).html"&lt;/span&gt;
&lt;span class="n"&gt;expression&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;re&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;compile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;expression&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Name: {expression.search(SAMPLE_URL).group('name')}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;hop&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;links&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;html&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"a"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;link_element&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;links&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Name: {link_element.text}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;link_element&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;attrs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"href"&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Final Answer: {link_element.text}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Name: Fikret
Name: Montgomery
Name: Mhairade
Name: Butchi
Name: Anayah
Final Answer: Anayah

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org19809c4" class="outline-4"&gt;
&lt;h4 id="org19809c4"&gt;The Slightly Less Easy Way&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org19809c4"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urllib&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;urlopen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;SAMPLE_URL&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Name: {expression.search(SAMPLE_URL).group('name')}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;hop&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
   &lt;span class="n"&gt;soup&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="s2"&gt;"html.parser"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
   &lt;span class="n"&gt;link_element&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;soup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find_all&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"a"&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; 
   &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Name: {link_element.text}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
   &lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urllib&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;urlopen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;link_element&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"href"&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;Final Answer: {link_element.text}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Name: Fikret
Name: Montgomery
Name: Mhairade
Name: Butchi
Name: Anayah

Final Answer: Anayah

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org45d41f3" class="outline-3"&gt;
&lt;h3 id="org45d41f3"&gt;The Real One&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org45d41f3"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org71f3761" class="outline-4"&gt;
&lt;h4 id="org71f3761"&gt;The Easy Way&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org71f3761"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;session&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;HTMLSession&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ASSIGNMENT_URL&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ok&lt;/span&gt;

&lt;span class="n"&gt;expression&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"_(?P&amp;lt;name&amp;gt;[^_.]+).html"&lt;/span&gt;
&lt;span class="n"&gt;expression&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;re&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;compile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;expression&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Name: {expression.search(ASSIGNMENT_URL).group('name')}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;hop&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;links&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;html&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"a"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;link_element&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;links&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;17&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Name: {link_element.text}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;link_element&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;attrs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"href"&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Final Answer: {link_element.text}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Name: Abdalroof
Name: Billi
Name: Jayse
Name: Amaarah
Name: Cesar
Name: Rosheen
Name: Mohamed
Name: Kiara
Final Answer: Kiara

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org82ae5d5" class="outline-4"&gt;
&lt;h4 id="org82ae5d5"&gt;The Assignment Way&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org82ae5d5"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;HOPS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;
&lt;span class="n"&gt;FIND_AT_INDEX&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;18&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urllib&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;urlopen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ASSIGNMENT_URL&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Name: {expression.search(ASSIGNMENT_URL).group('name')}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;hop&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;HOPS&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
   &lt;span class="n"&gt;soup&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="s2"&gt;"html.parser"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
   &lt;span class="n"&gt;link_element&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;soup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find_all&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"a"&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="n"&gt;FIND_AT_INDEX&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; 
   &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Name: {link_element.text}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
   &lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urllib&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;urlopen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;link_element&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"href"&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;Final Answer: {link_element.text}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Name: Abdalroof
Name: Billi
Name: Jayse
Name: Amaarah
Name: Cesar
Name: Rosheen
Name: Mohamed
Name: Kiara

Final Answer: Kiara
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org3222b0a" class="outline-2"&gt;
&lt;h2 id="org3222b0a"&gt;End&lt;/h2&gt;
&lt;/div&gt;</description><category>web-crawiling</category><category>web-scraping</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-2/</guid><pubDate>Fri, 02 Aug 2019 20:43:01 GMT</pubDate></item><item><title>Nested follower</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/nested-follower/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/nested-follower/#org8743d8f"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/nested-follower/#org1370d13"&gt;Create A Walker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/nested-follower/#org63dd93e"&gt;Specifications&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/nested-follower/#orgdfb08ae"&gt;Middle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/nested-follower/#org369ff3b"&gt;End&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org8743d8f" class="outline-2"&gt;
&lt;h2 id="org8743d8f"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org8743d8f"&gt;
&lt;p&gt;
This is assignment 1 from the Nature of Code course on Kadenze. I was originally going to make it a mouse-follower but I re-read the instructions and it seems like it's better to make it a random-walker. These are the requirements:
&lt;/p&gt;
&lt;/div&gt;

&lt;div id="outline-container-org1370d13" class="outline-3"&gt;
&lt;h3 id="org1370d13"&gt;Create A Walker&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org1370d13"&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;Create an object that moves around the screen&lt;/li&gt;
&lt;li&gt;Incorporate randomness or perlin noise&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org63dd93e" class="outline-3"&gt;
&lt;h3 id="org63dd93e"&gt;Specifications&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org63dd93e"&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;Needs to be visually different from the Nature of Code examples&lt;/li&gt;
&lt;li&gt;Use comments&lt;/li&gt;
&lt;li&gt;Only use &lt;code&gt;p5.js&lt;/code&gt; libraries&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgdfb08ae" class="outline-2"&gt;
&lt;h2 id="orgdfb08ae"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgdfb08ae"&gt;
&lt;script language="javascript" type="text/javascript" src="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/nested-follower/follower.js"&gt;&lt;/script&gt;
&lt;div id="nested-follower"&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;/**
 * Random Walker
 *
 * This is an implementation of the Random Walker based on the example given in
 * "The Nature of Code"
 */

// This is the div where the canvas will be placed
let nested_parent_div_id = "nested-follower";

/**
 * The sketch creator
 * 
 * @param {P5} p
 */
let nested_follower_sketch = function(p) {
    /**
     * Setup the canvas
     *
     * - Attaches the canvas to the div
     * - Creates the walker objects
     */
    p.setup = function() {
	this.canvas = p.createCanvas($("#" + nested_parent_div_id).outerWidth(true), 800);
	p.parent = new NoiseWalker(p);
	p.followers = [new Follower(p, p.parent), new Follower(p, p.parent), new Follower(p, p.parent)];
    };

    /**
     * Refresh the objects by calling their update functions
     *
     * This also clears the background.
     */
    p.draw = function() {
	p.background(255);
	p.parent.update();
	p.followers.forEach(function(follower) {
	    follower.update();
	});
    };
};

/**
 * The main walker (with perlin noise)
 *
 * @param {P5} p
 */
function NoiseWalker(p) {
    this.position = p.createVector(p.width/2, p.height/2);
    this.velocity = p.createVector(0, 0);
    this.weight = p.round(p.random(5, 10));
    this.time_x = 0;
    this.time_y = 10000;
    this.time_delta = 0.01;
    this.acceleration = p.createVector(0, 0);
    this.max_acceleration = 0.001;

    /**
     * Updates the walker's position
     */
    this.walk = function() {
	// set the acceleration using perlin noise
	this.acceleration.x = p.map(p.noise(this.time_x), 0, 1, 0, this.max_acceleration);
	this.acceleration.y = p.map(p.noise(this.time_y), 0, 1, 0, this.max_acceleration);
	console.log(this.acceleration)
	// update the time
	this.time_x += this.time_delta;
	this.time_y += this.time_delta;

	// setMag always produces the same magnitude (but the orientation stays the same)
	// this.acceleration.setMag(this.magnitude);

	this.velocity = this.velocity.add(this.acceleration);
	this.position = this.position.add(this.velocity);

	// keep it within the window
	if (this.position.x &amp;lt; 0)
	    this.position.x = p.width;
	else if (this.position.x &amp;gt; p.width)
	    this.position.x = 0;
	if (this.position.y &amp;lt; 0)
	    this.position.y = p.height;
	else if (this.position.y &amp;gt; p.height)
	    this.position.y = 0;
    };

    /**
     * draws the walker
     */
    this.display = function() {
	p.stroke(0);
	//p.background(255, 255, 255, 10);
	p.point(this.position.x, this.position.y);
    };

    /**
     * Calls the walk and update functions
     */
    this.update = function() {
	this.walk();
	this.display();
    };
}


/**
 * A follower that follows a parent object
 *
 * @param {P5} p
 * @param {NoiseWalker} parent
 */
function Follower(p, parent) {
    this.parent = parent;
    this.variance = p.random(5);
    this.position = p.createVector(
	this.parent.position.x + p.random(-this.variance, this.variance),
	this.parent.position.y + p.random(-this.variance, this.variance));
    this.velocity = p.createVector(0, 0);
    this.magnitude = p.random(0.05, 0.09);

    // some colors to cycle through
    this.red = [63, 123, 191, 191, 191];
    this.green = [63, 63, 63, 63, 63];
    this.blue = [191, 191, 191, 127, 63];
    this.colors = this.red.length;
    this.color = p.round(p.random(this.colors));

    /**
     * Moves the Follower
     *
     * sets the acceleration by pointing to the parent's position
     */
    this.walk = function() {
	let acceleration = p5.Vector.sub(this.parent.position, this.position);

	// acceleration.setMag(this.magnitude);
	this.velocity = this.velocity.add(acceleration);
	this.position = this.position.add(this.velocity);
    };

    /**
     * Display the Follower
     *
     * cycles through the colors as we go
     */
    this.display = function() {
	p.strokeWeight(p.random(this.variance, 2 * this.variance));
	p.stroke(this.red[this.color], this.green[this.color], this.blue[this.color]);
	this.color = (this.color + 1) % this.colors;
	p.noFill();
	p.ellipse(this.position.x, this.position.y, p.random(10, 45), p.random(10, 45));
    };

    /**
     * calls the update and walk 
     */
    this.update = function() {
	this.walk();
	this.display();
    };
}

new p5(nested_follower_sketch, nested_parent_div_id);
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org369ff3b" class="outline-2"&gt;
&lt;h2 id="org369ff3b"&gt;End&lt;/h2&gt;
&lt;/div&gt;</description><category>p5.js</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/nested-follower/</guid><pubDate>Tue, 23 Jul 2019 20:49:03 GMT</pubDate></item><item><title>A Mouse Follower</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-mouse-follower/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-mouse-follower/#org8ff362e"&gt;Beginning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-mouse-follower/#org1ccaf14"&gt;Middle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-mouse-follower/#org8abadfb"&gt;End&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org8ff362e" class="outline-2"&gt;
&lt;h2 id="org8ff362e"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org8ff362e"&gt;
&lt;p&gt;
Instead of a random walker this walker will be attracted (somewhat) to the mouse cursor.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org1ccaf14" class="outline-2"&gt;
&lt;h2 id="org1ccaf14"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org1ccaf14"&gt;
&lt;script language="javascript" type="text/javascript" src="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-mouse-follower/follower.js"&gt;&lt;/script&gt;
&lt;div id="mouse-follower"&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;let parent_div_id = "mouse-follower";

let mouse_follower_sketch = function(p) {
    p.setup = function() {
	this.canvas = p.createCanvas($("#" + parent_div_id).outerWidth(true), 800);
	p.walker = new MouseWalker(p);
    }

    p.draw = function() {
	p.background(255);
	p.walker.walk();
	p.walker.display();
    }
};

function MouseWalker(p) {
    this.position = p.createVector(p.width/2, p.height/2);
    this.velocity = p.createVector(0, 0)

    this.walk = function() {
	mouse = p.createVector(p.mouseX, p.mouseY);
	// calling sub on the vectors does an in-place update
	// using p5.Vector.sub creates a new vector
	// This is a static method so we use the module (p5) not the instance (p)
	acceleration = mouse.sub(this.position);

	// setMag always produces the same magnitude (but the orientation stays the same)
	acceleration.setMag(0.1);
	this.velocity = this.velocity.add(acceleration);
	this.position = this.position.add(this.velocity)
  }

  this.display = function() {
      p.stroke(0);
      p.noFill();
      p.background(255, 255, 255, 25);
      p.ellipse(this.position.x, this.position.y, 48, 48);
  }
}

sketch_container = new p5(mouse_follower_sketch, parent_div_id);
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org8abadfb" class="outline-2"&gt;
&lt;h2 id="org8abadfb"&gt;End&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org8abadfb"&gt;
&lt;ol class="org-ol"&gt;
&lt;li&gt;Shiffman D. &lt;a href="https://natureofcode.com/"&gt;The nature of code&lt;/a&gt;: simulating natural systems with processing. Version 1.0, generated December 6, 2012. s.l.: Selbstverl.; 2012. 498 p.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>p5.js</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-mouse-follower/</guid><pubDate>Sun, 21 Jul 2019 23:03:37 GMT</pubDate></item><item><title>A Random Accelerator</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-random-accelerator/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-random-accelerator/#org9518eca"&gt;Beginning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-random-accelerator/#org5c7540c"&gt;Middle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-random-accelerator/#org5f3a24f"&gt;End&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org9518eca" class="outline-2"&gt;
&lt;h2 id="org9518eca"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org9518eca"&gt;
&lt;p&gt;
This is an extension of the random walker with acceleration added.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org5c7540c" class="outline-2"&gt;
&lt;h2 id="org5c7540c"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org5c7540c"&gt;
&lt;script language="javascript" type="text/javascript" src="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-random-accelerator/walker.js"&gt;&lt;/script&gt;
&lt;div id="random-accelerator"&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;let random_accelerator_sketch = function(p) {
    p.setup = function() {
	let parent_div_id = "random-accelerator";
	this.canvas = p.createCanvas($("#" + parent_div_id).outerWidth(true), 800);
	this.canvas.parent(parent_div_id);
	p.walker = new Walker(p);
    }

    p.draw = function() {
	p.background(255);
	p.walker.walk();
	p.walker.display();
    }
};

function Walker(p) {
    this.position = p.createVector(p.width/2, p.height/2);
    this.velocity = p.createVector(0, 0)

    this.walk = function() {
	acceleration = p.createVector(p.random(-1, 1), p.random(-1, 1));
	acceleration = acceleration.mult(0.1)
	this.velocity = this.velocity.add(acceleration)
	this.position = this.position.add(this.velocity)
  }

  this.display = function() {
      p.stroke(0);
      p.noFill();
      p.background(255, 255, 255, 25);
      p.ellipse(this.position.x, this.position.y, 48, 48);
  }
}

sketch_container = new p5(random_accelerator_sketch, 'random-accelerator');
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org5f3a24f" class="outline-2"&gt;
&lt;h2 id="org5f3a24f"&gt;End&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org5f3a24f"&gt;
&lt;p&gt;
This was a very rudimentary walker, the main point of it was that at this point we have the basic kinematic elements to make something following the rules of classical physics (more or less).
&lt;/p&gt;

&lt;ol class="org-ol"&gt;
&lt;li&gt;Shiffman D. &lt;a href="https://natureofcode.com/"&gt;The nature of code&lt;/a&gt;: simulating natural systems with processing. Version 1.0, generated December 6, 2012. s.l.: Selbstverl.; 2012. 498 p.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>p5.js</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-random-accelerator/</guid><pubDate>Sun, 21 Jul 2019 22:14:42 GMT</pubDate></item><item><title>A Random Walk(er)</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-random-walker/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-random-walker/#org7f4ab1a"&gt;Beginning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-random-walker/#org3d7a5b6"&gt;Middle&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-random-walker/#org5a3f18e"&gt;A Div to Locate the Sketch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-random-walker/#org7d41e77"&gt;The Javascript&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-random-walker/#orgfb4bb0c"&gt;End&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7f4ab1a" class="outline-2"&gt;
&lt;h2 id="org7f4ab1a"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org7f4ab1a"&gt;
&lt;p&gt;
This is another post to see if I understand how to get &lt;a href="https://p5js.org/"&gt;p5.js&lt;/a&gt; working in nikola. It's been a while since I tried and I just want to see if I remember how. This uses the random walk example from Daniel Schiffman's book &lt;i&gt;the Nature of Code&lt;/i&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org3d7a5b6" class="outline-2"&gt;
&lt;h2 id="org3d7a5b6"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org3d7a5b6"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org5a3f18e" class="outline-3"&gt;
&lt;h3 id="org5a3f18e"&gt;A Div to Locate the Sketch&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org5a3f18e"&gt;
&lt;p&gt;
The id of this div is set in the &lt;code&gt;p5.js&lt;/code&gt; &lt;code&gt;setup&lt;/code&gt; function as the parent of the sketch.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&amp;lt;script language="javascript" type="text/javascript" src="walker.js"&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;div id="random-walk-container"&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;script language="javascript" type="text/javascript" src="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-random-walker/walker.js"&gt;&lt;/script&gt;
&lt;div id="random-walk-container"&gt;
&lt;/div&gt;

&lt;p&gt;
&lt;b&gt;Note:&lt;/b&gt; Originally this wasn't working, because I had the line to include the javascript inside the &lt;code&gt;div&lt;/code&gt; to hold the canvas. Make sure that &lt;code&gt;div&lt;/code&gt; is always empty.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org7d41e77" class="outline-3"&gt;
&lt;h3 id="org7d41e77"&gt;The Javascript&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org7d41e77"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;let sketch = function(p) {
    p.setup = function() {
	let parent_div_id = "random-walk-container";
	this.canvas = p.createCanvas($("#" + parent_div_id).outerWidth(true), 300);
	this.canvas.parent();
	p.walker = new Walker(p);
    }

    p.draw = function() {
	p.background(255);
	p.walker.walk();
	p.walker.display();
    }
};

function Walker(p) {
  this.x = p.width/2;
  this.y = p.height/2;

  this.walk = function() {
    this.x = this.x + p.random(-1, 1) * 10;
    this.y = this.y + p.random(-1, 1) * 10;
  }

  this.display = function() {
    p.fill(0);
    p.ellipse(this.x, this.y, 48, 48);
  }
}

//let node = document.getElementById("random-walk")
//window.document.getElementsByTagName("body")[0].appendChild(node);
sketch_container = new p5(sketch, 'random-walk-container');
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgfb4bb0c" class="outline-2"&gt;
&lt;h2 id="orgfb4bb0c"&gt;End&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgfb4bb0c"&gt;
&lt;p&gt;
As always, this was way harder than it should have been.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>javascript</category><category>p5.js</category><category>processing</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-random-walker/</guid><pubDate>Sun, 21 Jul 2019 19:29:09 GMT</pubDate></item><item><title>The Origin of Bayes Theorem</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/notes/the-origin-of-bayes-theorem/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/notes/the-origin-of-bayes-theorem/#org2ffff4c"&gt;A Brief Sketch of The Timelines to Bayes' Theorem&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/notes/the-origin-of-bayes-theorem/#org37313d1"&gt;The Equations&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/notes/the-origin-of-bayes-theorem/#org10aff08"&gt;Bayes' Formulation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/notes/the-origin-of-bayes-theorem/#orgee6afa6"&gt;Laplace's First Version&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/notes/the-origin-of-bayes-theorem/#org19fb7e8"&gt;Laplace's Final Version&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/notes/the-origin-of-bayes-theorem/#org9ca7d49"&gt;Sources&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
I'm reading "The theory that would not die" and these are notes I took from them. The book didn't really give me a clear idea about what Price's argument was so I also read a &lt;a href="https://qz.com/1315731/the-most-important-formula-in-data-science-was-first-used-to-prove-the-existence-of-god/"&gt;Quartz&lt;/a&gt; article about that part of the story and, of course, Wikipedia came into it at some points.
&lt;/p&gt;
&lt;div id="outline-container-org2ffff4c" class="outline-2"&gt;
&lt;h2 id="org2ffff4c"&gt;A Brief Sketch of The Timelines to Bayes' Theorem&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org2ffff4c"&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;1718: &lt;a href="https://www.wikiwand.com/en/Abraham_de_Moivre"&gt;Abraham de Moivre&lt;/a&gt; publishes &lt;a href="https://www.wikiwand.com/en/The_Doctrine_of_Chances"&gt;The Doctrine of Chances&lt;/a&gt;, the first textbook on probability.&lt;/li&gt;
&lt;li&gt;1746-1749: Somewhere in this period &lt;a href="https://www.wikiwand.com/en/Thomas_Bayes"&gt;Thomas Bayes&lt;/a&gt; comes writes &lt;a href="https://www.wikiwand.com/en/An_Essay_towards_solving_a_Problem_in_the_Doctrine_of_Chances"&gt;An Essay towards solving a Problem in the Doctrine of the Chances&lt;/a&gt; which describes elements of Inverse Probability, in which the probability of a cause is calculated based on observed effects, stated as a thought experiment in which a person turned away from a table estimates the position of a ball based on being told whether subsequent balls randomly dropped on the same table are to the left or the right of it.&lt;/li&gt;
&lt;li&gt;1748: &lt;a href="https://www.wikiwand.com/en/David_Hume"&gt;David Hume&lt;/a&gt; publishes &lt;a href="https://www.wikiwand.com/en/Of_Miracles"&gt;Of Miracles&lt;/a&gt;, in which he argues that since miracles are, by nature, singular, they can never have as much evidence in their favor as against them.&lt;/li&gt;
&lt;li&gt;1749: &lt;a href="https://www.wikiwand.com/en/Pierre-Simon_Laplace"&gt;Pierre-Simon Laplace&lt;/a&gt; is born&lt;/li&gt;
&lt;li&gt;1764: &lt;a href="https://www.wikiwand.com/en/Richard_Price"&gt;Richard Price&lt;/a&gt; publishes &lt;a href="https://www.wikiwand.com/en/An_Essay_towards_solving_a_Problem_in_the_Doctrine_of_Chances"&gt;An Essay towards solving a Problem in the Doctrine of the Chances&lt;/a&gt; with his additions, believing that it could act as a refutation of Hume's argument&lt;/li&gt;
&lt;li&gt;1774: Laplace comes up with idea that the probability of a cause given the observed effect is the ratio of the probability of that effect given the cause to sum of the probabilities for all other causes given that effect.&lt;/li&gt;
&lt;li&gt;1781: Price tells &lt;a href="https://www.wikiwand.com/en/Marquis_de_Condorcet"&gt;the Marquis of Condorcet&lt;/a&gt; about Bayes' work and Laplace incorporates the use of the prior into his formulation&lt;/li&gt;
&lt;li&gt;1810: Laplace discovers &lt;a href="https://www.wikiwand.com/en/Central_limit_theorem"&gt;the Central Limit Theorem&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;1814: Laplace extends his version of Bayes' equation&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org37313d1" class="outline-2"&gt;
&lt;h2 id="org37313d1"&gt;The Equations&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org37313d1"&gt;
&lt;p&gt;
Since it's hard to write out the equations in bullet points I'm going to write some simple versions here.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-org10aff08" class="outline-3"&gt;
&lt;h3 id="org10aff08"&gt;Bayes' Formulation&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org10aff08"&gt;
&lt;p&gt;
"The theory that would not die" notes that Bayes' didn't write out an equation, but it can be written out something like this.
\[
P(\textit{cause}|\textit{effect}) = \frac{P(\textit{effect}|\textit{cause}) P(\textit{cause})}{P(\textit{effect})}
\]
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgee6afa6" class="outline-3"&gt;
&lt;h3 id="orgee6afa6"&gt;Laplace's First Version&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgee6afa6"&gt;
&lt;p&gt;
Originally Laplace didn't have the prior's in his equation (I'll substitute &lt;i&gt;C&lt;/i&gt; for &lt;i&gt;cause&lt;/i&gt;, &lt;i&gt;E&lt;/i&gt; for &lt;i&gt;effect&lt;/i&gt; and &lt;i&gt;C'&lt;/i&gt; for not our theorized cause).
\[
P(C|E) = \frac{P(E|C)}{\sum P(E|C')}
\]
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org19fb7e8" class="outline-3"&gt;
&lt;h3 id="org19fb7e8"&gt;Laplace's Final Version&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org19fb7e8"&gt;
&lt;p&gt;
\[
P(C|E) = \frac{P(E|C)P_{\textit{prior}}(C)}{\sum P(E|C') P_{\textit{prior}} (C')}
\]
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org9ca7d49" class="outline-2"&gt;
&lt;h2 id="org9ca7d49"&gt;Sources&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org9ca7d49"&gt;
&lt;ol class="org-ol"&gt;
&lt;li&gt;McGrayne SB. The theory that would not die: how Bayes’ rule cracked the enigma code, hunted down Russian submarines, and emerged triumphant from two centuries of controversy. paperback ed. New Haven, Conn.: Yale University Press; 2011. 336 p.&lt;/li&gt;

&lt;li&gt;Kopf D. The most important formula in data science was first used to prove the existence of God [Internet]. Quartz. [cited 2019 May 12]. Available from: &lt;a href="https://qz.com/1315731/the-most-important-formula-in-data-science-was-first-used-to-prove-the-existence-of-god/"&gt;https://qz.com/1315731/the-most-important-formula-in-data-science-was-first-used-to-prove-the-existence-of-god/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>bayes theorem</category><category>history</category><category>notes</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/notes/the-origin-of-bayes-theorem/</guid><pubDate>Sun, 12 May 2019 21:02:18 GMT</pubDate></item><item><title>Looking at random graphs</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/networks/looking-at-random-graphs/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/looking-at-random-graphs/#org1b898cf"&gt;Imports&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/looking-at-random-graphs/#org74a2156"&gt;Part 1 - Random Graph Identification&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/looking-at-random-graphs/#orgc3de31c"&gt;Load the data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/looking-at-random-graphs/#orged95f0b"&gt;Graph Identification&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/looking-at-random-graphs/#orgc875065"&gt;Part 2 - Company Emails&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/looking-at-random-graphs/#org6e75e0f"&gt;Part 2A - Salary Prediction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/looking-at-random-graphs/#org55cad8d"&gt;Part 2B - New Connections Prediction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/looking-at-random-graphs/#orgb3ef176"&gt;Separate the Target and Training Sets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/looking-at-random-graphs/#orgad08b9a"&gt;Scaling the Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/looking-at-random-graphs/#org8ac5901"&gt;Feature Selection&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org1b898cf" class="outline-2"&gt;
&lt;h2 id="org1b898cf"&gt;Imports&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org1b898cf"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# python standard library
import os
import pickle

# from pypi
import networkx
import numpy
import pandas

from sklearn.linear_model import LogisticRegressionCV
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import (
    ExtraTreesClassifier,
    RandomForestClassifier,
    )
from sklearn.feature_selection import (
    RFECV,
    SelectFromModel,
)
from sklearn.model_selection import (
    GridSearchCV,
    StratifiedKFold,
    train_test_split,
    )
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;% matplotlib inline
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org74a2156" class="outline-2"&gt;
&lt;h2 id="org74a2156"&gt;Part 1 - Random Graph Identification&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org74a2156"&gt;
&lt;p&gt;
For the first part of this assignment you will analyze randomly generated graphs and determine which algorithm created them.
&lt;/p&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgc3de31c" class="outline-3"&gt;
&lt;h3 id="orgc3de31c"&gt;Load the data&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgc3de31c"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;part_one_graphs = pickle.load(open('A4_graphs','rb'))
print(len(part_one_graphs))
print(type(part_one_graphs[0]))
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
&lt;code&gt;part_one_graphs&lt;/code&gt; is a list containing 5 networkx graphs. Each of these graphs were generated by one of three possible algorithms:
&lt;/p&gt;

&lt;ul class="org-ul"&gt;
&lt;li&gt;Preferential Attachment (`'PA'`)&lt;/li&gt;
&lt;li&gt;Small World with low probability of rewiring (`'SW&lt;sub&gt;L&lt;/sub&gt;'`)&lt;/li&gt;
&lt;li&gt;Small World with high probability of rewiring (`'SW&lt;sub&gt;H&lt;/sub&gt;'`)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;
Analyze each of the 5 graphs and determine which of the three algorithms generated the graph.
&lt;/p&gt;

&lt;p&gt;
&lt;b&gt;The `graph&lt;sub&gt;identification&lt;/sub&gt;` function should return a list of length 5 where each element in the list is either `'PA'`, `'SW&lt;sub&gt;L&lt;/sub&gt;'`, or `'SW&lt;sub&gt;H&lt;/sub&gt;'`.&lt;/b&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orged95f0b" class="outline-3"&gt;
&lt;h3 id="orged95f0b"&gt;Graph Identification&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orged95f0b"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def graph_identification():
    """Identifies the type of graph each of the graphs is

    Returns:
     list: string identifiers for the type of graph
    """
    graph_types = []
    for graph in part_one_graphs:
	path = networkx.average_shortest_path_length(graph)
	coefficient = networkx.average_clustering(graph)
	if path &amp;gt; 6:
	    if coefficient &amp;lt; 0.5:
		graph_types.append("SW_L")
	    else:
		raise Exception("unexpected type")
	else:
	    if coefficient &amp;lt; 0.5:
		graph_types.append("PA")
	    else:
		graph_types.append("SW_H")
    return graph_types
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
This was marked wrong by the grader.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgc875065" class="outline-2"&gt;
&lt;h2 id="orgc875065"&gt;Part 2 - Company Emails&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgc875065"&gt;
&lt;p&gt;
For the second part of this assignment you will be working with a company's email network where each node corresponds to a person at the company, and each edge indicates that at least one email has been sent between two people.
&lt;/p&gt;

&lt;p&gt;
The network also contains the node attributes `Department` and `ManagementSalary`.
&lt;/p&gt;

&lt;p&gt;
`Department` indicates the department in the company which the person belongs to, and `ManagementSalary` indicates whether that person is receiving a managment position salary.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;email = networkx.read_gpickle('email_prediction.txt')
print(networkx.info(email))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org6e75e0f" class="outline-3"&gt;
&lt;h3 id="org6e75e0f"&gt;Part 2A - Salary Prediction&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org6e75e0f"&gt;
&lt;p&gt;
Using network `email`, identify the people in the network with missing values for the node attribute `ManagementSalary` and predict whether or not these individuals are receiving a managment position salary.
&lt;/p&gt;

&lt;p&gt;
To accomplish this, you will need to create a matrix of node features using networkx, train a sklearn classifier on nodes that have `ManagementSalary` data, and predict a probability of the node receiving a managment salary for nodes where `ManagementSalary` is missing.
&lt;/p&gt;

&lt;p&gt;
Your predictions will need to be given as the probability that the corresponding employee is receiving a managment position salary.
&lt;/p&gt;

&lt;p&gt;
The evaluation metric for this assignment is the Area Under the ROC Curve (AUC).
&lt;/p&gt;

&lt;p&gt;
Your grade will be based on the AUC score computed for your classifier. A model which with an AUC of 0.75 or higher will receive full points.
&lt;/p&gt;

&lt;p&gt;
Using your trained classifier, return a series of length 252 with the data being the probability of receiving managment salary, and the index being the node id.
&lt;/p&gt;

&lt;pre class="example"&gt;
1       1.0
2       0.0
5       0.8
8       1.0
    ...
996     0.7
1000    0.5
1001    0.0
Length: 252, dtype: float64
&lt;/pre&gt;
&lt;/div&gt;

&lt;div id="outline-container-org233ab2e" class="outline-4"&gt;
&lt;h4 id="org233ab2e"&gt;The Data Frame&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org233ab2e"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;if not os.path.isfile("email_data.h5"):
    data = pandas.DataFrame(index=email.nodes())
    data["department"] = pandas.Series(networkx.get_node_attributes(email, "Department"))
    data["management"] = pandas.Series(networkx.get_node_attributes(email, "ManagementSalary"))
    data["clustering"] = pandas.Series(networkx.clustering(email))
    data["degree"] = pandas.Series(email.degree())
    data["degree_centrality"] = pandas.Series(networkx.degree_centrality(email))
    data["closeness_centrality"] = pandas.Series(networkx.closeness_centrality(email))
    data["betweenness_centrality"] = pandas.Series(networkx.betweenness_centrality(email))
    data["pagerank"] = pandas.Series(networkx.pagerank(email))
    _, authority = networkx.hits(email)
    data["authority"] = pandas.Series(authority)
    data.to_hdf("email_data.h5","df" )
else:
    data = pandas.read_hdf('email_data.h5', "df")
print(data.head())    
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(data.management.unique())
print(data.department.unique())
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org4e3aa18" class="outline-4"&gt;
&lt;h4 id="org4e3aa18"&gt;Department Dummy Variables&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org4e3aa18"&gt;
&lt;p&gt;
Even though I don't think it's going to prove useful, the &lt;code&gt;department&lt;/code&gt; feature is actually categorical, despite the use of integers so we'll have to use One-Hot-Encoding to add dummy variables for it.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;dummies_data = pandas.get_dummies(data, columns=["department"])
print(dummies_data.head(1))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org62645a2" class="outline-4"&gt;
&lt;h4 id="org62645a2"&gt;Separating the Training and Prediction Sets&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org62645a2"&gt;
&lt;p&gt;
We're going to use the model to predict what the missing &lt;code&gt;management&lt;/code&gt; values are so I'm going to separate the missing and non-missing sets. 
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;training_data = dummies_data[pandas.notnull(dummies_data.management)]
prediction_data = dummies_data[pandas.isnull(dummies_data.management)]
print(training_data.shape)
print(prediction_data.shape)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
The problem description tells us that the answer should have 252 entries so this is a safe assertion.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;assert len(prediction_data) == 252
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org8500437" class="outline-4"&gt;
&lt;h4 id="org8500437"&gt;Training and Target Data&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org8500437"&gt;
&lt;p&gt;
To train the model we'll need to separate out the &lt;code&gt;management&lt;/code&gt; column (and remove it entirely from the &lt;code&gt;prediction&lt;/code&gt; set).
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;non_management = [column for column in training_data.columns if column != "management"]
y_train = training_data.management
x_train = training_data[non_management]
x_predict = prediction_data[non_management]
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org68cbaf5" class="outline-4"&gt;
&lt;h4 id="org68cbaf5"&gt;Scaling&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org68cbaf5"&gt;
&lt;p&gt;
I don't think the Random Forest model that I'm going to use needs it, but I'm going to standardize the data.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_predict = pandas.DataFrame(scaler.transform(x_predict), index=x_predict.index)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org1a136ba" class="outline-4"&gt;
&lt;h4 id="org1a136ba"&gt;Feature Selection&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org1a136ba"&gt;
&lt;p&gt;
Since we now have so many features, I'm going to do some feature selection.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(x_train.shape)
print(x_predict.shape)
trees = ExtraTreesClassifier(n_estimators=10)
eliminator = RFECV(estimator=trees, cv=StratifiedKFold(10), scoring="roc_auc")
eliminator.fit(x_train, y_train)
x_train_reduced = eliminator.transform(x_train)
x_predict_reduced = pandas.DataFrame(eliminator.transform(x_predict), index=x_predict.index)
print(x_train_reduced.shape)
print(x_predict_reduced.shape)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
When I used the train-test-split training model it left 17 columns. I wonder if using the whole training set messes it up.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org671a17a" class="outline-4"&gt;
&lt;h4 id="org671a17a"&gt;Logistic Regression&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org671a17a"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;model = LogisticRegressionCV(penalty="l1", scoring="roc_auc",
			     solver="liblinear", cv=StratifiedKFold(10))
model.fit(x_train_reduced, y_train)
print(model.scores_[1.0].mean())
print(model.scores_[1.0].std())
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
It seems to be doing much worse than when I used the train-test split.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgf4a25a4" class="outline-4"&gt;
&lt;h4 id="orgf4a25a4"&gt;Random Forests&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgf4a25a4"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;parameter_grid = dict(n_estimators=range(10, 100, 10))
search = GridSearchCV(RandomForestClassifier(), parameter_grid,
		      cv=StratifiedKFold(10), scoring="roc_auc")
search.fit(x_train_reduced, y_train)
print(search.best_score_)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class RandomForest(object):
    """builds the random forest

    Args:
     x_train(array): data to train on
     y_train(array): targets for training
     start (int): start value for number of estimators
     stop (int): upper value for range of estimators
     step (int): increment for range of estimators
     folds (int): K-folds for cross-validation    
    """
    def __init__(self, x_train, y_train,
		 start=10, stop=100, step=10, folds=10):
	self.x_train = x_train
	self.y_train = y_train
	self.start = start
	self.stop = stop
	self.step = step
	self.folds = folds
	self._parameters = None
	self._search = None
	self._model = None
	return

    @property
    def parameters(self):
	"""parameters for the grid-search"""
	if self._parameters is None:
	    self._parameters = dict(n_estimators=range(self.start,
						       self.stop,
						       self.step))
	return self._parameters

    @property
    def search(self):
	"""fitted grid search to find hyper-parameters"""
	if self._search is None:
	    self._search = GridSearchCV(RandomForestClassifier(),
					self.parameters,
					cv=StratifiedKFold(self.folds),
					scoring="roc_auc")
	    self._search.fit(self.x_train, self.y_train)
	return self._search

    @property
    def model(self):
	"""best model found by the grid search"""
	if self._model is None:
	    self._model = self.search.best_estimator_
	return self._model
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org139c2a7" class="outline-4"&gt;
&lt;h4 id="org139c2a7"&gt;Data Loader&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org139c2a7"&gt;
&lt;p&gt;
Since having all these org-babel things around makes things kind of hard I'm going to make a class to bundle everything together.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class DataLoader(object):
    """loads and transforms the data
    Args:
     estimators (int): number of trees to use for feature elimination
    """
    def __init__(self, estimators=10):
	self.estimators = estimators
	self._data = None
	self._dummies_data = None
	self._training_data = None
	self._prediction_data = None
	self._non_management = None
	self._y_train = None
	self._x_train = None
	self._x_predict = None
	self._scaler = None
	self._x_train_scaled = None
	self._x_predict_scaled = None
	self._eliminator = None
	self._x_train_reduced = None
	self._x_predict_reduced = None
	return

    @property
    def data(self):
	"""The initial data"""
	if self._data is None:
	    if not os.path.isfile("email_data.h5"):
		data = pandas.DataFrame(index=email.nodes())
		data["department"] = pandas.Series(networkx.get_node_attributes(email, "Department"))
		data["management"] = pandas.Series(networkx.get_node_attributes(email, "ManagementSalary"))
		data["clustering"] = pandas.Series(networkx.clustering(email))
		data["degree"] = pandas.Series(email.degree())
		data["degree_centrality"] = pandas.Series(networkx.degree_centrality(email))
		data["closeness_centrality"] = pandas.Series(networkx.closeness_centrality(email))
		data["betweenness_centrality"] = pandas.Series(networkx.betweenness_centrality(email))
		data["pagerank"] = pandas.Series(networkx.pagerank(email))
		_, authority = networkx.hits(email)
		data["authority"] = pandas.Series(authority)
		data.to_hdf("email_data.h5","df" )
		self._data = data
	    else:
		self._data = pandas.read_hdf('email_data.h5', "df")
	return self._data

    @property
    def dummies_data(self):
	"""one-hot-encoded data"""
	if self._dummies_data is None:
	    self._dummies_data = pandas.get_dummies(self.data, columns=["department"])
	return self._dummies_data

    @property
    def training_data(self):
	"""data with management information"""
	if self._training_data is None:
	    self._training_data = self.dummies_data[pandas.notnull(
		self.dummies_data.management)]
	return self._training_data

    @property
    def prediction_data(self):
	"""data missing management information"""
	if self._prediction_data is None:
	    self._prediction_data = self.dummies_data[pandas.isnull(
		self.dummies_data.management)]
	    assert len(self._prediction_data) == 252
	return self._prediction_data

    @property
    def non_management(self):
	"""list of columns minus management"""
	if self._non_management is None:
	    self._non_management = [
		column for column in self.training_data.columns
		if column != "management"]
	return self._non_management

    @property
    def y_train(self):
	"""target-data for training"""
	if self._y_train is None:
	    self._y_train = self.training_data.management
	return self._y_train

    @property
    def x_train(self):
	"""data for training"""
	if self._x_train is None:
	    self._x_train = self.training_data[self.non_management]
	return self._x_train

    @property
    def x_predict(self):
	"""set to make predictions"""
	if self._x_predict is None:
	    self._x_predict = self.prediction_data[self.non_management]
	return self._x_predict

    @property
    def scaler(self):
	"""standard scaler"""
	if self._scaler is None:
	    self._scaler = StandardScaler()
	return self._scaler

    @property
    def x_train_scaled(self):
	"""training data scaled to 1 std, 0 mean"""
	if self._x_train_scaled is None:
	    self._x_train_scaled = self.scaler.fit_transform(self.x_train)
	return self._x_train_scaled

    @property
    def x_predict_scaled(self):
	"""prediction data with mean 0, std 1

	The answer requires the index so this is a dataframe
	instead of an array

	Returns:
	 pandas.DataFrame: scaled data with index preserved
	"""
	if self._x_predict_scaled is None:
	    self._x_predict_scaled = pandas.DataFrame(
		self.scaler.transform(self.x_predict),
		index=self.x_predict.index)
	return self._x_predict_scaled

    @property
    def eliminator(self):
	"""recursive feature eliminator"""
	if self._eliminator is None:
	    trees = ExtraTreesClassifier(n_estimators=10)
	    self._eliminator = RFECV(estimator=trees, cv=StratifiedKFold(10), 
				     scoring="roc_auc")
	    self._eliminator.fit(self.x_train_scaled, self.y_train)
	return self._eliminator

    @property
    def x_train_reduced(self):
	"""training data with features eliminated"""
	if self._x_train_reduced is None:
	    self._x_train_reduced = self.eliminator.transform(
		self.x_train_scaled)
	return self._x_train_reduced

    @property
    def x_predict_reduced(self):
	"""prediction data with features eliminated"""
	if self._x_predict_reduced is None:
	    self._x_predict_reduced = pandas.DataFrame(
		self.eliminator.transform(self.x_predict_scaled),
		index=self.x_predict_scaled.index)
	return self._x_predict_reduced
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org05e74ea" class="outline-4"&gt;
&lt;h4 id="org05e74ea"&gt;Submission&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org05e74ea"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def salary_predictions():
    """Prediction that employee is management

    Calculates the probability that an employee is management

    Returns:
     pandas.Series: Node ID, probability of node
    """
    data = DataLoader()
    forest = RandomForest(data.x_train_reduced, data.y_train)
    # probabilites is an array with rows of 
    # [&amp;lt;probability not management&amp;gt;, &amp;lt;probability management&amp;gt;]
    # see forest.model.classes_ to see what each entry represents
    probabilities = forest.model.predict_proba(data.x_predict_reduced)
    return pandas.Series(probabilities[:, 1], index=data.x_predict_reduced.index)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;output = salary_predictions()
print(output.head())
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;assert all(output.index == DataLoader().prediction_data.index)
assert len(output) == 252
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org55cad8d" class="outline-3"&gt;
&lt;h3 id="org55cad8d"&gt;Part 2B - New Connections Prediction&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org55cad8d"&gt;
&lt;p&gt;
For the last part of this assignment, you will predict future connections between employees of the network. The future connections information has been loaded into the variable `future&lt;sub&gt;connections&lt;/sub&gt;`. The index is a tuple indicating a pair of nodes that currently do not have a connection, and the `Future Connection` column indicates if an edge between those two nodes will exist in the future, where a value of 1.0 indicates a future connection.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;future_connections = pandas.read_csv('Future_Connections.csv', index_col=0, converters={0: eval})
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(future_connections.head(10))
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(future_connections['Future Connection'].value_counts())
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;
Using network `G` and `future&lt;sub&gt;connections&lt;/sub&gt;`, identify the edges in `future&lt;sub&gt;connections&lt;/sub&gt;` with missing values and predict whether or not these edges will have a future connection.
&lt;/p&gt;

&lt;p&gt;
To accomplish this, you will need to create a matrix of features for the edges found in `future&lt;sub&gt;connections&lt;/sub&gt;` using networkx, train a sklearn classifier on those edges in `future&lt;sub&gt;connections&lt;/sub&gt;` that have `Future Connection` data, and predict a probability of the edge being a future connection for those edges in `future&lt;sub&gt;connections&lt;/sub&gt;` where `Future Connection` is missing.
&lt;/p&gt;

&lt;p&gt;
Your predictions will need to be given as the probability of the corresponding edge being a future connection.
&lt;/p&gt;

&lt;p&gt;
The evaluation metric for this assignment is the Area Under the ROC Curve (AUC).
&lt;/p&gt;

&lt;p&gt;
Your grade will be based on the AUC score computed for your classifier. A model which with an AUC of 0.75 or higher will receive full points.
&lt;/p&gt;

&lt;p&gt;
Using your trained classifier, return a series of length 122112 with the data being the probability of the edge being a future connection, and the index being the edge as represented by a tuple of nodes.
&lt;/p&gt;

&lt;pre class="example"&gt;
(107, 348)    0.35
(542, 751)    0.40
(20, 426)     0.55
(50, 989)     0.35
          ...
(939, 940)    0.15
(555, 905)    0.35
(75, 101)     0.65
Length: 122112, dtype: float64
&lt;/pre&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgdefe904" class="outline-4"&gt;
&lt;h4 id="orgdefe904"&gt;Add Network Features&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgdefe904"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class Futures(object):
    target = "Future Connection"
    data_file = "Future_Connections.csv"
    graph_file = "email_prediction.txt"
    networkx_data_index = 2
    folds = 10
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class DataNames(object):
    resource_allocation = 'resource_allocation'
    jaccard = 'jaccard_coefficient'
    adamic = "adamic_adar"
    preferential = "preferential_attachment"
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def add_networkx_data(adder, name, graph=email, frame=future_connections):
    """Adds networkx data to the frame

    The networkx link-prediction functions return generators of triples:
     (first-node, second-node, value)

    This will use the index of the frame that's passed in as the source of 
    node-pairs for the networkx function (called `ebunch` in the networkx
    documentation) and the add only the value we want back to the frame

    Args:
     adder: networkx function to call to get the new data
     name: column-name to add to the frame
     graph: networkx graph to pass to the function
     frame (pandas.DataFrame): frame with node-pairs as index to add data to
    """
    frame[name] = [output[Futures.networkx_data_index]
		   for output in adder(graph, frame.index)]
    return frame
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgc4ca998" class="outline-5"&gt;
&lt;h5 id="orgc4ca998"&gt;Adding A Resource Allocation Index&lt;/h5&gt;
&lt;div class="outline-text-5" id="text-orgc4ca998"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;add_networkx_data(networkx.resource_allocation_index,
		  DataNames.resource_allocation)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(future_connections.head(1))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org58f379f" class="outline-5"&gt;
&lt;h5 id="org58f379f"&gt;Adding the Jaccard Coefficient&lt;/h5&gt;
&lt;div class="outline-text-5" id="text-org58f379f"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;add_networkx_data(networkx.jaccard_coefficient, DataNames.jaccard)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(future_connections.head(1))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org92d86da" class="outline-5"&gt;
&lt;h5 id="org92d86da"&gt;Adamic Adar&lt;/h5&gt;
&lt;div class="outline-text-5" id="text-org92d86da"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;add_networkx_data(networkx.adamic_adar_index, DataNames.adamic)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(future_connections.head(1))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org3e4025c" class="outline-5"&gt;
&lt;h5 id="org3e4025c"&gt;Preferential Attachment&lt;/h5&gt;
&lt;div class="outline-text-5" id="text-org3e4025c"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;add_networkx_data(networkx.preferential_attachment, DataNames.preferential)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(future_connections.head(1))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgc16d60b" class="outline-4"&gt;
&lt;h4 id="orgc16d60b"&gt;Setup the Training and Testing Data&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgc16d60b"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org1c3a250" class="outline-5"&gt;
&lt;h5 id="org1c3a250"&gt;Separating the Edges Without 'Future Connection' Values&lt;/h5&gt;
&lt;div class="outline-text-5" id="text-org1c3a250"&gt;
&lt;p&gt;
We are going to train on the values in the data with predictions and then make predictions for those that don't.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;prediction_set = future_connections[future_connections[Futures.target].isnull()]
training_set = future_connections[future_connections[Futures.target].notnull()]
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(prediction_set.shape)
print(training_set.shape)
assert len(prediction_set) + len(training_set) == len(future_connections)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgb3ef176" class="outline-3"&gt;
&lt;h3 id="orgb3ef176"&gt;Separate the Target and Training Sets&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgb3ef176"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;non_target = [column for column in future_connections.columns
	      if column != Futures.target]
x_train = training_set[non_target]
y_train = training_set[Futures.target]
x_predict = prediction_set[non_target]
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;assert all(x_train.columns == x_predict.columns)
assert len(x_train) == len(x_test)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgad08b9a" class="outline-3"&gt;
&lt;h3 id="orgad08b9a"&gt;Scaling the Data&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgad08b9a"&gt;
&lt;p&gt;
To enable the use of linear models I'm going to scale the data so the mean is 0 and the variance is 1.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;scaler = StandardScaler()
x_train_scaled = scaler.fit_transform(x_train)
x_predict_scaled = scaler.transform(x_predict)

x_train_frame = pandas.DataFrame(x_train_scaled, columns=x_train.columns)
x_predict_frame = pandas.DataFrame(x_predict_scaled, columns=x_predict.columns)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(training.describe())
print(predictions.describe())
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org8ac5901" class="outline-3"&gt;
&lt;h3 id="org8ac5901"&gt;Feature Selection&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org8ac5901"&gt;
&lt;p&gt;
To reduce the dimensionality I'm going to use model-based selection with Extra Trees.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;estimator = ExtraTreesClassifier()
estimator.fit(x_train_scaled, y_train)
selector = SelectFromModel(estimator, prefit=True)
x_train_trees_sfm = selector.transform(x_train_scaled)
x_predict_sfm = selector.transform(x_predict_scaled)
print(estimator.feature_importances_)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(x_train_trees_sfm.shape)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org46db689" class="outline-4"&gt;
&lt;h4 id="org46db689"&gt;Missing Future Connections&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org46db689"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;model = LogisticRegressionCV(n_jobs=-1, scoring='roc_auc', solver='liblinear',
			     cv=StratifiedKFold())
model.fit(x_train_trees_sfm, y_train)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;for scores in model.scores_[1.0]:
    print(max(scores))
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(model.classes_)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def new_connections_predictions():    
    probabilities = model.predict_proba(x_predict_sfm)
    return pandas.Series(probabilities[:, 1], index=prediction_set.index)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;outcome = new_connections_predictions()
assert len(outcome) == 122112, len(outcome)
print(outcome.head())
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>networks</category><category>random graphs</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/networks/looking-at-random-graphs/</guid><pubDate>Sat, 13 Apr 2019 18:59:44 GMT</pubDate></item><item><title>Selecting the E-Mail Model</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/networks/selecting-the-e-mail-model/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/selecting-the-e-mail-model/#orgcdd8d54"&gt;Imports&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/selecting-the-e-mail-model/#orgf09d04e"&gt;The Data&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/selecting-the-e-mail-model/#org88f1e4e"&gt;Department&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/selecting-the-e-mail-model/#org1bd3f86"&gt;Splitting the Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/selecting-the-e-mail-model/#org18d22e8"&gt;Standardizing the Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/selecting-the-e-mail-model/#org84a74ef"&gt;Dummy Classifier&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/selecting-the-e-mail-model/#org81344d2"&gt;Feature Selection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/selecting-the-e-mail-model/#org19ffe46"&gt;Fit and Display&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/selecting-the-e-mail-model/#orgd6ee56a"&gt;Logistic Regression&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/selecting-the-e-mail-model/#org200e4fd"&gt;L1 Penalty&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/selecting-the-e-mail-model/#org78c87a6"&gt;Random Forests&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/selecting-the-e-mail-model/#orgb2e286f"&gt;K Nearest Neighbors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/selecting-the-e-mail-model/#orgf78b53b"&gt;Support Vector Classifier (SVC)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgcdd8d54" class="outline-2"&gt;
&lt;h2 id="orgcdd8d54"&gt;Imports&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgcdd8d54"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# pypi
from sklearn.ensemble import (
    ExtraTreesClassifier,
    RandomForestClassifier,
    )
from sklearn.feature_selection import (
    RFECV,
    SelectFromModel,
)
from sklearn.linear_model import LogisticRegressionCV
from sklearn.model_selection import (
    GridSearchCV,
    StratifiedKFold,
    train_test_split,
    )

from sklearn.dummy import DummyClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
import matplotlib.pyplot as pyplot
import mglearn
import numpy
import pandas
import seaborn
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;% matplotlib inline
seaborn.set_style("whitegrid")
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgf09d04e" class="outline-2"&gt;
&lt;h2 id="orgf09d04e"&gt;The Data&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgf09d04e"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;data = pandas.read_hdf("email_data.h5", "df")
cleaned_data = data[pandas.notnull(data.management)]
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(cleaned_data.head())
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org88f1e4e" class="outline-3"&gt;
&lt;h3 id="org88f1e4e"&gt;Department&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org88f1e4e"&gt;
&lt;p&gt;
Even though I don't think it's going to prove useful, the &lt;code&gt;department&lt;/code&gt; feature is actually categorical, despite the use of integers so we'll have to add dummy variables for it.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;cleaned_data = pandas.get_dummies(cleaned_data, columns=["department"])
print(cleaned_data.head(1))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org1bd3f86" class="outline-3"&gt;
&lt;h3 id="org1bd3f86"&gt;Splitting the Data&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org1bd3f86"&gt;
&lt;p&gt;
For evaluation purposes I'll use the traditional train-test split.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;x_data = cleaned_data.loc[:, cleaned_data.columns != "management"]

y_data = cleaned_data.management

print(x_data.head())
print(y_data.head())
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(y_data.value_counts())
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;seaborn.countplot(x='management', data=cleaned_data)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
It looks like the management data is unbalanced, so I'll do a stratified split.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, stratify=y_data)
print(x_train.shape)
print(y_test.shape)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;seaborn.countplot(y_train)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Looks close enough for government work.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org18d22e8" class="outline-2"&gt;
&lt;h2 id="org18d22e8"&gt;Standardizing the Data&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org18d22e8"&gt;
&lt;p&gt;
The linear models expect the data to be standardized, so to make the comparisons fair I'll standardize the data first. First, a look at the data before scaling.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(x_train.describe())
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Now I'll scale it.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;scaler = StandardScaler()
scaler.fit(x_train)
x_train = pandas.DataFrame(scaler.transform(x_train), columns=x_train.columns)
x_test = scaler.transform(x_test)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Now the means should be near 0 (very small) and the standard deviations should be around 1.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(x_train.describe())
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org84a74ef" class="outline-2"&gt;
&lt;h2 id="org84a74ef"&gt;Dummy Classifier&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org84a74ef"&gt;
&lt;p&gt;
As a baseline I'll use a &lt;a href="http://scikit-learn.org/stable/modules/model_evaluation.html#dummy-estimators"&gt;Dummy Classifier&lt;/a&gt; which uses a simple rule rather than the input data to make predictions.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;parameter_grid = dict(strategy=["stratified", 'most_frequent', 'prior', 'uniform'])
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Now we'll do a grid search.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;grid_search = GridSearchCV(DummyClassifier(), parameter_grid,
			   cv=StratifiedKFold(10), scoring="roc_auc")
grid_search.fit(x_train, y_train)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;BASELINE = grid_search.score(x_test, y_test)
print(grid_search.best_params_)
print(BASELINE)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
It looks like it chose the &lt;b&gt;stratified&lt;/b&gt; strategy, which should predict that the instances are all non-managers. Our baseline AUC score is 0.5 (0.47 now?).
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;results = pandas.DataFrame(grid_search.cv_results_)
print(results.head(1))
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;figure = pyplot.figure()
axe = figure.gca()
strategies = parameter_grid["strategy"]
x = pyplot.xticks(list(range(len(strategies))), strategies)
axe.plot(range(len(strategies)), results.mean_test_score)
axe.set_title("Dummy Classifier Strategy Vs AUC")
axe.set_xlabel("strategy")
axe.set_ylabel("AUC Score")
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
So it looks like all the strategies except &lt;b&gt;stratified&lt;/b&gt; did the same - and even the stratified did basically the same if you round it off.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org81344d2" class="outline-2"&gt;
&lt;h2 id="org81344d2"&gt;Feature Selection&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org81344d2"&gt;
&lt;p&gt;
I'm going to need to do some feature reduction, but figuring out what is important and what isn't is something I'm going to have to leave to the machine. I'm going to assume that the features thrown out by logistic regression with l1 penalization are unimportant. 
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;logistic_model = LogisticRegressionCV(penalty='l1',
				      solver='liblinear', scoring="roc_auc")
logistic_model.fit(x_train, y_train)
model = SelectFromModel(logistic_model, prefit=True)

x_train_positive = model.transform(x_train)
x_test_positive = model.transform(x_test)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(logistic_model.score(x_test, y_test))
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Logistic Regression with &lt;code&gt;L1&lt;/code&gt; penalty seems to do reasonably well even without feature selection.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;logistic_model.fit(x_train_positive, y_train)
print(logistic_model.score(x_test_positive, y_test))
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
It looks like feature selection didn't really help here.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(x_train.shape)
print(x_train_positive.shape)
print(model.ranking_)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
As a double-check I'll use a tree-based, recursive feature-elimination version.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;trees = ExtraTreesClassifier(n_estimators=10)
eliminator = RFECV(estimator=trees, cv=StratifiedKFold(10), scoring="roc_auc")
eliminator.fit(x_train, y_train)
x_train_trees = eliminator.transform(x_train)
x_test_trees = eliminator.transform(x_test)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(x_train_trees.shape)
print(eliminator.ranking_)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
This eliminated many more columns than the Logistic Regression version did.
&lt;/p&gt;

&lt;p&gt;
&lt;b&gt;warning&lt;/b&gt; this seem to change every time you run it - the randomness changes it. Only the elimination of the first column seems to do as well as not running it at all.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org19ffe46" class="outline-2"&gt;
&lt;h2 id="org19ffe46"&gt;Fit and Display&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org19ffe46"&gt;
&lt;p&gt;
This is a convenience function so I can fit and display the scores for the models.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def fit_and_display(model, identifier):
    """Fit and display the scores

    Args:
     model: The instantiated model to fit
     identifier (str): something to output at the beginning
    """
    print(identifier)
    print("=" * len(identifier))
    model.fit(x_train, y_train)
    print("\nX-train")
    print("Score: {:.2f}".format(model.score(x_test, y_test)))
    print("\nX-Train Positive")
    model.fit(x_train_positive, y_train)
    print("Score: {:.2f}".format(model.score(x_test_positive, y_test)))
    print("\nX-Train Trees")
    model.fit(x_train_trees, y_train)
    print("Score: {:.2f}".format(model.score(x_test_trees, y_test)))
    print("\nBest Training Score: {}".format(search.best_score_))
    return
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgd6ee56a" class="outline-2"&gt;
&lt;h2 id="orgd6ee56a"&gt;Logistic Regression&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgd6ee56a"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org200e4fd" class="outline-3"&gt;
&lt;h3 id="org200e4fd"&gt;L1 Penalty&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org200e4fd"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;model = LogisticRegressionCV(penalty="l1", scoring="roc_auc", solver="liblinear")
fit_and_display(model, "Logistic Regression L1")
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
I've already run the Logistic Regression using a 'l1' but I'll try it again with 'l2' to see if it improved.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;model = LogisticRegressionCV(scoring="roc_auc", solver="liblinear")
fit_and_display(model, "LogisticRegression")
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
L1 seems to do better than L1 overall, although it doesn't do as well with the recursively data form some reason.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org78c87a6" class="outline-2"&gt;
&lt;h2 id="org78c87a6"&gt;Random Forests&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org78c87a6"&gt;
&lt;p&gt;
I'll try a &lt;a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"&gt;Random Forest&lt;/a&gt; classifier next.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;parameter_grid = dict(n_estimators=range(10, 100, 10))
search = GridSearchCV(RandomForestClassifier(), parameter_grid,
		      cv=StratifiedKFold(10), scoring="roc_auc")
fit_and_display(search, "Random Forest")
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
This seems to have done much better than the logistic regression did. My logistic-regression feature reduction doesn't seem to help.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class RandomForest(object):
    """trains a random forest on the x-test-trees set

    Args:
     start (int): first n-estimators value to use
     stop (int): last n-estimators value (minus step)
     step (int): amount to increment estimators
     folds (int): Cross-validation-folds to usen

    Returns:
     GridSearchCV: grid-search with the best estimator
    """

    def __init__(self, start, stop, step, folds=10):
	self.start = start
	self.stop = stop
	self.step = step
	self.folds = folds
	self._search = None
	self._parameter_grid = None
	return

    @property
    def parameter_grid(self):
	"""dict of the number of estimators to use"""
	if self._parameter_grid is None:
	    self._parameter_grid = dict(n_estimators=list(range(self.start,
								self.stop,
								self.step)))
	return self._parameter_grid

    @property
    def search(self):
	"""grid-search cv object"""
	if self._search is None:
	    self._search = GridSearchCV(RandomForestClassifier(),
					self.parameter_grid,
					cv=StratifiedKFold(self.folds),
					scoring="roc_auc")
	return self._search    

    def fit(self):
	"""fits the model to the tree-based reduced-feature data"""
	self.search.fit(x_train_trees, y_train)
	print(self.search.score(x_test_trees, y_test))
	print(self.search.best_estimator_.feature_importances_)
	print(self.search.best_params_)
	return

    def plot(self):
	"""Plots estimators vs AUC scores"""
	figure = pyplot.figure()
	axe = figure.gca()
	axe.plot(self.parameter_grid["n_estimators"],
		 self.search.cv_results_["mean_test_score"])
	axe.set_title("Estimator Count vs AUC")
	axe.set_xlabel("Number of estimators (trees)")
	axe.set_ylabel("Mean AUC Score")
	return
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;search = RandomForest(10, 100, 10)
search.fit()
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Not a lot of variance in the importance of the features.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;search.plot()
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Would things get better with more trees?
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;search = RandomForest(150, 250, 10)
search.fit()
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;search.plot()
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
In this case the test-score was better, although the training scores don't look much better. I guess it's the randomness coming into play again. I'll try a long run instead.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;search = RandomForest(10, 500, 10)
search.fit()
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;search.plot()
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
The test-score for the best estimator is actually a little worse than it was for the previous case, although it's qute a small difference.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgb2e286f" class="outline-2"&gt;
&lt;h2 id="orgb2e286f"&gt;K Nearest Neighbors&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgb2e286f"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;parameters = dict(n_neighbors=range(10, 20),
		  weights=["uniform", "distance"],
		  p=[1, 2],
		  leaf_size=range(10, 50, 10))

search = GridSearchCV(KNeighborsClassifier(), parameters, scoring="roc_auc")
search.fit(x_train_trees, y_train)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(search.score(x_test_trees, y_test))
print(search.best_params_)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
This doesn't seem to do so well, although I'm not as experienced at using it so I might be using bad parameters.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgf78b53b" class="outline-2"&gt;
&lt;h2 id="orgf78b53b"&gt;Support Vector Classifier (SVC)&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgf78b53b"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;parameters = dict(C=numpy.arange(.1, 1, 0.1), gamma=range(1, 10, 1),
		  kernel=["linear", 'rbf', 'sigmoid'])
search = GridSearchCV(SVC(class_weight='balanced'), parameters, scoring='roc_auc')
fit_and_display(search, "SVC")
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(search.score(x_test_trees, y_test))
print(search.best_params_)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Now that the data is scaled, the svc does much better, alhough still not as well as the random forest.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>model selection</category><category>networks</category><category>sklearn</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/networks/selecting-the-e-mail-model/</guid><pubDate>Sat, 13 Apr 2019 18:57:42 GMT</pubDate></item><item><title>Future E-Mail</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org0bd1730"&gt;Tangle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org81fb40a"&gt;Imports&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org3804397"&gt;Constants&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org2a792c2"&gt;The Email-Graph&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org8ea422d"&gt;The Data&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org4dbe7da"&gt;The Given Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org35cf448"&gt;Adding networkx features&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org611230b"&gt;Add Networkx Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org3d753a0"&gt;Adding A Resource Allocation Index&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org2dee0ca"&gt;Adding the Jaccard Coefficient&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org56bc368"&gt;Adamic Adar&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org7d6a96f"&gt;Preferential Attachment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org07c8429"&gt;Community-Based Link Prediction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org0495260"&gt;Saving the Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#orgc9bc8f5"&gt;Setup the Training and Testing Data&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#orgfead0d3"&gt;Separating the Edges Without 'Future Connection' Values&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#orgaa6c514"&gt;Separate the Target and Training Sets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org9f0a896"&gt;Setting Up the Testing and Training Sets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org906bc5a"&gt;Scaling the Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org1fc0434"&gt;Feature Selection&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org108e511"&gt;Fitting the Models&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org98c5a48"&gt;Persistent Storage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org1d95d09"&gt;Logistic Regression&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#orgb165931"&gt;Fit Grid Search&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#org0f1b6c4"&gt;Random Forests&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/#orgcf84a9f"&gt;Extra Trees&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
This will select a model to predict whether an edge in the email-network that currently doesn't have an edge will have one in the future.
&lt;/p&gt;
&lt;div id="outline-container-org0bd1730" class="outline-2"&gt;
&lt;h2 id="org0bd1730"&gt;Tangle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org0bd1730"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;imports&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;futures&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;names&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;files&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;training&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;future&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;networkx&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;future&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;connections&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;jaccard&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;coefficient&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;adamic&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;adar&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;preferential&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;attachment&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;future&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;connections&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;future&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;connections&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;test&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;scaled&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;pickle&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;it&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;unpickle&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;it&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;lr&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;rfs&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;trees&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;rfs&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;lr&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;sfm&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;trees&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;fsm&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;scores&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;identifiers&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="ow"&gt;and&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;sets&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;key&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;by&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;value&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="ow"&gt;and&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nb"&gt;all&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;logistic&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;grid&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;search&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;grid&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;searches&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;forests&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;

&lt;span class="o"&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class="n"&gt;extra&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;trees&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org81fb40a" class="outline-2"&gt;
&lt;h2 id="org81fb40a"&gt;Imports&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org81fb40a"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# python standard library
import os
import pickle

# pypi
import networkx
import pandas
import seaborn

from numba import jit

from sklearn.ensemble import (
    ExtraTreesClassifier,
    RandomForestClassifier,
    )
from sklearn.feature_selection import (
    RFECV,
    SelectFromModel,
    )
from sklearn.linear_model import LogisticRegressionCV
from sklearn.model_selection import (
    train_test_split,
    GridSearchCV,
    StratifiedKFold,
    )
from sklearn.preprocessing import StandardScaler
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;% matplotlib inline
seaborn.set_style("whitegrid")
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org3804397" class="outline-2"&gt;
&lt;h2 id="org3804397"&gt;Constants&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org3804397"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class Futures(object):
    target = "Future Connection"
    data_file = "Future_Connections.csv"
    graph_file = "email_prediction.txt"
    networkx_data_index = 2
    folds = 10
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class DataNames(object):
    resource_allocation = 'resource_allocation'
    jaccard = 'jaccard_coefficient'
    adamic = "adamic_adar"
    preferential = "preferential_attachment"
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class Files(object):
    """File-names for data persistence"""
    future_training_data = 'future_training_data.csv'
    future_selection_outcomes = 'future_selection_outcomes.pkl'
    future_model_selection = "future_model_cvs.pkl"
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class Training(object):
    """data-pickles"""
    x_train_lr_rfs = "x_train_lr_rfs.pkl"
    x_test_lr_rfs = "x_test_lr_rfs.pkl"
    x_train_trees_rfs = "x_train_trees_rfs.pkl"
    x_test_trees_rfs = "x_test_trees_rfs.pkl"
    x_train_lr_sfm = "x_train_lr_sfm.pkl"
    x_test_lr_sfm = "x_test_lr_sfm.pkl"
    x_train_trees_sfm = "x_train_trees_sfm.pkl"
    x_test_trees_sfm = "x_test_trees_sfm.pkl"
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org2a792c2" class="outline-2"&gt;
&lt;h2 id="org2a792c2"&gt;The Email-Graph&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org2a792c2"&gt;
&lt;p&gt;
To get the features for the models we'll need to use the email-graph.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;email = networkx.read_gpickle(Futures.graph_file)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org8ea422d" class="outline-2"&gt;
&lt;h2 id="org8ea422d"&gt;The Data&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org8ea422d"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org4dbe7da" class="outline-3"&gt;
&lt;h3 id="org4dbe7da"&gt;The Given Data&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org4dbe7da"&gt;
&lt;p&gt;
We're given a csv file with the training and prediction data in it ('Future&lt;sub&gt;Connections.csv&lt;/sub&gt;').
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;head Future_Connections.csv
&lt;span class="nb"&gt;echo&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Org-mode converted it to a table, but it's actually a CSV. The first line of data looks like this.
&lt;/p&gt;

&lt;pre class="example"&gt;
"(6, 840)",0.0
&lt;/pre&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;future_connections_pre_loaded = os.path.isfile(Files.future_training_data)
if future_connections_pre_loaded:
    future_connections = pandas.read_csv(Files.future_training_data,
					 index_col=0)
else:
    future_connections = pandas.read_csv(Futures.data_file,
					 index_col=0,
					 converters={0: eval})
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
So, we're loading the node-pairs (edges) as the index of the data-frame and explicitly telling pandas that the Future Connection values should be converted , which I don't think is necessary, but this came with the problem statement so I'll just leave it in in case there's some side-effect I'm not aware of.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(future_connections[Futures.target].value_counts())
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
This is a fairly big (and lopsided) data-set.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;seaborn.countplot(x=Futures.target, data=future_connections)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org35cf448" class="outline-2"&gt;
&lt;h2 id="org35cf448"&gt;Adding networkx features&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org35cf448"&gt;
&lt;p&gt;
To create features to train the model and make predictions, I'm going to use the networkx &lt;a href="https://networkx.github.io/documentation/networkx-1.10/reference/algorithms.link_prediction.html"&gt;link prediction&lt;/a&gt; algorithms.
&lt;/p&gt;
&lt;/div&gt;

&lt;div id="outline-container-org611230b" class="outline-3"&gt;
&lt;h3 id="org611230b"&gt;Add Networkx Data&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org611230b"&gt;
&lt;p&gt;
This is a function to get networkx data and add it to the data-frame. It won't work for the community-based algorithms.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def add_networkx_data(adder, name, graph=email, frame=future_connections):
    """Adds networkx data to the frame

    The networkx link-prediction functions return generators of triples:
     (first-node, second-node, value)

    This will use the index of the frame that's passed in as the source of 
    node-pairs for the networkx function (called `ebunch` in the networkx
    documentation) and the add only the value we want back to the frame

    Args:
     adder: networkx function to call to get the new data
     name: column-name to add to the frame
     graph: networkx graph to pass to the function
     frame (pandas.DataFrame): frame with node-pairs as index to add data to
    """
    frame[name] = [output[Futures.networkx_data_index]
		   for output in adder(graph, frame.index)]
    return frame
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org3d753a0" class="outline-3"&gt;
&lt;h3 id="org3d753a0"&gt;Adding A Resource Allocation Index&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org3d753a0"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;if not future_connections_pre_loaded:
    add_networkx_data(networkx.resource_allocation_index,
		      DataNames.resource_allocation)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(future_connections.head(1))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org2dee0ca" class="outline-3"&gt;
&lt;h3 id="org2dee0ca"&gt;Adding the Jaccard Coefficient&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org2dee0ca"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;if not future_connections_pre_loaded:
    add_networkx_data(networkx.jaccard_coefficient, DataNames.jaccard)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(future_connections.head(1))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org56bc368" class="outline-3"&gt;
&lt;h3 id="org56bc368"&gt;Adamic Adar&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org56bc368"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;if not future_connections_pre_loaded:
    add_networkx_data(networkx.adamic_adar_index, DataNames.adamic)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(future_connections.head(1))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org7d6a96f" class="outline-3"&gt;
&lt;h3 id="org7d6a96f"&gt;Preferential Attachment&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org7d6a96f"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;if not future_connections_pre_loaded:
    add_networkx_data(networkx.preferential_attachment, DataNames.preferential)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(future_connections.head(1))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org07c8429" class="outline-3"&gt;
&lt;h3 id="org07c8429"&gt;Community-Based Link Prediction&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org07c8429"&gt;
&lt;p&gt;
This requires identifying 'communities' first, so I'll defer it for now.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;#add_networkx_data(networkx.cn_soundarajan_hopcroft, DataNames.common_neighbors)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
These three all require communities for them to work (so I'm skipping them):
&lt;/p&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;cn&lt;sub&gt;soundarajan&lt;/sub&gt;&lt;sub&gt;hopcroft&lt;/sub&gt;&lt;/li&gt;
&lt;li&gt;ra&lt;sub&gt;index&lt;/sub&gt;&lt;sub&gt;soundarajan&lt;/sub&gt;&lt;sub&gt;hopcroft&lt;/sub&gt;&lt;/li&gt;
&lt;li&gt;within&lt;sub&gt;inter&lt;/sub&gt;&lt;sub&gt;cluster&lt;/sub&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org0495260" class="outline-3"&gt;
&lt;h3 id="org0495260"&gt;Saving the Data&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org0495260"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;future_connections.to_csv(Files.future_training_data)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgc9bc8f5" class="outline-2"&gt;
&lt;h2 id="orgc9bc8f5"&gt;Setup the Training and Testing Data&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgc9bc8f5"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgfead0d3" class="outline-3"&gt;
&lt;h3 id="orgfead0d3"&gt;Separating the Edges Without 'Future Connection' Values&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgfead0d3"&gt;
&lt;p&gt;
We are going to train on the values in the data with predictions and then make predictions for those that don't. For model selection we don't need the set missing predictions, but I'll separate it out anyway to be complete.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;prediction_set = future_connections[future_connections[Futures.target].isnull()]
training_set = future_connections[future_connections[Futures.target].notnull()]
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(prediction_set.shape)
print(training_set.shape)
assert len(prediction_set) + len(training_set) == len(future_connections)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgaa6c514" class="outline-3"&gt;
&lt;h3 id="orgaa6c514"&gt;Separate the Target and Training Sets&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgaa6c514"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;non_target = [column for column in future_connections.columns
	      if column != Futures.target]
training = training_set[non_target]
testing = training_set[Futures.target]
predictions = prediction_set[non_target]
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;assert all(training.columns == predictions.columns)
assert len(training) == len(testing)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org9f0a896" class="outline-3"&gt;
&lt;h3 id="org9f0a896"&gt;Setting Up the Testing and Training Sets&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org9f0a896"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;x_train, x_test, y_train, y_test = train_test_split(training, testing, stratify=testing)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(x_train.shape)
print(x_test.shape)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;seaborn.countplot(y_train)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;seaborn.countplot(y_test)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org906bc5a" class="outline-3"&gt;
&lt;h3 id="org906bc5a"&gt;Scaling the Data&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org906bc5a"&gt;
&lt;p&gt;
To enable the use of linear models I'm going to scale the data so the mean is 0 and the variance is 1.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)

x_train = pandas.DataFrame(x_train, columns=training.columns)
x_test = pandas.DataFrame(x_test, columns=training.columns)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(x_train.describe())
print(x_test.describe())
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org1fc0434" class="outline-3"&gt;
&lt;h3 id="org1fc0434"&gt;Feature Selection&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org1fc0434"&gt;
&lt;p&gt;
To reduce the dimensionality I'm going to use recursive feature selection and model-based selection.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def pickle_it(thing, name):
    """saves the thing as a pickle"""
    with open(name, "wb") as writer:
	pickle.dump(thing, writer)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def unpickle_it(name):
    """loads the object from the file-name

    Args:
     name (str): name of binary pickle file

    Returns:
     obj: unpickled object
    """
    with open(name, 'rb') as reader:
	thing = pickle.load(reader)
    return thing
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org8b140d9" class="outline-4"&gt;
&lt;h4 id="org8b140d9"&gt;RFECV with Logistic Regression&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org8b140d9"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;if os.path.isfile(Training.x_train_lr_rfs):
    x_train_lr_rfs = unpickle_it(Training.x_train_lr_rfs)
    x_test_lr_rfs = unpickle_it(Training.x_test_lr_rfs)
else:
    estimator = LogisticRegressionCV(n_jobs=-1)
    selector = RFECV(estimator, scoring='roc_auc',
		     n_jobs=-1,
		     cv=StratifiedKFold(Futures.folds))
    x_train_lr_rfs = selector.fit_transform(x_train, y_train)
    x_test_lr_rfs = selector.transform(x_test)
    pickle_it(x_train_lr_rfs, Training.x_train_lr_rfs)
    pickle_it(x_test_lr_rfs, Training.x_test_lr_rfs)
    print(selector.ranking_)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
It looks like it only discarded preferential attachment.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org26492c4" class="outline-4"&gt;
&lt;h4 id="org26492c4"&gt;RFECV with Extra Trees&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org26492c4"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;if os.path.isfile(Training.x_train_trees_rfs):
    x_train_trees_rfs = unpickle_it(Training.x_train_trees_rfs)
    x_test_trees_rfs = unpickle_it(Training.x_test_trees_rfs)
else:
    estimator = ExtraTreesClassifier()
    selector = RFECV(estimator, scoring='roc_auc', n_jobs=-1, cv=StratifiedKFold(Futures.folds))
    x_train_trees_rfs = selector.fit_transform(x_train, y_train)
    x_test_trees_rfs = selector.transform(x_test)
    pickle_it(x_train_trees_rfs, Training.x_train_trees_rfs)
    pickle_it(x_test_trees_rfs, Training.x_test_trees_rfs)
    print(selector.ranking_)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Strangely, the Extra Trees Classifier didn't remove any columns…
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org1e35886" class="outline-4"&gt;
&lt;h4 id="org1e35886"&gt;Select Model Logistic Regression&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org1e35886"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;if os.path.isfile(Training.x_train_lr_sfm):
    x_train_lr_sfm = unpickle_it(Training.x_train_lr_sfm)
    x_test_lr_sfm = unpickle_it(Training.x_test_lr_sfm)
else:
    estimator = LogisticRegressionCV(
	n_jobs=-1, scoring='roc_auc',
	cv=StratifiedKFold(Futures.folds)).fit(x_train,
					       y_train)
    selector = SelectFromModel(estimator, prefit=True)
    x_train_lr_sfm = selector.transform(x_train)
    x_test_lr_sfm = selector.transform(x_test)
    pickle_it(x_train_lr_sfm, Training.x_train_lr_sfm)
    pickle_it(x_test_lr_sfm, Training.x_test_lr_sfm)
    print(estimator.coef_)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(x_train_lr_sfm.shape)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
This was more aggressive, cutting out half the features. It looks like it kept &lt;b&gt;Jaccard Coefficient&lt;/b&gt; and &lt;b&gt;Adamic Adar&lt;/b&gt; and got rid of &lt;b&gt;Resource Allocation&lt;/b&gt; and &lt;b&gt;Preferential Attachment&lt;/b&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org0af64f3" class="outline-4"&gt;
&lt;h4 id="org0af64f3"&gt;Select Model Extra Trees&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org0af64f3"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;if os.path.isfile(Training.x_train_trees_sfm):
    x_train_trees_sfm = unpickle_it(Training.x_train_trees_sfm)
    x_test_trees_sfm = unpickle_it(Training.x_test_trees_sfm)
else:
    estimator = ExtraTreesClassifier()
    estimator.fit(x_train, y_train)
    selector = SelectFromModel(estimator, prefit=True)
    x_train_trees_sfm = selector.transform(x_train)
    x_test_trees_sfm = selector.transform(x_test)
    pickle_it(x_train_trees_sfm, Training.x_train_trees_sfm)
    pickle_it(x_test_trees_sfm, Training.x_test_trees_sfm)
    print(estimator.feature_importances_)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(x_train_trees_sfm.shape)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
This is sometimes more aggressive, keeping only the &lt;b&gt;Adamic Adar&lt;/b&gt; feature… But maybe that's all you need, we'll see. Then again, other times it isn't as aggressive, only trimming two columns, and this tiem it only trimmed one…
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org108e511" class="outline-2"&gt;
&lt;h2 id="org108e511"&gt;Fitting the Models&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org108e511"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org98c5a48" class="outline-3"&gt;
&lt;h3 id="org98c5a48"&gt;Persistent Storage&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org98c5a48"&gt;
&lt;p&gt;
The outcomes will be stored in a dictionary called &lt;code&gt;scores&lt;/code&gt; with descriptions of the best model and feature-selection mapped to their testing-score.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;if os.path.isfile(Files.future_model_selection):
    with open(Files.future_model_selection, 'rb') as pkl:
	scores = pickle.load(pkl)
else:
    scores = {}
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def fit_and_print(estimator, x_train, x_test):
    """fits the estimator to the data

    Args:
     estimator: model to fit
     x_train: scaled data to fit model to
     x_test: data to test the model with

    Returns:
     tuple: model fit to the data, test score
    """
    model = estimator.fit(x_train, y_train)
    test_score = model.score(x_test, y_test)
    print("Mean Cross-Validation Score: {:.2f}".format(model.scores_[1].mean()))
    print("Testing Score: {:.2f}".format(test_score))
    return model, test_score
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;data_sets = {("extra trees", 'select from model') : (x_train_trees_sfm, x_test_trees_sfm),
	     ("extra trees", 'recursive feature selection') : (x_train_trees_rfs, x_test_trees_rfs),
	     ('logistic regression', "recursive feature selection") : (x_train_lr_rfs, x_test_lr_rfs),
	     ('logistic regression', "select from model") : (x_train_lr_sfm, x_test_lr_sfm)}
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def key_by_value(source, search_value):
    """Find the key in a dict that matches a value

    Args:
     source (dict): dictionary with value to search for
     search_value: value to search for

    Returns:
     object: key in source that matched value
    """
    for key, value in source.items():
	if value == search_value:
	    return key
    return
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def fit_and_print_all(model, model_name):
    """Fits the model against all data instances

    Args:
     model: model to fit to the data sets
     model_name: identifier for the outcomes
    """
    for data_set, x in data_sets.items():
	selector, method = data_set
	train, test = x
	key = ','.join([model_name, selector, method])
	print("Training Shape: {}".format(train.shape))
	if key not in scores:
	    print(key)
	    fitted, score = fit_and_print(model, train, test)
	    scores[key] = score
	else:
	    score = scores[key]
	    print("{}: {:.3f}".format(key, score))
	print()

    best_score = max(scores.values())
    best_key = key_by_value(scores, best_score)
    print("Best Model So Far: {}, Score={:.2f}".format(
	best_key,
	best_score))
    with open(Files.future_model_selection, 'wb') as writer:
	pickle.dump(scores, writer)
    return
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org1d95d09" class="outline-3"&gt;
&lt;h3 id="org1d95d09"&gt;Logistic Regression&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org1d95d09"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;logistic_model = LogisticRegressionCV(n_jobs=-1, scoring="roc_auc",
				      solver='liblinear',
				      cv=StratifiedKFold(Futures.folds))
fit_and_print_all(logistic_model, "Logistic Regression")
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgb165931" class="outline-3"&gt;
&lt;h3 id="orgb165931"&gt;Fit Grid Search&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgb165931"&gt;
&lt;p&gt;
Since the Logistic Regression had its own cross-validation I didn't use a grid search, but for the forests I'll use one to figure out the best number of estimators. I'll have to look into what the other parameters do to figure out whether they're going to be useful.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def fit_grid_search(estimator, parameters, x_train, x_test):
    """Fits the estimator using grid search

    Args:
     estimator: Model to fit
     parameters (dict): hyper-parameters for the grid search
     x_train (array): the training data input
     x_test (array): data to evaluate the best model with

    Returns: 
     tuple: Best Model, best model score
    """
    search = GridSearchCV(estimator, parameters, n_jobs=-1, scoring='roc_auc',
			  cv=StratifiedKFold(Futures.folds))
    search.fit(x_train, y_train)
    best_model = search.best_estimator_
    test_score = best_model.score(x_test, y_test)
    print("Mean of Mean Cross-Validation Scores: {:.2f}".format(
	search.cv_results_["mean_train_score"].mean()))
    print("Mean of Cross-Validation Score STDs: {:.2f}".format(
	search.cv_results_["std_train_score"].mean()))
    print("Testing Score: {:.2f}".format(test_score))
    return best_model, test_score
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def fit_grid_searches(estimator, parameters, name, data_sets=data_sets):
    """Fits the estimator against all the data-sets

    Args:
     estimator: instance of model to test
     parameters: dict of grid-search parameters
     name: identifier for the model
    """
    for data_set, x in data_sets.items():
	selector, method = data_set
	train, test = x
	key = ",".join([name, selector, method])
	if key not in scores:
	    print(key)
	    fitted, score = fit_grid_search(estimator, parameters, train, test)
	    scores[key] = score
	else:
	    score = scores[key]
	    print("{}: {:.2f}".format(key, score))
	print()
    best = max(scores.values())
    best_key = key_by_value(scores, best)
    print("Best Model So Far: {}, Score={:.2f}".format(best_key, best))
    with open(Files.future_model_selection, 'wb') as writer:
	pickle.dump(scores, writer)
    return
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org0f1b6c4" class="outline-3"&gt;
&lt;h3 id="org0f1b6c4"&gt;Random Forests&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org0f1b6c4"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;parameters = dict(n_estimators = list(range(10, 200, 10)))
forest = RandomForestClassifier()
fit_grid_searches(forest, parameters, "Random Forest")
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgcf84a9f" class="outline-3"&gt;
&lt;h3 id="orgcf84a9f"&gt;Extra Trees&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgcf84a9f"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;scores = {k:v for k,v in scores.items() if not k.startswith('Extra Trees,extra trees')}
parameters = dict(n_estimators = list(range(10, 200, 10)))
trees = ExtraTreesClassifier()
fit_grid_searches(trees, parameters, "Extra Trees")
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>networks</category><category>prediction</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/networks/future-e-mail/</guid><pubDate>Sat, 13 Apr 2019 18:52:40 GMT</pubDate></item></channel></rss>