<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Visions, Voices, Data</title><link>https://necromuralist.github.io/Visions-Voices-Data/</link><description>Adumbrations of data.</description><atom:link href="https://necromuralist.github.io/Visions-Voices-Data/rss.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2020 &lt;a href="mailto:necromuralist@protonmail.com"&gt;Cloistered Monkey&lt;/a&gt; </copyright><lastBuildDate>Tue, 28 Jan 2020 02:37:34 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Decision Trees</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/machine-learning/decision-trees/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/machine-learning/decision-trees/#orgbcddfe2"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/machine-learning/decision-trees/#orgdf6db35"&gt;Imports&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/machine-learning/decision-trees/#orgfe107b3"&gt;Set Up&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/machine-learning/decision-trees/#orga28221a"&gt;Splitting A Node&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/machine-learning/decision-trees/#orgd006346"&gt;Entropy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/machine-learning/decision-trees/#org7d9e0c9"&gt;Binary Splitting of Qualitative Attributes Using the Gini Index&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgbcddfe2" class="outline-2"&gt;
&lt;h2 id="orgbcddfe2"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgbcddfe2"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgdf6db35" class="outline-3"&gt;
&lt;h3 id="orgdf6db35"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgdf6db35"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7b1dcbf" class="outline-4"&gt;
&lt;h4 id="org7b1dcbf"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org7b1dcbf"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from functools import partial
from typing import Any
from math import log2
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org9bd7238" class="outline-4"&gt;
&lt;h4 id="org9bd7238"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org9bd7238"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from expects import (
    be_within,
    expect,
)
from tabulate import tabulate
import attr
import pandas
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgfe107b3" class="outline-3"&gt;
&lt;h3 id="orgfe107b3"&gt;Set Up&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgfe107b3"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;TABLE = partial(tabulate, headers="keys", tablefmt="orgtbl")
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orga28221a" class="outline-2"&gt;
&lt;h2 id="orga28221a"&gt;Splitting A Node&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orga28221a"&gt;
&lt;p&gt;
We choose which is the next node to split by checking the amount of information we would gain for each candidate node and picking the one that gives us the highest gain. We do this by measuring the &lt;b&gt;&lt;b&gt;impurity&lt;/b&gt;&lt;/b&gt; of the nodes, which is a measurement of how dissimilar the class labels are for a node.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgd006346" class="outline-3"&gt;
&lt;h3 id="orgd006346"&gt;Entropy&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgd006346"&gt;
&lt;p&gt;
One measure of "impurity" is &lt;a href="https://www.wikiwand.com/en/Entropy_(information_theory)"&gt;entropy&lt;/a&gt;, a measurement of the information associated with our nodes.
&lt;/p&gt;
&lt;/div&gt;

&lt;div id="outline-container-org199cb66" class="outline-4"&gt;
&lt;h4 id="org199cb66"&gt;Node Entropy&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org199cb66"&gt;
&lt;p&gt;
Here's where we'll calculate the entropy for a node.
&lt;/p&gt;

&lt;p&gt;
\[
Entropy = - \sum_{i=0}^{c-1} p_i(t)log_2 p_i(t)
\]
&lt;/p&gt;

&lt;p&gt;
Where \(p_1(t)\) is the fraction of training data (&lt;i&gt;t&lt;/i&gt;) that has the classification &lt;i&gt;i&lt;/i&gt;. We can translate that to a python function.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; def node_entropy(data: pandas.Series, debug: bool=False) -&amp;gt; float:
     """Calculate the entropy for a child node

     Args:
      data: target data filtered to match the child-node's class
      debug: emit values

     Returns:
      entropy for this node
     """
     if debug:
	 print("calculating node-entropy")
     total = len(data)
     accumulated = 0
     for classification in data.unique():
	 p = len(data[data == classification])/total
	 if debug:
	     print(f"\tclass: {classification}, p: {p} entropy: {p * log2(p)}")
	 accumulated += p * log2(p)
     if debug:
	 print(f"Node Entropy: {accumulated}")
     return -accumulated
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org5daa6c7" class="outline-4"&gt;
&lt;h4 id="org5daa6c7"&gt;Entropy of a Node's Children&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org5daa6c7"&gt;
&lt;p&gt;
We'll use the entropy formula to get the entropy for an indivdual node but to get the total contribution from the possible splits we'll take a weighted sum of the node entropies.
&lt;/p&gt;

&lt;p&gt;
\[
I(children) = \sum_{j=1}^k \frac{N(v_j)}{N} I(v_j)
\]
&lt;/p&gt;

&lt;p&gt;
Where \(\frac{N(v_j)}{N}\) is the fraction of the child data in node &lt;i&gt;j&lt;/i&gt; and \(I(v_j)\) is the entropy (Impurity) of node &lt;i&gt;j&lt;/i&gt;.
&lt;/p&gt;

&lt;p&gt;
Once again, in python.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def children_impurity(data: pandas.DataFrame, column: str, target: str,
		      impurity: object=node_entropy,
	    debug: bool=False) -&amp;gt; float:
    """Calculate the entropy for the parent of child nodes

    Args:
     data: the container for the values to check
     column: the column to get the entropy
     target: the target column
     impurity: the function to calculate the impurity of the child
     debug: whether to print some intermediate values

    Returns:
     entropy for the data
    """
    if debug:
	print("Calculating entropy for child nodes")
    total = len(data)
    accumulator = 0
    for classification in data[column].unique():
	child = data[data[column] == classification][target]
	if debug:
	    print(f"\tI_({classification}) = ({len(child)}/{total}) "
		  f"x {impurity(child)}")
	accumulator += (len(child)/total) * impurity(child)
    if debug:
	print(f"Child node entropy: {accumulator}")
    return accumulator
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org82a3430" class="outline-4"&gt;
&lt;h4 id="org82a3430"&gt;Information Gain&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org82a3430"&gt;
&lt;p&gt;
The measurement of how much is gained is the difference between a parent node and its children.
\[
\Delta = I(parent) - I(children)
\]
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; def information_gain(data: pandas.Series, column: str, target: str,
		      debug: bool=False) -&amp;gt; float:
     """See how much entropy is removed using this node

     Args:
      data: source to check
      column: name of the column representing the parent node
      target: name of the column we are trying to predict
      debug: emit messages
     """
     return node_entropy(data[target], debug=debug) - children_impurity(
	 data, column=column, target=target, debug=debug)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org53f16d8" class="outline-4"&gt;
&lt;h4 id="org53f16d8"&gt;Home Loans&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org53f16d8"&gt;
&lt;p&gt;
To make this concrete we can look at a small dataset of people applying for a loan. We want to know if they are likely to default and we need to decide if we want our first split to be on whether they own a home or are married (we'll ignore income for this check because it's meant to illustrate splitting qualitative data).
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; @attr.s(auto_attribs=True, slots=True, frozen=True)
 class LoanColumns:
     owner: str = "Home Owner"
     married: str = "Marital Status"
     income: str = "Annual Income"
     defaulted: str = "Defaulted"

 LOANS = LoanColumns()
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; loans = pandas.DataFrame({
     LOANS.owner: [True, False, False, True, False, False, True, False, False, False],
     LOANS.married: ["Single", "Married", "Single", "Married", "Divorced", "Single", "Divorced", "Single", "Married", "Single"],
     LOANS.income: [125000, 100000, 70000, 120000, 95000, 60000, 220000, 85000, 75000, 90000],
     LOANS.defaulted: [False, False, False, False, True, False, False, True, False, True],
 })
 print(TABLE(loans))
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-right"&gt;

&lt;col class="org-left"&gt;

&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-left"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-right"&gt; &lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Home Owner&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Marital Status&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Annual Income&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Defaulted&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-left"&gt;True&lt;/td&gt;
&lt;td class="org-left"&gt;Single&lt;/td&gt;
&lt;td class="org-right"&gt;125000&lt;/td&gt;
&lt;td class="org-left"&gt;False&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;td class="org-left"&gt;False&lt;/td&gt;
&lt;td class="org-left"&gt;Married&lt;/td&gt;
&lt;td class="org-right"&gt;100000&lt;/td&gt;
&lt;td class="org-left"&gt;False&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;2&lt;/td&gt;
&lt;td class="org-left"&gt;False&lt;/td&gt;
&lt;td class="org-left"&gt;Single&lt;/td&gt;
&lt;td class="org-right"&gt;70000&lt;/td&gt;
&lt;td class="org-left"&gt;False&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;3&lt;/td&gt;
&lt;td class="org-left"&gt;True&lt;/td&gt;
&lt;td class="org-left"&gt;Married&lt;/td&gt;
&lt;td class="org-right"&gt;120000&lt;/td&gt;
&lt;td class="org-left"&gt;False&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;4&lt;/td&gt;
&lt;td class="org-left"&gt;False&lt;/td&gt;
&lt;td class="org-left"&gt;Divorced&lt;/td&gt;
&lt;td class="org-right"&gt;95000&lt;/td&gt;
&lt;td class="org-left"&gt;True&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;5&lt;/td&gt;
&lt;td class="org-left"&gt;False&lt;/td&gt;
&lt;td class="org-left"&gt;Single&lt;/td&gt;
&lt;td class="org-right"&gt;60000&lt;/td&gt;
&lt;td class="org-left"&gt;False&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;6&lt;/td&gt;
&lt;td class="org-left"&gt;True&lt;/td&gt;
&lt;td class="org-left"&gt;Divorced&lt;/td&gt;
&lt;td class="org-right"&gt;220000&lt;/td&gt;
&lt;td class="org-left"&gt;False&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;7&lt;/td&gt;
&lt;td class="org-left"&gt;False&lt;/td&gt;
&lt;td class="org-left"&gt;Single&lt;/td&gt;
&lt;td class="org-right"&gt;85000&lt;/td&gt;
&lt;td class="org-left"&gt;True&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;8&lt;/td&gt;
&lt;td class="org-left"&gt;False&lt;/td&gt;
&lt;td class="org-left"&gt;Married&lt;/td&gt;
&lt;td class="org-right"&gt;75000&lt;/td&gt;
&lt;td class="org-left"&gt;False&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;9&lt;/td&gt;
&lt;td class="org-left"&gt;False&lt;/td&gt;
&lt;td class="org-left"&gt;Single&lt;/td&gt;
&lt;td class="org-right"&gt;90000&lt;/td&gt;
&lt;td class="org-left"&gt;True&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;
The first step is to calculate the entropy for the entire set using whether they defaulted or not as our classification.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; impurity_parent = node_entropy(loans[LOANS.defaulted])
 print(f"I_parent: {impurity_parent:0.3f}")

 expect(impurity_parent).to(be_within(0.8812, 0.8813))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
I_parent: 0.881
&lt;/pre&gt;


&lt;p&gt;
The next step is to figure out which of our two chosen attributes gives us the most information gain- whether the person was a Home Owner or their Marital Status. We could just look at which has a lower entropy, but the problem is stated so that we want to find the greatest difference between the class' entropy and the parent entropy instead.
&lt;/p&gt;
&lt;/div&gt;

&lt;ul class="org-ul"&gt;
&lt;li&gt;&lt;a id="org4eeda5d"&gt;&lt;/a&gt;Home Owners&lt;br&gt;
&lt;div class="outline-text-5" id="text-org4eeda5d"&gt;
&lt;p&gt;
We have two child nodes - one for homeowners and one for non-homeowners.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; print(loans[loans[LOANS.owner]][LOANS.defaulted].value_counts())
 print()
 print(loans[~loans[LOANS.owner]][LOANS.defaulted].value_counts())
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
False    3
Name: Defaulted, dtype: int64

False    4
True     3
Name: Defaulted, dtype: int64
&lt;/pre&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; impurity_home_owner = children_entropy(loans,
					column=LOANS.owner,
					target=LOANS.defaulted, debug=True)
 print(f"{impurity_home_owner: 0.3f}")
 expect(impurity_home_owner).to(be_within(0.689, 0.691))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Calculating entropy for child nodes
	I_(True) = (3/10) x -0.0
	I_(False) = (7/10) x 0.9852281360342515
Child node entropy: 0.6896596952239761
 0.690
&lt;/pre&gt;


&lt;p&gt;
Odd that python allows negative zero-values… Now we can see what the information gain will be.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; gain_home_owner = information_gain(loans, LOANS.owner, LOANS.defaulted)
 print(f"Delta Home-Owner: {gain_home_owner: 0.3}")
 expect(gain_home_owner).to(be_within(0.190, 0.19165))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Delta Home-Owner:  0.192
&lt;/pre&gt;


&lt;p&gt;
I seem to have precision differences with the book…
&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a id="org55384e0"&gt;&lt;/a&gt;Married Applicants&lt;br&gt;
&lt;div class="outline-text-5" id="text-org55384e0"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; gain_married = information_gain(loans, LOANS.married, LOANS.defaulted, debug=True)
 print(f"Delta Married: {gain_married: 0.3f}")
 expect(gain_married).to(be_within(0.194, 0.196))
 choice = max(((gain_home_owner, LOANS.owner),
	       (gain_married, LOANS.married)))
 print(f"Next Node: {choice}")
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
calculating node-entropy
        class: False, p: 0.7 entropy: -0.3602012209808308
        class: True, p: 0.3 entropy: -0.5210896782498619
Node Entropy: -0.8812908992306927
Calculating entropy for child nodes
        I_(Single) = (5/10) x 0.9709505944546686
        I_(Married) = (3/10) x -0.0
        I_(Divorced) = (2/10) x 1.0
Child node entropy: 0.6854752972273344
Delta Married:  0.196
Next Node: (0.19581560200335835, 'Marital Status')
&lt;/pre&gt;

&lt;p&gt;
Since we gain more information from checking whether someone was married or not, that would be the next node we would choose to split.
&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7d9e0c9" class="outline-3"&gt;
&lt;h3 id="org7d9e0c9"&gt;Binary Splitting of Qualitative Attributes Using the Gini Index&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org7d9e0c9"&gt;
&lt;p&gt;
\[
\textit{Gini Index} = 1 - \sum_{i=0}^{c - 1}
\]
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def gini(data: pandas.Series) -&amp;gt; float:
    """Calculate the gini index for the data"""
    total = len(data)
    accumulator = 0
    for classification in data.unique():
	accumulator += (len(data[data==classification])/total)**2
    return 1 - accumulator
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org5ec7157" class="outline-4"&gt;
&lt;h4 id="org5ec7157"&gt;Parent Impurity&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org5ec7157"&gt;
&lt;p&gt;
First we get the gini index for the overall data.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;parent_gini = gini(loans[LOANS.defaulted])
print(f"I_parent = {parent_gini: 0.3f}")
expect(parent_gini).to(be_within(0.420, 0.421))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
I_parent =  0.420
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org1454491" class="outline-4"&gt;
&lt;h4 id="org1454491"&gt;Home Owner Impurity&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org1454491"&gt;
&lt;p&gt;
Now the homeowner attribute.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;homeowner_gini = children_impurity(loans, LOANS.owner, LOANS.defaulted, gini, debug=True)
expect(homeowner_gini).to(be_within(0.342, 0.344))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Calculating entropy for child nodes
	I_(True) = (3/10) x 0.0
	I_(False) = (7/10) x 0.48979591836734704
Child node entropy: 0.3428571428571429
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org4ddb355" class="outline-4"&gt;
&lt;h4 id="org4ddb355"&gt;Married Impurity&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org4ddb355"&gt;
&lt;p&gt;
This is different from the entropy case because we want to do binary splits but the marital status attribute has three values (&lt;i&gt;Single&lt;/i&gt;, &lt;i&gt;Married&lt;/i&gt;, and &lt;i&gt;Divorced&lt;/i&gt;) so we need to use a different function that does each attribute against the other (or we could add columns which turn the marital status into a binary attribute, but this seems simpler).
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def binary_gini(data: pandas.Series, column: str, target: str,
		classification: object, debug: bool=False) -&amp;gt; float:
    """Calculate the gini value for the data using one against many

    Args:
     data: source with qualitative values
     column: column with the classifications to test
     target: column with the classifications to predict
     classification: the classification to compare
     debug: whether to emit messages
    """
    total = len(data)
    classified = data[data[column] == classification]
    others = data[data[column] != classification]
    if debug:
	print(f"N({classification}/N) I({classification}) = {len(classified)/total * gini(classified[target]):0.3f}")
	print(f"N(!{classification}/N) I!({classification}) = {len(others)/total * gini(others[target]):0.3f}")
	print(f"I({classification}) = {((len(classified)/total) * gini(classified[target]) + (len(others)/total) * gini(others[target])):0.3f}")
    return ((len(classified)/total) * gini(classified[target])
	    + (len(others)/total) * gini(others[target]))
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;@attr.s(auto_attribs=True, slots=True, frozen=True)
class MaritalStatus:
    single: str="Single"
    married: str="Married"
    divorced: str="Divorced"

status = MaritalStatus()
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;i_single = binary_gini(loans, LOANS.married, LOANS.defaulted, status.single,
		       debug=True)
print()
i_married = binary_gini(loans, LOANS.married, LOANS.defaulted, status.married,
			debug=True)
print()
i_divorced = binary_gini(loans, LOANS.married, LOANS.defaulted,
			 status.divorced, debug=True)
expect(i_single).to(be_within(0.39, 0.41))
expect(i_divorced).to(be_within(0.39, 0.41))
expect(i_married).to(be_within(0.342, 0.344))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
N(Single/N) I(Single) = 0.240
N(!Single/N) I!(Single) = 0.160
I(Single) = 0.400

N(Married/N) I(Married) = 0.000
N(!Married/N) I!(Married) = 0.343
I(Married) = 0.343

N(Divorced/N) I(Divorced) = 0.100
N(!Divorced/N) I!(Divorced) = 0.300
I(Divorced) = 0.400
&lt;/pre&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;best = 0
best_split = None
for candidate, label in ((homeowner_gini, "Homeowner"),
			 (i_single, "Single"),
			 (i_married, "Married"),
			 (i_divorced, "Divorced")):
    delta = parent_gini - candidate
    if delta &amp;gt; best:
	best = delta
	best_split = label
    print(f"Delta {label} = {delta:0.3f}")
print(f"Best Split: {best_split}")
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Delta Homeowner = 0.077
Delta Single = 0.020
Delta Married = 0.077
Delta Divorced = 0.020
Best Split: Homeowner
&lt;/pre&gt;


&lt;p&gt;
Either using Home Ownership or Whether someone is married would be the best candidates for the next split.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>trees</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/machine-learning/decision-trees/</guid><pubDate>Sun, 26 Jan 2020 00:31:40 GMT</pubDate></item><item><title>Snorkel Data Labeling</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-data-labeling/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-data-labeling/#org2d29170"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-data-labeling/#org49c5f44"&gt;Imports&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-data-labeling/#org3c3c8d9"&gt;Set Up&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org2d29170" class="outline-2"&gt;
&lt;h2 id="org2d29170"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org2d29170"&gt;
&lt;p&gt;
This is a walk-through of the Snorkel &lt;a href="https://www.snorkel.org/use-cases/01-spam-tutorial"&gt;Snorkel Data Labeling&lt;/a&gt; tutorial.It uses the &lt;a href="http://www.dt.fee.unicamp.br/~tiago//youtubespamcollection/"&gt;YouTube Spam Collection&lt;/a&gt; data set (downloaded from the &lt;a href="https://archive.ics.uci.edu/ml/datasets/YouTube+Spam+Collection"&gt;UCI Machine Learning Repository&lt;/a&gt;). The data was collected in 2015 and represents comments from five of the ten most popular videos on YouTube. It is a tabular dataset with the columns &lt;code&gt;COMMENT_ID&lt;/code&gt;, &lt;code&gt;AUTHOR&lt;/code&gt;, &lt;code&gt;DATE&lt;/code&gt;, &lt;code&gt;CONTENT&lt;/code&gt;, &lt;code&gt;CLASS&lt;/code&gt;. The tag represents whether it was considered &lt;i&gt;Spam&lt;/i&gt; or not, so we'll pretend it isn't there for most of this walk-through.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-org49c5f44" class="outline-3"&gt;
&lt;h3 id="org49c5f44"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org49c5f44"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orge9b8b1d" class="outline-4"&gt;
&lt;h4 id="orge9b8b1d"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orge9b8b1d"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from pathlib import Path
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org6092c7a" class="outline-4"&gt;
&lt;h4 id="org6092c7a"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org6092c7a"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;import pandas
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org3c3c8d9" class="outline-3"&gt;
&lt;h3 id="org3c3c8d9"&gt;Set Up&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org3c3c8d9"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org1895171" class="outline-4"&gt;
&lt;h4 id="org1895171"&gt;The Dataset&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org1895171"&gt;
&lt;p&gt;
The data is split up into separate files - one for each artist/video (they are named after the artist and each only appears to have one entry) so I'm going to smash them back together and add a &lt;code&gt;artist&lt;/code&gt; column.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;path = Path("~/data/datasets/texts/you_tube_comments/").expanduser()
sets = []
for name in path.glob("*.csv"):
    artist = name.stem.split()[-1]
    data = pandas.read_csv(name)
    data["artist"] = artist
    sets.append(data)
    print(artist)
data = pandas.concat(sets)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
KatyPerry
LMFAO
Eminem
Shakira
Psy
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgb21406b" class="outline-4"&gt;
&lt;h4 id="orgb21406b"&gt;Splitting the Set&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgb21406b"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;train, test = train_test_split(data)
print(train.shape)
print(test.shape)

train, development = train_test_split(train)
validation, test = train_test_split(test)
print(train.shape)
print(development.shape)
print(validation.shape)
print(test.shape)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
(1467, 6)
(489, 6)
(1100, 6)
(367, 6)
(366, 6)
(123, 6)
&lt;/pre&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;grouped = train.groupby(["artist"]).agg({"COMMENT_ID": "count"}).reset_index().rename(columns={"COMMENT_ID": "Count"})
plot = grouped.hvplot.bar(x="artist", y="Count").opts(title="Comments by Artist", width=1000, height=800)
Embed(plot=plot, file_name="comments_by_artist")()
&lt;/pre&gt;&lt;/div&gt;

&lt;object type="text/html" data="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-data-labeling/comments_by_artist.html" style="width:100%" height="800"&gt;
  &lt;p&gt;Figure Missing&lt;/p&gt;
&lt;/object&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;grouped = train.groupby(["artist", "CLASS"]).agg({"COMMENT_ID": "count"}).reset_index().rename(columns={"COMMENT_ID": "Count"})
plot = grouped.hvplot.bar(x="artist", y="Count", by="CLASS").opts(title="Comments by Artist and Class", width=1000, height=800)
Embed(plot=plot, file_name="comments_by_artist_and_class")()
&lt;/pre&gt;&lt;/div&gt;

&lt;object type="text/html" data="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-data-labeling/comments_by_artist_and_class.html" style="width:100%" height="800"&gt;
  &lt;p&gt;Figure Missing&lt;/p&gt;
&lt;/object&gt;

&lt;p&gt;
I said earlier that the spam/not-spam column was named tag, but its named &lt;code&gt;CLASS&lt;/code&gt; here, I don't know where the switch came (it says &lt;code&gt;TAG&lt;/code&gt; on the UCI page).
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>data</category><category>exploration</category><category>snorkel</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-data-labeling/</guid><pubDate>Fri, 10 Jan 2020 01:07:33 GMT</pubDate></item><item><title>Snorkel Example: Building a Spam Dataset</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-example-building-a-spam-dataset/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-example-building-a-spam-dataset/#org40dd6b3"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-example-building-a-spam-dataset/#org16510b3"&gt;Imports&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-example-building-a-spam-dataset/#org0578a38"&gt;Set Up&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-example-building-a-spam-dataset/#orge91f516"&gt;Middle&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-example-building-a-spam-dataset/#orgb681313"&gt;Labeling Functions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-example-building-a-spam-dataset/#orgadf32d2"&gt;Data Augmentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-example-building-a-spam-dataset/#org6972c97"&gt;Slicing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-example-building-a-spam-dataset/#orgc1745cb"&gt;End&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-example-building-a-spam-dataset/#org977c939"&gt;Train A Classifier&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org40dd6b3" class="outline-2"&gt;
&lt;h2 id="org40dd6b3"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org40dd6b3"&gt;
&lt;p&gt;
This is a walk-through of the Snorkel &lt;a href="https://www.snorkel.org/get-started/"&gt;Get Started&lt;/a&gt; tutorial which shows how you can use it to build a labeled dataset. It uses the &lt;a href="http://www.dt.fee.unicamp.br/~tiago//youtubespamcollection/"&gt;YouTube Spam Collection&lt;/a&gt; data set (downloaded from the &lt;a href="https://archive.ics.uci.edu/ml/datasets/YouTube+Spam+Collection"&gt;UCI Machine Learning Repository&lt;/a&gt;). The data was collected in 2015 and represents comments from five of the ten most popular videos on YouTube. It is a tabular dataset with the columns &lt;code&gt;COMMENT_ID&lt;/code&gt;, &lt;code&gt;AUTHOR&lt;/code&gt;, &lt;code&gt;DATE&lt;/code&gt;, &lt;code&gt;CONTENT&lt;/code&gt;, &lt;code&gt;TAG&lt;/code&gt;. The tag represents whether it was considered &lt;i&gt;Spam&lt;/i&gt; or not, so we'll pretend it isn't there for most of this walk-through.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-org16510b3" class="outline-3"&gt;
&lt;h3 id="org16510b3"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org16510b3"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org21f74c2" class="outline-4"&gt;
&lt;h4 id="org21f74c2"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org21f74c2"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from argparse import Namespace
from functools import partial
from pathlib import Path
import random
import re
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orge277dd1" class="outline-4"&gt;
&lt;h4 id="orge277dd1"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orge277dd1"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from nltk.corpus import wordnet
from sklearn import metrics
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from snorkel.augmentation import ApplyOnePolicy, PandasTFApplier, transformation_function
from snorkel.labeling import labeling_function, LabelModel, PandasLFApplier
from snorkel.slicing import slicing_function
from textblob import TextBlob
import hvplot.pandas
import nltk
import pandas
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgfdd7668" class="outline-4"&gt;
&lt;h4 id="orgfdd7668"&gt;Others&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgfdd7668"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from graeae import CountPercentage, EmbedHoloviews
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org0578a38" class="outline-3"&gt;
&lt;h3 id="org0578a38"&gt;Set Up&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org0578a38"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org0c57164" class="outline-4"&gt;
&lt;h4 id="org0c57164"&gt;The WordNet Corpus&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org0c57164"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;nltk.download("wordnet", quiet=True)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org9832938" class="outline-4"&gt;
&lt;h4 id="org9832938"&gt;Plotting&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org9832938"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Embed = partial(EmbedHoloviews, folder_path="../../../files/posts/libraries/snorkel/snorkel-example-building-a-spam-dataset")
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org1824b8e" class="outline-4"&gt;
&lt;h4 id="org1824b8e"&gt;The Dataset&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org1824b8e"&gt;
&lt;p&gt;
The data is split up into separate files - one for each artist/video (they are named after the artist and each only appears to have one entry) so I'm going to smash them back together and add a &lt;code&gt;artist&lt;/code&gt; column.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;path = Path("~/data/datasets/texts/you_tube_comments/").expanduser()
sets = []
for name in path.glob("*.csv"):
    artist = name.stem.split()[-1]
    data = pandas.read_csv(name)
    data["artist"] = artist
    sets.append(data)
    print(artist)
data = pandas.concat(sets)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
KatyPerry
LMFAO
Eminem
Shakira
Psy
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;


&lt;div id="outline-container-org8e6eafd" class="outline-4"&gt;
&lt;h4 id="org8e6eafd"&gt;Splitting the Set&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org8e6eafd"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;train, test = train_test_split(data)
print(train.shape)
print(test.shape)

train, development = train_test_split(train)
validation, test = train_test_split(test)
print(train.shape)
print(development.shape)
print(validation.shape)
print(test.shape)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
(1467, 6)
(489, 6)
(1100, 6)
(367, 6)
(366, 6)
(123, 6)
&lt;/pre&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;grouped = train.groupby(["artist"]).agg({"COMMENT_ID": "count"}).reset_index().rename(columns={"COMMENT_ID": "Count"})
plot = grouped.hvplot.bar(x="artist", y="Count").opts(title="Comments by Artist", width=1000, height=800)
Embed(plot=plot, file_name="comments_by_artist")()
&lt;/pre&gt;&lt;/div&gt;

&lt;object type="text/html" data="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-example-building-a-spam-dataset/comments_by_artist.html" style="width:100%" height="800"&gt;
  &lt;p&gt;Figure Missing&lt;/p&gt;
&lt;/object&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;grouped = train.groupby(["artist", "CLASS"]).agg({"COMMENT_ID": "count"}).reset_index().rename(columns={"COMMENT_ID": "Count"})
plot = grouped.hvplot.bar(x="artist", y="Count", by="CLASS").opts(title="Comments by Artist and Class", width=1000, height=800)
Embed(plot=plot, file_name="comments_by_artist_and_class")()
&lt;/pre&gt;&lt;/div&gt;

&lt;object type="text/html" data="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-example-building-a-spam-dataset/comments_by_artist_and_class.html" style="width:100%" height="800"&gt;
  &lt;p&gt;Figure Missing&lt;/p&gt;
&lt;/object&gt;

&lt;p&gt;
I said earlier that the spam/not-spam column was named tag, but its named &lt;code&gt;CLASS&lt;/code&gt; here, I don't know where the switch came (it says &lt;code&gt;TAG&lt;/code&gt; on the UCI page).
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orge91f516" class="outline-2"&gt;
&lt;h2 id="orge91f516"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orge91f516"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgb681313" class="outline-3"&gt;
&lt;h3 id="orgb681313"&gt;Labeling Functions&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgb681313"&gt;
&lt;p&gt;
Labeling functions output a label for values in the training set.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-org1b10309" class="outline-4"&gt;
&lt;h4 id="org1b10309"&gt;Labels&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org1b10309"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Label = Namespace(
    abstain = -1,
    not_spam = 0,
    spam = 1,
)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
The actual data-set only has spam/not-spam classes, but the Snorkel tutorial adds the &lt;code&gt;abstain&lt;/code&gt; class as well. Each function is going to be passed a row from the training dataframe, so the class name you use has to match it.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgf83d267" class="outline-4"&gt;
&lt;h4 id="orgf83d267"&gt;Keyword Matching&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgf83d267"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;@labeling_function()
def labeling_by_keyword(comment: pandas.Series) -&amp;gt; int:
    """Assume if the author refers to something he/she owns it's spam

    Args: 
     row with comment CONTENT

    Returns:
     label for the comment
    """
    return Label.spam if "my" in comment.CONTENT.lower() else Label.abstain
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org0c32df3" class="outline-4"&gt;
&lt;h4 id="org0c32df3"&gt;Regular Expressions&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org0c32df3"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;@labeling_function()
def label_check_out(comment) -&amp;gt; int:
    """check my/it/the out will be spam"""
    return Label.spam if re.search(r"check.*out", comment.CONTENT, flags=re.I) else Label.abstain
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org9581112" class="outline-4"&gt;
&lt;h4 id="org9581112"&gt;Short Comments&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org9581112"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;@labeling_function()
def label_short_comment(comment) -&amp;gt; int:
    """if a comment is short it's probably not spam"""
    return Label.not_spam if len(comment.CONTENT.split()) &amp;lt; 5 else Label.abstain
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgd646779" class="outline-4"&gt;
&lt;h4 id="orgd646779"&gt;Positive Comments&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgd646779"&gt;
&lt;p&gt;
Here we'll use &lt;a href="https://textblob.readthedocs.io/en/dev/"&gt;textblob&lt;/a&gt; to try and decide on whether a comment is positive (textblob uses &lt;a href="https://www.clips.uantwerpen.be/pattern"&gt;pattern&lt;/a&gt; to decide on the polarity.)
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;@labeling_function()
def label_positive_comment(comment) -&amp;gt; int:
    """If a comment is positive, we'll accept it"""
    return Label.not_spam if TextBlob(comment.CONTENT).sentiment.polarity &amp;gt; 0.3 else Label.abstain
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgdedcedc" class="outline-4"&gt;
&lt;h4 id="orgdedcedc"&gt;Combining the Functions and Cleaning the Labels&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgdedcedc"&gt;
&lt;p&gt;
First I'll create a list of the labeling functions so that we can pass it to the label-applier class.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;labeling_functions = [labeling_by_keyword, label_check_out, label_short_comment, label_positive_comment]
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Now create the applier.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;applier = PandasLFApplier(labeling_functions)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Now create it.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;label_matrix = applier.apply(train, progress_bar=False)

print(label_matrix.shape)
print(train.shape)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
(1100, 4)
(1100, 6)
&lt;/pre&gt;


&lt;p&gt;
The label-matrix has one row for each of the comments in our training set and one column for each of our labeling functions.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;label_frame = pandas.DataFrame(label_matrix, columns=["keyword", "check_out", "short", "positive"])
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;re_framed = {}

for column in label_frame.columns:
    re_framed[column] = 
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org2ec1c28" class="outline-4"&gt;
&lt;h4 id="org2ec1c28"&gt;Training the Label Model&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org2ec1c28"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;label_model = LabelModel(cardinality=2, verbose=True)
label_model.fit(label_matrix, n_epochs=500, log_freq=50, seed=0)
train["label"] = label_model.predict(L=label_matrix, tie_break_policy="abstain")
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;grouped = train.groupby(["label", "artist"]).agg({"COMMENT_ID": "count"}).reset_index().rename(columns={"COMMENT_ID": "count"})
plot = grouped.hvplot.bar(x="label", y="count", by="artist").opts(title="Label Counts", height=800, width=1000)
Embed(plot=plot, file_name="label_counts")()
&lt;/pre&gt;&lt;/div&gt;

&lt;object type="text/html" data="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-example-building-a-spam-dataset/label_counts.html" style="width:100%" height="800"&gt;
  &lt;p&gt;Figure Missing&lt;/p&gt;
&lt;/object&gt;

&lt;p&gt;
Most comments were labeled spam or not-spam, but some were abstained. In order to move on to the next section, we'll drop the rows where an opinion about the label was abstained.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;train = train[train.label != Label.abstain]
CountPercentage(train.label)()
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-right"&gt;Value&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Count&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Percent (%)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-right"&gt;419&lt;/td&gt;
&lt;td class="org-right"&gt;53.51&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;td class="org-right"&gt;364&lt;/td&gt;
&lt;td class="org-right"&gt;46.49&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;matched = sum(train.label == train.CLASS)
print(f"{matched/len(train): .2f}")
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
0.51
&lt;/pre&gt;


&lt;p&gt;
Of those that were matched, only a little more than half agree with the labels given by the dataset creators.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgadf32d2" class="outline-3"&gt;
&lt;h3 id="orgadf32d2"&gt;Data Augmentation&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgadf32d2"&gt;
&lt;p&gt;
We're going to create new entries in the data by randomly replacing words with their synonyms.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgfab4241" class="outline-4"&gt;
&lt;h4 id="orgfab4241"&gt;Synonym Lookup Function&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgfab4241"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def synonyms_for(word: str) -&amp;gt; list:
    """get synonyms for word"""
    lemmas = set().union(*[synset.lemmas() for synset in wordnet.synsets(word)])
    return list(set(lemma.name().lower().replace("_" , " ") for lemma in lemmas) - {word})
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgb76b7ac" class="outline-4"&gt;
&lt;h4 id="orgb76b7ac"&gt;The Transformation Function&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgb76b7ac"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;@transformation_function()
def replace_word_with_synonym(comment: pandas.Series) -&amp;gt; pandas.Series:
    """Replace one of the words with a synonym

    Args:
     comment: row with a comment

    Returns:
     comment with a word replaced
    """
    tokens = comment.CONTENT.lower().split()
    index = random.choice(range(len(tokens)))
    synonyms = synonyms_for(tokens[index])
    if synonyms:
	comment.CONTENT = " ".join(tokens[:index] + [synonyms[0]] + tokens[index + 1 :])
    return comment
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;transform_policy = ApplyOnePolicy(n_per_original=2, keep_original=True)
transform_applier = PandasTFApplier([replace_word_with_synonym], transform_policy)
train_augmented = transform_applier.apply(train, progress_bar=False)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(train_augmented[:3].CONTENT)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
415           very good song:)﻿
415    very respectable song:)﻿
415           very good song:)﻿
Name: CONTENT, dtype: object
&lt;/pre&gt;


&lt;p&gt;
Because it's random, we don't always end up with different content.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(f"{len(train_augmented):,}")
train_augmented = train_augmented.drop_duplicates(subset="CONTENT")
print(f"{len(train_augmented):,}")
print(f"{len(train):,}")
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
2,349
1,357
783
&lt;/pre&gt;


&lt;p&gt;
So we added some content.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org6972c97" class="outline-3"&gt;
&lt;h3 id="org6972c97"&gt;Slicing&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org6972c97"&gt;
&lt;p&gt;
A &lt;i&gt;slice&lt;/i&gt; is a subset of the data - in this case we want to identify slices that might be more important than others. In this case we're going to assume that we've identified that short links are more likely to be malicious, so we want to be more aware of them.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;@slicing_function()
def short_link(comment: pandas.Series) -&amp;gt; int:
    """checks for shortened links in the comment

    Args:
     comment: row with comment in it

    Returns:
     1 if short-link detected, 0 otherwise
    """
    return int(bool(re.search(r"\w+\.ly", comment.CONTENT)))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgc1745cb" class="outline-2"&gt;
&lt;h2 id="orgc1745cb"&gt;End&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgc1745cb"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org977c939" class="outline-3"&gt;
&lt;h3 id="org977c939"&gt;Train A Classifier&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org977c939"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;training_text = train_augmented.CONTENT.tolist()
vectorizer = CountVectorizer(ngram_range=(1, 2))
x_train = vectorizer.fit_transform(training_text)

classifier = LogisticRegression(solver="lbfgs")
classifier.fit(x_train, train_augmented.label.values)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;development_test = vectorizer.transform(development.CONTENT)
development["predicted"] = classifier.predict(development_test)

print(f"{sum(development.CLASS == development.predicted)/len(development):.2f}")
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
0.54
&lt;/pre&gt;


&lt;p&gt;
So our model is almost random.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(metrics.classification_report(development.CLASS, development.predicted, target_names=["not spam", "spam"]))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
              precision    recall  f1-score   support

    not spam       0.56      0.61      0.58       194
        spam       0.51      0.45      0.48       173

    accuracy                           0.54       367
   macro avg       0.53      0.53      0.53       367
weighted avg       0.53      0.54      0.53       367

&lt;/pre&gt;
&lt;/div&gt;
&lt;div id="outline-container-orge97cffb" class="outline-4"&gt;
&lt;h4 id="orge97cffb"&gt;Training on the Original Labels&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orge97cffb"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;vectorizer = CountVectorizer(ngram_range=(1, 2))
x_train = vectorizer.fit_transform(train.CONTENT)

classifier = LogisticRegression(solver="lbfgs")
classifier.fit(x_train, train.CLASS.values)

development_test = vectorizer.transform(development.CONTENT)
predicted = classifier.predict(development_test)

print(metrics.classification_report(development.CLASS, predicted, target_names=["not spam", "spam"]))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
              precision    recall  f1-score   support

    not spam       0.91      0.97      0.94       194
        spam       0.97      0.90      0.93       173

    accuracy                           0.94       367
   macro avg       0.94      0.94      0.94       367
weighted avg       0.94      0.94      0.94       367

&lt;/pre&gt;


&lt;p&gt;
So our self-labeled data set really hurt the performance, but this was the Getting Started tutorial, so it was meant to be just a skimming of what the basic procedure is, hopefully tuning the labeling and transformations more would improve the performance.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>data labeling</category><category>snorkel</category><category>weak supervision</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-example-building-a-spam-dataset/</guid><pubDate>Tue, 07 Jan 2020 01:40:40 GMT</pubDate></item><item><title>Trying out DABEST</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/trying-out-dabest/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/trying-out-dabest/#org27a196f"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/trying-out-dabest/#org9d3e203"&gt;Imports&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/trying-out-dabest/#org07e536a"&gt;Set Up&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/trying-out-dabest/#orgabbb33d"&gt;Middle&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/trying-out-dabest/#orga8af6cb"&gt;Petal Width&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/trying-out-dabest/#orgbcd0497"&gt;Hedge's G&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/trying-out-dabest/#org91c1a78"&gt;Cohen's D&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org27a196f" class="outline-2"&gt;
&lt;h2 id="org27a196f"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org27a196f"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org9d3e203" class="outline-3"&gt;
&lt;h3 id="org9d3e203"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org9d3e203"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org6c3bc52" class="outline-4"&gt;
&lt;h4 id="org6c3bc52"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org6c3bc52"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from sklearn.datasets import load_iris
import dabest
import pandas
import seaborn
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org07e536a" class="outline-3"&gt;
&lt;h3 id="org07e536a"&gt;Set Up&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org07e536a"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7515a90" class="outline-4"&gt;
&lt;h4 id="org7515a90"&gt;The Data Set&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org7515a90"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;iris = load_iris()
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(iris.DESCR)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Iris plants dataset
--------------------

**Data Set Characteristics:**

    :Number of Instances: 150 (50 in each of three classes)
    :Number of Attributes: 4 numeric, predictive attributes and the class
    :Attribute Information:
        - sepal length in cm
        - sepal width in cm
        - petal length in cm
        - petal width in cm
        - class:
                - Iris-Setosa
                - Iris-Versicolour
                - Iris-Virginica
                
    :Summary Statistics:

    ============== ==== ==== ======= ===== ====================
                    Min  Max   Mean    SD   Class Correlation
    ============== ==== ==== ======= ===== ====================
    sepal length:   4.3  7.9   5.84   0.83    0.7826
    sepal width:    2.0  4.4   3.05   0.43   -0.4194
    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)
    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)
    ============== ==== ==== ======= ===== ====================

    :Missing Attribute Values: None
    :Class Distribution: 33.3% for each of 3 classes.
    :Creator: R.A. Fisher
    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)
    :Date: July, 1988

The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken
from Fisher's paper. Note that it's the same as in R, but not as in the UCI
Machine Learning Repository, which has two wrong data points.

This is perhaps the best known database to be found in the
pattern recognition literature.  Fisher's paper is a classic in the field and
is referenced frequently to this day.  (See Duda &amp;amp; Hart, for example.)  The
data set contains 3 classes of 50 instances each, where each class refers to a
type of iris plant.  One class is linearly separable from the other 2; the
latter are NOT linearly separable from each other.

.. topic:: References

   - Fisher, R.A. "The use of multiple measurements in taxonomic problems"
     Annual Eugenics, 7, Part II, 179-188 (1936); also in "Contributions to
     Mathematical Statistics" (John Wiley, NY, 1950).
   - Duda, R.O., &amp;amp; Hart, P.E. (1973) Pattern Classification and Scene Analysis.
     (Q327.D83) John Wiley &amp;amp; Sons.  ISBN 0-471-22361-1.  See page 218.
   - Dasarathy, B.V. (1980) "Nosing Around the Neighborhood: A New System
     Structure and Classification Rule for Recognition in Partially Exposed
     Environments".  IEEE Transactions on Pattern Analysis and Machine
     Intelligence, Vol. PAMI-2, No. 1, 67-71.
   - Gates, G.W. (1972) "The Reduced Nearest Neighbor Rule".  IEEE Transactions
     on Information Theory, May 1972, 431-433.
   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al"s AUTOCLASS II
     conceptual clustering system finds 3 classes in the data.
   - Many, many more ...
&lt;/pre&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;data = pandas.DataFrame(iris.data, columns=iris.feature_names)
target = pandas.Series(iris.target)
names = dict(zip(range(len(iris.target_names)), iris.target_names))
data["species"] = target.map(names)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgabbb33d" class="outline-2"&gt;
&lt;h2 id="orgabbb33d"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgabbb33d"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orga8af6cb" class="outline-3"&gt;
&lt;h3 id="orga8af6cb"&gt;Petal Width&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orga8af6cb"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;iris_dabest = dabest.load(data=data, x="species", y="petal width (cm)", idx=iris.target_names)
iris_dabest.mean_diff.plot()
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/trying-out-dabest/petal_width.png" alt="petal_width.png"&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgbcd0497" class="outline-3"&gt;
&lt;h3 id="orgbcd0497"&gt;Hedge's G&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgbcd0497"&gt;
&lt;p&gt;
&lt;a href="https://www.itl.nist.gov/div898/software/dataplot/refman2/auxillar/hedgeg.htm"&gt;Hedges G&lt;/a&gt; is a measurement of effect size, similar to Cohen's d but with better properties when the samples are smaller or the sample sizes are different.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;iris_dabest.hedges_g.plot()
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/trying-out-dabest/hedges_g.png" alt="hedges_g.png"&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(iris_dabest.hedges_g)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
DABEST v0.2.7
=============
             
Good afternoon!
The current time is Mon Dec 16 15:56:24 2019.

The unpaired Hedges' g between setosa and versicolor is 6.76 [95%CI 5.71, 7.86].
The two-sided p-value of the Mann-Whitney test is 2.28e-18.

The unpaired Hedges' g between setosa and virginica is 8.49 [95%CI 7.08, 9.77].
The two-sided p-value of the Mann-Whitney test is 2.43e-18.

5000 bootstrap samples were taken; the confidence interval is bias-corrected and accelerated.
The p-value(s) reported are the likelihood(s) of observing the effect size(s),
if the null hypothesis of zero difference is true.

To get the results of all valid statistical tests, use `.hedges_g.statistical_tests`
&lt;/pre&gt;

&lt;p&gt;
According to &lt;a href="https://www.wikiwand.com/en/Effect_size"&gt;Wikipedia&lt;/a&gt;, an effect size of 2 is "huge" so since the differences between the setosa and versicolor and setosa and virginica are 6.76 and 8.49 respectively, we might conclude that there is a significant difference between the petal width of the setosa and the other two species.
&lt;/p&gt;

&lt;p&gt;
I don't think that's really what this is meant for, but I just wanted to see how it works.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org91c1a78" class="outline-3"&gt;
&lt;h3 id="org91c1a78"&gt;Cohen's D&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org91c1a78"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;iris_dabest.cohens_d.plot()
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/trying-out-dabest/cohens_d.png" alt="cohens_d.png"&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(iris_dabest.cohens_d)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
DABEST v0.2.7
=============
             
Good afternoon!
The current time is Mon Dec 16 16:46:25 2019.

The unpaired Cohen's d between setosa and versicolor is 6.82 [95%CI 5.76, 7.92].
The two-sided p-value of the Mann-Whitney test is 2.28e-18.

The unpaired Cohen's d between setosa and virginica is 8.56 [95%CI 7.13, 9.85].
The two-sided p-value of the Mann-Whitney test is 2.43e-18.

5000 bootstrap samples were taken; the confidence interval is bias-corrected and accelerated.
The p-value(s) reported are the likelihood(s) of observing the effect size(s),
if the null hypothesis of zero difference is true.

To get the results of all valid statistical tests, use `.cohens_d.statistical_tests`
&lt;/pre&gt;

&lt;p&gt;
In this case the Cohen's d and Hedges g look similar.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>exploration</category><category>statistics</category><category>visualization</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/trying-out-dabest/</guid><pubDate>Mon, 16 Dec 2019 21:50:24 GMT</pubDate></item><item><title>A First Look At DABEST</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/a-first-look-at-dabest/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/a-first-look-at-dabest/#org532c938"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/a-first-look-at-dabest/#org8ea9616"&gt;Imports&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/a-first-look-at-dabest/#org2c22b0b"&gt;PyPi&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org532c938" class="outline-2"&gt;
&lt;h2 id="org532c938"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org532c938"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org8ea9616" class="outline-3"&gt;
&lt;h3 id="org8ea9616"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org8ea9616"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org2c22b0b" class="outline-4"&gt;
&lt;h4 id="org2c22b0b"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org2c22b0b"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from sklearn.datasets import load_iris
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>dabest</category><category>visalization</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/a-first-look-at-dabest/</guid><pubDate>Mon, 16 Dec 2019 07:18:50 GMT</pubDate></item><item><title>A First Look At Snorkel</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/#orge9daf90"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/#orgb6187b9"&gt;Imports&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/#org5a4d26c"&gt;Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/#org3f24a07"&gt;PyPi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/#org430fcde"&gt;Others&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/#org93ee95a"&gt;Set Up&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/#org2a4a5a5"&gt;Some Constants&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/#org7f8a1e9"&gt;The Plotting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/#org44f8d52"&gt;The Data Set&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/#org973695b"&gt;Rename the Columns&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/#org0f08f4e"&gt;Middle&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/#org4d99c76"&gt;Setting Up the Training and Testing Sets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/#orgf2efbb5"&gt;Looking at the Data&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/#org853da44"&gt;Spam and Ham&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/#org54512f3"&gt;The Dates&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/#org4004a77"&gt;Some Samples&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/#org121ec30"&gt;Labeling Functions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/#org6c32e7a"&gt;End&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/#org6800c08"&gt;Citations&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orge9daf90" class="outline-2"&gt;
&lt;h2 id="orge9daf90"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orge9daf90"&gt;
&lt;p&gt;
This is a walk-through of Snorkel's &lt;a href="https://www.snorkel.org/get-started/"&gt;Get Started&lt;/a&gt; page.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgb6187b9" class="outline-3"&gt;
&lt;h3 id="orgb6187b9"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgb6187b9"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org5a4d26c" class="outline-4"&gt;
&lt;h4 id="org5a4d26c"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org5a4d26c"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from argparse import Namespace
from datetime import datetime
from functools import partial
from pathlib import Path
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org3f24a07" class="outline-4"&gt;
&lt;h4 id="org3f24a07"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org3f24a07"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from sklearn.model_selection import train_test_split
import hvplot.pandas
import pandas
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org430fcde" class="outline-4"&gt;
&lt;h4 id="org430fcde"&gt;Others&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org430fcde"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from graeae import CountPercentage, EmbedHoloviews
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org93ee95a" class="outline-3"&gt;
&lt;h3 id="org93ee95a"&gt;Set Up&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org93ee95a"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org2a4a5a5" class="outline-4"&gt;
&lt;h4 id="org2a4a5a5"&gt;Some Constants&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org2a4a5a5"&gt;
&lt;p&gt;
There are two classes in the data set - &lt;i&gt;spam&lt;/i&gt; and &lt;i&gt;not spam&lt;/i&gt;, and for the labeling that we're going to do we also need a third value for the cases where the code can't give it a label.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;classified_as = Namespace(
    not_spam = 0,
    spam = 1,
    unknown = -1,
)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7f8a1e9" class="outline-4"&gt;
&lt;h4 id="org7f8a1e9"&gt;The Plotting&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org7f8a1e9"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;path = "../../files/posts/data/a-first-look-at-snorkel"
Embed = partial(EmbedHoloviews, folder_path=path)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org44f8d52" class="outline-4"&gt;
&lt;h4 id="org44f8d52"&gt;The Data Set&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org44f8d52"&gt;
&lt;p&gt;
This dataset is a set of comments taken from you-tube videos and hosted on &lt;a href="http://www.dt.fee.unicamp.br/~tiago//youtubespamcollection/"&gt;this site&lt;/a&gt;. The comments are for music videos by five artists.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;path = Path("~/data/datasets/texts/you_tube_comments/").expanduser()
assert path.is_dir()

parts = []
for name in path.glob("*csv"):
    data = pandas.read_csv(name)    
    data["artist"] = name.name.split()[-1].split(".")[0]
    parts.append(data)

data = pandas.concat(parts)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org973695b" class="outline-4"&gt;
&lt;h4 id="org973695b"&gt;Rename the Columns&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org973695b"&gt;
&lt;p&gt;
This just makes it easier for me since it matches my style.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Column = Namespace(
    comment_id = "comment_id",
    author = "author",
    datetime = "datetime",
    text = "text",
    label = "label",
    artist = "artist",
)
renames = {"COMMENT_ID": Column.comment_id,
	   "AUTHOR": Column.author,
	   "DATE": Column.datetime,
	   "CONTENT": Column.text,
	   "CLASS": Column.label}
data = data.rename(columns=renames)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org0f08f4e" class="outline-2"&gt;
&lt;h2 id="org0f08f4e"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org0f08f4e"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org4d99c76" class="outline-3"&gt;
&lt;h3 id="org4d99c76"&gt;Setting Up the Training and Testing Sets&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org4d99c76"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;x_train, x_test, y_train, y_test = train_test_split(data[Column.comment_id,
							 Column.author,
							 Column.datetime,
							 Column.text,
							 Column.artist],
						    data[Column.label],
						    test_size=0.2)
x_train, x_dev, y_train, y_dev = train_test_split(x_train, y_train,
						  test_size=0.1)
x_test, x_validation, y_test, y_validation = train_test_split(x_test, y_test,
							      test_size=0.1)

print(f"Training Size: {len(x_train):,}")
print(f"Development Size: {len(x_dev):,}")
print(f"Validation Size: {len(x_validation):,}")
print(f"Test Size: {len(x_test):,}")
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Training Size: 1,407
Development Size: 157
Validation Size: 40
Test Size: 352
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgf2efbb5" class="outline-3"&gt;
&lt;h3 id="orgf2efbb5"&gt;Looking at the Data&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgf2efbb5"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(x_dev.sample().iloc[0])
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
If I get 100 subscribers, I will summon Freddy Mercury's ghost to whipe  from the face of earth One Direction and Miley Cirus.﻿
&lt;/pre&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(f"{len(data):,}")
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
1,956
&lt;/pre&gt;
&lt;/div&gt;

&lt;div id="outline-container-org853da44" class="outline-4"&gt;
&lt;h4 id="org853da44"&gt;Spam and Ham&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org853da44"&gt;
&lt;p&gt;
There are two classes in the dataset - SPAM (1) and not-spam (0), sometimes called HAM.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;counter = CountPercentage(data.label)
counter()
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-right"&gt;

&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-right"&gt;Value&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Count&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Percent (%)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;td class="org-left"&gt;1,005&lt;/td&gt;
&lt;td class="org-right"&gt;51.38&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-left"&gt;951&lt;/td&gt;
&lt;td class="org-right"&gt;48.62&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;grouped = data.groupby([Column.artist]).agg({Column.label: "sum", Column.comment_id: "count"}).reset_index().rename(
    columns={Column.label: "spam", Column.comment_id: "total"})
grouped["ham"] = grouped.total - grouped.spam
plotter = grouped[[Column.artist, "spam", "ham"]]
plot = plotter.hvplot.bar(x=Column.artist, stacked=True, legend=True,).opts(
    title="Spam Counts",
    width=1000, height=800)
Embed(plot=plot, file_name="spam_counts")()
&lt;/pre&gt;&lt;/div&gt;

&lt;object type="text/html" data="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/spam_counts.html" style="width:100%" height="800"&gt;
  &lt;p&gt;Figure Missing&lt;/p&gt;
&lt;/object&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org54512f3" class="outline-4"&gt;
&lt;h4 id="org54512f3"&gt;The Dates&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org54512f3"&gt;
&lt;p&gt;
I'll look at when the comments were made, just to see.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(len(data[data[Column.datetime].isna()]))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
245
&lt;/pre&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;with_date = data[~data[Column.datetime].isna()]
with_date.loc[:, Column.datetime] = pandas.to_datetime(with_date[Column.datetime])
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;with_date.loc[:, "Month"] = with_date[Column.datetime].apply(lambda date: datetime(date.year, date.month, 1))
group = with_date.groupby(["Month", Column.artist, Column.label]).agg(
    {Column.comment_id: "count"}).reset_index().rename(
	columns={Column.comment_id: "Count",
		 Column.artist: "Artist"})
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;spam = group[group[Column.label] == classified_as.spam]
ham = group[group[Column.label] == classified_as.not_spam]
spam_plot = spam.hvplot(x="Month", y="Count", by="Artist", label="Spam")
plot = spam_plot.opts(title="Monthly Spam By Artist", width=1000, height=800)
Embed(plot=plot, file_name="monthly_spam_by_artist")()
&lt;/pre&gt;&lt;/div&gt;

&lt;object type="text/html" data="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/monthly_spam_by_artist.html" style="width:100%" height="800"&gt;
  &lt;p&gt;Figure Missing&lt;/p&gt;
&lt;/object&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org4004a77" class="outline-4"&gt;
&lt;h4 id="org4004a77"&gt;Some Samples&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org4004a77"&gt;
&lt;/div&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;&lt;a id="orgd416c09"&gt;&lt;/a&gt;SPAM&lt;br&gt;
&lt;div class="outline-text-5" id="text-orgd416c09"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;spam = data[data[Column.label]==classified_as.spam].sample(5)
for index in range(len(spam)):
    print(f"({spam.iloc[index][Column.artist]}): {spam.iloc[index][Column.text]}")
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
(Eminem): Do you need more instagram followers or photo likes? Check out IGBlast.com and get em in minutes!
(Eminem): Check out my channel im 15 year old rapper!
(Shakira): Part 5. Comforter of the afflicted, pray for us Help of Christians, pray for us Queen of Angels, pray for us Queen of Patriarchs, pray for us Queen of Prophets, pray for us Queen of Apostles, pray for us Queen of Martyrs, pray for us Queen of Confessors, pray for us Queen of Virgins, pray for us Queen of all Saints, pray for us Queen conceived without original sin, pray for us Queen of the most holy Rosary, pray for us Queen of the family, pray for us Queen of peace, pray for us 
(Eminem): Hey guys I&amp;amp;#39;m 87 cypher im 11 years old and Rap is my life I recently made my second album desire ep . please take a moment to check out my album on YouTube thank you very much for reading every like comment and subscription counts
(Eminem): Check out this video on YouTube:﻿
&lt;/pre&gt;
&lt;/div&gt;
&lt;/li&gt;

&lt;li&gt;&lt;a id="orga91282d"&gt;&lt;/a&gt;Ham&lt;br&gt;
&lt;div class="outline-text-5" id="text-orga91282d"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ham = data[data[Column.label]==classified_as.not_spam].sample(5)
for index in range(len(ham)):
    print(f"({ham.iloc[index][Column.artist]}): {ham.iloc[index][Column.text]}")
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
(Eminem): charlieee :DDDD (Those who saw Lost only will understand)﻿
(LMFAO): BEST PARTY SONG LITERALLY PARTY ROCK IS IN THE HOUSEE TONIGHT!!!!﻿
(LMFAO): I like how the robot shuffles he shuffles good﻿
(KatyPerry): ROAAAAARRRRRR 🐯🐯🐯﻿
(Shakira): like me﻿
&lt;/pre&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org121ec30" class="outline-3"&gt;
&lt;h3 id="org121ec30"&gt;Labeling Functions&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org6c32e7a" class="outline-2"&gt;
&lt;h2 id="org6c32e7a"&gt;End&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org6c32e7a"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org6800c08" class="outline-3"&gt;
&lt;h3 id="org6800c08"&gt;Citations&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org6800c08"&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;Alberto, T.C., Lochter J.V., Almeida, T.A. TubeSpam: Comment Spam Filtering on YouTube. Proceedings of the 14th IEEE International Conference on Machine Learning and Applications (ICMLA'15), 1-6, Miami, FL, USA, December, 2015. (preprint)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>data</category><category>labeling</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/</guid><pubDate>Thu, 26 Sep 2019 21:47:16 GMT</pubDate></item><item><title>SQL Module 3</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/sql/sql-module-3/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/sql/sql-module-3/#org4031b9e"&gt;Question One&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/sql/sql-module-3/#org9dae90a"&gt;Question Two&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/sql/sql-module-3/#orgc36ad95"&gt;Question Three&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/sql/sql-module-3/#org09c58dc"&gt;Question Four&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/sql/sql-module-3/#org98a8407"&gt;Question Five&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/sql/sql-module-3/#org5ca8abf"&gt;Question Six&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/sql/sql-module-3/#org5679c2e"&gt;Question Seven&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
All the questions in this Quiz use the Chinook Database.
&lt;/p&gt;
&lt;div id="outline-container-org4031b9e" class="outline-2"&gt;
&lt;h2 id="org4031b9e"&gt;Question One&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org4031b9e"&gt;
&lt;p&gt;
Using a subquery, find the names of all the tracks for the album "Californication".
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt;
&lt;span class="n"&gt;name&lt;/span&gt;
&lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="n"&gt;tracks&lt;/span&gt;
&lt;span class="k"&gt;LEFT&lt;/span&gt; &lt;span class="k"&gt;JOIN&lt;/span&gt; &lt;span class="n"&gt;albums&lt;/span&gt; &lt;span class="k"&gt;ON&lt;/span&gt; &lt;span class="n"&gt;tracks&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;albumid&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;albums&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;albumid&lt;/span&gt;
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;albums&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="ss"&gt;"Californication"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
What is the 8th Track? Porcelain.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org9dae90a" class="outline-2"&gt;
&lt;h2 id="org9dae90a"&gt;Question Two&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org9dae90a"&gt;
&lt;p&gt;
Find the total number of invoices for each customer along with the customer's full name, city and email.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt;
&lt;span class="k"&gt;COUNT&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;invoiceid&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;firstname&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lastname&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;city&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;email&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;invoices&lt;/span&gt;
&lt;span class="k"&gt;LEFT&lt;/span&gt; &lt;span class="k"&gt;JOIN&lt;/span&gt; &lt;span class="n"&gt;customers&lt;/span&gt; &lt;span class="k"&gt;ON&lt;/span&gt; &lt;span class="n"&gt;invoices&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;customerid&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;customers&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;customerid&lt;/span&gt;
&lt;span class="k"&gt;GROUP&lt;/span&gt; &lt;span class="k"&gt;BY&lt;/span&gt; &lt;span class="n"&gt;invoices&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;customerid&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
What is the email address of the 5th person, Frantisek Wichterlova?
&lt;/p&gt;

&lt;p&gt;
frantsekw@jetbrains.com
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgc36ad95" class="outline-2"&gt;
&lt;h2 id="orgc36ad95"&gt;Question Three&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgc36ad95"&gt;
&lt;p&gt;
Retrieve the track name, album, artistID, and trackID for all the albums.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt;
&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;artistid&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;trackid&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;tracks&lt;/span&gt;
&lt;span class="k"&gt;LEFT&lt;/span&gt; &lt;span class="k"&gt;JOIN&lt;/span&gt; &lt;span class="n"&gt;albums&lt;/span&gt; &lt;span class="k"&gt;ON&lt;/span&gt; &lt;span class="n"&gt;tracks&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;albumid&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;albums&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;albumid&lt;/span&gt;
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="ss"&gt;"For Those About To Rock We Salute You"&lt;/span&gt; &lt;span class="k"&gt;AND&lt;/span&gt; &lt;span class="n"&gt;trackid&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
What is the song title of trackID 12 from the "For Those About to Rock We Salute You" album? Enter the answer below
&lt;/p&gt;

&lt;p&gt;
Breaking The Rules
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org09c58dc" class="outline-2"&gt;
&lt;h2 id="org09c58dc"&gt;Question Four&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org09c58dc"&gt;
&lt;p&gt;
Retrieve a list with the managers last name, and the last name of the employees who report to him or her.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt;
&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LastName&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LastName&lt;/span&gt;
&lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="n"&gt;employees&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;
&lt;span class="k"&gt;LEFT&lt;/span&gt; &lt;span class="k"&gt;JOIN&lt;/span&gt; &lt;span class="n"&gt;employees&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;B&lt;/span&gt; &lt;span class="k"&gt;ON&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ReportsTo&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;EmployeeId&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;
After running the query described above, who are the reports for the manager named Mitchell (select all that apply)?
&lt;/p&gt;

&lt;p&gt;
King and Callahan.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org98a8407" class="outline-2"&gt;
&lt;h2 id="org98a8407"&gt;Question Five&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org98a8407"&gt;
&lt;p&gt;
Find the name and ID of the artists who do not have albums. 
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt;
&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ArtistId&lt;/span&gt;
&lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="n"&gt;artists&lt;/span&gt;
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;ArtistId&lt;/span&gt; &lt;span class="k"&gt;NOT&lt;/span&gt; &lt;span class="k"&gt;IN&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
  &lt;span class="k"&gt;SELECT&lt;/span&gt;
  &lt;span class="n"&gt;ArtistId&lt;/span&gt;
  &lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;albums&lt;/span&gt;
  &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
After running the query described above, two of the records returned have the same last name. Enter that name below.
&lt;/p&gt;

&lt;p&gt;
Gilberto
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org5ca8abf" class="outline-2"&gt;
&lt;h2 id="org5ca8abf"&gt;Question Six&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org5ca8abf"&gt;
&lt;p&gt;
Use a UNION to create a list of all the employee's and customer's first names and last names ordered by the last name in descending order.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt;
&lt;span class="n"&gt;FirstName&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;LastName&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;customers&lt;/span&gt;
&lt;span class="k"&gt;UNION&lt;/span&gt;
&lt;span class="k"&gt;SELECT&lt;/span&gt;
&lt;span class="n"&gt;FirstName&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;LastName&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;employees&lt;/span&gt;
&lt;span class="k"&gt;ORDER&lt;/span&gt; &lt;span class="k"&gt;BY&lt;/span&gt; &lt;span class="n"&gt;LastName&lt;/span&gt; &lt;span class="k"&gt;DESC&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
After running the query described above, determine what is the last name of the 6th record? Enter it below. Remember to order things in descending order to be sure to get the correct answer.
&lt;/p&gt;

&lt;p&gt;
Taylor
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org5679c2e" class="outline-2"&gt;
&lt;h2 id="org5679c2e"&gt;Question Seven&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org5679c2e"&gt;
&lt;p&gt;
See if there are any customers who have a different city listed in their billing city versus their customer city.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt;
&lt;span class="n"&gt;customers&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CustomerID&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;City&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;BillingCity&lt;/span&gt; &lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="n"&gt;customers&lt;/span&gt;
&lt;span class="k"&gt;LEFT&lt;/span&gt; &lt;span class="k"&gt;JOIN&lt;/span&gt; &lt;span class="n"&gt;invoices&lt;/span&gt; &lt;span class="k"&gt;ON&lt;/span&gt; &lt;span class="n"&gt;customers&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CustomerID&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;invoices&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CustomerId&lt;/span&gt;
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;City&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;BillingCity&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
No, there aren't.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;</description><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/sql/sql-module-3/</guid><pubDate>Fri, 30 Aug 2019 11:17:17 GMT</pubDate></item><item><title>Chinook Questions</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/sql/chinook-questions/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/sql/chinook-questions/#orge65da72"&gt;Beginning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/sql/chinook-questions/#orgd3858b3"&gt;Middle&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/sql/chinook-questions/#org708ca9e"&gt;Question One&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/sql/chinook-questions/#org3ab48f2"&gt;Question Two&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/sql/chinook-questions/#org0830803"&gt;Question Three&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/sql/chinook-questions/#org26ab570"&gt;Question Four&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/sql/chinook-questions/#org909b2fb"&gt;Question Five&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/sql/chinook-questions/#orge5212e9"&gt;Question Six&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/sql/chinook-questions/#org3efe939"&gt;Question Seven&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/sql/chinook-questions/#orgb0e1e09"&gt;End&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orge65da72" class="outline-2"&gt;
&lt;h2 id="orge65da72"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orge65da72"&gt;
&lt;p&gt;
The following questions use the &lt;a href="http://www.sqlitetutorial.net/sqlite-sample-database/"&gt;SQLite Sample Database&lt;/a&gt; - called the Chinook database - found on &lt;a href="http://www.sqlitetutorial.net"&gt;the SQLite Tutorial site&lt;/a&gt;.
&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/sql/chinook-questions/chinook-entity-diagram.png" alt="chinook-entity-diagram.png"&gt;
&lt;/p&gt;

&lt;p&gt;
It is made up of 11 tables:
&lt;/p&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-left"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Table&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;employees&lt;/td&gt;
&lt;td class="org-left"&gt;stores employees data such as employee id, last name, first name, etc. It also has a field named ReportsTo to specify who reports to whom.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;customers&lt;/td&gt;
&lt;td class="org-left"&gt;stores customers data.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;invoices&lt;/td&gt;
&lt;td class="org-left"&gt;stores invoice header data&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;&amp;amp; invoice_items&lt;/td&gt;
&lt;td class="org-left"&gt;stores the invoice line items data.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;artists&lt;/td&gt;
&lt;td class="org-left"&gt;stores artists data. It is a simple table that contains only artist id and name.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;albums&lt;/td&gt;
&lt;td class="org-left"&gt;stores data about a list of tracks. Each album belongs to one artist. However, one artist may have multiple albums.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;media_types&lt;/td&gt;
&lt;td class="org-left"&gt;stores media types such as MPEG audio and AAC audio file.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;genres&lt;/td&gt;
&lt;td class="org-left"&gt;stores music types such as rock, jazz, metal, etc.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;tracks&lt;/td&gt;
&lt;td class="org-left"&gt;store the data of songs. Each track belongs to one album.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;playlists&lt;/td&gt;
&lt;td class="org-left"&gt;stores data about playlists. Each playlist contains a list of tracks. Each track may belong to multiple playlists.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;playlist_track&lt;/td&gt;
&lt;td class="org-left"&gt;The relationship between the playlists table and tracks table is many-to-many. The playlist_track table is used to reflect this relationship.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgd3858b3" class="outline-2"&gt;
&lt;h2 id="orgd3858b3"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgd3858b3"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org708ca9e" class="outline-3"&gt;
&lt;h3 id="org708ca9e"&gt;Question One&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org708ca9e"&gt;
&lt;p&gt;
Pull a list of customer ids with the customer’s full name, and address, along with combining their city and country together. Be sure to make a space in between these two and make it UPPER CASE.
&lt;/p&gt;

&lt;p&gt;
What is the city and country result for CustomerID 16?
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org3ab48f2" class="outline-3"&gt;
&lt;h3 id="org3ab48f2"&gt;Question Two&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org3ab48f2"&gt;
&lt;p&gt;
Create a new employee user id by combining the first 4 letters of the employee’s first name with the first 2 letters of the employee’s last name. Make the new field lower case and pull each individual step to show your work.
&lt;/p&gt;

&lt;p&gt;
What is the final result for Robert King?
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org0830803" class="outline-3"&gt;
&lt;h3 id="org0830803"&gt;Question Three&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org0830803"&gt;
&lt;p&gt;
Show a list of employees who have worked for the company for 15 or more years using the current date function. Sort by lastname ascending.
&lt;/p&gt;

&lt;p&gt;
What is the lastname of the last person on the list returned?
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org26ab570" class="outline-3"&gt;
&lt;h3 id="org26ab570"&gt;Question Four&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org26ab570"&gt;
&lt;p&gt;
Profiling the Customers table, answer the following question.
&lt;/p&gt;

&lt;p&gt;
Are there any columns with null values? Indicate any below. Select all that apply.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org909b2fb" class="outline-3"&gt;
&lt;h3 id="org909b2fb"&gt;Question Five&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org909b2fb"&gt;
&lt;p&gt;
Find the cities with the most customers and rank in descending order.
&lt;/p&gt;

&lt;p&gt;
Which of the following cities indicate having 2 customers?
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orge5212e9" class="outline-3"&gt;
&lt;h3 id="orge5212e9"&gt;Question Six&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orge5212e9"&gt;
&lt;p&gt;
Create a new customer invoice id by combining a customer’s invoice id with their first and last name while ordering your query in the following order: firstname, lastname, and invoiceID.
&lt;/p&gt;

&lt;p&gt;
Select all of the correct "AstridGruber" entries that are returned in your results below. Select all that apply.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org3efe939" class="outline-3"&gt;
&lt;h3 id="org3efe939"&gt;Question Seven&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgb0e1e09" class="outline-2"&gt;
&lt;h2 id="orgb0e1e09"&gt;End&lt;/h2&gt;
&lt;/div&gt;</description><category>practice</category><category>sql</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/sql/chinook-questions/</guid><pubDate>Wed, 21 Aug 2019 15:39:49 GMT</pubDate></item><item><title>Calling a JSON API</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/calling-a-json-api/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/calling-a-json-api/#org3fb20d4"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/calling-a-json-api/#org663d11d"&gt;Imports&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/calling-a-json-api/#orgd4a57ec"&gt;Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/calling-a-json-api/#org6806545"&gt;PyPi&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/calling-a-json-api/#orgee1f254"&gt;Set Up&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/calling-a-json-api/#orgccd59ba"&gt;URL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/calling-a-json-api/#org80c0fc4"&gt;Sample&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/calling-a-json-api/#org6130de2"&gt;Actual&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/calling-a-json-api/#org0cc1baf"&gt;Middle&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/calling-a-json-api/#orge8d13d4"&gt;The Sample&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/calling-a-json-api/#org278a8f9"&gt;The Actual&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/calling-a-json-api/#orge542544"&gt;End&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org3fb20d4" class="outline-2"&gt;
&lt;h2 id="org3fb20d4"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org3fb20d4"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org663d11d" class="outline-3"&gt;
&lt;h3 id="org663d11d"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org663d11d"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgd4a57ec" class="outline-4"&gt;
&lt;h4 id="orgd4a57ec"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgd4a57ec"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from pprint import pprint
import json
import urllib
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org6806545" class="outline-4"&gt;
&lt;h4 id="org6806545"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org6806545"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from expects import (
    equal,
    expect,
    start_with,
)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgee1f254" class="outline-3"&gt;
&lt;h3 id="orgee1f254"&gt;Set Up&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgee1f254"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgccd59ba" class="outline-4"&gt;
&lt;h4 id="orgccd59ba"&gt;URL&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgccd59ba"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;API_KEY = 42
API_URL = "http://py4e-data.dr-chuck.net/json?"
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org80c0fc4" class="outline-4"&gt;
&lt;h4 id="org80c0fc4"&gt;Sample&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org80c0fc4"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;SAMPLE_LOCATION = "South Federal University"
SAMPLE_PLACE_ID = "ChIJ9e_QQm0sDogRhUPatldEFxw"
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org6130de2" class="outline-4"&gt;
&lt;h4 id="org6130de2"&gt;Actual&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org6130de2"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ACTUAL_LOCATION = "Kazan Federal University"
ACTUAL_PLACE_ID_STARTS_WITH = "ChIJGf9"
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org0cc1baf" class="outline-2"&gt;
&lt;h2 id="org0cc1baf"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org0cc1baf"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def get_place_id(location: str) -&amp;gt; str:
    """Get the place ID for the location

    Args:
     location: place to look up

    Returns:
     the place ID for the location
    """
    parameters = {"address": location, "key": API_KEY}
    request = API_URL + urllib.parse.urlencode(parameters)

    with urllib.request.urlopen(request) as response:
	data = json.loads(response.read().decode())
	results = data["results"][0]
	expect(data["status"]).to(equal("OK"))
	place_id = results["place_id"]
	print(f"Location: {location}")
	print(f"Place ID: {place_id}")
    return place_id
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orge8d13d4" class="outline-3"&gt;
&lt;h3 id="orge8d13d4"&gt;The Sample&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orge8d13d4"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;place_id = get_place_id(SAMPLE_LOCATION)
expect(SAMPLE_PLACE_ID).to(equal(place_id))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Location: South Federal University
Place ID: ChIJ9e_QQm0sDogRhUPatldEFxw
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org278a8f9" class="outline-3"&gt;
&lt;h3 id="org278a8f9"&gt;The Actual&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org278a8f9"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;place_id = get_place_id(ACTUAL_LOCATION)
expect(place_id).to(start_with(ACTUAL_PLACE_ID_STARTS_WITH))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Location: Kazan Federal University
Place ID: ChIJGf9kMxGtXkERIzwzBzFo8kY
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orge542544" class="outline-2"&gt;
&lt;h2 id="orge542544"&gt;End&lt;/h2&gt;
&lt;/div&gt;</description><category>api</category><category>json</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/calling-a-json-api/</guid><pubDate>Sun, 04 Aug 2019 18:53:29 GMT</pubDate></item><item><title>Extracting Data From JSON</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/#org75a3b2d"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/#org1da480e"&gt;Imports&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/#org6b2b81c"&gt;Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/#orge511c4c"&gt;PyPi&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/#orgdaf8c7f"&gt;Set Up&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/#org6ff1f5f"&gt;The URLs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/#org7dab0aa"&gt;The Expected&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/#org9ec9212"&gt;Middle&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/#orga87c597"&gt;The Sample&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/#orgd09098d"&gt;The Assignment&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/#org69bd47d"&gt;End&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org75a3b2d" class="outline-2"&gt;
&lt;h2 id="org75a3b2d"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org75a3b2d"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org1da480e" class="outline-3"&gt;
&lt;h3 id="org1da480e"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org1da480e"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org6b2b81c" class="outline-4"&gt;
&lt;h4 id="org6b2b81c"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org6b2b81c"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;import json
import urllib
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orge511c4c" class="outline-4"&gt;
&lt;h4 id="orge511c4c"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orge511c4c"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from expects import expect, equal
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgdaf8c7f" class="outline-3"&gt;
&lt;h3 id="orgdaf8c7f"&gt;Set Up&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgdaf8c7f"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org6ff1f5f" class="outline-4"&gt;
&lt;h4 id="org6ff1f5f"&gt;The URLs&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org6ff1f5f"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;SAMPLE_URL = "http://py4e-data.dr-chuck.net/comments_42.json"
ACTUAL_URL = "http://py4e-data.dr-chuck.net/comments_260445.json"
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7dab0aa" class="outline-4"&gt;
&lt;h4 id="org7dab0aa"&gt;The Expected&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org7dab0aa"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;SAMPLE_EXPECTED = 2553
ACTUAL_EXPECTED_LAST_TWO_DIGITS = 94
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org9ec9212" class="outline-2"&gt;
&lt;h2 id="org9ec9212"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org9ec9212"&gt;
&lt;p&gt;
We're going to pull a JSON blob and extract the "count" values and sum them. The data is structured with a single top-level key ("comments") which holds a list of dicts with "name" (name of the commenter) and "count" (the number of comments the commenter has made) values.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def count(url: str) -&amp;gt; int:
    """Totals the comment counts

    Args:
     url: source of the JSON

    Returns:
     the total of the comment counts
    """
    response = urllib.request.urlopen(url)
    data = json.loads(response.read())
    total = 0
    for index, commenter in enumerate(data["comments"]):
	total += int(commenter["count"])

    print(f"Comments: {index + 1}")
    print(f"Comments: {total: ,}")
    return total
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orga87c597" class="outline-3"&gt;
&lt;h3 id="orga87c597"&gt;The Sample&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orga87c597"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;total = count(SAMPLE_URL)
expect(total).to(equal(SAMPLE_EXPECTED))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Comments: 50
Comments:  2,553

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgd09098d" class="outline-3"&gt;
&lt;h3 id="orgd09098d"&gt;The Assignment&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgd09098d"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;total = count(ACTUAL_URL)
expect(int(str(total)[-2:])).to(equal(ACTUAL_EXPECTED_LAST_TWO_DIGITS))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Comments: 50
Comments:  2,594

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org69bd47d" class="outline-2"&gt;
&lt;h2 id="org69bd47d"&gt;End&lt;/h2&gt;
&lt;/div&gt;</description><category>json</category><category>web-scraping</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/</guid><pubDate>Sun, 04 Aug 2019 18:22:51 GMT</pubDate></item></channel></rss>