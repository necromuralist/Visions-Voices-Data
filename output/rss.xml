<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Visions, Voices, Data</title><link>https://necromuralist.github.io/Visions-Voices-Data/</link><description>Adumbrations of data.</description><atom:link href="https://necromuralist.github.io/Visions-Voices-Data/rss.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2020 &lt;a href="mailto:necromuralist@protonmail.com"&gt;Cloistered Monkey&lt;/a&gt; </copyright><lastBuildDate>Thu, 06 Feb 2020 01:05:17 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Permutation Importance</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/#org4e10308"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/#org944c4b8"&gt;Imports&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/#org7625a5f"&gt;Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/#orgf001945"&gt;PyPi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/#orgde3f10e"&gt;Others&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/#orgaef4e50"&gt;Set Up&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/#org0a8e4db"&gt;Plotting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/#org08e1cea"&gt;The Environment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/#org84cc911"&gt;The Table Printer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/#orgfc2f9d7"&gt;The Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/#org78fa31c"&gt;Middle&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/#orgd16a3f5"&gt;Looking at the Dataset&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/#org0fd89f8"&gt;The Target&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/#org1c96a7e"&gt;The Features&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/#org1df2d09"&gt;Build and Train the Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/#orgd79f9a3"&gt;Permutation Importance&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/#org3b157c7"&gt;Plotting the Importance&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/#orgc3cd38f"&gt;End&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org4e10308" class="outline-2"&gt;
&lt;h2 id="org4e10308"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org4e10308"&gt;
&lt;p&gt;
This is some notes on the kaggle tutorial on &lt;a href="https://www.kaggle.com/dansbecker/permutation-importance"&gt;Permutation Importance&lt;/a&gt;. &lt;i&gt;Permutation Importance&lt;/i&gt; is a form of feature selection where you ask - &lt;i&gt;If you randomly shuffle the values one column in the dataset and leave the others in place, how does this affect the performance of the model?&lt;/i&gt;. The idea is that if the column is important, then shuffling the values should make the model perform worse, so you can measure how much it degrades after you shuffle each column and figure out which columns are contributing to the model. Here's the rough process:
&lt;/p&gt;

&lt;ol class="org-ol"&gt;
&lt;li&gt;Start with a trained model and a labeled dataset.&lt;/li&gt;
&lt;li&gt;Shuffle a single column&lt;/li&gt;
&lt;li&gt;Measure how much worse the model does predicting the target.&lt;/li&gt;
&lt;li&gt;Restore the column and move on to the next column, repeating the steps until you have covered all the columns.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id="outline-container-org944c4b8" class="outline-3"&gt;
&lt;h3 id="org944c4b8"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org944c4b8"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7625a5f" class="outline-4"&gt;
&lt;h4 id="org7625a5f"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org7625a5f"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from functools import partial
from pathlib import Path
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgf001945" class="outline-4"&gt;
&lt;h4 id="orgf001945"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgf001945"&gt;
&lt;/div&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;&lt;a id="org7439362"&gt;&lt;/a&gt;eli5&lt;br&gt;
&lt;div class="outline-text-5" id="text-org7439362"&gt;
&lt;p&gt;
&lt;a href="https://eli5.readthedocs.io/en/latest/"&gt;eli5&lt;/a&gt; (which is presumably short for &lt;a href="https://www.dictionary.com/e/slang/eli5/"&gt;explain it like I'm five&lt;/a&gt;) is a library to help with machine learning model debugging and visualization. You can read about the PermutationImportance class &lt;a href="https://eli5.readthedocs.io/en/latest/autodocs/sklearn.html#eli5.sklearn.permutation_importance.PermutationImportance"&gt;here&lt;/a&gt;.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from eli5.sklearn import PermutationImportance
import eli5
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a id="orgf72ac86"&gt;&lt;/a&gt;sklearn&lt;br&gt;
&lt;div class="outline-text-5" id="text-orgf72ac86"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from tabulate import tabulate
import hvplot.pandas
import numpy
import pandas
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgde3f10e" class="outline-4"&gt;
&lt;h4 id="orgde3f10e"&gt;Others&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgde3f10e"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from graeae import CountPercentage, EmbedHoloviews, EnvironmentLoader
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgaef4e50" class="outline-3"&gt;
&lt;h3 id="orgaef4e50"&gt;Set Up&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgaef4e50"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org0a8e4db" class="outline-4"&gt;
&lt;h4 id="org0a8e4db"&gt;Plotting&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org0a8e4db"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;SLUG = "permutation-importance"
PATH = Path("../../files/posts/tutorials/")/SLUG
Embed = partial(EmbedHoloviews, folder_path=PATH)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org08e1cea" class="outline-4"&gt;
&lt;h4 id="org08e1cea"&gt;The Environment&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org08e1cea"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ENVIRONMENT = EnvironmentLoader()
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org84cc911" class="outline-4"&gt;
&lt;h4 id="org84cc911"&gt;The Table Printer&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org84cc911"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;TABLE = partial(tabulate, tablefmt="orgtbl", headers="keys", showindex=False)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgfc2f9d7" class="outline-4"&gt;
&lt;h4 id="orgfc2f9d7"&gt;The Data&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgfc2f9d7"&gt;
&lt;p&gt;
The dataset here is the &lt;a href="https://www.kaggle.com/mathan/fifa-2018-match-statistics"&gt;Predict FIFA 2018 Man of the Match&lt;/a&gt; dataset from kaggle.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;path = Path(ENVIRONMENT["FIFA"]).expanduser()
data = pandas.read_csv(path)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org78fa31c" class="outline-2"&gt;
&lt;h2 id="org78fa31c"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org78fa31c"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgd16a3f5" class="outline-3"&gt;
&lt;h3 id="orgd16a3f5"&gt;Looking at the Dataset&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgd16a3f5"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(TABLE(data.sample().iloc[0].reset_index(), headers="Column Value".split()))
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Column&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;Date&lt;/td&gt;
&lt;td class="org-right"&gt;17-06-2018&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Team&lt;/td&gt;
&lt;td class="org-right"&gt;Mexico&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Opponent&lt;/td&gt;
&lt;td class="org-right"&gt;Germany&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Goal Scored&lt;/td&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Ball Possession %&lt;/td&gt;
&lt;td class="org-right"&gt;40&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Attempts&lt;/td&gt;
&lt;td class="org-right"&gt;12&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;On-Target&lt;/td&gt;
&lt;td class="org-right"&gt;4&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Off-Target&lt;/td&gt;
&lt;td class="org-right"&gt;6&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Blocked&lt;/td&gt;
&lt;td class="org-right"&gt;2&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Corners&lt;/td&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Offsides&lt;/td&gt;
&lt;td class="org-right"&gt;2&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Free Kicks&lt;/td&gt;
&lt;td class="org-right"&gt;11&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Saves&lt;/td&gt;
&lt;td class="org-right"&gt;9&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Pass Accuracy %&lt;/td&gt;
&lt;td class="org-right"&gt;82&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Passes&lt;/td&gt;
&lt;td class="org-right"&gt;281&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Distance Covered (Kms)&lt;/td&gt;
&lt;td class="org-right"&gt;106&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Fouls Committed&lt;/td&gt;
&lt;td class="org-right"&gt;15&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Yellow Card&lt;/td&gt;
&lt;td class="org-right"&gt;2&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Yellow &amp;amp; Red&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Red&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Man of the Match&lt;/td&gt;
&lt;td class="org-right"&gt;No&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;1st Goal&lt;/td&gt;
&lt;td class="org-right"&gt;35.0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Round&lt;/td&gt;
&lt;td class="org-right"&gt;Group Stage&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;PSO&lt;/td&gt;
&lt;td class="org-right"&gt;No&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Goals in PSO&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Own goals&lt;/td&gt;
&lt;td class="org-right"&gt;nan&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Own goal Time&lt;/td&gt;
&lt;td class="org-right"&gt;nan&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;div id="outline-container-org0fd89f8" class="outline-4"&gt;
&lt;h4 id="org0fd89f8"&gt;The Target&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org0fd89f8"&gt;
&lt;p&gt;
The target is "Man of the Match".
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;CountPercentage(data["Man of the Match"])()
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Value&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Count&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Percent (%)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;No&lt;/td&gt;
&lt;td class="org-right"&gt;64&lt;/td&gt;
&lt;td class="org-right"&gt;50.00&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;Yes&lt;/td&gt;
&lt;td class="org-right"&gt;64&lt;/td&gt;
&lt;td class="org-right"&gt;50.00&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;
Not a particularly large dataset, but we aren't really interested in it per-se but rather how to use permutation importance with it.
&lt;/p&gt;

&lt;p&gt;
We want it to be a True/False value rather than a string value so let's change it.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;data.loc[:, "Man of the Match"] = data["Man of the Match"] == "Yes"
CountPercentage(data["Man of the Match"])()
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Value&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Count&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Percent (%)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;True&lt;/td&gt;
&lt;td class="org-right"&gt;64&lt;/td&gt;
&lt;td class="org-right"&gt;50.00&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;False&lt;/td&gt;
&lt;td class="org-right"&gt;64&lt;/td&gt;
&lt;td class="org-right"&gt;50.00&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org1c96a7e" class="outline-3"&gt;
&lt;h3 id="org1c96a7e"&gt;The Features&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org1c96a7e"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(data.info())
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
&amp;lt;class 'pandas.core.frame.DataFrame'&amp;gt;
RangeIndex: 128 entries, 0 to 127
Data columns (total 27 columns):
Date                      128 non-null object
Team                      128 non-null object
Opponent                  128 non-null object
Goal Scored               128 non-null int64
Ball Possession %         128 non-null int64
Attempts                  128 non-null int64
On-Target                 128 non-null int64
Off-Target                128 non-null int64
Blocked                   128 non-null int64
Corners                   128 non-null int64
Offsides                  128 non-null int64
Free Kicks                128 non-null int64
Saves                     128 non-null int64
Pass Accuracy %           128 non-null int64
Passes                    128 non-null int64
Distance Covered (Kms)    128 non-null int64
Fouls Committed           128 non-null int64
Yellow Card               128 non-null int64
Yellow &amp;amp; Red              128 non-null int64
Red                       128 non-null int64
Man of the Match          128 non-null bool
1st Goal                  94 non-null float64
Round                     128 non-null object
PSO                       128 non-null object
Goals in PSO              128 non-null int64
Own goals                 12 non-null float64
Own goal Time             12 non-null float64
dtypes: bool(1), float64(3), int64(18), object(5)
memory usage: 26.2+ KB
None
&lt;/pre&gt;

&lt;p&gt;
As you can see there's both numeric and non-numeric columns. For illustration purposes let's use just the integer columns.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;columns = [column for column in data.columns if data[column].dtype == numpy.int64]
for column in sorted(columns):
    print(f" * {column}")
X = data[columns]

x_train, x_validate, y_train, y_validate = train_test_split(
    X,
    data["Man of the Match"], random_state=1)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
* Attempts
* Ball Possession %
* Blocked
* Corners
* Distance Covered (Kms)
* Fouls Committed
* Free Kicks
* Goal Scored
* Goals in PSO
* Off-Target
* Offsides
* On-Target
* Pass Accuracy %
* Passes
* Red
* Saves
* Yellow &amp;amp; Red
* Yellow Card
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org1df2d09" class="outline-3"&gt;
&lt;h3 id="org1df2d09"&gt;Build and Train the Model&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org1df2d09"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;model = RandomForestClassifier(n_estimators=100, random_state=0).fit(x_train, y_train)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgd79f9a3" class="outline-3"&gt;
&lt;h3 id="orgd79f9a3"&gt;Permutation Importance&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgd79f9a3"&gt;
&lt;p&gt;
As I noted previously, you can read about the &lt;code&gt;PermutationImportance&lt;/code&gt; class &lt;a href="https://eli5.readthedocs.io/en/latest/autodocs/sklearn.html#eli5.sklearn.permutation_importance.PermutationImportance"&gt;here&lt;/a&gt;. If you read the documentation you'll see that you don't have to pass it a prefit model, and in some cases you don't want to (if you're using a hyper-parameter-search pipeline, say).
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;permutor = PermutationImportance(model, random_state=1).fit(x_validate, y_validate)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ipython_html = eli5.show_weights(permutor, feature_names=x_validate.columns.tolist())
table = pandas.read_html(ipython_html.data)[0]
print(TABLE(table))
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-left"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Weight&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Feature&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;0.1750  ± 0.0848&lt;/td&gt;
&lt;td class="org-left"&gt;Goal Scored&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0500  ± 0.0637&lt;/td&gt;
&lt;td class="org-left"&gt;Distance Covered (Kms)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0437  ± 0.0637&lt;/td&gt;
&lt;td class="org-left"&gt;Yellow Card&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0187  ± 0.0500&lt;/td&gt;
&lt;td class="org-left"&gt;Off-Target&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0187  ± 0.0637&lt;/td&gt;
&lt;td class="org-left"&gt;Free Kicks&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0187  ± 0.0637&lt;/td&gt;
&lt;td class="org-left"&gt;Fouls Committed&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0125  ± 0.0637&lt;/td&gt;
&lt;td class="org-left"&gt;Pass Accuracy %&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0125  ± 0.0306&lt;/td&gt;
&lt;td class="org-left"&gt;Blocked&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0063  ± 0.0612&lt;/td&gt;
&lt;td class="org-left"&gt;Saves&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0063  ± 0.0250&lt;/td&gt;
&lt;td class="org-left"&gt;Ball Possession %&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0  ± 0.0000&lt;/td&gt;
&lt;td class="org-left"&gt;Red&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0  ± 0.0000&lt;/td&gt;
&lt;td class="org-left"&gt;Yellow &amp;amp; Red&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;0.0000  ± 0.0559&lt;/td&gt;
&lt;td class="org-left"&gt;On-Target&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;-0.0063  ± 0.0729&lt;/td&gt;
&lt;td class="org-left"&gt;Offsides&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;-0.0063  ± 0.0919&lt;/td&gt;
&lt;td class="org-left"&gt;Corners&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;-0.0063  ± 0.0250&lt;/td&gt;
&lt;td class="org-left"&gt;Goals in PSO&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;-0.0187  ± 0.0306&lt;/td&gt;
&lt;td class="org-left"&gt;Attempts&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;-0.0500  ± 0.0637&lt;/td&gt;
&lt;td class="org-left"&gt;Passes&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;
The table is ranked from most important feature to least important (based on the accuracy after shuffling the column). Anything with 0 or less essenttially contributed nothing to the model. Although that doesn't mean that they might not be useful for more feature engineering.
&lt;/p&gt;

&lt;p&gt;
The data is for the team as a whole, not an individual, so the "Man of the Match" column is telling you if any player on the team was awarded the "Budweiser Man of the Match".
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-org3b157c7" class="outline-4"&gt;
&lt;h4 id="org3b157c7"&gt;Plotting the Importance&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org3b157c7"&gt;
&lt;p&gt;
The numbers are okay, but let's take a look at a plot of the weights.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;weights = table.Weight.str.split(expand=True)[0].astype(float)
table["weights"] = weights
plot = table.hvplot.bar(x="Feature", y="weights").opts(
    title="Permutation Importance (by Accuracy)",
    width=1000, height=800, xrotation=45)
Embed(plot=plot, file_name="permutation_importance")()
&lt;/pre&gt;&lt;/div&gt;

&lt;object type="text/html" data="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/permutation_importance.html" style="width:100%" height="800"&gt;
  &lt;p&gt;Figure Missing&lt;/p&gt;
&lt;/object&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgc3cd38f" class="outline-2"&gt;
&lt;h2 id="orgc3cd38f"&gt;End&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgc3cd38f"&gt;
&lt;p&gt;
So that's a quick look at getting a sense of the importance of a feature using &lt;code&gt;eli5&lt;/code&gt; and permutation importance. There's a more in depth look at it on their site, but next is another look at it with a different data set.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>feature importance</category><category>kaggle</category><category>tutorial</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/permutation-importance/</guid><pubDate>Wed, 05 Feb 2020 20:33:20 GMT</pubDate></item><item><title>Snorkel Data Labeling</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-data-labeling/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-data-labeling/#org7110700"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-data-labeling/#org1eea11a"&gt;Imports&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-data-labeling/#org1367a1e"&gt;Set Up&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-data-labeling/#org695e908"&gt;Middle&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-data-labeling/#org459bf62"&gt;Finding Labeling Functions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-data-labeling/#orgdaac3af"&gt;Using TextBlob with a Preprocessor&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-data-labeling/#orgd7660b8"&gt;More Labeling Functions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-data-labeling/#org99ea299"&gt;Adding a Spacy Preprocessor&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7110700" class="outline-2"&gt;
&lt;h2 id="org7110700"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org7110700"&gt;
&lt;p&gt;
This is a walk-through of the Snorkel &lt;a href="https://www.snorkel.org/use-cases/01-spam-tutorial"&gt;Snorkel Data Labeling&lt;/a&gt; tutorial.It uses the &lt;a href="http://www.dt.fee.unicamp.br/~tiago//youtubespamcollection/"&gt;YouTube Spam Collection&lt;/a&gt; data set (downloaded from the &lt;a href="https://archive.ics.uci.edu/ml/datasets/YouTube+Spam+Collection"&gt;UCI Machine Learning Repository&lt;/a&gt;). The data was collected in 2015 and represents comments from five of the ten most popular videos on YouTube. It is a tabular dataset with the columns &lt;code&gt;COMMENT_ID&lt;/code&gt;, &lt;code&gt;AUTHOR&lt;/code&gt;, &lt;code&gt;DATE&lt;/code&gt;, &lt;code&gt;CONTENT&lt;/code&gt;, &lt;code&gt;CLASS&lt;/code&gt;. The tag represents whether it was considered &lt;i&gt;Spam&lt;/i&gt; or not, so we'll pretend it isn't there for most of this walk-through.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-org1eea11a" class="outline-3"&gt;
&lt;h3 id="org1eea11a"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org1eea11a"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org97bc1a0" class="outline-4"&gt;
&lt;h4 id="org97bc1a0"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org97bc1a0"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from argparse import Namespace
from functools import partial
from pathlib import Path
import re
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgc38d5c3" class="outline-4"&gt;
&lt;h4 id="orgc38d5c3"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgc38d5c3"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from snorkel.analysis import get_label_buckets
from snorkel.labeling import labeling_function, LabelingFunction, LFAnalysis, PandasLFApplier
from snorkel.preprocess import preprocessor
from snorkel.labeling.lf.nlp import nlp_labeling_function
from sklearn.model_selection import train_test_split
from tabulate import tabulate
from textblob import TextBlob

import pandas
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org1367a1e" class="outline-3"&gt;
&lt;h3 id="org1367a1e"&gt;Set Up&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org1367a1e"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org11e2015" class="outline-4"&gt;
&lt;h4 id="org11e2015"&gt;The Tabulate Table&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org11e2015"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;TABLE = partial(tabulate, tablefmt="orgtbl", headers="keys")
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgb273a95" class="outline-4"&gt;
&lt;h4 id="orgb273a95"&gt;Some Constants&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgb273a95"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Comment = Namespace(
    is_ambiguous = -1,
    is_ham = 0,
    is_spam = 1
)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Data = Namespace(
    test_artist = "Shakira",
    development_size = 200,
    validation_size = 0.5,
    random_seed = 666,
)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Columns = Namespace(
    comment = "CONTENT",
    classification = "CLASS",
    artist = "artist",
)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org695e908" class="outline-2"&gt;
&lt;h2 id="org695e908"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org695e908"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org1650a13" class="outline-4"&gt;
&lt;h4 id="org1650a13"&gt;The Dataset&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org1650a13"&gt;
&lt;p&gt;
The data is split up into separate files - one for each artist/video (they are named after the artist and each only appears to have one entry) so I'm going to smash them back together and add a &lt;code&gt;artist&lt;/code&gt; column.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;path = Path("~/data/datasets/texts/you_tube_comments/").expanduser()
sets = []
for name in path.glob("*.csv"):
    artist = name.stem.split()[-1]
    data = pandas.read_csv(name)
    data["artist"] = artist
    sets.append(data)
    print(artist)
data = pandas.concat(sets)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
KatyPerry
LMFAO
Eminem
Shakira
Psy
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org1c9ca1f" class="outline-4"&gt;
&lt;h4 id="org1c9ca1f"&gt;Splitting the Set&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org1c9ca1f"&gt;
&lt;p&gt;
The tutorial takes a slightly different approach from the one I previously took. Here's their four data-set splits:
&lt;/p&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;&lt;i&gt;train&lt;/i&gt;: Comments from the first four videos&lt;/li&gt;
&lt;li&gt;&lt;i&gt;dev&lt;/i&gt;: 200 comments taken from &lt;i&gt;train&lt;/i&gt;&lt;/li&gt;
&lt;li&gt;&lt;i&gt;valid &amp;amp; test&lt;/i&gt;: A 50-50 split of the last video (actually &lt;i&gt;Shakira&lt;/i&gt;, not &lt;i&gt;Psy&lt;/i&gt; as listed above)&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;test = data[data.artist==Data.test_artist]
train = data[data.artist != Data.test_artist]
train, development = train_test_split(train, test_size=Data.development_size)

validation, test = train_test_split(test, test_size=Data.validation_size)
print(f"Training: {train.shape}")
print(f"Development: {development.shape}")
print(f"Validation: {validation.shape}")
print(f"Testing: {test.shape}")
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Training: (1386, 6)
Development: (200, 6)
Validation: (185, 6)
Testing: (185, 6)
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org459bf62" class="outline-3"&gt;
&lt;h3 id="org459bf62"&gt;Finding Labeling Functions&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org459bf62"&gt;
&lt;p&gt;
The place to start is with the development set - it's labeled (although in this case the training set is as well, but pretend it isn't) and we can inspect it to get ideas.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(development.sample(random_state=Data.random_seed)[[Columns.comment, Columns.classification]])
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
                                               CONTENT  CLASS
216  Lol...I dunno how this joke gets a lot of like...      0
&lt;/pre&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;spam = development[development[Columns.classification]==Comment.is_spam]
for count in range(10):
    print(spam.sample(random_state=count).iloc[0][Columns.comment])
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
I #votekatyperry for the 2014 MTV #VMA Best Lyric Video! See who's in the  lead and vote:  http://on.mtv.com/Ut15kX﻿
LIKE AND SUBSCRIB IF YOU WATCH IN 2015 ;)﻿
 HI IM 14 YEAR RAPPER SUPPORT ME GUY AND CHECK OUT MY CHANNEL AND CHECK OUT MY SONG YOU MIGHT LIKE IT ALSO FOLLOW ME IN TWITTER @McAshim for follow back.
LIKE AND SUBSCRIB IF YOU WATCH IN 2015 ;)﻿
HAPPY BIRTHDAY KATY :) http://giphy.com/gifs/birthday-flowers-happy-gw3JY2uqiaXKaQXS/fullscreen  (That´s not me)﻿
plz check out fablife / welcome to fablife for diys and challenges so plz  subscribe thx!﻿
CHECK OUT MY CHANNEL BOYS AND GIRLS ;)
HAPPY BIRTHDAY KATY :) http://giphy.com/gifs/birthday-flowers-happy-gw3JY2uqiaXKaQXS/fullscreen  (That´s not me)﻿
*for 90&amp;amp;#39;s rap fans*  check out my Big Pun - &amp;amp;#39;Beware&amp;amp;#39; cover!  Likes n comments very much appreciated!
Who&amp;amp;#39;s watching in 2015 Subscribe for me !﻿
&lt;/pre&gt;

&lt;p&gt;
You can already see that the spam has people asking viewers to check out their sites.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-org91909ee" class="outline-4"&gt;
&lt;h4 id="org91909ee"&gt;Check vs Check Out&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org91909ee"&gt;
&lt;p&gt;
Let's see which one of the strings (&lt;i&gt;check&lt;/i&gt; or &lt;i&gt;check out&lt;/i&gt;) does better for us.
&lt;/p&gt;
&lt;/div&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;&lt;a id="orgd403fd3"&gt;&lt;/a&gt;The Labeling Functions&lt;br&gt;
&lt;div class="outline-text-5" id="text-orgd403fd3"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;@labeling_function()
def check(row: pandas.Series) -&amp;gt; int:
    """sees if the word 'check' is in the comment"""
    return Comment.is_spam if "check" in row.CONTENT.lower() else Comment.is_ambiguous
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;@labeling_function()
def check_out(row: pandas.Series) -&amp;gt; int:
    """looks for phrase 'check out'"""
    return Comment.is_spam if "check out" in row.CONTENT.lower() else Comment.is_ambiguous
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a id="orgc76c9b2"&gt;&lt;/a&gt;Applying the Functions&lt;br&gt;
&lt;div class="outline-text-5" id="text-orgc76c9b2"&gt;
&lt;p&gt;
The next step is to create some Labeling Matrices using our labeling functions by applying them to our training and development sets. Since our data is stored using pandas, we'll use the &lt;code&gt;PandasLFApplier&lt;/code&gt;, but there are &lt;a href="https://snorkel.readthedocs.io/en/master/packages/labeling.html"&gt;other types available&lt;/a&gt; as well.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;labeling_functions = [check, check_out]

applier = PandasLFApplier(lfs=labeling_functions)
train_labeling_matrix = applier.apply(df=train, progress_bar=False)
development_labeling_matrix = applier.apply(df=development, progress_bar=False)
print(f"Training Labeling Matrix: {train_labeling_matrix.shape}")
print(f"Development Labeling Matrix: {development_labeling_matrix.shape}")
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Training Labeling Matrix: (1386, 2)
Development Labeling Matrix: (200, 2)
&lt;/pre&gt;


&lt;p&gt;
Each matrix has one column for each of our labeling functions (so two in this case) and one row for each of the rows in the set that the functions were applied to.
&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;

&lt;li&gt;&lt;a id="org94db4a7"&gt;&lt;/a&gt;Evaluating the Labeling Functions&lt;br&gt;
&lt;div class="outline-text-5" id="text-org94db4a7"&gt;
&lt;p&gt;
Snorkel provides a &lt;a href="https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.LFAnalysis.html"&gt;LFAnalysis&lt;/a&gt; class to help you see how well the labeling functions do.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;analysis = LFAnalysis(L=train_labeling_matrix, lfs=labeling_functions)
print(TABLE(analysis.lf_summary()))
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt; &lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;j&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Polarity&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Coverage&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Overlaps&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Conflicts&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;check&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-left"&gt;[1]&lt;/td&gt;
&lt;td class="org-right"&gt;0.257576&lt;/td&gt;
&lt;td class="org-right"&gt;0.212843&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;check_out&lt;/td&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;td class="org-left"&gt;[1]&lt;/td&gt;
&lt;td class="org-right"&gt;0.212843&lt;/td&gt;
&lt;td class="org-right"&gt;0.212843&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;
This is what the table is giving us for each of the labeling functions:
&lt;/p&gt;

&lt;ul class="org-ul"&gt;
&lt;li&gt;&lt;i&gt;j&lt;/i&gt; : I think this is just an index&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Polarity&lt;/i&gt;: The number of unique values the function puts out (other than -1, which is interpreted as an un-labeled row)&lt;/li&gt;
&lt;li&gt;/Coverage: The fraction of the data-set that the function labeled&lt;/li&gt;
&lt;li&gt;/Overlaps: The fraction of the data that the function labeled and at least one other function also labeled&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Conflicts&lt;/i&gt;: The fraction of the data that the function labeled something different from at least one other function&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;
So it looks like &lt;code&gt;check&lt;/code&gt; covers slightly more than &lt;code&gt;check_out&lt;/code&gt;, and they don't disagree with each other at all. This makes sense when you consider that &lt;code&gt;check&lt;/code&gt; is a sub-string of &lt;code&gt;check out&lt;/code&gt; - we can guess that all the overlaps are cases where &lt;code&gt;check out&lt;/code&gt; were found in the comment.
&lt;/p&gt;

&lt;p&gt;
We can also pass it a set of labels and it will see how well the functions did. In this case we have labels for all the rows, but in most cases we won't just for the development set so we'll use it here.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(TABLE(LFAnalysis(
    L=development_labeling_matrix,
    lfs=labeling_functions).lf_summary(Y=development.CLASS.values)))
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt; &lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;j&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Polarity&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Coverage&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Overlaps&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Conflicts&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Correct&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Incorrect&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Emp. Acc.&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;check&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-left"&gt;[1]&lt;/td&gt;
&lt;td class="org-right"&gt;0.26&lt;/td&gt;
&lt;td class="org-right"&gt;0.225&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-right"&gt;49&lt;/td&gt;
&lt;td class="org-right"&gt;3&lt;/td&gt;
&lt;td class="org-right"&gt;0.942308&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;check_out&lt;/td&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;td class="org-left"&gt;[1]&lt;/td&gt;
&lt;td class="org-right"&gt;0.225&lt;/td&gt;
&lt;td class="org-right"&gt;0.225&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-right"&gt;45&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;
&lt;b&gt;&lt;b&gt;Note:&lt;/b&gt;&lt;/b&gt; The &lt;code&gt;LFAnalysis&lt;/code&gt; class works with &lt;code&gt;numpy&lt;/code&gt; arrays, so when I called the &lt;code&gt;lf_summary&lt;/code&gt; method I had to pass in the &lt;code&gt;values&lt;/code&gt; and not the &lt;code&gt;CLASS&lt;/code&gt; Series.
&lt;/p&gt;

&lt;p&gt;
With our development set, the functions cover slightly less than before (as a fraction of the total), and although &lt;code&gt;check&lt;/code&gt; covers slightly more that &lt;code&gt;check_out&lt;/code&gt;, it also has some false-postives, so we'd have to decide if we care about getting all the spam or not accidentally labeling non-spam as spam.
&lt;/p&gt;

&lt;p&gt;
We can also check which ones were mis-labeled to get a better idea of how off they were.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;buckets = get_label_buckets(development.CLASS.values, development_labeling_matrix[:, 0])
for key, value in buckets.items():
    print(key)
    print(value)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
(0, -1)
[  0   1   2   3   4   7   9  10  11  12  13  15  16  17  19  22  27  28
  33  34  35  39  41  43  44  46  48  49  50  51  52  53  55  57  58  61
  62  65  66  68  78  79  81  82  86  88  89  92  94  95  98  99 100 103
 104 105 107 108 112 113 114 120 121 122 123 124 125 128 129 131 133 135
 141 142 144 146 148 150 153 154 155 162 165 166 167 168 171 173 174 179
 182 183 184 190 191 195 196 197]
(1, 1)
[  5  14  23  25  29  36  40  42  45  59  67  69  71  73  74  75  76  77
  80  83  87  90  91  93 101 109 110 116 117 126 127 134 138 139 140 143
 149 151 157 160 163 164 169 172 186 189 192 193 198]
(1, -1)
[  6   8  18  20  21  24  26  30  31  32  38  47  54  56  60  63  64  70
  72  84  85  96  97 102 106 111 115 119 130 132 136 137 145 147 152 156
 158 159 161 175 176 177 178 180 181 185 187 188 194 199]
(0, 1)
[ 37 118 170]
&lt;/pre&gt;

&lt;p&gt;
Buckets is a dict whose keys are tuples of (actual classes, predicted classes) and whose values are the indices of the rows matching the keys (so the key &lt;code&gt;(0, 1)&lt;/code&gt; returns the indices for rows where we labeled the comment as spam but it wasn't). Looking at the output you can see that the last key (0, 1) has the cases that we labeled as spam when they weren't, let's take a look at them.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;for comment in development.iloc[buckets[(Comment.is_ham, Comment.is_spam)]]["CONTENT"]:
    print(comment)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
i turned it on mute as soon is i came on i just wanted to check the  views...﻿
i check back often to help reach 2x10^9 views and I avoid watching Baby﻿
Admit it you just came here to check the number of viewers ﻿
&lt;/pre&gt;


&lt;p&gt;
It's not obvious to me how you should handle those.
&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a id="org2b15e9b"&gt;&lt;/a&gt;Check Out But Not Check&lt;br&gt;
&lt;div class="outline-text-5" id="text-org2b15e9b"&gt;
&lt;p&gt;
What are some training examples that &lt;code&gt;check&lt;/code&gt; labels but &lt;code&gt;check_out&lt;/code&gt; doesn't? We can check by feeding the columns from the labeling matrix for the &lt;code&gt;check&lt;/code&gt; and &lt;code&gt;check_out&lt;/code&gt; functions and see where &lt;code&gt;check_out&lt;/code&gt; abstained and &lt;code&gt;check&lt;/code&gt; didn't. I said earlier that the first argument to &lt;code&gt;get_label_buckets&lt;/code&gt; is the actual label, but really you can feed any two arrays and it will find give you the indices for the permutations of their row-values.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;buckets = get_label_buckets(train_labeling_matrix[:, 0], train_labeling_matrix[:, 1])
sampled = train.iloc[buckets[(Comment.is_spam, Comment.is_ambiguous)]].sample(10, random_state=Data.random_seed)
for sample in sampled.itertuples():
    print(sample.CONTENT)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Lil m !!!!! Check hi out!!!!! Does live the way you lie and many more ! Check it out!!! And subscribe
https://soundcloud.com/artady please check my stuff; and make some feedback﻿
Hey guys can you check my channel out plz. I do mine craft videos. Let's  shoot for 20 subs﻿
┏━━━┓┏┓╋┏┓┏━━━┓┏━━━┓┏┓╋╋┏┓  ┃┏━┓┃┃┃╋┃┃┃┏━┓┃┗┓┏┓┃┃┗┓┏┛┃  ┃┗━━┓┃┗━┛┃┃┃╋┃┃╋┃┃┃┃┗┓┗┛┏  ┗━━┓┃┃┏━┓┃┃┗━┛┃╋┃┃┃┃╋┗┓┏┛  ┃┗━┛┃┃┃╋┃┃┃┏━┓┃┏┛┗┛┃╋╋┃┃  ┗━━━┛┗┛╋┗┛┗┛╋┗┛┗━━━┛╋╋┗┛ CHECK MY VIDEOS AND SUBSCRIBE AND LIKE PLZZ
if you like raw talent, raw lyrics, straight real hip hop Everyone check my newest sound  Dizzy X - Got the Juice (Prod by. Drugs the Model Citizen)   COMMENT TELL ME WHAT YOU THINK  DONT BE LAZY!!!!  - 1/7 Prophetz﻿
check it out free stuff for watching videos and filling surveys&amp;lt;br /&amp;gt;&amp;lt;br /&amp;gt;&amp;lt;a href="http://www.prizerebel.com/index.php?r=1446084"&amp;gt;http://www.prizerebel.com/index.php?r=1446084&amp;lt;/a&amp;gt;﻿
Hey! I'm NERDY PEACH and I'm a new youtuber and it would mean THE ABSOLUTE  world to me if you could check 'em out! &amp;amp;lt;3  Hope you like them! =D﻿
Check my first video out﻿
http://tankionline.com#friend=cd92db3f4 great game check it out!﻿
hi beaties! i made a new channel please go check it out and subscribe and  enjoy!﻿
&lt;/pre&gt;

&lt;p&gt;
I'm going to deviate from the tutorial a little and create a regular expression to match any comment with "check" and not "view" to avoid cases where the commenter is saying that they're checking out how many views the video had.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;EXPRESSION = re.compile(r"check(?!.*view)")

assert EXPRESSION.search("everyone please come check our newest song in memories of Martin Luther  King Jr.﻿")
assert EXPRESSION.search("and u should.d check my channel and tell me what I should do next!﻿")
assert not EXPRESSION.search("Admit it you just came here to check the number of viewers ﻿")

@labeling_function()
def re_check_out(row: pandas.Series) -&amp;gt; int:
    """match cases with 'check' but not view"""
    return Comment.is_spam if EXPRESSION.search(row.CONTENT.lower()) else Comment.is_ambiguous
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;labeling_functions = [check, check_out, re_check_out]
applier = PandasLFApplier(lfs=labeling_functions)
train_labeling_matrix = applier.apply(df=train, progress_bar=False)
development_labeling_matrix = applier.apply(df=development, progress_bar=False)
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;analysis = LFAnalysis(L=train_labeling_matrix, lfs=labeling_functions)
print(TABLE(analysis.lf_summary()))
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt; &lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;j&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Polarity&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Coverage&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Overlaps&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Conflicts&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;check&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-left"&gt;[1]&lt;/td&gt;
&lt;td class="org-right"&gt;0.257576&lt;/td&gt;
&lt;td class="org-right"&gt;0.248196&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;check_out&lt;/td&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;td class="org-left"&gt;[1]&lt;/td&gt;
&lt;td class="org-right"&gt;0.212843&lt;/td&gt;
&lt;td class="org-right"&gt;0.212843&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;re_check_out&lt;/td&gt;
&lt;td class="org-right"&gt;2&lt;/td&gt;
&lt;td class="org-left"&gt;[1]&lt;/td&gt;
&lt;td class="org-right"&gt;0.243146&lt;/td&gt;
&lt;td class="org-right"&gt;0.243146&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;
Our &lt;code&gt;re_check_out&lt;/code&gt; function has a little less coverage than &lt;code&gt;check&lt;/code&gt; as we'd expect, since it excludes reviews with "view" in them but it also covers a little more than &lt;code&gt;check_out&lt;/code&gt;.
&lt;/p&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(TABLE(LFAnalysis(
    L=development_labeling_matrix,
    lfs=labeling_functions).lf_summary(Y=development.CLASS.values)))
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt; &lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;j&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Polarity&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Coverage&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Overlaps&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Conflicts&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Correct&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Incorrect&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Emp. Acc.&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;check&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-left"&gt;[1]&lt;/td&gt;
&lt;td class="org-right"&gt;0.26&lt;/td&gt;
&lt;td class="org-right"&gt;0.245&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-right"&gt;49&lt;/td&gt;
&lt;td class="org-right"&gt;3&lt;/td&gt;
&lt;td class="org-right"&gt;0.942308&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;check_out&lt;/td&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;td class="org-left"&gt;[1]&lt;/td&gt;
&lt;td class="org-right"&gt;0.225&lt;/td&gt;
&lt;td class="org-right"&gt;0.225&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-right"&gt;45&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;re_check_out&lt;/td&gt;
&lt;td class="org-right"&gt;2&lt;/td&gt;
&lt;td class="org-left"&gt;[1]&lt;/td&gt;
&lt;td class="org-right"&gt;0.245&lt;/td&gt;
&lt;td class="org-right"&gt;0.245&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-right"&gt;49&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;
It looks like we were able to avoid the false-positives by adding our regular expression.
&lt;/p&gt;



&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;buckets = get_label_buckets(development_labeling_matrix[:, 0], development_labeling_matrix[:,2])
for comment in development.iloc[buckets[(Comment.is_spam, Comment.is_ambiguous)]]["CONTENT"]:
    print(comment)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
i turned it on mute as soon is i came on i just wanted to check the  views...﻿
i check back often to help reach 2x10^9 views and I avoid watching Baby﻿
Admit it you just came here to check the number of viewers ﻿
&lt;/pre&gt;


&lt;p&gt;
So it looks like we got rid of some false positives but also missed some spam by using the regular expression. We could probably grab more by searching for "my" as well.
&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgdaac3af" class="outline-3"&gt;
&lt;h3 id="orgdaac3af"&gt;Using TextBlob with a Preprocessor&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgdaac3af"&gt;
&lt;p&gt;
Here we'll use text-blobs sentiment scorer to find comments that aren't spam. To do this we'll need to use snorkel's Preprocessor, which maps data using black-box functions.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;@preprocessor(memoize=True)
def textblob_sentiment(row: pandas.Series) -&amp;gt; pandas.Series:
    """Add the polarity and subjectivity of the comment's sentiment

    This adds two columns ('polarity' and 'subjectivity') based on the comment

    """
    blob = TextBlob(row.CONTENT)
    row["polarity"] = blob.sentiment.polarity
    row["subjectivity"] = blob.sentiment.subjectivity
    return row
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
The &lt;code&gt;polarity&lt;/code&gt; is a value from -1.0 to 1.0 which reflects how negative or positive the text is believed to be. The &lt;code&gt;subjectivity&lt;/code&gt; is a value from 0.0 to 1.0 which reflects whether the text is objective or subjective - whether it is a statement of fact or opinion.
&lt;/p&gt;

&lt;p&gt;
Now that we have the pre-processor we can use it with a labeling function.
&lt;/p&gt;
&lt;/div&gt;

&lt;div id="outline-container-org34bd21b" class="outline-4"&gt;
&lt;h4 id="org34bd21b"&gt;Polarity&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org34bd21b"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;@labeling_function(pre=[textblob_sentiment])
def textblob_polarity(row: pandas.Series) -&amp;gt; int:
    """decides if the comment is ham based on the polarity of the sentiment"""
    return Comment.is_ham if row.polarity &amp;gt; 0.9 else Comment.is_ambiguous
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgfb221bc" class="outline-4"&gt;
&lt;h4 id="orgfb221bc"&gt;Subjectivity&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgfb221bc"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;@labeling_function(pre=[textblob_sentiment])
def textblob_subjectivity(row: pandas.Series) -&amp;gt; int:
    """decides if the comment is ham based on the subjectivity"""
    return Comment.is_ham if row.subjectivity &amp;gt; 0.5 else Comment.is_ambiguous
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orga088176" class="outline-4"&gt;
&lt;h4 id="orga088176"&gt;Analyzing the Performance&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orga088176"&gt;
&lt;p&gt;
Once again, now that we have labeling functions we need to analyze how well they do.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;labeling_functions = [textblob_polarity, textblob_subjectivity]
applier = PandasLFApplier(lfs=labeling_functions)
train_label_matrix = applier.apply(train, progress_bar=False)
development_label_matrix = applier.apply(development, progress_bar=False)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(TABLE(LFAnalysis(train_label_matrix, labeling_functions).lf_summary()))
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt; &lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;j&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Polarity&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Coverage&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Overlaps&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Conflicts&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;textblob_polarity&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-left"&gt;[0]&lt;/td&gt;
&lt;td class="org-right"&gt;0.033189&lt;/td&gt;
&lt;td class="org-right"&gt;0.0122655&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;textblob_subjectivity&lt;/td&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;td class="org-left"&gt;[0]&lt;/td&gt;
&lt;td class="org-right"&gt;0.32684&lt;/td&gt;
&lt;td class="org-right"&gt;0.0122655&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(TABLE(LFAnalysis(development_label_matrix, labeling_functions).lf_summary(Y=development.CLASS.values)))
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt; &lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;j&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Polarity&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Coverage&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Overlaps&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Conflicts&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Correct&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Incorrect&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Emp. Acc.&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;textblob_polarity&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-left"&gt;[0]&lt;/td&gt;
&lt;td class="org-right"&gt;0.05&lt;/td&gt;
&lt;td class="org-right"&gt;0.025&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-right"&gt;9&lt;/td&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;td class="org-right"&gt;0.9&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;textblob_subjectivity&lt;/td&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;td class="org-left"&gt;[0]&lt;/td&gt;
&lt;td class="org-right"&gt;0.3&lt;/td&gt;
&lt;td class="org-right"&gt;0.025&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-right"&gt;32&lt;/td&gt;
&lt;td class="org-right"&gt;28&lt;/td&gt;
&lt;td class="org-right"&gt;0.533333&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;
Subjectivity seems to have much better coverage, but it was also fairly inaccurate.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgd7660b8" class="outline-3"&gt;
&lt;h3 id="orgd7660b8"&gt;More Labeling Functions&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgd7660b8"&gt;
&lt;p&gt;
We previously created a keyword-based labeling function for "check". Because using keywords is such a common thing Snorkel has a way to create them with a little less work than creating the labeling functions individually.
&lt;/p&gt;

&lt;p&gt;
First we make a function that checks if any of a collection of keywords is in the comment.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def lookup_keyword(row: pandas.Series, keywords: list, label: int) -&amp;gt; int:
    """check if any of the keywords are in the comment

    Args:
     row: the series with the Comment
     keywords: collection of keywords indicating spam
     label: what to return if the keyword is in the comment

    Returns:
     label if keyword in comment else -1
    """
    return label if any(keyword in row.CONTENT.lower() for keyword in keywords) else Comment.is_ambiguous
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Now we make the labeling-function creator that uses the &lt;code&gt;lookup_keyword&lt;/code&gt;.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def make_keyword_labeling_function(keywords: list, label: int=Comment.is_spam) -&amp;gt; LabelingFunction:
    """Makes LabelingFunction objects that check keywords"""
    return LabelingFunction(
	name=f"keyword_{keywords[0]}",
	f=lookup_keyword,
	resources=dict(keywords=keywords, label=label)
    )
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;keyword_my = make_keyword_labeling_function(keywords=["my"])
keyword_subscribe = make_keyword_labeling_function(keywords=["subscribe"])
keyword_link = make_keyword_labeling_function(keywords=["http"])
keyword_please = make_keyword_labeling_function(keywords=["please", "plz"])
keyword_song = make_keyword_labeling_function(keywords=["song"], label=Comment.is_ham)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;labeling_functions = [
    keyword_my,
    keyword_subscribe,
    keyword_link,
    keyword_please,
    keyword_song,
]
applier = PandasLFApplier(lfs=labeling_functions)
train_label_matrix = applier.apply(train, progress_bar=False)
development_label_matrix = applier.apply(development, progress_bar=False)
print(TABLE(LFAnalysis(development_label_matrix, labeling_functions).lf_summary(Y=development.CLASS.values)))
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt; &lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;j&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Polarity&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Coverage&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Overlaps&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Conflicts&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Correct&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Incorrect&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Emp. Acc.&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;keyword_my&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-left"&gt;[1]&lt;/td&gt;
&lt;td class="org-right"&gt;0.18&lt;/td&gt;
&lt;td class="org-right"&gt;0.115&lt;/td&gt;
&lt;td class="org-right"&gt;0.05&lt;/td&gt;
&lt;td class="org-right"&gt;33&lt;/td&gt;
&lt;td class="org-right"&gt;3&lt;/td&gt;
&lt;td class="org-right"&gt;0.916667&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;keyword_subscribe&lt;/td&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;td class="org-left"&gt;[1]&lt;/td&gt;
&lt;td class="org-right"&gt;0.125&lt;/td&gt;
&lt;td class="org-right"&gt;0.075&lt;/td&gt;
&lt;td class="org-right"&gt;0.015&lt;/td&gt;
&lt;td class="org-right"&gt;25&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;keyword_http&lt;/td&gt;
&lt;td class="org-right"&gt;2&lt;/td&gt;
&lt;td class="org-left"&gt;[1]&lt;/td&gt;
&lt;td class="org-right"&gt;0.09&lt;/td&gt;
&lt;td class="org-right"&gt;0.03&lt;/td&gt;
&lt;td class="org-right"&gt;0.005&lt;/td&gt;
&lt;td class="org-right"&gt;16&lt;/td&gt;
&lt;td class="org-right"&gt;2&lt;/td&gt;
&lt;td class="org-right"&gt;0.888889&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;keyword_please&lt;/td&gt;
&lt;td class="org-right"&gt;3&lt;/td&gt;
&lt;td class="org-left"&gt;[1]&lt;/td&gt;
&lt;td class="org-right"&gt;0.095&lt;/td&gt;
&lt;td class="org-right"&gt;0.08&lt;/td&gt;
&lt;td class="org-right"&gt;0.02&lt;/td&gt;
&lt;td class="org-right"&gt;19&lt;/td&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;keyword_song&lt;/td&gt;
&lt;td class="org-right"&gt;4&lt;/td&gt;
&lt;td class="org-left"&gt;[0]&lt;/td&gt;
&lt;td class="org-right"&gt;0.16&lt;/td&gt;
&lt;td class="org-right"&gt;0.06&lt;/td&gt;
&lt;td class="org-right"&gt;0.06&lt;/td&gt;
&lt;td class="org-right"&gt;20&lt;/td&gt;
&lt;td class="org-right"&gt;12&lt;/td&gt;
&lt;td class="org-right"&gt;0.625&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;
There are varying degrees of coveragen and accuracy with these. Interestingly, the &lt;code&gt;subscribe&lt;/code&gt; keyword was completely accurate and had pretty good coverage (compared to our check-out labelers).
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org99ea299" class="outline-3"&gt;
&lt;h3 id="org99ea299"&gt;Adding a Spacy Preprocessor&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org99ea299"&gt;
&lt;p&gt;
The purpose of the pre-processors is to do a little feature engineering to add features that aren't in the original dataset but which can be derived from it. Becaues SpaCY is used so much for this, snorkel comes with a labeling function that adds a &lt;code&gt;doc&lt;/code&gt; attribute (you can also create it manually to get more control).
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;@nlp_labeling_function()
def short_with_person(row: pandas.Series) -&amp;gt; int:
    """Check if the comment is short and mentions a person"""
    return (Comment.is_ham if (len(row.CONTENT) &amp;lt; 20 and any((entity.label_=="PERSON" for entity in row.dot.ents)))
			       else Comment.is_ambiguous)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>data</category><category>exploration</category><category>snorkel</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-data-labeling/</guid><pubDate>Fri, 10 Jan 2020 01:07:33 GMT</pubDate></item><item><title>Snorkel Example: Building a Spam Dataset</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-example-building-a-spam-dataset/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-example-building-a-spam-dataset/#org89a3c47"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-example-building-a-spam-dataset/#org7968733"&gt;Imports&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-example-building-a-spam-dataset/#orgdb7cb96"&gt;Set Up&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-example-building-a-spam-dataset/#org9480efd"&gt;Middle&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-example-building-a-spam-dataset/#org13e9910"&gt;Labeling Functions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-example-building-a-spam-dataset/#org6de3899"&gt;Data Augmentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-example-building-a-spam-dataset/#org4799114"&gt;Slicing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-example-building-a-spam-dataset/#org9899a6d"&gt;End&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-example-building-a-spam-dataset/#org0072178"&gt;Train A Classifier&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org89a3c47" class="outline-2"&gt;
&lt;h2 id="org89a3c47"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org89a3c47"&gt;
&lt;p&gt;
This is a walk-through of the Snorkel &lt;a href="https://www.snorkel.org/get-started/"&gt;Get Started&lt;/a&gt; tutorial which shows how you can use it to build a labeled dataset. It uses the &lt;a href="http://www.dt.fee.unicamp.br/~tiago//youtubespamcollection/"&gt;YouTube Spam Collection&lt;/a&gt; data set (downloaded from the &lt;a href="https://archive.ics.uci.edu/ml/datasets/YouTube+Spam+Collection"&gt;UCI Machine Learning Repository&lt;/a&gt;). The data was collected in 2015 and represents comments from five of the ten most popular videos on YouTube. It is a tabular dataset with the columns &lt;code&gt;COMMENT_ID&lt;/code&gt;, &lt;code&gt;AUTHOR&lt;/code&gt;, &lt;code&gt;DATE&lt;/code&gt;, &lt;code&gt;CONTENT&lt;/code&gt;, &lt;code&gt;TAG&lt;/code&gt;. The tag represents whether it was considered &lt;i&gt;Spam&lt;/i&gt; or not, so we'll pretend it isn't there for most of this walk-through.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7968733" class="outline-3"&gt;
&lt;h3 id="org7968733"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org7968733"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org3420f0c" class="outline-4"&gt;
&lt;h4 id="org3420f0c"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org3420f0c"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from argparse import Namespace
from functools import partial
from pathlib import Path
import random
import re
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgc91dc97" class="outline-4"&gt;
&lt;h4 id="orgc91dc97"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgc91dc97"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from nltk.corpus import wordnet
from sklearn import metrics
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from snorkel.augmentation import ApplyOnePolicy, PandasTFApplier, transformation_function
from snorkel.labeling import labeling_function, LabelModel, PandasLFApplier
from snorkel.slicing import slicing_function
from textblob import TextBlob
import hvplot.pandas
import nltk
import pandas
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org0ccb75a" class="outline-4"&gt;
&lt;h4 id="org0ccb75a"&gt;Others&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org0ccb75a"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from graeae import CountPercentage, EmbedHoloviews
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgdb7cb96" class="outline-3"&gt;
&lt;h3 id="orgdb7cb96"&gt;Set Up&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgdb7cb96"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org140b22d" class="outline-4"&gt;
&lt;h4 id="org140b22d"&gt;The WordNet Corpus&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org140b22d"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;nltk.download("wordnet", quiet=True)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org0ee993b" class="outline-4"&gt;
&lt;h4 id="org0ee993b"&gt;Plotting&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org0ee993b"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Embed = partial(EmbedHoloviews, folder_path="../../../files/posts/libraries/snorkel/snorkel-example-building-a-spam-dataset")
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org0e59cdc" class="outline-4"&gt;
&lt;h4 id="org0e59cdc"&gt;The Dataset&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org0e59cdc"&gt;
&lt;p&gt;
The data is split up into separate files - one for each artist/video (they are named after the artist and each only appears to have one entry) so I'm going to smash them back together and add a &lt;code&gt;artist&lt;/code&gt; column.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;path = Path("~/data/datasets/texts/you_tube_comments/").expanduser()
sets = []
for name in path.glob("*.csv"):
    artist = name.stem.split()[-1]
    data = pandas.read_csv(name)
    data["artist"] = artist
    sets.append(data)
    print(artist)
data = pandas.concat(sets)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
KatyPerry
LMFAO
Eminem
Shakira
Psy
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;


&lt;div id="outline-container-org91c7de7" class="outline-4"&gt;
&lt;h4 id="org91c7de7"&gt;Splitting the Set&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org91c7de7"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;train, test = train_test_split(data)
print(train.shape)
print(test.shape)

train, development = train_test_split(train)
validation, test = train_test_split(test)
print(train.shape)
print(development.shape)
print(validation.shape)
print(test.shape)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
(1467, 6)
(489, 6)
(1100, 6)
(367, 6)
(366, 6)
(123, 6)
&lt;/pre&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;grouped = train.groupby(["artist"]).agg({"COMMENT_ID": "count"}).reset_index().rename(columns={"COMMENT_ID": "Count"})
plot = grouped.hvplot.bar(x="artist", y="Count").opts(title="Comments by Artist", width=1000, height=800)
Embed(plot=plot, file_name="comments_by_artist")()
&lt;/pre&gt;&lt;/div&gt;

&lt;object type="text/html" data="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-example-building-a-spam-dataset/comments_by_artist.html" style="width:100%" height="800"&gt;
  &lt;p&gt;Figure Missing&lt;/p&gt;
&lt;/object&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;grouped = train.groupby(["artist", "CLASS"]).agg({"COMMENT_ID": "count"}).reset_index().rename(columns={"COMMENT_ID": "Count"})
plot = grouped.hvplot.bar(x="artist", y="Count", by="CLASS").opts(title="Comments by Artist and Class", width=1000, height=800)
Embed(plot=plot, file_name="comments_by_artist_and_class")()
&lt;/pre&gt;&lt;/div&gt;

&lt;object type="text/html" data="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-example-building-a-spam-dataset/comments_by_artist_and_class.html" style="width:100%" height="800"&gt;
  &lt;p&gt;Figure Missing&lt;/p&gt;
&lt;/object&gt;

&lt;p&gt;
I said earlier that the spam/not-spam column was named tag, but its named &lt;code&gt;CLASS&lt;/code&gt; here, I don't know where the switch came (it says &lt;code&gt;TAG&lt;/code&gt; on the UCI page).
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org9480efd" class="outline-2"&gt;
&lt;h2 id="org9480efd"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org9480efd"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org13e9910" class="outline-3"&gt;
&lt;h3 id="org13e9910"&gt;Labeling Functions&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org13e9910"&gt;
&lt;p&gt;
Labeling functions output a label for values in the training set.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgb63ee9a" class="outline-4"&gt;
&lt;h4 id="orgb63ee9a"&gt;Labels&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgb63ee9a"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Label = Namespace(
    abstain = -1,
    not_spam = 0,
    spam = 1,
)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
The actual data-set only has spam/not-spam classes, but the Snorkel tutorial adds the &lt;code&gt;abstain&lt;/code&gt; class as well. Each function is going to be passed a row from the training dataframe, so the class name you use has to match it.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgee81dc8" class="outline-4"&gt;
&lt;h4 id="orgee81dc8"&gt;Keyword Matching&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgee81dc8"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;@labeling_function()
def labeling_by_keyword(comment: pandas.Series) -&amp;gt; int:
    """Assume if the author refers to something he/she owns it's spam

    Args: 
     row with comment CONTENT

    Returns:
     label for the comment
    """
    return Label.spam if "my" in comment.CONTENT.lower() else Label.abstain
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org3828297" class="outline-4"&gt;
&lt;h4 id="org3828297"&gt;Regular Expressions&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org3828297"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;@labeling_function()
def label_check_out(comment) -&amp;gt; int:
    """check my/it/the out will be spam"""
    return Label.spam if re.search(r"check.*out", comment.CONTENT, flags=re.I) else Label.abstain
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org397666a" class="outline-4"&gt;
&lt;h4 id="org397666a"&gt;Short Comments&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org397666a"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;@labeling_function()
def label_short_comment(comment) -&amp;gt; int:
    """if a comment is short it's probably not spam"""
    return Label.not_spam if len(comment.CONTENT.split()) &amp;lt; 5 else Label.abstain
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgd454a3d" class="outline-4"&gt;
&lt;h4 id="orgd454a3d"&gt;Positive Comments&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgd454a3d"&gt;
&lt;p&gt;
Here we'll use &lt;a href="https://textblob.readthedocs.io/en/dev/"&gt;textblob&lt;/a&gt; to try and decide on whether a comment is positive (textblob uses &lt;a href="https://www.clips.uantwerpen.be/pattern"&gt;pattern&lt;/a&gt; to decide on the polarity.)
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;@labeling_function()
def label_positive_comment(comment) -&amp;gt; int:
    """If a comment is positive, we'll accept it"""
    return Label.not_spam if TextBlob(comment.CONTENT).sentiment.polarity &amp;gt; 0.3 else Label.abstain
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgeea7f75" class="outline-4"&gt;
&lt;h4 id="orgeea7f75"&gt;Combining the Functions and Cleaning the Labels&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgeea7f75"&gt;
&lt;p&gt;
First I'll create a list of the labeling functions so that we can pass it to the label-applier class.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;labeling_functions = [labeling_by_keyword, label_check_out, label_short_comment, label_positive_comment]
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Now create the applier.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;applier = PandasLFApplier(labeling_functions)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
Now create it.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;label_matrix = applier.apply(train, progress_bar=False)

print(label_matrix.shape)
print(train.shape)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
(1100, 4)
(1100, 6)
&lt;/pre&gt;


&lt;p&gt;
The label-matrix has one row for each of the comments in our training set and one column for each of our labeling functions.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;label_frame = pandas.DataFrame(label_matrix, columns=["keyword", "check_out", "short", "positive"])
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;re_framed = {}

for column in label_frame.columns:
    re_framed[column] = 
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org6cd1648" class="outline-4"&gt;
&lt;h4 id="org6cd1648"&gt;Training the Label Model&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org6cd1648"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;label_model = LabelModel(cardinality=2, verbose=True)
label_model.fit(label_matrix, n_epochs=500, log_freq=50, seed=0)
train["label"] = label_model.predict(L=label_matrix, tie_break_policy="abstain")
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;grouped = train.groupby(["label", "artist"]).agg({"COMMENT_ID": "count"}).reset_index().rename(columns={"COMMENT_ID": "count"})
plot = grouped.hvplot.bar(x="label", y="count", by="artist").opts(title="Label Counts", height=800, width=1000)
Embed(plot=plot, file_name="label_counts")()
&lt;/pre&gt;&lt;/div&gt;

&lt;object type="text/html" data="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-example-building-a-spam-dataset/label_counts.html" style="width:100%" height="800"&gt;
  &lt;p&gt;Figure Missing&lt;/p&gt;
&lt;/object&gt;

&lt;p&gt;
Most comments were labeled spam or not-spam, but some were abstained. In order to move on to the next section, we'll drop the rows where an opinion about the label was abstained.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;train = train[train.label != Label.abstain]
CountPercentage(train.label)()
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;

&lt;col class="org-right"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-right"&gt;Value&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Count&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Percent (%)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-right"&gt;419&lt;/td&gt;
&lt;td class="org-right"&gt;53.51&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;td class="org-right"&gt;364&lt;/td&gt;
&lt;td class="org-right"&gt;46.49&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;matched = sum(train.label == train.CLASS)
print(f"{matched/len(train): .2f}")
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
0.51
&lt;/pre&gt;


&lt;p&gt;
Of those that were matched, only a little more than half agree with the labels given by the dataset creators.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org6de3899" class="outline-3"&gt;
&lt;h3 id="org6de3899"&gt;Data Augmentation&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org6de3899"&gt;
&lt;p&gt;
We're going to create new entries in the data by randomly replacing words with their synonyms.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgc686f43" class="outline-4"&gt;
&lt;h4 id="orgc686f43"&gt;Synonym Lookup Function&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgc686f43"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def synonyms_for(word: str) -&amp;gt; list:
    """get synonyms for word"""
    lemmas = set().union(*[synset.lemmas() for synset in wordnet.synsets(word)])
    return list(set(lemma.name().lower().replace("_" , " ") for lemma in lemmas) - {word})
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org98d2a72" class="outline-4"&gt;
&lt;h4 id="org98d2a72"&gt;The Transformation Function&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org98d2a72"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;@transformation_function()
def replace_word_with_synonym(comment: pandas.Series) -&amp;gt; pandas.Series:
    """Replace one of the words with a synonym

    Args:
     comment: row with a comment

    Returns:
     comment with a word replaced
    """
    tokens = comment.CONTENT.lower().split()
    index = random.choice(range(len(tokens)))
    synonyms = synonyms_for(tokens[index])
    if synonyms:
	comment.CONTENT = " ".join(tokens[:index] + [synonyms[0]] + tokens[index + 1 :])
    return comment
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;transform_policy = ApplyOnePolicy(n_per_original=2, keep_original=True)
transform_applier = PandasTFApplier([replace_word_with_synonym], transform_policy)
train_augmented = transform_applier.apply(train, progress_bar=False)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(train_augmented[:3].CONTENT)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
415           very good song:)﻿
415    very respectable song:)﻿
415           very good song:)﻿
Name: CONTENT, dtype: object
&lt;/pre&gt;


&lt;p&gt;
Because it's random, we don't always end up with different content.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(f"{len(train_augmented):,}")
train_augmented = train_augmented.drop_duplicates(subset="CONTENT")
print(f"{len(train_augmented):,}")
print(f"{len(train):,}")
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
2,349
1,357
783
&lt;/pre&gt;


&lt;p&gt;
So we added some content.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org4799114" class="outline-3"&gt;
&lt;h3 id="org4799114"&gt;Slicing&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org4799114"&gt;
&lt;p&gt;
A &lt;i&gt;slice&lt;/i&gt; is a subset of the data - in this case we want to identify slices that might be more important than others. In this case we're going to assume that we've identified that short links are more likely to be malicious, so we want to be more aware of them.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;@slicing_function()
def short_link(comment: pandas.Series) -&amp;gt; int:
    """checks for shortened links in the comment

    Args:
     comment: row with comment in it

    Returns:
     1 if short-link detected, 0 otherwise
    """
    return int(bool(re.search(r"\w+\.ly", comment.CONTENT)))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org9899a6d" class="outline-2"&gt;
&lt;h2 id="org9899a6d"&gt;End&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org9899a6d"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org0072178" class="outline-3"&gt;
&lt;h3 id="org0072178"&gt;Train A Classifier&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org0072178"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;training_text = train_augmented.CONTENT.tolist()
vectorizer = CountVectorizer(ngram_range=(1, 2))
x_train = vectorizer.fit_transform(training_text)

classifier = LogisticRegression(solver="lbfgs")
classifier.fit(x_train, train_augmented.label.values)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;development_test = vectorizer.transform(development.CONTENT)
development["predicted"] = classifier.predict(development_test)

print(f"{sum(development.CLASS == development.predicted)/len(development):.2f}")
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
0.54
&lt;/pre&gt;


&lt;p&gt;
So our model is almost random.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(metrics.classification_report(development.CLASS, development.predicted, target_names=["not spam", "spam"]))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
              precision    recall  f1-score   support

    not spam       0.56      0.61      0.58       194
        spam       0.51      0.45      0.48       173

    accuracy                           0.54       367
   macro avg       0.53      0.53      0.53       367
weighted avg       0.53      0.54      0.53       367

&lt;/pre&gt;
&lt;/div&gt;
&lt;div id="outline-container-org898d8b7" class="outline-4"&gt;
&lt;h4 id="org898d8b7"&gt;Training on the Original Labels&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org898d8b7"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;vectorizer = CountVectorizer(ngram_range=(1, 2))
x_train = vectorizer.fit_transform(train.CONTENT)

classifier = LogisticRegression(solver="lbfgs")
classifier.fit(x_train, train.CLASS.values)

development_test = vectorizer.transform(development.CONTENT)
predicted = classifier.predict(development_test)

print(metrics.classification_report(development.CLASS, predicted, target_names=["not spam", "spam"]))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
              precision    recall  f1-score   support

    not spam       0.91      0.97      0.94       194
        spam       0.97      0.90      0.93       173

    accuracy                           0.94       367
   macro avg       0.94      0.94      0.94       367
weighted avg       0.94      0.94      0.94       367

&lt;/pre&gt;


&lt;p&gt;
So our self-labeled data set really hurt the performance, but this was the Getting Started tutorial, so it was meant to be just a skimming of what the basic procedure is, hopefully tuning the labeling and transformations more would improve the performance.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>data labeling</category><category>snorkel</category><category>weak supervision</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/snorkel/snorkel-example-building-a-spam-dataset/</guid><pubDate>Tue, 07 Jan 2020 01:40:40 GMT</pubDate></item><item><title>Trying out DABEST</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/trying-out-dabest/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/trying-out-dabest/#org11bd7bb"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/trying-out-dabest/#orgdb433f1"&gt;Imports&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/trying-out-dabest/#org28995cc"&gt;Set Up&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/trying-out-dabest/#org0ef2ac9"&gt;Middle&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/trying-out-dabest/#orgd119e94"&gt;Petal Width&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/trying-out-dabest/#org5d88711"&gt;Hedge's G&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/trying-out-dabest/#orgeb657d5"&gt;Cohen's D&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org11bd7bb" class="outline-2"&gt;
&lt;h2 id="org11bd7bb"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org11bd7bb"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgdb433f1" class="outline-3"&gt;
&lt;h3 id="orgdb433f1"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgdb433f1"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org6aed581" class="outline-4"&gt;
&lt;h4 id="org6aed581"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org6aed581"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from sklearn.datasets import load_iris
import dabest
import pandas
import seaborn
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org28995cc" class="outline-3"&gt;
&lt;h3 id="org28995cc"&gt;Set Up&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org28995cc"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org49fbab0" class="outline-4"&gt;
&lt;h4 id="org49fbab0"&gt;The Data Set&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org49fbab0"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;iris = load_iris()
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(iris.DESCR)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Iris plants dataset
--------------------

**Data Set Characteristics:**

    :Number of Instances: 150 (50 in each of three classes)
    :Number of Attributes: 4 numeric, predictive attributes and the class
    :Attribute Information:
        - sepal length in cm
        - sepal width in cm
        - petal length in cm
        - petal width in cm
        - class:
                - Iris-Setosa
                - Iris-Versicolour
                - Iris-Virginica
                
    :Summary Statistics:

    ============== ==== ==== ======= ===== ====================
                    Min  Max   Mean    SD   Class Correlation
    ============== ==== ==== ======= ===== ====================
    sepal length:   4.3  7.9   5.84   0.83    0.7826
    sepal width:    2.0  4.4   3.05   0.43   -0.4194
    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)
    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)
    ============== ==== ==== ======= ===== ====================

    :Missing Attribute Values: None
    :Class Distribution: 33.3% for each of 3 classes.
    :Creator: R.A. Fisher
    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)
    :Date: July, 1988

The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken
from Fisher's paper. Note that it's the same as in R, but not as in the UCI
Machine Learning Repository, which has two wrong data points.

This is perhaps the best known database to be found in the
pattern recognition literature.  Fisher's paper is a classic in the field and
is referenced frequently to this day.  (See Duda &amp;amp; Hart, for example.)  The
data set contains 3 classes of 50 instances each, where each class refers to a
type of iris plant.  One class is linearly separable from the other 2; the
latter are NOT linearly separable from each other.

.. topic:: References

   - Fisher, R.A. "The use of multiple measurements in taxonomic problems"
     Annual Eugenics, 7, Part II, 179-188 (1936); also in "Contributions to
     Mathematical Statistics" (John Wiley, NY, 1950).
   - Duda, R.O., &amp;amp; Hart, P.E. (1973) Pattern Classification and Scene Analysis.
     (Q327.D83) John Wiley &amp;amp; Sons.  ISBN 0-471-22361-1.  See page 218.
   - Dasarathy, B.V. (1980) "Nosing Around the Neighborhood: A New System
     Structure and Classification Rule for Recognition in Partially Exposed
     Environments".  IEEE Transactions on Pattern Analysis and Machine
     Intelligence, Vol. PAMI-2, No. 1, 67-71.
   - Gates, G.W. (1972) "The Reduced Nearest Neighbor Rule".  IEEE Transactions
     on Information Theory, May 1972, 431-433.
   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al"s AUTOCLASS II
     conceptual clustering system finds 3 classes in the data.
   - Many, many more ...
&lt;/pre&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;data = pandas.DataFrame(iris.data, columns=iris.feature_names)
target = pandas.Series(iris.target)
names = dict(zip(range(len(iris.target_names)), iris.target_names))
data["species"] = target.map(names)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org0ef2ac9" class="outline-2"&gt;
&lt;h2 id="org0ef2ac9"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org0ef2ac9"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgd119e94" class="outline-3"&gt;
&lt;h3 id="orgd119e94"&gt;Petal Width&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgd119e94"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;iris_dabest = dabest.load(data=data, x="species", y="petal width (cm)", idx=iris.target_names)
iris_dabest.mean_diff.plot()
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/trying-out-dabest/petal_width.png" alt="petal_width.png"&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org5d88711" class="outline-3"&gt;
&lt;h3 id="org5d88711"&gt;Hedge's G&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org5d88711"&gt;
&lt;p&gt;
&lt;a href="https://www.itl.nist.gov/div898/software/dataplot/refman2/auxillar/hedgeg.htm"&gt;Hedges G&lt;/a&gt; is a measurement of effect size, similar to Cohen's d but with better properties when the samples are smaller or the sample sizes are different.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;iris_dabest.hedges_g.plot()
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/trying-out-dabest/hedges_g.png" alt="hedges_g.png"&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(iris_dabest.hedges_g)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
DABEST v0.2.7
=============
             
Good afternoon!
The current time is Mon Dec 16 15:56:24 2019.

The unpaired Hedges' g between setosa and versicolor is 6.76 [95%CI 5.71, 7.86].
The two-sided p-value of the Mann-Whitney test is 2.28e-18.

The unpaired Hedges' g between setosa and virginica is 8.49 [95%CI 7.08, 9.77].
The two-sided p-value of the Mann-Whitney test is 2.43e-18.

5000 bootstrap samples were taken; the confidence interval is bias-corrected and accelerated.
The p-value(s) reported are the likelihood(s) of observing the effect size(s),
if the null hypothesis of zero difference is true.

To get the results of all valid statistical tests, use `.hedges_g.statistical_tests`
&lt;/pre&gt;

&lt;p&gt;
According to &lt;a href="https://www.wikiwand.com/en/Effect_size"&gt;Wikipedia&lt;/a&gt;, an effect size of 2 is "huge" so since the differences between the setosa and versicolor and setosa and virginica are 6.76 and 8.49 respectively, we might conclude that there is a significant difference between the petal width of the setosa and the other two species.
&lt;/p&gt;

&lt;p&gt;
I don't think that's really what this is meant for, but I just wanted to see how it works.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgeb657d5" class="outline-3"&gt;
&lt;h3 id="orgeb657d5"&gt;Cohen's D&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgeb657d5"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;iris_dabest.cohens_d.plot()
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/trying-out-dabest/cohens_d.png" alt="cohens_d.png"&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(iris_dabest.cohens_d)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
DABEST v0.2.7
=============
             
Good afternoon!
The current time is Mon Dec 16 16:46:25 2019.

The unpaired Cohen's d between setosa and versicolor is 6.82 [95%CI 5.76, 7.92].
The two-sided p-value of the Mann-Whitney test is 2.28e-18.

The unpaired Cohen's d between setosa and virginica is 8.56 [95%CI 7.13, 9.85].
The two-sided p-value of the Mann-Whitney test is 2.43e-18.

5000 bootstrap samples were taken; the confidence interval is bias-corrected and accelerated.
The p-value(s) reported are the likelihood(s) of observing the effect size(s),
if the null hypothesis of zero difference is true.

To get the results of all valid statistical tests, use `.cohens_d.statistical_tests`
&lt;/pre&gt;

&lt;p&gt;
In this case the Cohen's d and Hedges g look similar.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>exploration</category><category>statistics</category><category>visualization</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/trying-out-dabest/</guid><pubDate>Mon, 16 Dec 2019 21:50:24 GMT</pubDate></item><item><title>A First Look At DABEST</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/a-first-look-at-dabest/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/a-first-look-at-dabest/#orgc1a8a9e"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/a-first-look-at-dabest/#org2e82353"&gt;Imports&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/a-first-look-at-dabest/#orgfd82f5d"&gt;PyPi&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgc1a8a9e" class="outline-2"&gt;
&lt;h2 id="orgc1a8a9e"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgc1a8a9e"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org2e82353" class="outline-3"&gt;
&lt;h3 id="org2e82353"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org2e82353"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgfd82f5d" class="outline-4"&gt;
&lt;h4 id="orgfd82f5d"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgfd82f5d"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from sklearn.datasets import load_iris
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>dabest</category><category>visalization</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/libraries/a-first-look-at-dabest/</guid><pubDate>Mon, 16 Dec 2019 07:18:50 GMT</pubDate></item><item><title>A First Look At Snorkel</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/#org83af856"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/#org50b1cc8"&gt;Imports&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/#orgbef0233"&gt;Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/#org1cfa078"&gt;PyPi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/#orgeef6a87"&gt;Others&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/#orgbeae10d"&gt;Set Up&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/#org5c6ade9"&gt;Some Constants&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/#org64c9634"&gt;The Plotting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/#orgfbafcf0"&gt;The Data Set&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/#orgaf96094"&gt;Rename the Columns&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/#org12c172b"&gt;Middle&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/#org88e7e5b"&gt;Setting Up the Training and Testing Sets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/#orgad9c906"&gt;Looking at the Data&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/#org6025f0a"&gt;Spam and Ham&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/#org5b86e70"&gt;The Dates&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/#org04c222b"&gt;Some Samples&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/#orgb646f5e"&gt;Labeling Functions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/#orgd3004ee"&gt;End&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/#org5d50667"&gt;Citations&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org83af856" class="outline-2"&gt;
&lt;h2 id="org83af856"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org83af856"&gt;
&lt;p&gt;
This is a walk-through of Snorkel's &lt;a href="https://www.snorkel.org/get-started/"&gt;Get Started&lt;/a&gt; page.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-org50b1cc8" class="outline-3"&gt;
&lt;h3 id="org50b1cc8"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org50b1cc8"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgbef0233" class="outline-4"&gt;
&lt;h4 id="orgbef0233"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgbef0233"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from argparse import Namespace
from datetime import datetime
from functools import partial
from pathlib import Path
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org1cfa078" class="outline-4"&gt;
&lt;h4 id="org1cfa078"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org1cfa078"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from sklearn.model_selection import train_test_split
import hvplot.pandas
import pandas
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgeef6a87" class="outline-4"&gt;
&lt;h4 id="orgeef6a87"&gt;Others&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgeef6a87"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from graeae import CountPercentage, EmbedHoloviews
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgbeae10d" class="outline-3"&gt;
&lt;h3 id="orgbeae10d"&gt;Set Up&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgbeae10d"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org5c6ade9" class="outline-4"&gt;
&lt;h4 id="org5c6ade9"&gt;Some Constants&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org5c6ade9"&gt;
&lt;p&gt;
There are two classes in the data set - &lt;i&gt;spam&lt;/i&gt; and &lt;i&gt;not spam&lt;/i&gt;, and for the labeling that we're going to do we also need a third value for the cases where the code can't give it a label.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;classified_as = Namespace(
    not_spam = 0,
    spam = 1,
    unknown = -1,
)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org64c9634" class="outline-4"&gt;
&lt;h4 id="org64c9634"&gt;The Plotting&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org64c9634"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;path = "../../files/posts/data/a-first-look-at-snorkel"
Embed = partial(EmbedHoloviews, folder_path=path)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgfbafcf0" class="outline-4"&gt;
&lt;h4 id="orgfbafcf0"&gt;The Data Set&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgfbafcf0"&gt;
&lt;p&gt;
This dataset is a set of comments taken from you-tube videos and hosted on &lt;a href="http://www.dt.fee.unicamp.br/~tiago//youtubespamcollection/"&gt;this site&lt;/a&gt;. The comments are for music videos by five artists.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;path = Path("~/data/datasets/texts/you_tube_comments/").expanduser()
assert path.is_dir()

parts = []
for name in path.glob("*csv"):
    data = pandas.read_csv(name)    
    data["artist"] = name.name.split()[-1].split(".")[0]
    parts.append(data)

data = pandas.concat(parts)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgaf96094" class="outline-4"&gt;
&lt;h4 id="orgaf96094"&gt;Rename the Columns&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgaf96094"&gt;
&lt;p&gt;
This just makes it easier for me since it matches my style.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Column = Namespace(
    comment_id = "comment_id",
    author = "author",
    datetime = "datetime",
    text = "text",
    label = "label",
    artist = "artist",
)
renames = {"COMMENT_ID": Column.comment_id,
	   "AUTHOR": Column.author,
	   "DATE": Column.datetime,
	   "CONTENT": Column.text,
	   "CLASS": Column.label}
data = data.rename(columns=renames)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org12c172b" class="outline-2"&gt;
&lt;h2 id="org12c172b"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org12c172b"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org88e7e5b" class="outline-3"&gt;
&lt;h3 id="org88e7e5b"&gt;Setting Up the Training and Testing Sets&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org88e7e5b"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;x_train, x_test, y_train, y_test = train_test_split(data[Column.comment_id,
							 Column.author,
							 Column.datetime,
							 Column.text,
							 Column.artist],
						    data[Column.label],
						    test_size=0.2)
x_train, x_dev, y_train, y_dev = train_test_split(x_train, y_train,
						  test_size=0.1)
x_test, x_validation, y_test, y_validation = train_test_split(x_test, y_test,
							      test_size=0.1)

print(f"Training Size: {len(x_train):,}")
print(f"Development Size: {len(x_dev):,}")
print(f"Validation Size: {len(x_validation):,}")
print(f"Test Size: {len(x_test):,}")
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Training Size: 1,407
Development Size: 157
Validation Size: 40
Test Size: 352

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgad9c906" class="outline-3"&gt;
&lt;h3 id="orgad9c906"&gt;Looking at the Data&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgad9c906"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(x_dev.sample().iloc[0])
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
If I get 100 subscribers, I will summon Freddy Mercury's ghost to whipe  from the face of earth One Direction and Miley Cirus.﻿

&lt;/pre&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(f"{len(data):,}")
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
1,956

&lt;/pre&gt;
&lt;/div&gt;

&lt;div id="outline-container-org6025f0a" class="outline-4"&gt;
&lt;h4 id="org6025f0a"&gt;Spam and Ham&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org6025f0a"&gt;
&lt;p&gt;
There are two classes in the dataset - SPAM (1) and not-spam (0), sometimes called HAM.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;counter = CountPercentage(data.label)
counter()
&lt;/pre&gt;&lt;/div&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-right"&gt;

&lt;col class="org-left"&gt;

&lt;col class="org-right"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-right"&gt;Value&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Count&lt;/th&gt;
&lt;th scope="col" class="org-right"&gt;Percent (%)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-right"&gt;1&lt;/td&gt;
&lt;td class="org-left"&gt;1,005&lt;/td&gt;
&lt;td class="org-right"&gt;51.38&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-right"&gt;0&lt;/td&gt;
&lt;td class="org-left"&gt;951&lt;/td&gt;
&lt;td class="org-right"&gt;48.62&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;grouped = data.groupby([Column.artist]).agg({Column.label: "sum", Column.comment_id: "count"}).reset_index().rename(
    columns={Column.label: "spam", Column.comment_id: "total"})
grouped["ham"] = grouped.total - grouped.spam
plotter = grouped[[Column.artist, "spam", "ham"]]
plot = plotter.hvplot.bar(x=Column.artist, stacked=True, legend=True,).opts(
    title="Spam Counts",
    width=1000, height=800)
Embed(plot=plot, file_name="spam_counts")()
&lt;/pre&gt;&lt;/div&gt;

&lt;object type="text/html" data="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/spam_counts.html" style="width:100%" height="800"&gt;
  &lt;p&gt;Figure Missing&lt;/p&gt;
&lt;/object&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org5b86e70" class="outline-4"&gt;
&lt;h4 id="org5b86e70"&gt;The Dates&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org5b86e70"&gt;
&lt;p&gt;
I'll look at when the comments were made, just to see.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(len(data[data[Column.datetime].isna()]))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
245

&lt;/pre&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;with_date = data[~data[Column.datetime].isna()]
with_date.loc[:, Column.datetime] = pandas.to_datetime(with_date[Column.datetime])
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;with_date.loc[:, "Month"] = with_date[Column.datetime].apply(lambda date: datetime(date.year, date.month, 1))
group = with_date.groupby(["Month", Column.artist, Column.label]).agg(
    {Column.comment_id: "count"}).reset_index().rename(
	columns={Column.comment_id: "Count",
		 Column.artist: "Artist"})
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;spam = group[group[Column.label] == classified_as.spam]
ham = group[group[Column.label] == classified_as.not_spam]
spam_plot = spam.hvplot(x="Month", y="Count", by="Artist", label="Spam")
plot = spam_plot.opts(title="Monthly Spam By Artist", width=1000, height=800)
Embed(plot=plot, file_name="monthly_spam_by_artist")()
&lt;/pre&gt;&lt;/div&gt;

&lt;object type="text/html" data="https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/monthly_spam_by_artist.html" style="width:100%" height="800"&gt;
  &lt;p&gt;Figure Missing&lt;/p&gt;
&lt;/object&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org04c222b" class="outline-4"&gt;
&lt;h4 id="org04c222b"&gt;Some Samples&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org04c222b"&gt;
&lt;/div&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;&lt;a id="orgd494599"&gt;&lt;/a&gt;SPAM&lt;br&gt;
&lt;div class="outline-text-5" id="text-orgd494599"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;spam = data[data[Column.label]==classified_as.spam].sample(5)
for index in range(len(spam)):
    print(f"({spam.iloc[index][Column.artist]}): {spam.iloc[index][Column.text]}")
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
(Eminem): Do you need more instagram followers or photo likes? Check out IGBlast.com and get em in minutes!
(Eminem): Check out my channel im 15 year old rapper!
(Shakira): Part 5. Comforter of the afflicted, pray for us Help of Christians, pray for us Queen of Angels, pray for us Queen of Patriarchs, pray for us Queen of Prophets, pray for us Queen of Apostles, pray for us Queen of Martyrs, pray for us Queen of Confessors, pray for us Queen of Virgins, pray for us Queen of all Saints, pray for us Queen conceived without original sin, pray for us Queen of the most holy Rosary, pray for us Queen of the family, pray for us Queen of peace, pray for us 
(Eminem): Hey guys I&amp;amp;#39;m 87 cypher im 11 years old and Rap is my life I recently made my second album desire ep . please take a moment to check out my album on YouTube thank you very much for reading every like comment and subscription counts
(Eminem): Check out this video on YouTube:﻿

&lt;/pre&gt;
&lt;/div&gt;
&lt;/li&gt;

&lt;li&gt;&lt;a id="org9f1160e"&gt;&lt;/a&gt;Ham&lt;br&gt;
&lt;div class="outline-text-5" id="text-org9f1160e"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ham = data[data[Column.label]==classified_as.not_spam].sample(5)
for index in range(len(ham)):
    print(f"({ham.iloc[index][Column.artist]}): {ham.iloc[index][Column.text]}")
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
(Eminem): charlieee :DDDD (Those who saw Lost only will understand)﻿
(LMFAO): BEST PARTY SONG LITERALLY PARTY ROCK IS IN THE HOUSEE TONIGHT!!!!﻿
(LMFAO): I like how the robot shuffles he shuffles good﻿
(KatyPerry): ROAAAAARRRRRR 🐯🐯🐯﻿
(Shakira): like me﻿

&lt;/pre&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgb646f5e" class="outline-3"&gt;
&lt;h3 id="orgb646f5e"&gt;Labeling Functions&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgd3004ee" class="outline-2"&gt;
&lt;h2 id="orgd3004ee"&gt;End&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgd3004ee"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org5d50667" class="outline-3"&gt;
&lt;h3 id="org5d50667"&gt;Citations&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org5d50667"&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;Alberto, T.C., Lochter J.V., Almeida, T.A. TubeSpam: Comment Spam Filtering on YouTube. Proceedings of the 14th IEEE International Conference on Machine Learning and Applications (ICMLA'15), 1-6, Miami, FL, USA, December, 2015. (preprint)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>data</category><category>labeling</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/data/a-first-look-at-snorkel/</guid><pubDate>Thu, 26 Sep 2019 21:47:16 GMT</pubDate></item><item><title>SQL Module 3</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/sql/sql-module-3/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/sql/sql-module-3/#org6504b4e"&gt;Question One&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/sql/sql-module-3/#org44b7e42"&gt;Question Two&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/sql/sql-module-3/#orgd57ae30"&gt;Question Three&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/sql/sql-module-3/#org884cf32"&gt;Question Four&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/sql/sql-module-3/#org4616b09"&gt;Question Five&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/sql/sql-module-3/#org6e7ea02"&gt;Question Six&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/sql/sql-module-3/#org12dcfd2"&gt;Question Seven&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
All the questions in this Quiz use the Chinook Database.
&lt;/p&gt;
&lt;div id="outline-container-org6504b4e" class="outline-2"&gt;
&lt;h2 id="org6504b4e"&gt;Question One&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org6504b4e"&gt;
&lt;p&gt;
Using a subquery, find the names of all the tracks for the album "Californication".
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt;
&lt;span class="n"&gt;name&lt;/span&gt;
&lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="n"&gt;tracks&lt;/span&gt;
&lt;span class="k"&gt;LEFT&lt;/span&gt; &lt;span class="k"&gt;JOIN&lt;/span&gt; &lt;span class="n"&gt;albums&lt;/span&gt; &lt;span class="k"&gt;ON&lt;/span&gt; &lt;span class="n"&gt;tracks&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;albumid&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;albums&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;albumid&lt;/span&gt;
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;albums&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="ss"&gt;"Californication"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
What is the 8th Track? Porcelain.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org44b7e42" class="outline-2"&gt;
&lt;h2 id="org44b7e42"&gt;Question Two&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org44b7e42"&gt;
&lt;p&gt;
Find the total number of invoices for each customer along with the customer's full name, city and email.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt;
&lt;span class="k"&gt;COUNT&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;invoiceid&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;firstname&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;lastname&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;city&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;email&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;invoices&lt;/span&gt;
&lt;span class="k"&gt;LEFT&lt;/span&gt; &lt;span class="k"&gt;JOIN&lt;/span&gt; &lt;span class="n"&gt;customers&lt;/span&gt; &lt;span class="k"&gt;ON&lt;/span&gt; &lt;span class="n"&gt;invoices&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;customerid&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;customers&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;customerid&lt;/span&gt;
&lt;span class="k"&gt;GROUP&lt;/span&gt; &lt;span class="k"&gt;BY&lt;/span&gt; &lt;span class="n"&gt;invoices&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;customerid&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
What is the email address of the 5th person, Frantisek Wichterlova?
&lt;/p&gt;

&lt;p&gt;
frantsekw@jetbrains.com
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgd57ae30" class="outline-2"&gt;
&lt;h2 id="orgd57ae30"&gt;Question Three&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgd57ae30"&gt;
&lt;p&gt;
Retrieve the track name, album, artistID, and trackID for all the albums.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt;
&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;artistid&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;trackid&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;tracks&lt;/span&gt;
&lt;span class="k"&gt;LEFT&lt;/span&gt; &lt;span class="k"&gt;JOIN&lt;/span&gt; &lt;span class="n"&gt;albums&lt;/span&gt; &lt;span class="k"&gt;ON&lt;/span&gt; &lt;span class="n"&gt;tracks&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;albumid&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;albums&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;albumid&lt;/span&gt;
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="ss"&gt;"For Those About To Rock We Salute You"&lt;/span&gt; &lt;span class="k"&gt;AND&lt;/span&gt; &lt;span class="n"&gt;trackid&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
What is the song title of trackID 12 from the "For Those About to Rock We Salute You" album? Enter the answer below
&lt;/p&gt;

&lt;p&gt;
Breaking The Rules
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org884cf32" class="outline-2"&gt;
&lt;h2 id="org884cf32"&gt;Question Four&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org884cf32"&gt;
&lt;p&gt;
Retrieve a list with the managers last name, and the last name of the employees who report to him or her.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt;
&lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LastName&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;LastName&lt;/span&gt;
&lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="n"&gt;employees&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;
&lt;span class="k"&gt;LEFT&lt;/span&gt; &lt;span class="k"&gt;JOIN&lt;/span&gt; &lt;span class="n"&gt;employees&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;B&lt;/span&gt; &lt;span class="k"&gt;ON&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ReportsTo&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;B&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;EmployeeId&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;
After running the query described above, who are the reports for the manager named Mitchell (select all that apply)?
&lt;/p&gt;

&lt;p&gt;
King and Callahan.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org4616b09" class="outline-2"&gt;
&lt;h2 id="org4616b09"&gt;Question Five&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org4616b09"&gt;
&lt;p&gt;
Find the name and ID of the artists who do not have albums. 
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt;
&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ArtistId&lt;/span&gt;
&lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="n"&gt;artists&lt;/span&gt;
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;ArtistId&lt;/span&gt; &lt;span class="k"&gt;NOT&lt;/span&gt; &lt;span class="k"&gt;IN&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
  &lt;span class="k"&gt;SELECT&lt;/span&gt;
  &lt;span class="n"&gt;ArtistId&lt;/span&gt;
  &lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;albums&lt;/span&gt;
  &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
After running the query described above, two of the records returned have the same last name. Enter that name below.
&lt;/p&gt;

&lt;p&gt;
Gilberto
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org6e7ea02" class="outline-2"&gt;
&lt;h2 id="org6e7ea02"&gt;Question Six&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org6e7ea02"&gt;
&lt;p&gt;
Use a UNION to create a list of all the employee's and customer's first names and last names ordered by the last name in descending order.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt;
&lt;span class="n"&gt;FirstName&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;LastName&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;customers&lt;/span&gt;
&lt;span class="k"&gt;UNION&lt;/span&gt;
&lt;span class="k"&gt;SELECT&lt;/span&gt;
&lt;span class="n"&gt;FirstName&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;LastName&lt;/span&gt;
&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;employees&lt;/span&gt;
&lt;span class="k"&gt;ORDER&lt;/span&gt; &lt;span class="k"&gt;BY&lt;/span&gt; &lt;span class="n"&gt;LastName&lt;/span&gt; &lt;span class="k"&gt;DESC&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
After running the query described above, determine what is the last name of the 6th record? Enter it below. Remember to order things in descending order to be sure to get the correct answer.
&lt;/p&gt;

&lt;p&gt;
Taylor
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org12dcfd2" class="outline-2"&gt;
&lt;h2 id="org12dcfd2"&gt;Question Seven&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org12dcfd2"&gt;
&lt;p&gt;
See if there are any customers who have a different city listed in their billing city versus their customer city.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;SELECT&lt;/span&gt;
&lt;span class="n"&gt;customers&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CustomerID&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;City&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;BillingCity&lt;/span&gt; &lt;span class="k"&gt;from&lt;/span&gt; &lt;span class="n"&gt;customers&lt;/span&gt;
&lt;span class="k"&gt;LEFT&lt;/span&gt; &lt;span class="k"&gt;JOIN&lt;/span&gt; &lt;span class="n"&gt;invoices&lt;/span&gt; &lt;span class="k"&gt;ON&lt;/span&gt; &lt;span class="n"&gt;customers&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CustomerID&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;invoices&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CustomerId&lt;/span&gt;
&lt;span class="k"&gt;WHERE&lt;/span&gt; &lt;span class="n"&gt;City&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;BillingCity&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
No, there aren't.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;</description><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/sql/sql-module-3/</guid><pubDate>Fri, 30 Aug 2019 11:17:17 GMT</pubDate></item><item><title>Chinook Questions</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/sql/chinook-questions/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/sql/chinook-questions/#org74f709c"&gt;Beginning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/sql/chinook-questions/#orga1e1b3a"&gt;Middle&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/sql/chinook-questions/#org0c3f7b9"&gt;Question One&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/sql/chinook-questions/#orga8092d9"&gt;Question Two&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/sql/chinook-questions/#org3e7cca2"&gt;Question Three&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/sql/chinook-questions/#org713c32c"&gt;Question Four&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/sql/chinook-questions/#org8a0964b"&gt;Question Five&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/sql/chinook-questions/#org6255f3a"&gt;Question Six&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/sql/chinook-questions/#orgc5d411f"&gt;Question Seven&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/sql/chinook-questions/#orgfd1ac03"&gt;End&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org74f709c" class="outline-2"&gt;
&lt;h2 id="org74f709c"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org74f709c"&gt;
&lt;p&gt;
The following questions use the &lt;a href="http://www.sqlitetutorial.net/sqlite-sample-database/"&gt;SQLite Sample Database&lt;/a&gt; - called the Chinook database - found on &lt;a href="http://www.sqlitetutorial.net"&gt;the SQLite Tutorial site&lt;/a&gt;.
&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/sql/chinook-questions/chinook-entity-diagram.png" alt="chinook-entity-diagram.png"&gt;
&lt;/p&gt;

&lt;p&gt;
It is made up of 11 tables:
&lt;/p&gt;

&lt;table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides"&gt;


&lt;colgroup&gt;
&lt;col class="org-left"&gt;

&lt;col class="org-left"&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th scope="col" class="org-left"&gt;Table&lt;/th&gt;
&lt;th scope="col" class="org-left"&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class="org-left"&gt;employees&lt;/td&gt;
&lt;td class="org-left"&gt;stores employees data such as employee id, last name, first name, etc. It also has a field named ReportsTo to specify who reports to whom.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;customers&lt;/td&gt;
&lt;td class="org-left"&gt;stores customers data.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;invoices&lt;/td&gt;
&lt;td class="org-left"&gt;stores invoice header data&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;&amp;amp; invoice_items&lt;/td&gt;
&lt;td class="org-left"&gt;stores the invoice line items data.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;artists&lt;/td&gt;
&lt;td class="org-left"&gt;stores artists data. It is a simple table that contains only artist id and name.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;albums&lt;/td&gt;
&lt;td class="org-left"&gt;stores data about a list of tracks. Each album belongs to one artist. However, one artist may have multiple albums.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;media_types&lt;/td&gt;
&lt;td class="org-left"&gt;stores media types such as MPEG audio and AAC audio file.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;genres&lt;/td&gt;
&lt;td class="org-left"&gt;stores music types such as rock, jazz, metal, etc.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;tracks&lt;/td&gt;
&lt;td class="org-left"&gt;store the data of songs. Each track belongs to one album.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;playlists&lt;/td&gt;
&lt;td class="org-left"&gt;stores data about playlists. Each playlist contains a list of tracks. Each track may belong to multiple playlists.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td class="org-left"&gt;playlist_track&lt;/td&gt;
&lt;td class="org-left"&gt;The relationship between the playlists table and tracks table is many-to-many. The playlist_track table is used to reflect this relationship.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orga1e1b3a" class="outline-2"&gt;
&lt;h2 id="orga1e1b3a"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orga1e1b3a"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org0c3f7b9" class="outline-3"&gt;
&lt;h3 id="org0c3f7b9"&gt;Question One&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org0c3f7b9"&gt;
&lt;p&gt;
Pull a list of customer ids with the customer’s full name, and address, along with combining their city and country together. Be sure to make a space in between these two and make it UPPER CASE.
&lt;/p&gt;

&lt;p&gt;
What is the city and country result for CustomerID 16?
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orga8092d9" class="outline-3"&gt;
&lt;h3 id="orga8092d9"&gt;Question Two&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orga8092d9"&gt;
&lt;p&gt;
Create a new employee user id by combining the first 4 letters of the employee’s first name with the first 2 letters of the employee’s last name. Make the new field lower case and pull each individual step to show your work.
&lt;/p&gt;

&lt;p&gt;
What is the final result for Robert King?
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org3e7cca2" class="outline-3"&gt;
&lt;h3 id="org3e7cca2"&gt;Question Three&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org3e7cca2"&gt;
&lt;p&gt;
Show a list of employees who have worked for the company for 15 or more years using the current date function. Sort by lastname ascending.
&lt;/p&gt;

&lt;p&gt;
What is the lastname of the last person on the list returned?
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org713c32c" class="outline-3"&gt;
&lt;h3 id="org713c32c"&gt;Question Four&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org713c32c"&gt;
&lt;p&gt;
Profiling the Customers table, answer the following question.
&lt;/p&gt;

&lt;p&gt;
Are there any columns with null values? Indicate any below. Select all that apply.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org8a0964b" class="outline-3"&gt;
&lt;h3 id="org8a0964b"&gt;Question Five&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org8a0964b"&gt;
&lt;p&gt;
Find the cities with the most customers and rank in descending order.
&lt;/p&gt;

&lt;p&gt;
Which of the following cities indicate having 2 customers?
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org6255f3a" class="outline-3"&gt;
&lt;h3 id="org6255f3a"&gt;Question Six&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org6255f3a"&gt;
&lt;p&gt;
Create a new customer invoice id by combining a customer’s invoice id with their first and last name while ordering your query in the following order: firstname, lastname, and invoiceID.
&lt;/p&gt;

&lt;p&gt;
Select all of the correct "AstridGruber" entries that are returned in your results below. Select all that apply.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgc5d411f" class="outline-3"&gt;
&lt;h3 id="orgc5d411f"&gt;Question Seven&lt;/h3&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgfd1ac03" class="outline-2"&gt;
&lt;h2 id="orgfd1ac03"&gt;End&lt;/h2&gt;
&lt;/div&gt;</description><category>practice</category><category>sql</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/sql/chinook-questions/</guid><pubDate>Wed, 21 Aug 2019 15:39:49 GMT</pubDate></item><item><title>Calling a JSON API</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/calling-a-json-api/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/calling-a-json-api/#org82399df"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/calling-a-json-api/#orgc979628"&gt;Imports&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/calling-a-json-api/#org0ce9794"&gt;Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/calling-a-json-api/#org0cc3d69"&gt;PyPi&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/calling-a-json-api/#org28455d8"&gt;Set Up&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/calling-a-json-api/#org0a30d04"&gt;URL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/calling-a-json-api/#org2bbff95"&gt;Sample&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/calling-a-json-api/#org3dd109f"&gt;Actual&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/calling-a-json-api/#org33c7380"&gt;Middle&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/calling-a-json-api/#orgc93ede2"&gt;The Sample&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/calling-a-json-api/#org18d24d9"&gt;The Actual&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/calling-a-json-api/#orgb941af8"&gt;End&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org82399df" class="outline-2"&gt;
&lt;h2 id="org82399df"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org82399df"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgc979628" class="outline-3"&gt;
&lt;h3 id="orgc979628"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgc979628"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org0ce9794" class="outline-4"&gt;
&lt;h4 id="org0ce9794"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org0ce9794"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from pprint import pprint
import json
import urllib
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org0cc3d69" class="outline-4"&gt;
&lt;h4 id="org0cc3d69"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org0cc3d69"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from expects import (
    equal,
    expect,
    start_with,
)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org28455d8" class="outline-3"&gt;
&lt;h3 id="org28455d8"&gt;Set Up&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org28455d8"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org0a30d04" class="outline-4"&gt;
&lt;h4 id="org0a30d04"&gt;URL&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org0a30d04"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;API_KEY = 42
API_URL = "http://py4e-data.dr-chuck.net/json?"
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org2bbff95" class="outline-4"&gt;
&lt;h4 id="org2bbff95"&gt;Sample&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org2bbff95"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;SAMPLE_LOCATION = "South Federal University"
SAMPLE_PLACE_ID = "ChIJ9e_QQm0sDogRhUPatldEFxw"
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org3dd109f" class="outline-4"&gt;
&lt;h4 id="org3dd109f"&gt;Actual&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org3dd109f"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ACTUAL_LOCATION = "Kazan Federal University"
ACTUAL_PLACE_ID_STARTS_WITH = "ChIJGf9"
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org33c7380" class="outline-2"&gt;
&lt;h2 id="org33c7380"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org33c7380"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def get_place_id(location: str) -&amp;gt; str:
    """Get the place ID for the location

    Args:
     location: place to look up

    Returns:
     the place ID for the location
    """
    parameters = {"address": location, "key": API_KEY}
    request = API_URL + urllib.parse.urlencode(parameters)

    with urllib.request.urlopen(request) as response:
	data = json.loads(response.read().decode())
	results = data["results"][0]
	expect(data["status"]).to(equal("OK"))
	place_id = results["place_id"]
	print(f"Location: {location}")
	print(f"Place ID: {place_id}")
    return place_id
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgc93ede2" class="outline-3"&gt;
&lt;h3 id="orgc93ede2"&gt;The Sample&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgc93ede2"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;place_id = get_place_id(SAMPLE_LOCATION)
expect(SAMPLE_PLACE_ID).to(equal(place_id))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Location: South Federal University
Place ID: ChIJ9e_QQm0sDogRhUPatldEFxw

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org18d24d9" class="outline-3"&gt;
&lt;h3 id="org18d24d9"&gt;The Actual&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org18d24d9"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;place_id = get_place_id(ACTUAL_LOCATION)
expect(place_id).to(start_with(ACTUAL_PLACE_ID_STARTS_WITH))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Location: Kazan Federal University
Place ID: ChIJGf9kMxGtXkERIzwzBzFo8kY

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgb941af8" class="outline-2"&gt;
&lt;h2 id="orgb941af8"&gt;End&lt;/h2&gt;
&lt;/div&gt;</description><category>api</category><category>json</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/calling-a-json-api/</guid><pubDate>Sun, 04 Aug 2019 18:53:29 GMT</pubDate></item><item><title>Extracting Data From JSON</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/#orgc589c7c"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/#org0d718da"&gt;Imports&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/#org21c2aca"&gt;Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/#org5b09150"&gt;PyPi&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/#org78ae5fb"&gt;Set Up&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/#org7b6a504"&gt;The URLs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/#org3b63353"&gt;The Expected&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/#org5e33258"&gt;Middle&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/#org3bafdb5"&gt;The Sample&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/#org986f540"&gt;The Assignment&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/#org4d0c963"&gt;End&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgc589c7c" class="outline-2"&gt;
&lt;h2 id="orgc589c7c"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgc589c7c"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org0d718da" class="outline-3"&gt;
&lt;h3 id="org0d718da"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org0d718da"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org21c2aca" class="outline-4"&gt;
&lt;h4 id="org21c2aca"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org21c2aca"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;import json
import urllib
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org5b09150" class="outline-4"&gt;
&lt;h4 id="org5b09150"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org5b09150"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from expects import expect, equal
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org78ae5fb" class="outline-3"&gt;
&lt;h3 id="org78ae5fb"&gt;Set Up&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org78ae5fb"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7b6a504" class="outline-4"&gt;
&lt;h4 id="org7b6a504"&gt;The URLs&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org7b6a504"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;SAMPLE_URL = "http://py4e-data.dr-chuck.net/comments_42.json"
ACTUAL_URL = "http://py4e-data.dr-chuck.net/comments_260445.json"
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org3b63353" class="outline-4"&gt;
&lt;h4 id="org3b63353"&gt;The Expected&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org3b63353"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;SAMPLE_EXPECTED = 2553
ACTUAL_EXPECTED_LAST_TWO_DIGITS = 94
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org5e33258" class="outline-2"&gt;
&lt;h2 id="org5e33258"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org5e33258"&gt;
&lt;p&gt;
We're going to pull a JSON blob and extract the "count" values and sum them. The data is structured with a single top-level key ("comments") which holds a list of dicts with "name" (name of the commenter) and "count" (the number of comments the commenter has made) values.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def count(url: str) -&amp;gt; int:
    """Totals the comment counts

    Args:
     url: source of the JSON

    Returns:
     the total of the comment counts
    """
    response = urllib.request.urlopen(url)
    data = json.loads(response.read())
    total = 0
    for index, commenter in enumerate(data["comments"]):
	total += int(commenter["count"])

    print(f"Comments: {index + 1}")
    print(f"Comments: {total: ,}")
    return total
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org3bafdb5" class="outline-3"&gt;
&lt;h3 id="org3bafdb5"&gt;The Sample&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org3bafdb5"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;total = count(SAMPLE_URL)
expect(total).to(equal(SAMPLE_EXPECTED))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Comments: 50
Comments:  2,553

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org986f540" class="outline-3"&gt;
&lt;h3 id="org986f540"&gt;The Assignment&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org986f540"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;total = count(ACTUAL_URL)
expect(int(str(total)[-2:])).to(equal(ACTUAL_EXPECTED_LAST_TWO_DIGITS))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Comments: 50
Comments:  2,594

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org4d0c963" class="outline-2"&gt;
&lt;h2 id="org4d0c963"&gt;End&lt;/h2&gt;
&lt;/div&gt;</description><category>json</category><category>web-scraping</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/</guid><pubDate>Sun, 04 Aug 2019 18:22:51 GMT</pubDate></item></channel></rss>