<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Visions, Voices, Data</title><link>https://necromuralist.github.io/Visions-Voices-Data/</link><description>Adumbrations of data.</description><atom:link href="https://necromuralist.github.io/Visions-Voices-Data/rss.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents Â© 2019 &lt;a href="mailto:necromuralist@protonmail.com"&gt;Cloistered Monkey&lt;/a&gt; </copyright><lastBuildDate>Sun, 04 Aug 2019 18:52:18 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Extracting Data From JSON</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/#org75a3b2d"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/#org1da480e"&gt;Imports&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/#org6b2b81c"&gt;Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/#orge511c4c"&gt;PyPi&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/#orgdaf8c7f"&gt;Set Up&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/#org6ff1f5f"&gt;The URLs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/#org7dab0aa"&gt;The Expected&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/#org9ec9212"&gt;Middle&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/#orga87c597"&gt;The Sample&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/#orgd09098d"&gt;The Assignment&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/#org69bd47d"&gt;End&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org75a3b2d" class="outline-2"&gt;
&lt;h2 id="org75a3b2d"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org75a3b2d"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org1da480e" class="outline-3"&gt;
&lt;h3 id="org1da480e"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org1da480e"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org6b2b81c" class="outline-4"&gt;
&lt;h4 id="org6b2b81c"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org6b2b81c"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;import json
import urllib
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orge511c4c" class="outline-4"&gt;
&lt;h4 id="orge511c4c"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orge511c4c"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from expects import expect, equal
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgdaf8c7f" class="outline-3"&gt;
&lt;h3 id="orgdaf8c7f"&gt;Set Up&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgdaf8c7f"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org6ff1f5f" class="outline-4"&gt;
&lt;h4 id="org6ff1f5f"&gt;The URLs&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org6ff1f5f"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;SAMPLE_URL = "http://py4e-data.dr-chuck.net/comments_42.json"
ACTUAL_URL = "http://py4e-data.dr-chuck.net/comments_260445.json"
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7dab0aa" class="outline-4"&gt;
&lt;h4 id="org7dab0aa"&gt;The Expected&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org7dab0aa"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;SAMPLE_EXPECTED = 2553
ACTUAL_EXPECTED_LAST_TWO_DIGITS = 94
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org9ec9212" class="outline-2"&gt;
&lt;h2 id="org9ec9212"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org9ec9212"&gt;
&lt;p&gt;
We're going to pull a JSON blob and extract the "count" values and sum them. The data is structured with a single top-level key ("comments") which holds a list of dicts with "name" (name of the commenter) and "count" (the number of comments the commenter has made) values.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def count(url: str) -&amp;gt; int:
    """Totals the comment counts

    Args:
     url: source of the JSON

    Returns:
     the total of the comment counts
    """
    response = urllib.request.urlopen(url)
    data = json.loads(response.read())
    total = 0
    for index, commenter in enumerate(data["comments"]):
	total += int(commenter["count"])

    print(f"Comments: {index + 1}")
    print(f"Comments: {total: ,}")
    return total
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orga87c597" class="outline-3"&gt;
&lt;h3 id="orga87c597"&gt;The Sample&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orga87c597"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;total = count(SAMPLE_URL)
expect(total).to(equal(SAMPLE_EXPECTED))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Comments: 50
Comments:  2,553

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgd09098d" class="outline-3"&gt;
&lt;h3 id="orgd09098d"&gt;The Assignment&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgd09098d"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;total = count(ACTUAL_URL)
expect(int(str(total)[-2:])).to(equal(ACTUAL_EXPECTED_LAST_TWO_DIGITS))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Comments: 50
Comments:  2,594

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org69bd47d" class="outline-2"&gt;
&lt;h2 id="org69bd47d"&gt;End&lt;/h2&gt;
&lt;/div&gt;</description><category>json</category><category>web-scraping</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-json/</guid><pubDate>Sun, 04 Aug 2019 18:22:51 GMT</pubDate></item><item><title>Extracting Data From XML</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-xml/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-xml/#org7c9f478"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-xml/#org81e866e"&gt;Imports&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-xml/#org7f5fbdd"&gt;Python&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-xml/#org1ff73c4"&gt;Set Up&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-xml/#org9763fef"&gt;The URLS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-xml/#org6428cc3"&gt;The Expected&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-xml/#orgdfdac58"&gt;Middle&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-xml/#org51c2b4f"&gt;Sample&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-xml/#orgc4382e3"&gt;The Assignment&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-xml/#org473c754"&gt;End&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7c9f478" class="outline-2"&gt;
&lt;h2 id="org7c9f478"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org7c9f478"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org81e866e" class="outline-3"&gt;
&lt;h3 id="org81e866e"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org81e866e"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7f5fbdd" class="outline-4"&gt;
&lt;h4 id="org7f5fbdd"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org7f5fbdd"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from xml.etree import ElementTree
import urllib
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org1ff73c4" class="outline-3"&gt;
&lt;h3 id="org1ff73c4"&gt;Set Up&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org1ff73c4"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org9763fef" class="outline-4"&gt;
&lt;h4 id="org9763fef"&gt;The URLS&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org9763fef"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;SAMPLE_URL = "http://py4e-data.dr-chuck.net/comments_42.xml"
ACTUAL_URL = "http://py4e-data.dr-chuck.net/comments_260444.xml"
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org6428cc3" class="outline-4"&gt;
&lt;h4 id="org6428cc3"&gt;The Expected&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org6428cc3"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;SAMPLE_EXPECTED = 2553
ACTUAL_EXPECTED_LAST_TWO_DIGITS = 34
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgdfdac58" class="outline-2"&gt;
&lt;h2 id="orgdfdac58"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgdfdac58"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def get_counts(url: str) -&amp;gt; int:
    """Get the sum of the 'count' tags 

    Args:
     url: URL to get the XML from

    Returns:
     sum of the count tags payloads
    """
    response = urllib.request.urlopen(url)
    tree = ElementTree.fromstring(response.read())
    total = 0
    for index, count in enumerate(tree.findall(".//count")):
	total += int(count.text)

    print(f"Tags: {index + 1}")
    print(f"Sum of Counts: {total}")
    return total
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org51c2b4f" class="outline-3"&gt;
&lt;h3 id="org51c2b4f"&gt;Sample&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org51c2b4f"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;total = get_counts(SAMPLE_URL)
assert total == SAMPLE_EXPECTED
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Tags: 50
Sum of Counts: 2553

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgc4382e3" class="outline-3"&gt;
&lt;h3 id="orgc4382e3"&gt;The Assignment&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgc4382e3"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;total =get_counts(ACTUAL_URL)
assert int(str(total)[-2:]) == ACTUAL_EXPECTED_LAST_TWO_DIGITS
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Tags: 50
Sum of Counts: 2634

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org473c754" class="outline-2"&gt;
&lt;h2 id="org473c754"&gt;End&lt;/h2&gt;
&lt;/div&gt;</description><category>data</category><category>xml</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/extracting-data-from-xml/</guid><pubDate>Sat, 03 Aug 2019 23:24:05 GMT</pubDate></item><item><title>Web Scraping Assignment 1</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#org1bf5ce9"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#orgbc5ccb0"&gt;Imports&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#org33f05c7"&gt;Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#org4ae7d9e"&gt;PyPi&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#org8d842ca"&gt;Setup&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#org5d3858b"&gt;The URLs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#org44ddbff"&gt;The Expected&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#org5c47d76"&gt;Middle&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#org4316a82"&gt;The Sample&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#orgcf94ed6"&gt;The Way I Would Do It&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#org8ba1b75"&gt;The Assignment Way&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#org266a87b"&gt;The Assignment&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#org67e1616"&gt;Requests HTML&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#org8b173f1"&gt;Urllib&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#orgaec2d7b"&gt;End&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org1bf5ce9" class="outline-2"&gt;
&lt;h2 id="org1bf5ce9"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org1bf5ce9"&gt;
&lt;p&gt;
The goal of this exercise is to find all the &lt;code&gt;&amp;lt;span&amp;gt;&lt;/code&gt; tags on a page and sum the numbers they contain.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgbc5ccb0" class="outline-3"&gt;
&lt;h3 id="orgbc5ccb0"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgbc5ccb0"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org33f05c7" class="outline-4"&gt;
&lt;h4 id="org33f05c7"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org33f05c7"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;urllib&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org4ae7d9e" class="outline-4"&gt;
&lt;h4 id="org4ae7d9e"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org4ae7d9e"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;bs4&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;expects&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;
    &lt;span class="n"&gt;equal&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;expect&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="n"&gt;be_true&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;requests_html&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;HTMLSession&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org8d842ca" class="outline-3"&gt;
&lt;h3 id="org8d842ca"&gt;Setup&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org8d842ca"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org5d3858b" class="outline-4"&gt;
&lt;h4 id="org5d3858b"&gt;The URLs&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org5d3858b"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;SAMPLE_URL&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;" http://py4e-data.dr-chuck.net/comments_42.html"&lt;/span&gt;
&lt;span class="n"&gt;ACTUAL_URL&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"http://py4e-data.dr-chuck.net/comments_260442.html"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org44ddbff" class="outline-4"&gt;
&lt;h4 id="org44ddbff"&gt;The Expected&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org44ddbff"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;SAMPLE_EXPECTED&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;2553&lt;/span&gt;
&lt;span class="n"&gt;ACTUAL_EXPECTED_LAST_DIGIT&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org5c47d76" class="outline-2"&gt;
&lt;h2 id="org5c47d76"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org5c47d76"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org4316a82" class="outline-3"&gt;
&lt;h3 id="org4316a82"&gt;The Sample&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org4316a82"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgcf94ed6" class="outline-4"&gt;
&lt;h4 id="orgcf94ed6"&gt;The Way I Would Do It&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgcf94ed6"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;using_requests&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="sd"&gt;"""get the span total&lt;/span&gt;

&lt;span class="sd"&gt;    Args:&lt;/span&gt;
&lt;span class="sd"&gt;     url: The URL for the page&lt;/span&gt;

&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;span class="sd"&gt;     the total sum&lt;/span&gt;
&lt;span class="sd"&gt;    """&lt;/span&gt;
    &lt;span class="n"&gt;session&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;HTMLSession&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;expect&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ok&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;be_true&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;total&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;span&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;html&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"span"&lt;/span&gt;&lt;span class="p"&gt;)):&lt;/span&gt;
	&lt;span class="n"&gt;total&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Count: {count + 1}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Sum: {total}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;total&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;total&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;using_requests&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;SAMPLE_URL&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;expect&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;total&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;equal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;SAMPLE_EXPECTED&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Count: 50
Sum: 2553

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org8ba1b75" class="outline-4"&gt;
&lt;h4 id="org8ba1b75"&gt;The Assignment Way&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org8ba1b75"&gt;
&lt;p&gt;
For this kind of thing, using urllib isn't really much more work, I'm used to the older python 2 version which (maybe only seemed at the time) was more complicated to use.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;using_urllib&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="sd"&gt;"""get the span total with urllib and beautiful soup&lt;/span&gt;

&lt;span class="sd"&gt;    Args:&lt;/span&gt;
&lt;span class="sd"&gt;     url: the URL for the page&lt;/span&gt;

&lt;span class="sd"&gt;    Returns:&lt;/span&gt;
&lt;span class="sd"&gt;     the total of the span contents&lt;/span&gt;
&lt;span class="sd"&gt;    """&lt;/span&gt;
    &lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urllib&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;urlopen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;soup&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="s2"&gt;"html.parser"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;total&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;count&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;span&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;soup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find_all&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"span"&lt;/span&gt;&lt;span class="p"&gt;)):&lt;/span&gt;
	&lt;span class="n"&gt;total&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Count: {count + 1}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Sum: {total}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;total&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;total&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;using_urllib&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;SAMPLE_URL&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;expect&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;total&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;equal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;SAMPLE_EXPECTED&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Count: 50
Sum: 2553

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org266a87b" class="outline-3"&gt;
&lt;h3 id="org266a87b"&gt;The Assignment&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org266a87b"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org67e1616" class="outline-4"&gt;
&lt;h4 id="org67e1616"&gt;Requests HTML&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org67e1616"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;total&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;using_requests&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ACTUAL_URL&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;expect&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;total&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;equal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ACTUAL_EXPECTED_LAST_DIGIT&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Count: 50
Sum: 2305

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org8b173f1" class="outline-4"&gt;
&lt;h4 id="org8b173f1"&gt;Urllib&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org8b173f1"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;total&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;using_urllib&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ACTUAL_URL&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;expect&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;total&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;to&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;equal&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ACTUAL_EXPECTED_LAST_DIGIT&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Count: 50
Sum: 2305

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgaec2d7b" class="outline-2"&gt;
&lt;h2 id="orgaec2d7b"&gt;End&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgaec2d7b"&gt;
&lt;p&gt;
Although I normally use &lt;code&gt;requests&lt;/code&gt; or &lt;code&gt;requests-html&lt;/code&gt;, I must say that the &lt;code&gt;urllib&lt;/code&gt; version with &lt;a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/"&gt;BeautifulSoup&lt;/a&gt; for this particular exercise wasn't much different.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>web-scraping</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/</guid><pubDate>Sat, 03 Aug 2019 19:07:56 GMT</pubDate></item><item><title>Web Scraping Assignment 2</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-2/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-2/#orge963253"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-2/#org8433374"&gt;Imports&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-2/#org04e5580"&gt;Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-2/#org264839a"&gt;PyPi&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-2/#orgff32d65"&gt;Setup&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-2/#org89ae143"&gt;The URL&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-2/#orgabe8dd0"&gt;Middle&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-2/#orgcc42471"&gt;The Sample Exercise&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-2/#org83df5a1"&gt;The Easy Way&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-2/#org19809c4"&gt;The Slightly Less Easy Way&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-2/#org45d41f3"&gt;The Real One&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-2/#org71f3761"&gt;The Easy Way&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-2/#org82ae5d5"&gt;The Assignment Way&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-2/#org3222b0a"&gt;End&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orge963253" class="outline-2"&gt;
&lt;h2 id="orge963253"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orge963253"&gt;
&lt;p&gt;
The goal of this exercise is to crawl through a set of anchor links to get a particular name stored in the &lt;i&gt;nth&lt;/i&gt; anchor tag. The assignment specifically says to use &lt;a href="https://docs.python.org/3/library/urllib.html"&gt;urllib&lt;/a&gt; but, if you go to the documentation for &lt;a href="https://docs.python.org/3/library/urllib.request.html#module-urllib.request"&gt;urllib.request&lt;/a&gt; it tells you to use to use &lt;a href="https://2.python-requests.org/en/master/"&gt;requests&lt;/a&gt;, which, if you go to its documentation says that it's in maintenance mode while work is being done on &lt;a href="https://3.python-requests.org/"&gt;Requests III&lt;/a&gt;â¦ anyway, I like using &lt;a href="https://html.python-requests.org/"&gt;Requests-HTML&lt;/a&gt; so I'll use that and urllib side-by-side.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-org8433374" class="outline-3"&gt;
&lt;h3 id="org8433374"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org8433374"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org04e5580" class="outline-4"&gt;
&lt;h4 id="org04e5580"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org04e5580"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;re&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;urllib&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org264839a" class="outline-4"&gt;
&lt;h4 id="org264839a"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org264839a"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;bs4&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;requests_html&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;HTMLSession&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgff32d65" class="outline-3"&gt;
&lt;h3 id="orgff32d65"&gt;Setup&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgff32d65"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org89ae143" class="outline-4"&gt;
&lt;h4 id="org89ae143"&gt;The URL&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org89ae143"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;BASE_URL&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"http://py4e-data.dr-chuck.net/known_by_"&lt;/span&gt;
&lt;span class="n"&gt;SAMPLE_URL&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"{BASE_URL}Fikret.html"&lt;/span&gt;
&lt;span class="n"&gt;ASSIGNMENT_URL&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"{BASE_URL}Abdalroof.html"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgabe8dd0" class="outline-2"&gt;
&lt;h2 id="orgabe8dd0"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgabe8dd0"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgcc42471" class="outline-3"&gt;
&lt;h3 id="orgcc42471"&gt;The Sample Exercise&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgcc42471"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org83df5a1" class="outline-4"&gt;
&lt;h4 id="org83df5a1"&gt;The Easy Way&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org83df5a1"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;session&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;HTMLSession&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;SAMPLE_URL&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ok&lt;/span&gt;

&lt;span class="n"&gt;expression&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"_(?P&amp;lt;name&amp;gt;[^_.]+).html"&lt;/span&gt;
&lt;span class="n"&gt;expression&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;re&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;compile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;expression&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Name: {expression.search(SAMPLE_URL).group('name')}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;hop&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;links&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;html&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"a"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;link_element&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;links&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Name: {link_element.text}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;link_element&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;attrs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"href"&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Final Answer: {link_element.text}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Name: Fikret
Name: Montgomery
Name: Mhairade
Name: Butchi
Name: Anayah
Final Answer: Anayah

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org19809c4" class="outline-4"&gt;
&lt;h4 id="org19809c4"&gt;The Slightly Less Easy Way&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org19809c4"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urllib&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;urlopen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;SAMPLE_URL&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Name: {expression.search(SAMPLE_URL).group('name')}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;hop&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
   &lt;span class="n"&gt;soup&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="s2"&gt;"html.parser"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
   &lt;span class="n"&gt;link_element&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;soup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find_all&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"a"&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; 
   &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Name: {link_element.text}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
   &lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urllib&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;urlopen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;link_element&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"href"&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;Final Answer: {link_element.text}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Name: Fikret
Name: Montgomery
Name: Mhairade
Name: Butchi
Name: Anayah

Final Answer: Anayah

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org45d41f3" class="outline-3"&gt;
&lt;h3 id="org45d41f3"&gt;The Real One&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org45d41f3"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org71f3761" class="outline-4"&gt;
&lt;h4 id="org71f3761"&gt;The Easy Way&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org71f3761"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;session&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;HTMLSession&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ASSIGNMENT_URL&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;assert&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ok&lt;/span&gt;

&lt;span class="n"&gt;expression&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"_(?P&amp;lt;name&amp;gt;[^_.]+).html"&lt;/span&gt;
&lt;span class="n"&gt;expression&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;re&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;compile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;expression&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Name: {expression.search(ASSIGNMENT_URL).group('name')}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;hop&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;links&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;html&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"a"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="n"&gt;link_element&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;links&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;17&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Name: {link_element.text}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;session&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;link_element&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;attrs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"href"&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Final Answer: {link_element.text}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Name: Abdalroof
Name: Billi
Name: Jayse
Name: Amaarah
Name: Cesar
Name: Rosheen
Name: Mohamed
Name: Kiara
Final Answer: Kiara

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org82ae5d5" class="outline-4"&gt;
&lt;h4 id="org82ae5d5"&gt;The Assignment Way&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org82ae5d5"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;HOPS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;
&lt;span class="n"&gt;FIND_AT_INDEX&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;18&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urllib&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;urlopen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ASSIGNMENT_URL&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Name: {expression.search(ASSIGNMENT_URL).group('name')}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;hop&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;HOPS&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
   &lt;span class="n"&gt;soup&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="s2"&gt;"html.parser"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
   &lt;span class="n"&gt;link_element&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;soup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find_all&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"a"&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="n"&gt;FIND_AT_INDEX&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; 
   &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"Name: {link_element.text}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
   &lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urllib&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;request&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;urlopen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;link_element&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"href"&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s2"&gt;Final Answer: {link_element.text}"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Name: Abdalroof
Name: Billi
Name: Jayse
Name: Amaarah
Name: Cesar
Name: Rosheen
Name: Mohamed
Name: Kiara

Final Answer: Kiara
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org3222b0a" class="outline-2"&gt;
&lt;h2 id="org3222b0a"&gt;End&lt;/h2&gt;
&lt;/div&gt;</description><category>web-crawiling</category><category>web-scraping</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-2/</guid><pubDate>Fri, 02 Aug 2019 20:43:01 GMT</pubDate></item><item><title>Nested follower</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/nested-follower/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/nested-follower/#org8743d8f"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/nested-follower/#org1370d13"&gt;Create A Walker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/nested-follower/#org63dd93e"&gt;Specifications&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/nested-follower/#orgdfb08ae"&gt;Middle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/nested-follower/#org369ff3b"&gt;End&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org8743d8f" class="outline-2"&gt;
&lt;h2 id="org8743d8f"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org8743d8f"&gt;
&lt;p&gt;
This is assignment 1 from the Nature of Code course on Kadenze. I was originally going to make it a mouse-follower but I re-read the instructions and it seems like it's better to make it a random-walker. These are the requirements:
&lt;/p&gt;
&lt;/div&gt;

&lt;div id="outline-container-org1370d13" class="outline-3"&gt;
&lt;h3 id="org1370d13"&gt;Create A Walker&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org1370d13"&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;Create an object that moves around the screen&lt;/li&gt;
&lt;li&gt;Incorporate randomness or perlin noise&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org63dd93e" class="outline-3"&gt;
&lt;h3 id="org63dd93e"&gt;Specifications&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org63dd93e"&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;Needs to be visually different from the Nature of Code examples&lt;/li&gt;
&lt;li&gt;Use comments&lt;/li&gt;
&lt;li&gt;Only use &lt;code&gt;p5.js&lt;/code&gt; libraries&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgdfb08ae" class="outline-2"&gt;
&lt;h2 id="orgdfb08ae"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgdfb08ae"&gt;
&lt;script language="javascript" type="text/javascript" src="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/nested-follower/follower.js"&gt;&lt;/script&gt;
&lt;div id="nested-follower"&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;/**
 * Random Walker
 *
 * This is an implementation of the Random Walker based on the example given in
 * "The Nature of Code"
 */

// This is the div where the canvas will be placed
let nested_parent_div_id = "nested-follower";

/**
 * The sketch creator
 * 
 * @param {P5} p
 */
let nested_follower_sketch = function(p) {
    /**
     * Setup the canvas
     *
     * - Attaches the canvas to the div
     * - Creates the walker objects
     */
    p.setup = function() {
	this.canvas = p.createCanvas($("#" + nested_parent_div_id).outerWidth(true), 800);
	p.parent = new NoiseWalker(p);
	p.followers = [new Follower(p, p.parent), new Follower(p, p.parent), new Follower(p, p.parent)];
    };

    /**
     * Refresh the objects by calling their update functions
     *
     * This also clears the background.
     */
    p.draw = function() {
	p.background(255);
	p.parent.update();
	p.followers.forEach(function(follower) {
	    follower.update();
	});
    };
};

/**
 * The main walker (with perlin noise)
 *
 * @param {P5} p
 */
function NoiseWalker(p) {
    this.position = p.createVector(p.width/2, p.height/2);
    this.velocity = p.createVector(0, 0);
    this.weight = p.round(p.random(5, 10));
    this.time_x = 0;
    this.time_y = 10000;
    this.time_delta = 0.01;
    this.acceleration = p.createVector(0, 0);
    this.max_acceleration = 0.001;

    /**
     * Updates the walker's position
     */
    this.walk = function() {
	// set the acceleration using perlin noise
	this.acceleration.x = p.map(p.noise(this.time_x), 0, 1, 0, this.max_acceleration);
	this.acceleration.y = p.map(p.noise(this.time_y), 0, 1, 0, this.max_acceleration);
	console.log(this.acceleration)
	// update the time
	this.time_x += this.time_delta;
	this.time_y += this.time_delta;

	// setMag always produces the same magnitude (but the orientation stays the same)
	// this.acceleration.setMag(this.magnitude);

	this.velocity = this.velocity.add(this.acceleration);
	this.position = this.position.add(this.velocity);

	// keep it within the window
	if (this.position.x &amp;lt; 0)
	    this.position.x = p.width;
	else if (this.position.x &amp;gt; p.width)
	    this.position.x = 0;
	if (this.position.y &amp;lt; 0)
	    this.position.y = p.height;
	else if (this.position.y &amp;gt; p.height)
	    this.position.y = 0;
    };

    /**
     * draws the walker
     */
    this.display = function() {
	p.stroke(0);
	//p.background(255, 255, 255, 10);
	p.point(this.position.x, this.position.y);
    };

    /**
     * Calls the walk and update functions
     */
    this.update = function() {
	this.walk();
	this.display();
    };
}


/**
 * A follower that follows a parent object
 *
 * @param {P5} p
 * @param {NoiseWalker} parent
 */
function Follower(p, parent) {
    this.parent = parent;
    this.variance = p.random(5);
    this.position = p.createVector(
	this.parent.position.x + p.random(-this.variance, this.variance),
	this.parent.position.y + p.random(-this.variance, this.variance));
    this.velocity = p.createVector(0, 0);
    this.magnitude = p.random(0.05, 0.09);

    // some colors to cycle through
    this.red = [63, 123, 191, 191, 191];
    this.green = [63, 63, 63, 63, 63];
    this.blue = [191, 191, 191, 127, 63];
    this.colors = this.red.length;
    this.color = p.round(p.random(this.colors));

    /**
     * Moves the Follower
     *
     * sets the acceleration by pointing to the parent's position
     */
    this.walk = function() {
	let acceleration = p5.Vector.sub(this.parent.position, this.position);

	// acceleration.setMag(this.magnitude);
	this.velocity = this.velocity.add(acceleration);
	this.position = this.position.add(this.velocity);
    };

    /**
     * Display the Follower
     *
     * cycles through the colors as we go
     */
    this.display = function() {
	p.strokeWeight(p.random(this.variance, 2 * this.variance));
	p.stroke(this.red[this.color], this.green[this.color], this.blue[this.color]);
	this.color = (this.color + 1) % this.colors;
	p.noFill();
	p.ellipse(this.position.x, this.position.y, p.random(10, 45), p.random(10, 45));
    };

    /**
     * calls the update and walk 
     */
    this.update = function() {
	this.walk();
	this.display();
    };
}

new p5(nested_follower_sketch, nested_parent_div_id);
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org369ff3b" class="outline-2"&gt;
&lt;h2 id="org369ff3b"&gt;End&lt;/h2&gt;
&lt;/div&gt;</description><category>p5.js</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/nested-follower/</guid><pubDate>Tue, 23 Jul 2019 20:49:03 GMT</pubDate></item><item><title>A Mouse Follower</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-mouse-follower/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-mouse-follower/#org8ff362e"&gt;Beginning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-mouse-follower/#org1ccaf14"&gt;Middle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-mouse-follower/#org8abadfb"&gt;End&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org8ff362e" class="outline-2"&gt;
&lt;h2 id="org8ff362e"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org8ff362e"&gt;
&lt;p&gt;
Instead of a random walker this walker will be attracted (somewhat) to the mouse cursor.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org1ccaf14" class="outline-2"&gt;
&lt;h2 id="org1ccaf14"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org1ccaf14"&gt;
&lt;script language="javascript" type="text/javascript" src="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-mouse-follower/follower.js"&gt;&lt;/script&gt;
&lt;div id="mouse-follower"&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;let parent_div_id = "mouse-follower";

let mouse_follower_sketch = function(p) {
    p.setup = function() {
	this.canvas = p.createCanvas($("#" + parent_div_id).outerWidth(true), 800);
	p.walker = new MouseWalker(p);
    }

    p.draw = function() {
	p.background(255);
	p.walker.walk();
	p.walker.display();
    }
};

function MouseWalker(p) {
    this.position = p.createVector(p.width/2, p.height/2);
    this.velocity = p.createVector(0, 0)

    this.walk = function() {
	mouse = p.createVector(p.mouseX, p.mouseY);
	// calling sub on the vectors does an in-place update
	// using p5.Vector.sub creates a new vector
	// This is a static method so we use the module (p5) not the instance (p)
	acceleration = mouse.sub(this.position);

	// setMag always produces the same magnitude (but the orientation stays the same)
	acceleration.setMag(0.1);
	this.velocity = this.velocity.add(acceleration);
	this.position = this.position.add(this.velocity)
  }

  this.display = function() {
      p.stroke(0);
      p.noFill();
      p.background(255, 255, 255, 25);
      p.ellipse(this.position.x, this.position.y, 48, 48);
  }
}

sketch_container = new p5(mouse_follower_sketch, parent_div_id);
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org8abadfb" class="outline-2"&gt;
&lt;h2 id="org8abadfb"&gt;End&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org8abadfb"&gt;
&lt;ol class="org-ol"&gt;
&lt;li&gt;Shiffman D. &lt;a href="https://natureofcode.com/"&gt;The nature of code&lt;/a&gt;: simulating natural systems with processing. Version 1.0, generated December 6, 2012. s.l.: Selbstverl.; 2012. 498 p.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>p5.js</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-mouse-follower/</guid><pubDate>Sun, 21 Jul 2019 23:03:37 GMT</pubDate></item><item><title>A Random Accelerator</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-random-accelerator/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-random-accelerator/#org9518eca"&gt;Beginning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-random-accelerator/#org5c7540c"&gt;Middle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-random-accelerator/#org5f3a24f"&gt;End&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org9518eca" class="outline-2"&gt;
&lt;h2 id="org9518eca"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org9518eca"&gt;
&lt;p&gt;
This is an extension of the random walker with acceleration added.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org5c7540c" class="outline-2"&gt;
&lt;h2 id="org5c7540c"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org5c7540c"&gt;
&lt;script language="javascript" type="text/javascript" src="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-random-accelerator/walker.js"&gt;&lt;/script&gt;
&lt;div id="random-accelerator"&gt;
&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;let random_accelerator_sketch = function(p) {
    p.setup = function() {
	let parent_div_id = "random-accelerator";
	this.canvas = p.createCanvas($("#" + parent_div_id).outerWidth(true), 800);
	this.canvas.parent(parent_div_id);
	p.walker = new Walker(p);
    }

    p.draw = function() {
	p.background(255);
	p.walker.walk();
	p.walker.display();
    }
};

function Walker(p) {
    this.position = p.createVector(p.width/2, p.height/2);
    this.velocity = p.createVector(0, 0)

    this.walk = function() {
	acceleration = p.createVector(p.random(-1, 1), p.random(-1, 1));
	acceleration = acceleration.mult(0.1)
	this.velocity = this.velocity.add(acceleration)
	this.position = this.position.add(this.velocity)
  }

  this.display = function() {
      p.stroke(0);
      p.noFill();
      p.background(255, 255, 255, 25);
      p.ellipse(this.position.x, this.position.y, 48, 48);
  }
}

sketch_container = new p5(random_accelerator_sketch, 'random-accelerator');
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org5f3a24f" class="outline-2"&gt;
&lt;h2 id="org5f3a24f"&gt;End&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org5f3a24f"&gt;
&lt;p&gt;
This was a very rudimentary walker, the main point of it was that at this point we have the basic kinematic elements to make something following the rules of classical physics (more or less).
&lt;/p&gt;

&lt;ol class="org-ol"&gt;
&lt;li&gt;Shiffman D. &lt;a href="https://natureofcode.com/"&gt;The nature of code&lt;/a&gt;: simulating natural systems with processing. Version 1.0, generated December 6, 2012. s.l.: Selbstverl.; 2012. 498 p.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>p5.js</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-random-accelerator/</guid><pubDate>Sun, 21 Jul 2019 22:14:42 GMT</pubDate></item><item><title>A Random Walk(er)</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-random-walker/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-random-walker/#org7f4ab1a"&gt;Beginning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-random-walker/#org3d7a5b6"&gt;Middle&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-random-walker/#org5a3f18e"&gt;A Div to Locate the Sketch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-random-walker/#org7d41e77"&gt;The Javascript&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-random-walker/#orgfb4bb0c"&gt;End&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7f4ab1a" class="outline-2"&gt;
&lt;h2 id="org7f4ab1a"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org7f4ab1a"&gt;
&lt;p&gt;
This is another post to see if I understand how to get &lt;a href="https://p5js.org/"&gt;p5.js&lt;/a&gt; working in nikola. It's been a while since I tried and I just want to see if I remember how. This uses the random walk example from Daniel Schiffman's book &lt;i&gt;the Nature of Code&lt;/i&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org3d7a5b6" class="outline-2"&gt;
&lt;h2 id="org3d7a5b6"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org3d7a5b6"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org5a3f18e" class="outline-3"&gt;
&lt;h3 id="org5a3f18e"&gt;A Div to Locate the Sketch&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org5a3f18e"&gt;
&lt;p&gt;
The id of this div is set in the &lt;code&gt;p5.js&lt;/code&gt; &lt;code&gt;setup&lt;/code&gt; function as the parent of the sketch.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&amp;lt;script language="javascript" type="text/javascript" src="walker.js"&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;div id="random-walk-container"&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;script language="javascript" type="text/javascript" src="https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-random-walker/walker.js"&gt;&lt;/script&gt;
&lt;div id="random-walk-container"&gt;
&lt;/div&gt;

&lt;p&gt;
&lt;b&gt;Note:&lt;/b&gt; Originally this wasn't working, because I had the line to include the javascript inside the &lt;code&gt;div&lt;/code&gt; to hold the canvas. Make sure that &lt;code&gt;div&lt;/code&gt; is always empty.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org7d41e77" class="outline-3"&gt;
&lt;h3 id="org7d41e77"&gt;The Javascript&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org7d41e77"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;let sketch = function(p) {
    p.setup = function() {
	let parent_div_id = "random-walk-container";
	this.canvas = p.createCanvas($("#" + parent_div_id).outerWidth(true), 300);
	this.canvas.parent();
	p.walker = new Walker(p);
    }

    p.draw = function() {
	p.background(255);
	p.walker.walk();
	p.walker.display();
    }
};

function Walker(p) {
  this.x = p.width/2;
  this.y = p.height/2;

  this.walk = function() {
    this.x = this.x + p.random(-1, 1) * 10;
    this.y = this.y + p.random(-1, 1) * 10;
  }

  this.display = function() {
    p.fill(0);
    p.ellipse(this.x, this.y, 48, 48);
  }
}

//let node = document.getElementById("random-walk")
//window.document.getElementsByTagName("body")[0].appendChild(node);
sketch_container = new p5(sketch, 'random-walk-container');
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgfb4bb0c" class="outline-2"&gt;
&lt;h2 id="orgfb4bb0c"&gt;End&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgfb4bb0c"&gt;
&lt;p&gt;
As always, this was way harder than it should have been.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>javascript</category><category>p5.js</category><category>processing</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/nature-of-code/a-random-walker/</guid><pubDate>Sun, 21 Jul 2019 19:29:09 GMT</pubDate></item><item><title>The Origin of Bayes Theorem</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/notes/the-origin-of-bayes-theorem/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/notes/the-origin-of-bayes-theorem/#org2ffff4c"&gt;A Brief Sketch of The Timelines to Bayes' Theorem&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/notes/the-origin-of-bayes-theorem/#org37313d1"&gt;The Equations&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/notes/the-origin-of-bayes-theorem/#org10aff08"&gt;Bayes' Formulation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/notes/the-origin-of-bayes-theorem/#orgee6afa6"&gt;Laplace's First Version&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/notes/the-origin-of-bayes-theorem/#org19fb7e8"&gt;Laplace's Final Version&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/notes/the-origin-of-bayes-theorem/#org9ca7d49"&gt;Sources&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;
I'm reading "The theory that would not die" and these are notes I took from them. The book didn't really give me a clear idea about what Price's argument was so I also read a &lt;a href="https://qz.com/1315731/the-most-important-formula-in-data-science-was-first-used-to-prove-the-existence-of-god/"&gt;Quartz&lt;/a&gt; article about that part of the story and, of course, Wikipedia came into it at some points.
&lt;/p&gt;
&lt;div id="outline-container-org2ffff4c" class="outline-2"&gt;
&lt;h2 id="org2ffff4c"&gt;A Brief Sketch of The Timelines to Bayes' Theorem&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org2ffff4c"&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;1718: &lt;a href="https://www.wikiwand.com/en/Abraham_de_Moivre"&gt;Abraham de Moivre&lt;/a&gt; publishes &lt;a href="https://www.wikiwand.com/en/The_Doctrine_of_Chances"&gt;The Doctrine of Chances&lt;/a&gt;, the first textbook on probability.&lt;/li&gt;
&lt;li&gt;1746-1749: Somewhere in this period &lt;a href="https://www.wikiwand.com/en/Thomas_Bayes"&gt;Thomas Bayes&lt;/a&gt; comes writes &lt;a href="https://www.wikiwand.com/en/An_Essay_towards_solving_a_Problem_in_the_Doctrine_of_Chances"&gt;An Essay towards solving a Problem in the Doctrine of the Chances&lt;/a&gt; which describes elements of Inverse Probability, in which the probability of a cause is calculated based on observed effects, stated as a thought experiment in which a person turned away from a table estimates the position of a ball based on being told whether subsequent balls randomly dropped on the same table are to the left or the right of it.&lt;/li&gt;
&lt;li&gt;1748: &lt;a href="https://www.wikiwand.com/en/David_Hume"&gt;David Hume&lt;/a&gt; publishes &lt;a href="https://www.wikiwand.com/en/Of_Miracles"&gt;Of Miracles&lt;/a&gt;, in which he argues that since miracles are, by nature, singular, they can never have as much evidence in their favor as against them.&lt;/li&gt;
&lt;li&gt;1749: &lt;a href="https://www.wikiwand.com/en/Pierre-Simon_Laplace"&gt;Pierre-Simon Laplace&lt;/a&gt; is born&lt;/li&gt;
&lt;li&gt;1764: &lt;a href="https://www.wikiwand.com/en/Richard_Price"&gt;Richard Price&lt;/a&gt; publishes &lt;a href="https://www.wikiwand.com/en/An_Essay_towards_solving_a_Problem_in_the_Doctrine_of_Chances"&gt;An Essay towards solving a Problem in the Doctrine of the Chances&lt;/a&gt; with his additions, believing that it could act as a refutation of Hume's argument&lt;/li&gt;
&lt;li&gt;1774: Laplace comes up with idea that the probability of a cause given the observed effect is the ratio of the probability of that effect given the cause to sum of the probabilities for all other causes given that effect.&lt;/li&gt;
&lt;li&gt;1781: Price tells &lt;a href="https://www.wikiwand.com/en/Marquis_de_Condorcet"&gt;the Marquis of Condorcet&lt;/a&gt; about Bayes' work and Laplace incorporates the use of the prior into his formulation&lt;/li&gt;
&lt;li&gt;1810: Laplace discovers &lt;a href="https://www.wikiwand.com/en/Central_limit_theorem"&gt;the Central Limit Theorem&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;1814: Laplace extends his version of Bayes' equation&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org37313d1" class="outline-2"&gt;
&lt;h2 id="org37313d1"&gt;The Equations&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org37313d1"&gt;
&lt;p&gt;
Since it's hard to write out the equations in bullet points I'm going to write some simple versions here.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-org10aff08" class="outline-3"&gt;
&lt;h3 id="org10aff08"&gt;Bayes' Formulation&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org10aff08"&gt;
&lt;p&gt;
"The theory that would not die" notes that Bayes' didn't write out an equation, but it can be written out something like this.
\[
P(\textit{cause}|\textit{effect}) = \frac{P(\textit{effect}|\textit{cause}) P(\textit{cause})}{P(\textit{effect})}
\]
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgee6afa6" class="outline-3"&gt;
&lt;h3 id="orgee6afa6"&gt;Laplace's First Version&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgee6afa6"&gt;
&lt;p&gt;
Originally Laplace didn't have the prior's in his equation (I'll substitute &lt;i&gt;C&lt;/i&gt; for &lt;i&gt;cause&lt;/i&gt;, &lt;i&gt;E&lt;/i&gt; for &lt;i&gt;effect&lt;/i&gt; and &lt;i&gt;C'&lt;/i&gt; for not our theorized cause).
\[
P(C|E) = \frac{P(E|C)}{\sum P(E|C')}
\]
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org19fb7e8" class="outline-3"&gt;
&lt;h3 id="org19fb7e8"&gt;Laplace's Final Version&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org19fb7e8"&gt;
&lt;p&gt;
\[
P(C|E) = \frac{P(E|C)P_{\textit{prior}}(C)}{\sum P(E|C') P_{\textit{prior}} (C')}
\]
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org9ca7d49" class="outline-2"&gt;
&lt;h2 id="org9ca7d49"&gt;Sources&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org9ca7d49"&gt;
&lt;ol class="org-ol"&gt;
&lt;li&gt;McGrayne SB. The theory that would not die: how Bayesâ rule cracked the enigma code, hunted down Russian submarines, and emerged triumphant from two centuries of controversy. paperback ed. New Haven, Conn.: Yale University Press; 2011. 336 p.&lt;/li&gt;

&lt;li&gt;Kopf D. The most important formula in data science was first used to prove the existence of God [Internet]. Quartz. [cited 2019 May 12]. Available from: &lt;a href="https://qz.com/1315731/the-most-important-formula-in-data-science-was-first-used-to-prove-the-existence-of-god/"&gt;https://qz.com/1315731/the-most-important-formula-in-data-science-was-first-used-to-prove-the-existence-of-god/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>bayes theorem</category><category>history</category><category>notes</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/notes/the-origin-of-bayes-theorem/</guid><pubDate>Sun, 12 May 2019 21:02:18 GMT</pubDate></item><item><title>Looking at random graphs</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/networks/looking-at-random-graphs/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/looking-at-random-graphs/#org1b898cf"&gt;Imports&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/looking-at-random-graphs/#org74a2156"&gt;Part 1 - Random Graph Identification&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/looking-at-random-graphs/#orgc3de31c"&gt;Load the data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/looking-at-random-graphs/#orged95f0b"&gt;Graph Identification&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/looking-at-random-graphs/#orgc875065"&gt;Part 2 - Company Emails&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/looking-at-random-graphs/#org6e75e0f"&gt;Part 2A - Salary Prediction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/looking-at-random-graphs/#org55cad8d"&gt;Part 2B - New Connections Prediction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/looking-at-random-graphs/#orgb3ef176"&gt;Separate the Target and Training Sets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/looking-at-random-graphs/#orgad08b9a"&gt;Scaling the Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/looking-at-random-graphs/#org8ac5901"&gt;Feature Selection&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org1b898cf" class="outline-2"&gt;
&lt;h2 id="org1b898cf"&gt;Imports&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org1b898cf"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# python standard library
import os
import pickle

# from pypi
import networkx
import numpy
import pandas

from sklearn.linear_model import LogisticRegressionCV
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import (
    ExtraTreesClassifier,
    RandomForestClassifier,
    )
from sklearn.feature_selection import (
    RFECV,
    SelectFromModel,
)
from sklearn.model_selection import (
    GridSearchCV,
    StratifiedKFold,
    train_test_split,
    )
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;% matplotlib inline
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org74a2156" class="outline-2"&gt;
&lt;h2 id="org74a2156"&gt;Part 1 - Random Graph Identification&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org74a2156"&gt;
&lt;p&gt;
For the first part of this assignment you will analyze randomly generated graphs and determine which algorithm created them.
&lt;/p&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgc3de31c" class="outline-3"&gt;
&lt;h3 id="orgc3de31c"&gt;Load the data&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgc3de31c"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;part_one_graphs = pickle.load(open('A4_graphs','rb'))
print(len(part_one_graphs))
print(type(part_one_graphs[0]))
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
&lt;code&gt;part_one_graphs&lt;/code&gt; is a list containing 5 networkx graphs. Each of these graphs were generated by one of three possible algorithms:
&lt;/p&gt;

&lt;ul class="org-ul"&gt;
&lt;li&gt;Preferential Attachment (`'PA'`)&lt;/li&gt;
&lt;li&gt;Small World with low probability of rewiring (`'SW&lt;sub&gt;L&lt;/sub&gt;'`)&lt;/li&gt;
&lt;li&gt;Small World with high probability of rewiring (`'SW&lt;sub&gt;H&lt;/sub&gt;'`)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;
Analyze each of the 5 graphs and determine which of the three algorithms generated the graph.
&lt;/p&gt;

&lt;p&gt;
&lt;b&gt;The `graph&lt;sub&gt;identification&lt;/sub&gt;` function should return a list of length 5 where each element in the list is either `'PA'`, `'SW&lt;sub&gt;L&lt;/sub&gt;'`, or `'SW&lt;sub&gt;H&lt;/sub&gt;'`.&lt;/b&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orged95f0b" class="outline-3"&gt;
&lt;h3 id="orged95f0b"&gt;Graph Identification&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orged95f0b"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def graph_identification():
    """Identifies the type of graph each of the graphs is

    Returns:
     list: string identifiers for the type of graph
    """
    graph_types = []
    for graph in part_one_graphs:
	path = networkx.average_shortest_path_length(graph)
	coefficient = networkx.average_clustering(graph)
	if path &amp;gt; 6:
	    if coefficient &amp;lt; 0.5:
		graph_types.append("SW_L")
	    else:
		raise Exception("unexpected type")
	else:
	    if coefficient &amp;lt; 0.5:
		graph_types.append("PA")
	    else:
		graph_types.append("SW_H")
    return graph_types
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
This was marked wrong by the grader.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgc875065" class="outline-2"&gt;
&lt;h2 id="orgc875065"&gt;Part 2 - Company Emails&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgc875065"&gt;
&lt;p&gt;
For the second part of this assignment you will be working with a company's email network where each node corresponds to a person at the company, and each edge indicates that at least one email has been sent between two people.
&lt;/p&gt;

&lt;p&gt;
The network also contains the node attributes `Department` and `ManagementSalary`.
&lt;/p&gt;

&lt;p&gt;
`Department` indicates the department in the company which the person belongs to, and `ManagementSalary` indicates whether that person is receiving a managment position salary.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;email = networkx.read_gpickle('email_prediction.txt')
print(networkx.info(email))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org6e75e0f" class="outline-3"&gt;
&lt;h3 id="org6e75e0f"&gt;Part 2A - Salary Prediction&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org6e75e0f"&gt;
&lt;p&gt;
Using network `email`, identify the people in the network with missing values for the node attribute `ManagementSalary` and predict whether or not these individuals are receiving a managment position salary.
&lt;/p&gt;

&lt;p&gt;
To accomplish this, you will need to create a matrix of node features using networkx, train a sklearn classifier on nodes that have `ManagementSalary` data, and predict a probability of the node receiving a managment salary for nodes where `ManagementSalary` is missing.
&lt;/p&gt;

&lt;p&gt;
Your predictions will need to be given as the probability that the corresponding employee is receiving a managment position salary.
&lt;/p&gt;

&lt;p&gt;
The evaluation metric for this assignment is the Area Under the ROC Curve (AUC).
&lt;/p&gt;

&lt;p&gt;
Your grade will be based on the AUC score computed for your classifier. A model which with an AUC of 0.75 or higher will receive full points.
&lt;/p&gt;

&lt;p&gt;
Using your trained classifier, return a series of length 252 with the data being the probability of receiving managment salary, and the index being the node id.
&lt;/p&gt;

&lt;pre class="example"&gt;
1       1.0
2       0.0
5       0.8
8       1.0
    ...
996     0.7
1000    0.5
1001    0.0
Length: 252, dtype: float64
&lt;/pre&gt;
&lt;/div&gt;

&lt;div id="outline-container-org233ab2e" class="outline-4"&gt;
&lt;h4 id="org233ab2e"&gt;The Data Frame&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org233ab2e"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;if not os.path.isfile("email_data.h5"):
    data = pandas.DataFrame(index=email.nodes())
    data["department"] = pandas.Series(networkx.get_node_attributes(email, "Department"))
    data["management"] = pandas.Series(networkx.get_node_attributes(email, "ManagementSalary"))
    data["clustering"] = pandas.Series(networkx.clustering(email))
    data["degree"] = pandas.Series(email.degree())
    data["degree_centrality"] = pandas.Series(networkx.degree_centrality(email))
    data["closeness_centrality"] = pandas.Series(networkx.closeness_centrality(email))
    data["betweenness_centrality"] = pandas.Series(networkx.betweenness_centrality(email))
    data["pagerank"] = pandas.Series(networkx.pagerank(email))
    _, authority = networkx.hits(email)
    data["authority"] = pandas.Series(authority)
    data.to_hdf("email_data.h5","df" )
else:
    data = pandas.read_hdf('email_data.h5', "df")
print(data.head())    
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(data.management.unique())
print(data.department.unique())
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org4e3aa18" class="outline-4"&gt;
&lt;h4 id="org4e3aa18"&gt;Department Dummy Variables&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org4e3aa18"&gt;
&lt;p&gt;
Even though I don't think it's going to prove useful, the &lt;code&gt;department&lt;/code&gt; feature is actually categorical, despite the use of integers so we'll have to use One-Hot-Encoding to add dummy variables for it.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;dummies_data = pandas.get_dummies(data, columns=["department"])
print(dummies_data.head(1))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org62645a2" class="outline-4"&gt;
&lt;h4 id="org62645a2"&gt;Separating the Training and Prediction Sets&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org62645a2"&gt;
&lt;p&gt;
We're going to use the model to predict what the missing &lt;code&gt;management&lt;/code&gt; values are so I'm going to separate the missing and non-missing sets. 
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;training_data = dummies_data[pandas.notnull(dummies_data.management)]
prediction_data = dummies_data[pandas.isnull(dummies_data.management)]
print(training_data.shape)
print(prediction_data.shape)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
The problem description tells us that the answer should have 252 entries so this is a safe assertion.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;assert len(prediction_data) == 252
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org8500437" class="outline-4"&gt;
&lt;h4 id="org8500437"&gt;Training and Target Data&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org8500437"&gt;
&lt;p&gt;
To train the model we'll need to separate out the &lt;code&gt;management&lt;/code&gt; column (and remove it entirely from the &lt;code&gt;prediction&lt;/code&gt; set).
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;non_management = [column for column in training_data.columns if column != "management"]
y_train = training_data.management
x_train = training_data[non_management]
x_predict = prediction_data[non_management]
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org68cbaf5" class="outline-4"&gt;
&lt;h4 id="org68cbaf5"&gt;Scaling&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org68cbaf5"&gt;
&lt;p&gt;
I don't think the Random Forest model that I'm going to use needs it, but I'm going to standardize the data.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_predict = pandas.DataFrame(scaler.transform(x_predict), index=x_predict.index)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org1a136ba" class="outline-4"&gt;
&lt;h4 id="org1a136ba"&gt;Feature Selection&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org1a136ba"&gt;
&lt;p&gt;
Since we now have so many features, I'm going to do some feature selection.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(x_train.shape)
print(x_predict.shape)
trees = ExtraTreesClassifier(n_estimators=10)
eliminator = RFECV(estimator=trees, cv=StratifiedKFold(10), scoring="roc_auc")
eliminator.fit(x_train, y_train)
x_train_reduced = eliminator.transform(x_train)
x_predict_reduced = pandas.DataFrame(eliminator.transform(x_predict), index=x_predict.index)
print(x_train_reduced.shape)
print(x_predict_reduced.shape)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
When I used the train-test-split training model it left 17 columns. I wonder if using the whole training set messes it up.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org671a17a" class="outline-4"&gt;
&lt;h4 id="org671a17a"&gt;Logistic Regression&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org671a17a"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;model = LogisticRegressionCV(penalty="l1", scoring="roc_auc",
			     solver="liblinear", cv=StratifiedKFold(10))
model.fit(x_train_reduced, y_train)
print(model.scores_[1.0].mean())
print(model.scores_[1.0].std())
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
It seems to be doing much worse than when I used the train-test split.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgf4a25a4" class="outline-4"&gt;
&lt;h4 id="orgf4a25a4"&gt;Random Forests&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgf4a25a4"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;parameter_grid = dict(n_estimators=range(10, 100, 10))
search = GridSearchCV(RandomForestClassifier(), parameter_grid,
		      cv=StratifiedKFold(10), scoring="roc_auc")
search.fit(x_train_reduced, y_train)
print(search.best_score_)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class RandomForest(object):
    """builds the random forest

    Args:
     x_train(array): data to train on
     y_train(array): targets for training
     start (int): start value for number of estimators
     stop (int): upper value for range of estimators
     step (int): increment for range of estimators
     folds (int): K-folds for cross-validation    
    """
    def __init__(self, x_train, y_train,
		 start=10, stop=100, step=10, folds=10):
	self.x_train = x_train
	self.y_train = y_train
	self.start = start
	self.stop = stop
	self.step = step
	self.folds = folds
	self._parameters = None
	self._search = None
	self._model = None
	return

    @property
    def parameters(self):
	"""parameters for the grid-search"""
	if self._parameters is None:
	    self._parameters = dict(n_estimators=range(self.start,
						       self.stop,
						       self.step))
	return self._parameters

    @property
    def search(self):
	"""fitted grid search to find hyper-parameters"""
	if self._search is None:
	    self._search = GridSearchCV(RandomForestClassifier(),
					self.parameters,
					cv=StratifiedKFold(self.folds),
					scoring="roc_auc")
	    self._search.fit(self.x_train, self.y_train)
	return self._search

    @property
    def model(self):
	"""best model found by the grid search"""
	if self._model is None:
	    self._model = self.search.best_estimator_
	return self._model
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org139c2a7" class="outline-4"&gt;
&lt;h4 id="org139c2a7"&gt;Data Loader&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org139c2a7"&gt;
&lt;p&gt;
Since having all these org-babel things around makes things kind of hard I'm going to make a class to bundle everything together.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class DataLoader(object):
    """loads and transforms the data
    Args:
     estimators (int): number of trees to use for feature elimination
    """
    def __init__(self, estimators=10):
	self.estimators = estimators
	self._data = None
	self._dummies_data = None
	self._training_data = None
	self._prediction_data = None
	self._non_management = None
	self._y_train = None
	self._x_train = None
	self._x_predict = None
	self._scaler = None
	self._x_train_scaled = None
	self._x_predict_scaled = None
	self._eliminator = None
	self._x_train_reduced = None
	self._x_predict_reduced = None
	return

    @property
    def data(self):
	"""The initial data"""
	if self._data is None:
	    if not os.path.isfile("email_data.h5"):
		data = pandas.DataFrame(index=email.nodes())
		data["department"] = pandas.Series(networkx.get_node_attributes(email, "Department"))
		data["management"] = pandas.Series(networkx.get_node_attributes(email, "ManagementSalary"))
		data["clustering"] = pandas.Series(networkx.clustering(email))
		data["degree"] = pandas.Series(email.degree())
		data["degree_centrality"] = pandas.Series(networkx.degree_centrality(email))
		data["closeness_centrality"] = pandas.Series(networkx.closeness_centrality(email))
		data["betweenness_centrality"] = pandas.Series(networkx.betweenness_centrality(email))
		data["pagerank"] = pandas.Series(networkx.pagerank(email))
		_, authority = networkx.hits(email)
		data["authority"] = pandas.Series(authority)
		data.to_hdf("email_data.h5","df" )
		self._data = data
	    else:
		self._data = pandas.read_hdf('email_data.h5', "df")
	return self._data

    @property
    def dummies_data(self):
	"""one-hot-encoded data"""
	if self._dummies_data is None:
	    self._dummies_data = pandas.get_dummies(self.data, columns=["department"])
	return self._dummies_data

    @property
    def training_data(self):
	"""data with management information"""
	if self._training_data is None:
	    self._training_data = self.dummies_data[pandas.notnull(
		self.dummies_data.management)]
	return self._training_data

    @property
    def prediction_data(self):
	"""data missing management information"""
	if self._prediction_data is None:
	    self._prediction_data = self.dummies_data[pandas.isnull(
		self.dummies_data.management)]
	    assert len(self._prediction_data) == 252
	return self._prediction_data

    @property
    def non_management(self):
	"""list of columns minus management"""
	if self._non_management is None:
	    self._non_management = [
		column for column in self.training_data.columns
		if column != "management"]
	return self._non_management

    @property
    def y_train(self):
	"""target-data for training"""
	if self._y_train is None:
	    self._y_train = self.training_data.management
	return self._y_train

    @property
    def x_train(self):
	"""data for training"""
	if self._x_train is None:
	    self._x_train = self.training_data[self.non_management]
	return self._x_train

    @property
    def x_predict(self):
	"""set to make predictions"""
	if self._x_predict is None:
	    self._x_predict = self.prediction_data[self.non_management]
	return self._x_predict

    @property
    def scaler(self):
	"""standard scaler"""
	if self._scaler is None:
	    self._scaler = StandardScaler()
	return self._scaler

    @property
    def x_train_scaled(self):
	"""training data scaled to 1 std, 0 mean"""
	if self._x_train_scaled is None:
	    self._x_train_scaled = self.scaler.fit_transform(self.x_train)
	return self._x_train_scaled

    @property
    def x_predict_scaled(self):
	"""prediction data with mean 0, std 1

	The answer requires the index so this is a dataframe
	instead of an array

	Returns:
	 pandas.DataFrame: scaled data with index preserved
	"""
	if self._x_predict_scaled is None:
	    self._x_predict_scaled = pandas.DataFrame(
		self.scaler.transform(self.x_predict),
		index=self.x_predict.index)
	return self._x_predict_scaled

    @property
    def eliminator(self):
	"""recursive feature eliminator"""
	if self._eliminator is None:
	    trees = ExtraTreesClassifier(n_estimators=10)
	    self._eliminator = RFECV(estimator=trees, cv=StratifiedKFold(10), 
				     scoring="roc_auc")
	    self._eliminator.fit(self.x_train_scaled, self.y_train)
	return self._eliminator

    @property
    def x_train_reduced(self):
	"""training data with features eliminated"""
	if self._x_train_reduced is None:
	    self._x_train_reduced = self.eliminator.transform(
		self.x_train_scaled)
	return self._x_train_reduced

    @property
    def x_predict_reduced(self):
	"""prediction data with features eliminated"""
	if self._x_predict_reduced is None:
	    self._x_predict_reduced = pandas.DataFrame(
		self.eliminator.transform(self.x_predict_scaled),
		index=self.x_predict_scaled.index)
	return self._x_predict_reduced
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org05e74ea" class="outline-4"&gt;
&lt;h4 id="org05e74ea"&gt;Submission&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org05e74ea"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def salary_predictions():
    """Prediction that employee is management

    Calculates the probability that an employee is management

    Returns:
     pandas.Series: Node ID, probability of node
    """
    data = DataLoader()
    forest = RandomForest(data.x_train_reduced, data.y_train)
    # probabilites is an array with rows of 
    # [&amp;lt;probability not management&amp;gt;, &amp;lt;probability management&amp;gt;]
    # see forest.model.classes_ to see what each entry represents
    probabilities = forest.model.predict_proba(data.x_predict_reduced)
    return pandas.Series(probabilities[:, 1], index=data.x_predict_reduced.index)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;output = salary_predictions()
print(output.head())
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;assert all(output.index == DataLoader().prediction_data.index)
assert len(output) == 252
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org55cad8d" class="outline-3"&gt;
&lt;h3 id="org55cad8d"&gt;Part 2B - New Connections Prediction&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org55cad8d"&gt;
&lt;p&gt;
For the last part of this assignment, you will predict future connections between employees of the network. The future connections information has been loaded into the variable `future&lt;sub&gt;connections&lt;/sub&gt;`. The index is a tuple indicating a pair of nodes that currently do not have a connection, and the `Future Connection` column indicates if an edge between those two nodes will exist in the future, where a value of 1.0 indicates a future connection.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;future_connections = pandas.read_csv('Future_Connections.csv', index_col=0, converters={0: eval})
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(future_connections.head(10))
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(future_connections['Future Connection'].value_counts())
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;
Using network `G` and `future&lt;sub&gt;connections&lt;/sub&gt;`, identify the edges in `future&lt;sub&gt;connections&lt;/sub&gt;` with missing values and predict whether or not these edges will have a future connection.
&lt;/p&gt;

&lt;p&gt;
To accomplish this, you will need to create a matrix of features for the edges found in `future&lt;sub&gt;connections&lt;/sub&gt;` using networkx, train a sklearn classifier on those edges in `future&lt;sub&gt;connections&lt;/sub&gt;` that have `Future Connection` data, and predict a probability of the edge being a future connection for those edges in `future&lt;sub&gt;connections&lt;/sub&gt;` where `Future Connection` is missing.
&lt;/p&gt;

&lt;p&gt;
Your predictions will need to be given as the probability of the corresponding edge being a future connection.
&lt;/p&gt;

&lt;p&gt;
The evaluation metric for this assignment is the Area Under the ROC Curve (AUC).
&lt;/p&gt;

&lt;p&gt;
Your grade will be based on the AUC score computed for your classifier. A model which with an AUC of 0.75 or higher will receive full points.
&lt;/p&gt;

&lt;p&gt;
Using your trained classifier, return a series of length 122112 with the data being the probability of the edge being a future connection, and the index being the edge as represented by a tuple of nodes.
&lt;/p&gt;

&lt;pre class="example"&gt;
(107, 348)    0.35
(542, 751)    0.40
(20, 426)     0.55
(50, 989)     0.35
          ...
(939, 940)    0.15
(555, 905)    0.35
(75, 101)     0.65
Length: 122112, dtype: float64
&lt;/pre&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgdefe904" class="outline-4"&gt;
&lt;h4 id="orgdefe904"&gt;Add Network Features&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgdefe904"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class Futures(object):
    target = "Future Connection"
    data_file = "Future_Connections.csv"
    graph_file = "email_prediction.txt"
    networkx_data_index = 2
    folds = 10
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;class DataNames(object):
    resource_allocation = 'resource_allocation'
    jaccard = 'jaccard_coefficient'
    adamic = "adamic_adar"
    preferential = "preferential_attachment"
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def add_networkx_data(adder, name, graph=email, frame=future_connections):
    """Adds networkx data to the frame

    The networkx link-prediction functions return generators of triples:
     (first-node, second-node, value)

    This will use the index of the frame that's passed in as the source of 
    node-pairs for the networkx function (called `ebunch` in the networkx
    documentation) and the add only the value we want back to the frame

    Args:
     adder: networkx function to call to get the new data
     name: column-name to add to the frame
     graph: networkx graph to pass to the function
     frame (pandas.DataFrame): frame with node-pairs as index to add data to
    """
    frame[name] = [output[Futures.networkx_data_index]
		   for output in adder(graph, frame.index)]
    return frame
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgc4ca998" class="outline-5"&gt;
&lt;h5 id="orgc4ca998"&gt;Adding A Resource Allocation Index&lt;/h5&gt;
&lt;div class="outline-text-5" id="text-orgc4ca998"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;add_networkx_data(networkx.resource_allocation_index,
		  DataNames.resource_allocation)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(future_connections.head(1))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org58f379f" class="outline-5"&gt;
&lt;h5 id="org58f379f"&gt;Adding the Jaccard Coefficient&lt;/h5&gt;
&lt;div class="outline-text-5" id="text-org58f379f"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;add_networkx_data(networkx.jaccard_coefficient, DataNames.jaccard)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(future_connections.head(1))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org92d86da" class="outline-5"&gt;
&lt;h5 id="org92d86da"&gt;Adamic Adar&lt;/h5&gt;
&lt;div class="outline-text-5" id="text-org92d86da"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;add_networkx_data(networkx.adamic_adar_index, DataNames.adamic)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(future_connections.head(1))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org3e4025c" class="outline-5"&gt;
&lt;h5 id="org3e4025c"&gt;Preferential Attachment&lt;/h5&gt;
&lt;div class="outline-text-5" id="text-org3e4025c"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;add_networkx_data(networkx.preferential_attachment, DataNames.preferential)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(future_connections.head(1))
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgc16d60b" class="outline-4"&gt;
&lt;h4 id="orgc16d60b"&gt;Setup the Training and Testing Data&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgc16d60b"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org1c3a250" class="outline-5"&gt;
&lt;h5 id="org1c3a250"&gt;Separating the Edges Without 'Future Connection' Values&lt;/h5&gt;
&lt;div class="outline-text-5" id="text-org1c3a250"&gt;
&lt;p&gt;
We are going to train on the values in the data with predictions and then make predictions for those that don't.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;prediction_set = future_connections[future_connections[Futures.target].isnull()]
training_set = future_connections[future_connections[Futures.target].notnull()]
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(prediction_set.shape)
print(training_set.shape)
assert len(prediction_set) + len(training_set) == len(future_connections)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgb3ef176" class="outline-3"&gt;
&lt;h3 id="orgb3ef176"&gt;Separate the Target and Training Sets&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgb3ef176"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;non_target = [column for column in future_connections.columns
	      if column != Futures.target]
x_train = training_set[non_target]
y_train = training_set[Futures.target]
x_predict = prediction_set[non_target]
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;assert all(x_train.columns == x_predict.columns)
assert len(x_train) == len(x_test)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgad08b9a" class="outline-3"&gt;
&lt;h3 id="orgad08b9a"&gt;Scaling the Data&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgad08b9a"&gt;
&lt;p&gt;
To enable the use of linear models I'm going to scale the data so the mean is 0 and the variance is 1.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;scaler = StandardScaler()
x_train_scaled = scaler.fit_transform(x_train)
x_predict_scaled = scaler.transform(x_predict)

x_train_frame = pandas.DataFrame(x_train_scaled, columns=x_train.columns)
x_predict_frame = pandas.DataFrame(x_predict_scaled, columns=x_predict.columns)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(training.describe())
print(predictions.describe())
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org8ac5901" class="outline-3"&gt;
&lt;h3 id="org8ac5901"&gt;Feature Selection&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org8ac5901"&gt;
&lt;p&gt;
To reduce the dimensionality I'm going to use model-based selection with Extra Trees.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;estimator = ExtraTreesClassifier()
estimator.fit(x_train_scaled, y_train)
selector = SelectFromModel(estimator, prefit=True)
x_train_trees_sfm = selector.transform(x_train_scaled)
x_predict_sfm = selector.transform(x_predict_scaled)
print(estimator.feature_importances_)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(x_train_trees_sfm.shape)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org46db689" class="outline-4"&gt;
&lt;h4 id="org46db689"&gt;Missing Future Connections&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org46db689"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;model = LogisticRegressionCV(n_jobs=-1, scoring='roc_auc', solver='liblinear',
			     cv=StratifiedKFold())
model.fit(x_train_trees_sfm, y_train)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;for scores in model.scores_[1.0]:
    print(max(scores))
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(model.classes_)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def new_connections_predictions():    
    probabilities = model.predict_proba(x_predict_sfm)
    return pandas.Series(probabilities[:, 1], index=prediction_set.index)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;outcome = new_connections_predictions()
assert len(outcome) == 122112, len(outcome)
print(outcome.head())
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>networks</category><category>random graphs</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/networks/looking-at-random-graphs/</guid><pubDate>Sat, 13 Apr 2019 18:59:44 GMT</pubDate></item></channel></rss>