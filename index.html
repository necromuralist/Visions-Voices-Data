<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content="Adumbrations of data." name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>Visions, Voices, Data</title>
<link href="assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="rss.xml" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/Visions-Voices-Data/" rel="canonical">
<link href="index-6.html" rel="next" type="text/html"><!--[if lt IE 9]><script src="assets/js/html5.js"></script><![endif]-->
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script><!--
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/0.9.0/p5.min.js"
</script>
-->
<script async src="javascript/p5.min.js" type="text/javascript"></script>
<link href="/posts/tutorials/data-leakage/" rel="prefetch" type="text/html">
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="https://necromuralist.github.io/Visions-Voices-Data/"><span id="blog-title">Visions, Voices, Data</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="/archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="/categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="/rss.xml">RSS feed</a></li>
<li class="nav-item dropdown"><a aria-expanded="false" aria-haspopup="true" class="nav-link dropdown-toggle" data-toggle="dropdown" href="#">Pages</a>
<div class="dropdown-menu"><a class="dropdown-item active" href="/">Cloistered Monkey <span class="sr-only">(active)</span></a> <a class="dropdown-item" href="/pages/giss/giss-yearly-anomalies-by-climate-zone">GISS Anomalies</a></div>
</li>
</ul>
<!-- DuckDuckGo custom search -->
<form action="https://duckduckgo.com/" class="navbar-form pull-left" id="search" method="get" name="search"><input name="sites" type="hidden" value="https://necromuralist.github.io/Visions-Voices-Data/"> <input name="k8" type="hidden" value="#444444"> <input name="k9" type="hidden" value="#D51920"> <input name="kt" type="hidden" value="h"> <input class="span2" maxlength="255" name="q" placeholder="Searchâ€¦" type="text"> <input style="visibility: hidden;display:none" type="submit" value="DuckDuckGo Search"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right"></ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<div class="postindex">
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="/posts/tutorials/data-leakage/">Data Leakage</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="/posts/tutorials/data-leakage/" rel="bookmark"><time class="published dt-published" datetime="2020-02-20T21:26:31-08:00" itemprop="datePublished" title="2020-02-20 21:26">2020-02-20 21:26</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="/posts/tutorials/data-leakage/#orgff5f1d7">Beginning</a>
<ul>
<li><a href="/posts/tutorials/data-leakage/#org0385a5f">1. The Data Science of Shoelaces</a></li>
<li><a href="/posts/tutorials/data-leakage/#org1a934c8">2. Return of the Shoelaces</a></li>
<li><a href="/posts/tutorials/data-leakage/#org765822f">3. Getting Rich With Cryptocurrencies?</a></li>
<li><a href="/posts/tutorials/data-leakage/#org2c6ffe1">4. Preventing Infections</a></li>
<li><a href="/posts/tutorials/data-leakage/#org441106d">5. Housing Prices</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orgff5f1d7">
<h2 id="orgff5f1d7">Beginning</h2>
<div class="outline-text-2" id="text-orgff5f1d7">
<blockquote>
<p>Most people find target leakage very tricky until they've thought about it for a long time.</p>
<p>So, before trying to think about leakage in the housing price example, we'll go through a few examples in other applications. Things will feel more familiar once you come back to a question about house prices.</p>
</blockquote>
</div>
<div class="outline-3" id="outline-container-org0385a5f">
<h3 id="org0385a5f">1. The Data Science of Shoelaces</h3>
<div class="outline-text-3" id="text-org0385a5f">
<blockquote>
<p>Nike has hired you as a data science consultant to help them save money on shoe materials. Your first assignment is to review a model one of their employees built to predict how many shoelaces they'll need each month. The features going into the machine learning model include:</p>
<ul class="org-ul">
<li>The current month (January, February, etc)</li>
<li>Advertising expenditures in the previous month</li>
<li>Various macroeconomic features (like the unemployment rate) as of the beginning of the current month</li>
<li>The amount of leather they ended up using in the current month</li>
</ul>
<p>The results show the model is almost perfectly accurate if you include the feature about how much leather they used. But it is only moderately accurate if you leave that feature out. You realize this is because the amount of leather they use is a perfect indicator of how many shoes they produce, which in turn tells you how many shoelaces they need.</p>
<p>Do you think the <code>leather used</code> feature constitutes a source of data leakage? If your answer is "it depends," what does it depend on?</p>
</blockquote>
<p><code>leather_used</code> does seem like a leakage, but it depends on whether the value is known before the shoelace predictions are made. If you won't know it in time for the predictions, then it is a leak. If there's a reason why you would always know the amount used but somehow not know how many shoes were made it might not be a data leak, but it seems odd that it would be useful. It be useable if it is a prediction of the amount of leather that will be needed, but it seems odd to use it then to predict shoelaces.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org1a934c8">
<h3 id="org1a934c8">2. Return of the Shoelaces</h3>
<div class="outline-text-3" id="text-org1a934c8">
<blockquote>
<p>You have a new idea. You could use the amount of leather Nike ordered (rather than the amount they actually used) leading up to a given month as a predictor in your shoelace model.</p>
<p>Does this change your answer about whether there is a leakage problem? If you answer "it depends," what does it depend on?</p>
</blockquote>
<p>Whether it is a leak will depend on whether the leather is always ordered before the shoelaces or not. If they are always ordered before shoelaces then it wouldn't be a leak.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org765822f">
<h3 id="org765822f">3. Getting Rich With Cryptocurrencies?</h3>
<div class="outline-text-3" id="text-org765822f">
<blockquote>
<p>You saved Nike so much money that they gave you a bonus. Congratulations.</p>
<p>Your friend, who is also a data scientist, says he has built a model that will let you turn your bonus into millions of dollars. Specifically, his model predicts the price of a new cryptocurrency (like Bitcoin, but a newer one) one day ahead of the moment of prediction. His plan is to purchase the cryptocurrency whenever the model says the price of the currency (in dollars) is about to go up.</p>
<p>The most important features in his model are:</p>
<ul class="org-ul">
<li>Current price of the currency</li>
<li>Amount of the currency sold in the last 24 hours</li>
<li>Change in the currency price in the last 24 hours</li>
<li>Change in the currency price in the last 1 hour</li>
<li>Number of new tweets in the last 24 hours that mention the currency</li>
</ul>
<p>The value of the cryptocurrency in dollars has fluctuated up and down by over $100 in the last year, and yet his model's average error is less than $1. He says this is proof his model is accurate, and you should invest with him, buying the currency whenever the model says it is about to go up.</p>
<p>Is he right? If there is a problem with his model, what is it?</p>
</blockquote>
<p>The data isn't leaking.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org2c6ffe1">
<h3 id="org2c6ffe1">4. Preventing Infections</h3>
<div class="outline-text-3" id="text-org2c6ffe1">
<blockquote>
<p>An agency that provides healthcare wants to predict which patients from a rare surgery are at risk of infection, so it can alert the nurses to be especially careful when following up with those patients.</p>
<p>You want to build a model. Each row in the modeling dataset will be a single patient who received the surgery, and the prediction target will be whether they got an infection.</p>
<p>Some surgeons may do the procedure in a manner that raises or lowers the risk of infection. But how can you best incorporate the surgeon information into the model?</p>
<p>You have a clever idea.</p>
<ol class="org-ol">
<li>Take all surgeries by each surgeon and calculate the infection rate among those surgeons.</li>
<li>For each patient in the data, find out who the surgeon was and plug in that surgeon's average infection rate as a feature.</li>
</ol>
<p>Does this pose any target leakage issues? Does it pose any train-test contamination issues?</p>
</blockquote>
<p>The infection rate would have a target leak if the calculated value includes the patient whose row it is added to.</p>
<p>You would have train-test contamination if you calculated this value using both the train and test set. You would have to calculate it only on the training set to avoid contamination.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org441106d">
<h3 id="org441106d">5. Housing Prices</h3>
<div class="outline-text-3" id="text-org441106d">
<blockquote>
<p>You will build a model to predict housing prices. The model will be deployed on an ongoing basis, to predict the price of a new house when a description is added to a website. Here are four features that could be used as predictors.</p>
<ol class="org-ol">
<li>Size of the house (in square meters)</li>
<li>Average sales price of homes in the same neighborhood</li>
<li>Latitude and longitude of the house</li>
<li>Whether the house has a basement</li>
</ol>
<p>You have historic data to train and validate the model.</p>
<p>Which of the features is most likely to be a source of leakage?</p>
</blockquote>
<p>Average sales price of homes in the same neighborhood. If the home was sold in the past, then it would contribute to the average.</p>
<blockquote>
<p>Leakage is a hard and subtle issue. You should be proud if you picked up on the issues in these examples.</p>
<p>Now you have the tools to make highly accurate models, and pick up on the most difficult practical problems that arise with applying these models to solve real problems.</p>
</blockquote>
</div>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="/posts/tutorials/xgboost/">XGBoost</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="/posts/tutorials/xgboost/" rel="bookmark"><time class="published dt-published" datetime="2020-02-20T21:25:25-08:00" itemprop="datePublished" title="2020-02-20 21:25">2020-02-20 21:25</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="/posts/tutorials/xgboost/#org3f2ac50">Beginning</a>
<ul>
<li><a href="/posts/tutorials/xgboost/#orgbaab2a6">Imports</a>
<ul>
<li><a href="/posts/tutorials/xgboost/#org06228ab">Python</a></li>
<li><a href="/posts/tutorials/xgboost/#orge65cb7a">PyPi</a></li>
<li><a href="/posts/tutorials/xgboost/#org12ebcc4">Others</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/xgboost/#org517df4d">Set Up</a>
<ul>
<li><a href="/posts/tutorials/xgboost/#org92e63c1">Table</a></li>
<li><a href="/posts/tutorials/xgboost/#orgfa6537a">Plottting</a></li>
<li><a href="/posts/tutorials/xgboost/#orgcf8a438">The Timer</a></li>
<li><a href="/posts/tutorials/xgboost/#org266de72">Environment</a></li>
<li><a href="/posts/tutorials/xgboost/#org8adf81f">The Data</a></li>
<li><a href="/posts/tutorials/xgboost/#org2d79006">Some Constants</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/xgboost/#org534d681">Setup The Data</a>
<ul>
<li><a href="/posts/tutorials/xgboost/#org4a8f899">Selecting columns</a></li>
<li><a href="/posts/tutorials/xgboost/#orgf5a81d8">One-Hot Encoding</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/xgboost/#org30fba0f">Step 1: Build model</a></li>
<li><a href="/posts/tutorials/xgboost/#orgead6233">Step 2: Improve the model</a></li>
<li><a href="/posts/tutorials/xgboost/#org7e0b1d7">Step 3: Break the model</a></li>
<li><a href="/posts/tutorials/xgboost/#orgec53d5e">Numeric Values Only</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/xgboost/#org27be213">End</a>
<ul>
<li>
<ul>
<li><a href="/posts/tutorials/xgboost/#orgf2433c0">Make a Submission using the XGB early-stopping model</a></li>
<li><a href="/posts/tutorials/xgboost/#org84194b9">Random Search CV</a></li>
<li><a href="/posts/tutorials/xgboost/#orgfe4a3ab">Early Stopping with Imputation</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org3f2ac50">
<h2 id="org3f2ac50">Beginning</h2>
<div class="outline-text-2" id="text-org3f2ac50">
<blockquote>
<p>In this exercise, you will leverage what you've learned to tune a machine learning model with <b>cross-validation</b>.</p>
</blockquote>
</div>
<div class="outline-3" id="outline-container-orgbaab2a6">
<h3 id="orgbaab2a6">Imports</h3>
<div class="outline-text-3" id="text-orgbaab2a6"></div>
<div class="outline-4" id="outline-container-org06228ab">
<h4 id="org06228ab">Python</h4>
<div class="outline-text-4" id="text-org06228ab">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="kn">import</span> <span class="nn">random</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orge65cb7a">
<h4 id="orge65cb7a">PyPi</h4>
<div class="outline-text-4" id="text-orge65cb7a">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">eli5.sklearn</span> <span class="kn">import</span> <span class="n">PermutationImportance</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span>

<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.experimental</span> <span class="kn">import</span> <span class="n">enable_iterative_imputer</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">IterativeImputer</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">RandomizedSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>

<span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBRegressor</span>

<span class="kn">from</span> <span class="nn">tabulate</span> <span class="kn">import</span> <span class="n">tabulate</span>

<span class="kn">import</span> <span class="nn">eli5</span>
<span class="kn">import</span> <span class="nn">hvplot.pandas</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">pandas</span>
<span class="kn">import</span> <span class="nn">shap</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org12ebcc4">
<h4 id="org12ebcc4">Others</h4>
<div class="outline-text-4" id="text-org12ebcc4">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">CountPercentage</span><span class="p">,</span> <span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">EnvironmentLoader</span><span class="p">,</span> <span class="n">Timer</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org517df4d">
<h3 id="org517df4d">Set Up</h3>
<div class="outline-text-3" id="text-org517df4d"></div>
<div class="outline-4" id="outline-container-org92e63c1">
<h4 id="org92e63c1">Table</h4>
<div class="outline-text-4" id="text-org92e63c1">
<div class="highlight">
<pre><span></span><span class="n">TABLE</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">tabulate</span><span class="p">,</span> <span class="n">tablefmt</span><span class="o">=</span><span class="s2">"orgtbl"</span><span class="p">,</span> <span class="n">showindex</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="s2">"keys"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgfa6537a">
<h4 id="orgfa6537a">Plottting</h4>
<div class="outline-text-4" id="text-orgfa6537a">
<div class="highlight">
<pre><span></span><span class="n">SLUG</span> <span class="o">=</span> <span class="s2">"xgboost"</span>
<span class="n">OUTPUT_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"../../files/posts/tutorials/"</span><span class="p">)</span><span class="o">/</span><span class="n">SLUG</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">OUTPUT_PATH</span><span class="o">.</span><span class="n">is_dir</span><span class="p">():</span>
    <span class="n">OUTPUT_PATH</span><span class="o">.</span><span class="n">mkdir</span><span class="p">()</span>
<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">folder_path</span><span class="o">=</span><span class="n">OUTPUT_PATH</span><span class="p">)</span>
<span class="n">Plot</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgcf8a438">
<h4 id="orgcf8a438">The Timer</h4>
<div class="outline-text-4" id="text-orgcf8a438">
<div class="highlight">
<pre><span></span><span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org266de72">
<h4 id="org266de72">Environment</h4>
<div class="outline-text-4" id="text-org266de72">
<div class="highlight">
<pre><span></span><span class="n">ENVIRONMENT</span> <span class="o">=</span> <span class="n">EnvironmentLoader</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org8adf81f">
<h4 id="org8adf81f">The Data</h4>
<div class="outline-text-4" id="text-org8adf81f">
<div class="highlight">
<pre><span></span><span class="n">DATA_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">ENVIRONMENT</span><span class="p">[</span><span class="s2">"HOUSE-PRICES-IOWA"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="n">DATA_PATH</span><span class="o">/</span><span class="s2">"train.csv"</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s2">"Id"</span><span class="p">)</span>

<span class="n">test_data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="n">DATA_PATH</span><span class="o">/</span><span class="s2">"test.csv"</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s2">"Id"</span>
<span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">test_data</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org2d79006">
<h4 id="org2d79006">Some Constants</h4>
<div class="outline-text-4" id="text-org2d79006">
<div class="highlight">
<pre><span></span><span class="n">Data</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">target</span><span class="o">=</span><span class="s2">"SalePrice"</span><span class="p">,</span>
    <span class="n">train_size</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">random_seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org534d681">
<h3 id="org534d681">Setup The Data</h3>
<div class="outline-text-3" id="text-org534d681">
<p>Split up the target and features.</p>
<div class="highlight">
<pre><span></span><span class="k">assert</span> <span class="ow">not</span> <span class="n">train_data</span><span class="p">[</span><span class="n">Data</span><span class="o">.</span><span class="n">target</span><span class="p">]</span><span class="o">.</span><span class="n">hasnans</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="n">Data</span><span class="o">.</span><span class="n">target</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="n">Data</span><span class="o">.</span><span class="n">target</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="s2">"columns"</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_validate</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_validate</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
    <span class="n">train_size</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">train_size</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">test_size</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-org4a8f899">
<h4 id="org4a8f899">Selecting columns</h4>
<div class="outline-text-4" id="text-org4a8f899">
<p>"Cardinality" means the number of unique values in a column. Select categorical columns with relatively low cardinality (convenient but arbitrary).</p>
<div class="highlight">
<pre><span></span><span class="n">low_cardinality_cols</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">cname</span> <span class="k">for</span> <span class="n">cname</span> <span class="ow">in</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">X_train</span><span class="p">[</span><span class="n">cname</span><span class="p">]</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mi">10</span> <span class="ow">and</span>
    <span class="n">X_train</span><span class="p">[</span><span class="n">cname</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="s2">"object"</span><span class="p">]</span>
</pre></div>
<p>Select numeric columns.</p>
<div class="highlight">
<pre><span></span><span class="n">numeric_columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">column</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span>
                   <span class="k">if</span> <span class="n">X_train</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'int64'</span><span class="p">,</span> <span class="s1">'float64'</span><span class="p">]]</span>
</pre></div>
<p>Keep selected columns only</p>
<div class="highlight">
<pre><span></span><span class="n">keep_columns</span> <span class="o">=</span> <span class="n">low_cardinality_cols</span> <span class="o">+</span> <span class="n">numeric_columns</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">keep_columns</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">X_valid</span> <span class="o">=</span> <span class="n">X_validate</span><span class="p">[</span><span class="n">keep_columns</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">[</span><span class="n">keep_columns</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgf5a81d8">
<h4 id="orgf5a81d8">One-Hot Encoding</h4>
<div class="outline-text-4" id="text-orgf5a81d8">
<p>One-hot encode the data (to shorten the code, we use pandas).</p>
<div class="highlight">
<pre><span></span><span class="n">X_train</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_validate</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">X_validate</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_validate</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">align</span><span class="p">(</span><span class="n">X_validate</span><span class="p">,</span> <span class="n">join</span><span class="o">=</span><span class="s1">'left'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">align</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">join</span><span class="o">=</span><span class="s1">'left'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org30fba0f">
<h3 id="org30fba0f">Step 1: Build model</h3>
<div class="outline-text-3" id="text-org30fba0f">
<blockquote>
<p>In this step, you'll build and train your first model with gradient boosting.</p>
<ul class="org-ul">
<li>Begin by setting <code>my_model_1</code> to an XGBoost model. Use the <a href="https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBRegressor">XGBRegressor</a> class, and set the random seed to 0 (<code>random_state=0</code>). <b>Leave all other parameters as default.</b></li>
<li>Then, fit the model to the training data in <code>X_train</code> and <code>y_train</code>.</li>
</ul>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">XGBRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">predictions_1</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_validate</span><span class="p">)</span>
</pre></div>
<blockquote>
<p>Finally, use the <code>mean_absolute_error()</code> function to calculate the mean absolute error (MAE) corresponding to the predictions for the validation set. Recall that the labels for the validation data are stored in <code>y_valid</code>.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">mae_1</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">predictions_1</span><span class="p">,</span> <span class="n">y_validate</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Mean Absolute Error: {mae_1}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Mean Absolute Error: 17662.736729452055
</pre></div>
</div>
<div class="outline-3" id="outline-container-orgead6233">
<h3 id="orgead6233">Step 2: Improve the model</h3>
<div class="outline-text-3" id="text-orgead6233">
<blockquote>
<p>Now that you've trained a default model as baseline, it's time to tinker with the parameters, to see if you can get better performance.</p>
<ul class="org-ul">
<li>Begin by setting <code>my_model_2</code> to an XGBoost model, using the <a href="https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBRegressor">XGBRegressor</a> class. Use what you learned in the previous tutorial to figure out how to change the default parameters (like <code>n_estimators</code> and <code>learning_rate</code>) to get better results.</li>
<li>Then, fit the model to the training data in <code>X_train</code> and <code>y_train</code>.</li>
<li>Set <code>predictions_2</code> to the model's predictions for the validation data. Recall that the validation features are stored in <code>X_valid</code>.</li>
<li>Finally, use the <code>mean_absolute_error()</code> function to calculate the mean absolute error (MAE) corresponding to the predictions on the validation set. Recall that the labels for the validation data are stored in <code>y_valid</code>.</li>
</ul>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">estimators</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">max_depth</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span> <span class="o">+</span> <span class="p">[</span><span class="bp">None</span><span class="p">]</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.05</span> <span class="o">*</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

<span class="n">grid</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="n">estimators</span><span class="p">,</span>
            <span class="n">max_depth</span><span class="o">=</span><span class="n">max_depth</span><span class="p">)</span>
            <span class="c1">#learning_rate=learning_rate)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">XGBRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">random_seed</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.05</span><span class="p">)</span>
<span class="n">search</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                            <span class="n">param_distributions</span><span class="o">=</span><span class="n">grid</span><span class="p">,</span>
                            <span class="n">n_iter</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
                            <span class="n">scoring</span><span class="o">=</span><span class="s2">"neg_mean_absolute_error"</span><span class="p">,</span>
                            <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
                            <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">X_cv</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_validate</span><span class="p">])</span>
<span class="n">y_cv</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_validate</span><span class="p">])</span>
<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_cv</span><span class="p">,</span> <span class="n">y_cv</span><span class="p">)</span>
<span class="n">first_model</span> <span class="o">=</span> <span class="n">search</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"CV Training MAE: {-search.best_score_:0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
</pre></div>
<pre class="example">
2020-03-01 21:34:37,418 graeae.timers.timer start: Started: 2020-03-01 21:34:37.418449
2020-03-01 21:36:24,107 graeae.timers.timer end: Ended: 2020-03-01 21:36:24.107671
2020-03-01 21:36:24,109 graeae.timers.timer end: Elapsed: 0:01:46.689222
CV Training MAE: 16048.16
{'n_estimators': 160, 'max_depth': None}
</pre>
<div class="highlight">
<pre><span></span><span class="n">outcome</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">"Score"</span><span class="p">:</span> <span class="n">search</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s2">"mean_test_score"</span><span class="p">]})</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">early_stopping_model</span> <span class="o">=</span> <span class="n">XGBRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">random_seed</span><span class="p">,</span>
                                    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
                                    <span class="n">early_stopping_rounds</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                                    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="n">early_stopping_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">X_validate</span><span class="p">,</span> <span class="n">y_validate</span><span class="p">)],</span>
                         <span class="n">verbose</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">early_stopping_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_validate</span><span class="p">),</span>
                          <span class="n">y_validate</span><span class="p">))</span>
</pre></div>
<pre class="example">
16728.27523009418
</pre>
<div class="highlight">
<pre><span></span><span class="n">params</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Trees: {params['n_estimators']}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Trees: 100
</pre></div>
</div>
<div class="outline-3" id="outline-container-org7e0b1d7">
<h3 id="org7e0b1d7">Step 3: Break the model</h3>
<div class="outline-text-3" id="text-org7e0b1d7">
<blockquote>
<p>In this step, you will create a model that performs worse than the original model in Step 1. This will help you to develop your intuition for how to set parameters. You might even find that you accidentally get better performance, which is ultimately a nice problem to have and a valuable learning experience!</p>
<ul class="org-ul">
<li>Begin by setting <code>my_model_3</code> to an XGBoost model, using the <a href="https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBRegressor">XGBRegressor</a> class. Use what you learned in the previous tutorial to figure out how to change the default parameters (like <code>n_estimators</code> and <code>learning_rate</code>) to design a model to get high MAE.</li>
<li>Then, fit the model to the training data in <code>X_train</code> and <code>y_train</code>.</li>
<li>Set <code>predictions_3</code> to the model's predictions for the validation data. Recall that the validation features are stored in <code>X_valid</code>.</li>
<li>Finally, use the <code>mean_absolute_error()</code> function to calculate the mean absolute error (MAE) corresponding to the predictions on the validation set. Recall that the labels for the validation data are stored in <code>y_valid</code>.</li>
</ul>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">parameters</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">search</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s2">"params"</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="n">parameters</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">XGBRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">random_seed</span><span class="p">,</span> <span class="o">**</span><span class="n">parameters</span><span class="p">)</span>
<span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"MAE: {mean_absolute_error(model.predict(X_validate), y_validate)}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
2020-02-29 20:55:54,573 graeae.timers.timer start: Started: 2020-02-29 20:55:54.573008
{'n_estimators': 60, 'max_depth': 20, 'learning_rate': 0.7000000000000001}
2020-02-29 20:55:55,019 graeae.timers.timer end: Ended: 2020-02-29 20:55:55.019335
2020-02-29 20:55:55,020 graeae.timers.timer end: Elapsed: 0:00:00.446327
MAE: 25077.38005672089
</pre></div>
</div>
<div class="outline-3" id="outline-container-orgec53d5e">
<h3 id="orgec53d5e">Numeric Values Only</h3>
<div class="outline-text-3" id="text-orgec53d5e">
<div class="highlight">
<pre><span></span><span class="n">imputer</span> <span class="o">=</span> <span class="n">IterativeImputer</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>

<span class="n">final_x_train</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span>
                                 <span class="n">columns</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">early_stopping_model_2</span> <span class="o">=</span> <span class="n">XGBRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">random_seed</span><span class="p">,</span>
                                      <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
                                      <span class="n">early_stopping_rounds</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                                      <span class="n">n_estimators</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
<span class="n">early_stopping_model_2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">final_x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">eval_set</span><span class="o">=</span><span class="p">[(</span><span class="n">X_validate</span><span class="p">,</span> <span class="n">y_validate</span><span class="p">)],</span>
                         <span class="n">verbose</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">early_stopping_model_2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_validate</span><span class="p">),</span>
                          <span class="n">y_validate</span><span class="p">))</span>
</pre></div>
<pre class="example">
16516.399373929795
</pre></div>
</div>
</div>
<div class="outline-2" id="outline-container-org27be213">
<h2 id="org27be213">End</h2>
<div class="outline-text-2" id="text-org27be213"></div>
<div class="outline-4" id="outline-container-orgf2433c0">
<h4 id="orgf2433c0">Make a Submission using the XGB early-stopping model</h4>
<div class="outline-text-4" id="text-orgf2433c0">
<div class="highlight">
<pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">early_stopping_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">'Id'</span><span class="p">:</span> <span class="n">X_test</span><span class="o">.</span><span class="n">index</span><span class="p">,</span>
                           <span class="s1">'SalePrice'</span><span class="p">:</span> <span class="n">predictions</span><span class="p">})</span>
<span class="n">output</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">DATA_PATH</span><span class="o">/</span><span class="s1">'submission.csv'</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
<p>This got a score of <i>14777.96266</i> on the kaggle submissions page.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org84194b9">
<h4 id="org84194b9">Random Search CV</h4>
<div class="outline-text-4" id="text-org84194b9">
<div class="highlight">
<pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">search</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">'Id'</span><span class="p">:</span> <span class="n">X_test</span><span class="o">.</span><span class="n">index</span><span class="p">,</span>
                           <span class="s1">'SalePrice'</span><span class="p">:</span> <span class="n">predictions</span><span class="p">})</span>
<span class="n">output</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">DATA_PATH</span><span class="o">/</span><span class="s1">'submission.csv'</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
<p>This one got a score of <i>14976.55345</i>, so the early stopping model is the best one so farâ€¦ It had fewer trees than the model that the RandomSearch CV ended up with, maybe the Random Search overfit the data.</p>
</div>
</div>
<div class="outline-4" id="outline-container-orgfe4a3ab">
<h4 id="orgfe4a3ab">Early Stopping with Imputation</h4>
<div class="outline-text-4" id="text-orgfe4a3ab">
<div class="highlight">
<pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">early_stopping_model_2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">'Id'</span><span class="p">:</span> <span class="n">X_test</span><span class="o">.</span><span class="n">index</span><span class="p">,</span>
                           <span class="s1">'SalePrice'</span><span class="p">:</span> <span class="n">predictions</span><span class="p">})</span>
<span class="n">output</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">DATA_PATH</span><span class="o">/</span><span class="s1">'submission.csv'</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
<p>This gets a score of <i>14965.20801</i> so it looks like the XGBoost model without imputation is the best one.</p>
</div>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="/posts/tutorials/cross-validation/">Cross Validation</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="/posts/tutorials/cross-validation/" rel="bookmark"><time class="published dt-published" datetime="2020-02-20T21:15:04-08:00" itemprop="datePublished" title="2020-02-20 21:15">2020-02-20 21:15</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="/posts/tutorials/cross-validation/#org8497bc2">Beginning</a>
<ul>
<li><a href="/posts/tutorials/cross-validation/#orga36a449">Imports</a>
<ul>
<li><a href="/posts/tutorials/cross-validation/#orgcdb5281">Python</a></li>
<li><a href="/posts/tutorials/cross-validation/#org176f97c">PyPi</a></li>
<li><a href="/posts/tutorials/cross-validation/#orgb01b5fc">Others</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/cross-validation/#org004074e">Set Up</a>
<ul>
<li><a href="/posts/tutorials/cross-validation/#org14e06dc">Table</a></li>
<li><a href="/posts/tutorials/cross-validation/#orgc9df300">Plottting</a></li>
<li><a href="/posts/tutorials/cross-validation/#orgf234cd1">The Timer</a></li>
<li><a href="/posts/tutorials/cross-validation/#org27a76b2">Environment</a></li>
<li><a href="/posts/tutorials/cross-validation/#orgb550015">The Data</a></li>
<li><a href="/posts/tutorials/cross-validation/#org0f0c80a">Some Constants</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/cross-validation/#org7a36c76">Setup The Data</a>
<ul>
<li><a href="/posts/tutorials/cross-validation/#orgf689e45">Drop Categorical Columns</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="/posts/tutorials/cross-validation/#org345da5c">Middle</a>
<ul>
<li><a href="/posts/tutorials/cross-validation/#orgd65d0d7">Some Pipelines</a></li>
<li><a href="/posts/tutorials/cross-validation/#org680b48e">Step 1: Write a useful function</a></li>
<li><a href="/posts/tutorials/cross-validation/#orgc74547a">Step 2: Test different parameter values</a></li>
<li><a href="/posts/tutorials/cross-validation/#org0ecb068">Step 3: Find the best parameter value</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org8497bc2">
<h2 id="org8497bc2">Beginning</h2>
<div class="outline-text-2" id="text-org8497bc2">
<blockquote>
<p>In this exercise, you will leverage what you've learned to tune a machine learning model with <b>cross-validation</b>.</p>
</blockquote>
</div>
<div class="outline-3" id="outline-container-orga36a449">
<h3 id="orga36a449">Imports</h3>
<div class="outline-text-3" id="text-orga36a449"></div>
<div class="outline-4" id="outline-container-orgcdb5281">
<h4 id="orgcdb5281">Python</h4>
<div class="outline-text-4" id="text-orgcdb5281">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org176f97c">
<h4 id="org176f97c">PyPi</h4>
<div class="outline-text-4" id="text-org176f97c">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">eli5.sklearn</span> <span class="kn">import</span> <span class="n">PermutationImportance</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span>

<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.experimental</span> <span class="kn">import</span> <span class="n">enable_iterative_imputer</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">IterativeImputer</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>

<span class="kn">from</span> <span class="nn">tabulate</span> <span class="kn">import</span> <span class="n">tabulate</span>

<span class="kn">import</span> <span class="nn">eli5</span>
<span class="kn">import</span> <span class="nn">hvplot.pandas</span>
<span class="kn">import</span> <span class="nn">pandas</span>
<span class="kn">import</span> <span class="nn">shap</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgb01b5fc">
<h4 id="orgb01b5fc">Others</h4>
<div class="outline-text-4" id="text-orgb01b5fc">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">CountPercentage</span><span class="p">,</span> <span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">EnvironmentLoader</span><span class="p">,</span> <span class="n">Timer</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org004074e">
<h3 id="org004074e">Set Up</h3>
<div class="outline-text-3" id="text-org004074e"></div>
<div class="outline-4" id="outline-container-org14e06dc">
<h4 id="org14e06dc">Table</h4>
<div class="outline-text-4" id="text-org14e06dc">
<div class="highlight">
<pre><span></span><span class="n">TABLE</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">tabulate</span><span class="p">,</span> <span class="n">tablefmt</span><span class="o">=</span><span class="s2">"orgtbl"</span><span class="p">,</span> <span class="n">showindex</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="s2">"keys"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgc9df300">
<h4 id="orgc9df300">Plottting</h4>
<div class="outline-text-4" id="text-orgc9df300">
<div class="highlight">
<pre><span></span><span class="n">SLUG</span> <span class="o">=</span> <span class="s2">"cross-validation"</span>
<span class="n">OUTPUT_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"../../files/posts/tutorials/"</span><span class="p">)</span><span class="o">/</span><span class="n">SLUG</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">OUTPUT_PATH</span><span class="o">.</span><span class="n">is_dir</span><span class="p">():</span>
    <span class="n">OUTPUT_PATH</span><span class="o">.</span><span class="n">mkdir</span><span class="p">()</span>
<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">folder_path</span><span class="o">=</span><span class="n">OUTPUT_PATH</span><span class="p">)</span>
<span class="n">Plot</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgf234cd1">
<h4 id="orgf234cd1">The Timer</h4>
<div class="outline-text-4" id="text-orgf234cd1">
<div class="highlight">
<pre><span></span><span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org27a76b2">
<h4 id="org27a76b2">Environment</h4>
<div class="outline-text-4" id="text-org27a76b2">
<div class="highlight">
<pre><span></span><span class="n">ENVIRONMENT</span> <span class="o">=</span> <span class="n">EnvironmentLoader</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgb550015">
<h4 id="orgb550015">The Data</h4>
<div class="outline-text-4" id="text-orgb550015">
<div class="highlight">
<pre><span></span><span class="n">DATA_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">ENVIRONMENT</span><span class="p">[</span><span class="s2">"HOUSE-PRICES-IOWA"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="n">DATA_PATH</span><span class="o">/</span><span class="s2">"train.csv"</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s2">"Id"</span><span class="p">)</span>

<span class="n">test_data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="n">DATA_PATH</span><span class="o">/</span><span class="s2">"test.csv"</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s2">"Id"</span>
<span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">test_data</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org0f0c80a">
<h4 id="org0f0c80a">Some Constants</h4>
<div class="outline-text-4" id="text-org0f0c80a">
<div class="highlight">
<pre><span></span><span class="n">Data</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">target</span><span class="o">=</span><span class="s2">"SalePrice"</span><span class="p">,</span>
    <span class="n">train_size</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">random_seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org7a36c76">
<h3 id="org7a36c76">Setup The Data</h3>
<div class="outline-text-3" id="text-org7a36c76">
<p>Split up the target and features.</p>
<div class="highlight">
<pre><span></span><span class="k">assert</span> <span class="ow">not</span> <span class="n">train_data</span><span class="p">[</span><span class="n">Data</span><span class="o">.</span><span class="n">target</span><span class="p">]</span><span class="o">.</span><span class="n">hasnans</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="n">Data</span><span class="o">.</span><span class="n">target</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="n">Data</span><span class="o">.</span><span class="n">target</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="s2">"columns"</span><span class="p">)</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-orgf689e45">
<h4 id="orgf689e45">Drop Categorical Columns</h4>
<div class="outline-text-4" id="text-orgf689e45">
<p>To make it simpler (since we're only looking at cross-validation, and having them didn't seem to help) we're going to drop the categorical columns.</p>
<div class="highlight">
<pre><span></span><span class="n">numeric_columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">column</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">X</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="s2">"object"</span><span class="p">]</span>
<span class="n">rows_0</span><span class="p">,</span> <span class="n">columns_0</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">numeric_columns</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">row</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Keeping {columns} columns, dropped ({columns_0 - columns})"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Keeping 36 columns, dropped (43)
</pre></div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org345da5c">
<h2 id="org345da5c">Middle</h2>
<div class="outline-text-2" id="text-org345da5c"></div>
<div class="outline-3" id="outline-container-orgd65d0d7">
<h3 id="orgd65d0d7">Some Pipelines</h3>
<div class="outline-text-3" id="text-orgd65d0d7">
<blockquote>
<p>So far, you've learned how to build pipelines with scikit-learn. For instance, the pipeline below will use <a href="https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html"><code>SimpleImputer()</code></a> to replace missing values in the data, before using <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"><code>RandomForestRegressor()</code></a> to train a random forest model to make predictions. We set the number of trees in the random forest model with the <code>n_estimators</code> parameter, and setting <code>random_state</code> ensures reproducibility.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">steps</span><span class="o">=</span><span class="p">[</span>
    <span class="p">(</span><span class="s1">'preprocessor'</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">()),</span>
    <span class="p">(</span><span class="s1">'model'</span><span class="p">,</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">random_seed</span><span class="p">))</span>
<span class="p">])</span>
</pre></div>
<blockquote>
<p>You have also learned how to use pipelines in cross-validation. The code below uses the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html"><code>cross_val_score()</code></a> function to obtain the mean absolute error (MAE), averaged across five different folds. Recall we set the number of folds with the <code>cv</code> parameter.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="c1"># Multiply by -1 since sklearn calculates *negative* MAE</span>
<span class="n">scores</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
                              <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                              <span class="n">scoring</span><span class="o">=</span><span class="s1">'neg_mean_absolute_error'</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s2">"Average MAE score:"</span><span class="p">,</span> <span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</pre></div>
<pre class="example">
Average MAE score: 18276.410356164386
</pre></div>
</div>
<div class="outline-3" id="outline-container-org680b48e">
<h3 id="org680b48e">Step 1: Write a useful function</h3>
<div class="outline-text-3" id="text-org680b48e">
<blockquote>
<p>In this exercise, you'll use cross-validation to select parameters for a machine learning model.</p>
<p>Begin by writing a function <code>get_score()</code> that reports the average (over three cross-validation folds) MAE of a machine learning pipeline that uses:</p>
<ul class="org-ul">
<li>the data in <code>X</code> and <code>y</code> to create folds,</li>
<li><code>SimpleImputer()</code> (with all parameters left as default) to replace missing values, and</li>
<li><code>RandomForestRegressor()</code> (with <code>random_state=0</code>) to fit a random forest model.</li>
</ul>
<p>The <code>n_estimators</code> parameter supplied to <code>get_score()</code> is used when setting the number of trees in the random forest model.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">get_score</span><span class="p">(</span><span class="n">n_estimators</span><span class="p">):</span>
    <span class="sd">"""Return the average MAE over 3 CV folds of random forest model.</span>

<span class="sd">    Args:</span>
<span class="sd">     n_estimators: the number of trees in the forest</span>
<span class="sd">    """</span>
    <span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">steps</span><span class="o">=</span><span class="p">[</span>
        <span class="p">(</span><span class="s1">'preprocessor'</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">()),</span>
        <span class="p">(</span><span class="s1">'model'</span><span class="p">,</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="n">n_estimators</span><span class="p">,</span>
                                        <span class="n">random_state</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">random_seed</span><span class="p">))</span>
    <span class="p">])</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span> <span class="o">*</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
                                  <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                                  <span class="n">scoring</span><span class="o">=</span><span class="s1">'neg_mean_absolute_error'</span><span class="p">)</span>
    <span class="c1"># Replace this body with your own code</span>
    <span class="k">return</span> <span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgc74547a">
<h3 id="orgc74547a">Step 2: Test different parameter values</h3>
<div class="outline-text-3" id="text-orgc74547a">
<blockquote>
<p>Now, you will use the function that you defined in Step 1 to evaluate the model performance corresponding to eight different values for the number of trees in the random forest: 50, 100, 150, â€¦, 300, 350, 400. Store your results in a Python dictionary <code>results</code>, where <code>results[i]</code> is the average MAE returned by <code>get_scores(i)</code>.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="p">{</span><span class="n">trees</span><span class="p">:</span> <span class="n">get_score</span><span class="p">(</span><span class="n">trees</span><span class="p">)</span> <span class="k">for</span> <span class="n">trees</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">450</span><span class="p">,</span> <span class="mi">50</span><span class="p">)}</span>

<span class="n">results_frame</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span><span class="s2">"Trees"</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">keys</span><span class="p">()),</span> <span class="s2">"MAE"</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">values</span><span class="p">())})</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org0ecb068">
<h3 id="org0ecb068">Step 3: Find the best parameter value</h3>
<div class="outline-text-3" id="text-org0ecb068">
<div class="highlight">
<pre><span></span><span class="n">plot</span> <span class="o">=</span> <span class="n">results_frame</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"Trees"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"MAE"</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"Cross-Validation Mean Absolute Error"</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">)</span>

<span class="n">source</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"mean_absolute_error"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">source</span><span class="p">)</span>
</pre></div>
: <object data="/posts/tutorials/cross-validation/mean_absolute_error.html" height="800" style="width:100%" type="text/html">:
<p>Figure Missing</p>
:</object>
<p>200 appears to be the best number of trees for our forest.</p>
</div>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="/posts/tutorials/kaggle-intermediate-machine-learning-pipelines/">Pipelines</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="/posts/tutorials/kaggle-intermediate-machine-learning-pipelines/" rel="bookmark"><time class="published dt-published" datetime="2020-02-20T21:14:10-08:00" itemprop="datePublished" title="2020-02-20 21:14">2020-02-20 21:14</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="/posts/tutorials/kaggle-intermediate-machine-learning-pipelines/#org12c5702">Beginning</a>
<ul>
<li><a href="/posts/tutorials/kaggle-intermediate-machine-learning-pipelines/#org6543be1">Imports</a>
<ul>
<li><a href="/posts/tutorials/kaggle-intermediate-machine-learning-pipelines/#orgb349127">Python</a></li>
<li><a href="/posts/tutorials/kaggle-intermediate-machine-learning-pipelines/#orga5deced">PyPi</a></li>
<li><a href="/posts/tutorials/kaggle-intermediate-machine-learning-pipelines/#orgca9b544">Others</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/kaggle-intermediate-machine-learning-pipelines/#orge549416">Set Up</a>
<ul>
<li><a href="/posts/tutorials/kaggle-intermediate-machine-learning-pipelines/#orgaadc9a7">Table</a></li>
<li><a href="/posts/tutorials/kaggle-intermediate-machine-learning-pipelines/#orgc948e6f">Plottting</a></li>
<li><a href="/posts/tutorials/kaggle-intermediate-machine-learning-pipelines/#org6fc1207">The Timer</a></li>
<li><a href="/posts/tutorials/kaggle-intermediate-machine-learning-pipelines/#org49cc604">Environment</a></li>
<li><a href="/posts/tutorials/kaggle-intermediate-machine-learning-pipelines/#orgd4ba3b5">The Data</a></li>
<li><a href="/posts/tutorials/kaggle-intermediate-machine-learning-pipelines/#org2e434a6">Some Constants</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/kaggle-intermediate-machine-learning-pipelines/#org8b2bf11">Setup The Data</a>
<ul>
<li><a href="/posts/tutorials/kaggle-intermediate-machine-learning-pipelines/#orgf127a13">Trim the columns</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="/posts/tutorials/kaggle-intermediate-machine-learning-pipelines/#org154b786">Middle</a>
<ul>
<li><a href="/posts/tutorials/kaggle-intermediate-machine-learning-pipelines/#org5ffb9f5">Preprocess Data and Train the Model</a>
<ul>
<li><a href="/posts/tutorials/kaggle-intermediate-machine-learning-pipelines/#org6e5ec1c">Define The Model</a></li>
<li><a href="/posts/tutorials/kaggle-intermediate-machine-learning-pipelines/#orgcdf09d6">Build the Pipeline</a></li>
<li><a href="/posts/tutorials/kaggle-intermediate-machine-learning-pipelines/#org92630be">Fit the Model</a></li>
<li><a href="/posts/tutorials/kaggle-intermediate-machine-learning-pipelines/#org2caa9d4">Score the Model</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/kaggle-intermediate-machine-learning-pipelines/#org27d2c90">Improving the Performance</a></li>
<li><a href="/posts/tutorials/kaggle-intermediate-machine-learning-pipelines/#org195f57e">SHAP</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/kaggle-intermediate-machine-learning-pipelines/#org72a4ae9">End</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org12c5702">
<h2 id="org12c5702">Beginning</h2>
<div class="outline-text-2" id="text-org12c5702">
<blockquote>
<p>In this exercise, you will use <b>pipelines</b> to improve the efficiency of your machine learning code.</p>
</blockquote>
</div>
<div class="outline-3" id="outline-container-org6543be1">
<h3 id="org6543be1">Imports</h3>
<div class="outline-text-3" id="text-org6543be1"></div>
<div class="outline-4" id="outline-container-orgb349127">
<h4 id="orgb349127">Python</h4>
<div class="outline-text-4" id="text-orgb349127">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orga5deced">
<h4 id="orga5deced">PyPi</h4>
<div class="outline-text-4" id="text-orga5deced">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">eli5.sklearn</span> <span class="kn">import</span> <span class="n">PermutationImportance</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span>

<span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.experimental</span> <span class="kn">import</span> <span class="n">enable_iterative_imputer</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">IterativeImputer</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>

<span class="kn">from</span> <span class="nn">tabulate</span> <span class="kn">import</span> <span class="n">tabulate</span>

<span class="kn">import</span> <span class="nn">eli5</span>
<span class="kn">import</span> <span class="nn">pandas</span>
<span class="kn">import</span> <span class="nn">shap</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgca9b544">
<h4 id="orgca9b544">Others</h4>
<div class="outline-text-4" id="text-orgca9b544">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">CountPercentage</span><span class="p">,</span> <span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">EnvironmentLoader</span><span class="p">,</span> <span class="n">Timer</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orge549416">
<h3 id="orge549416">Set Up</h3>
<div class="outline-text-3" id="text-orge549416"></div>
<div class="outline-4" id="outline-container-orgaadc9a7">
<h4 id="orgaadc9a7">Table</h4>
<div class="outline-text-4" id="text-orgaadc9a7">
<div class="highlight">
<pre><span></span><span class="n">TABLE</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">tabulate</span><span class="p">,</span> <span class="n">tablefmt</span><span class="o">=</span><span class="s2">"orgtbl"</span><span class="p">,</span> <span class="n">showindex</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="s2">"keys"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgc948e6f">
<h4 id="orgc948e6f">Plottting</h4>
<div class="outline-text-4" id="text-orgc948e6f">
<div class="highlight">
<pre><span></span><span class="n">SLUG</span> <span class="o">=</span> <span class="s2">"kaggle-intermediate-machine-learning-pipelines"</span>
<span class="n">OUTPUT_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"../../files/posts/tutorials/"</span><span class="p">)</span><span class="o">/</span><span class="n">SLUG</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">OUTPUT_PATH</span><span class="o">.</span><span class="n">is_dir</span><span class="p">():</span>
    <span class="n">OUTPUT_PATH</span><span class="o">.</span><span class="n">mkdir</span><span class="p">()</span>
<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">folder_path</span><span class="o">=</span><span class="n">OUTPUT_PATH</span><span class="p">)</span>
<span class="n">Plot</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org6fc1207">
<h4 id="org6fc1207">The Timer</h4>
<div class="outline-text-4" id="text-org6fc1207">
<div class="highlight">
<pre><span></span><span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org49cc604">
<h4 id="org49cc604">Environment</h4>
<div class="outline-text-4" id="text-org49cc604">
<div class="highlight">
<pre><span></span><span class="n">ENVIRONMENT</span> <span class="o">=</span> <span class="n">EnvironmentLoader</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgd4ba3b5">
<h4 id="orgd4ba3b5">The Data</h4>
<div class="outline-text-4" id="text-orgd4ba3b5">
<div class="highlight">
<pre><span></span><span class="n">DATA_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">ENVIRONMENT</span><span class="p">[</span><span class="s2">"HOUSE-PRICES-IOWA"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="n">DATA_PATH</span><span class="o">/</span><span class="s2">"train.csv"</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s2">"Id"</span><span class="p">)</span>

<span class="n">test_data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="n">DATA_PATH</span><span class="o">/</span><span class="s2">"test.csv"</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s2">"Id"</span>
<span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">test_data</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org2e434a6">
<h4 id="org2e434a6">Some Constants</h4>
<div class="outline-text-4" id="text-org2e434a6">
<div class="highlight">
<pre><span></span><span class="n">Data</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">target</span><span class="o">=</span><span class="s2">"SalePrice"</span><span class="p">,</span>
    <span class="n">train_size</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">random_seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org8b2bf11">
<h3 id="org8b2bf11">Setup The Data</h3>
<div class="outline-text-3" id="text-org8b2bf11">
<p>Split up the target and features.</p>
<div class="highlight">
<pre><span></span><span class="k">assert</span> <span class="ow">not</span> <span class="n">train_data</span><span class="p">[</span><span class="n">Data</span><span class="o">.</span><span class="n">target</span><span class="p">]</span><span class="o">.</span><span class="n">hasnans</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="n">Data</span><span class="o">.</span><span class="n">target</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="n">Data</span><span class="o">.</span><span class="n">target</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="s2">"columns"</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_validate</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_validate</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
    <span class="n">train_size</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">train_size</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">test_size</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-orgf127a13">
<h4 id="orgf127a13">Trim the columns</h4>
<div class="outline-text-4" id="text-orgf127a13">
<div class="highlight">
<pre><span></span><span class="c1"># Select categorical columns with relatively low cardinality (convenient but arbitrary)</span>
<span class="n">categorical_columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">column</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span>
                       <span class="n">X_train</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mi">10</span> <span class="ow">and</span> 
                       <span class="n">X_train</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="nb">object</span><span class="p">]</span>

<span class="c1"># Select numerical columns</span>
<span class="n">numerical_columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">column</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> 
                     <span class="n">X_train</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">'int64'</span><span class="p">,</span> <span class="s1">'float64'</span><span class="p">]]</span>

<span class="c1"># Keep selected columns only</span>
<span class="n">columns</span> <span class="o">=</span> <span class="n">categorical_columns</span> <span class="o">+</span> <span class="n">numerical_columns</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">X_validate</span> <span class="o">=</span> <span class="n">X_validate</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org154b786">
<h2 id="org154b786">Middle</h2>
<div class="outline-text-2" id="text-org154b786"></div>
<div class="outline-3" id="outline-container-org5ffb9f5">
<h3 id="org5ffb9f5">Preprocess Data and Train the Model</h3>
<div class="outline-text-3" id="text-org5ffb9f5">
<p>The missing numeric values will be filled in with a simple imputer. When the <code>strategy</code> is set to constant then it will fill missing values with a single value (which is 0 by default).</p>
<div class="highlight">
<pre><span></span><span class="n">numerical_transformer</span> <span class="o">=</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">'constant'</span><span class="p">)</span>
</pre></div>
<p>Now the categorical data transformer. We'll use the most frequent value in any column with missing values to fill them in and the do one-hot encoding.</p>
<div class="highlight">
<pre><span></span><span class="n">categorical_transformer</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">steps</span><span class="o">=</span><span class="p">[</span>
    <span class="p">(</span><span class="s1">'imputer'</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">'most_frequent'</span><span class="p">)),</span>
    <span class="p">(</span><span class="s1">'onehot'</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">handle_unknown</span><span class="o">=</span><span class="s1">'ignore'</span><span class="p">))</span>
<span class="p">])</span>
</pre></div>
<p>Now we can bundle them together into a single transformer.</p>
<div class="highlight">
<pre><span></span><span class="n">preprocessor</span> <span class="o">=</span> <span class="n">ColumnTransformer</span><span class="p">(</span>
    <span class="n">transformers</span><span class="o">=</span><span class="p">[</span>
        <span class="p">(</span><span class="s1">'num'</span><span class="p">,</span> <span class="n">numerical_transformer</span><span class="p">,</span> <span class="n">numerical_columns</span><span class="p">),</span>
        <span class="p">(</span><span class="s1">'cat'</span><span class="p">,</span> <span class="n">categorical_transformer</span><span class="p">,</span> <span class="n">categorical_columns</span><span class="p">)</span>
    <span class="p">])</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-org6e5ec1c">
<h4 id="org6e5ec1c">Define The Model</h4>
<div class="outline-text-4" id="text-org6e5ec1c">
<div class="highlight">
<pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgcdf09d6">
<h4 id="orgcdf09d6">Build the Pipeline</h4>
<div class="outline-text-4" id="text-orgcdf09d6">
<div class="highlight">
<pre><span></span><span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">steps</span><span class="o">=</span><span class="p">[(</span><span class="s1">'preprocessor'</span><span class="p">,</span> <span class="n">preprocessor</span><span class="p">),</span>
                      <span class="p">(</span><span class="s1">'model'</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
                     <span class="p">])</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org92630be">
<h4 id="org92630be">Fit the Model</h4>
<div class="outline-text-4" id="text-org92630be">
<div class="highlight">
<pre><span></span><span class="c1"># Preprocessing of training data, fit model </span>
<span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org2caa9d4">
<h4 id="org2caa9d4">Score the Model</h4>
<div class="outline-text-4" id="text-org2caa9d4">
<div class="highlight">
<pre><span></span><span class="n">preds</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_validate</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"MAE: {mean_absolute_error(y_validate, preds):,}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
MAE: 17,861.780102739725
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org27d2c90">
<h3 id="org27d2c90">Improving the Performance</h3>
<div class="outline-text-3" id="text-org27d2c90">
<blockquote>
<p>Now, it's your turn! In the code cell below, define your own preprocessing steps and random forest model. Fill in values for the following variables:</p>
<ul class="org-ul">
<li><code>numerical_transformer</code></li>
<li><code>categorical_transformer</code></li>
<li><code>model</code></li>
</ul>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">numerical_transformer</span> <span class="o">=</span> <span class="n">IterativeImputer</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
</pre></div>
<p>I'll use the same categorical imputer.</p>
<div class="highlight">
<pre><span></span><span class="n">categorical_transformer</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">steps</span><span class="o">=</span><span class="p">[</span>
    <span class="p">(</span><span class="s1">'imputer'</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">'most_frequent'</span><span class="p">)),</span>
    <span class="p">(</span><span class="s1">'onehot'</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">handle_unknown</span><span class="o">=</span><span class="s1">'ignore'</span><span class="p">))</span>
<span class="p">])</span>
</pre></div>
<p>And now we bundle them together.</p>
<div class="highlight">
<pre><span></span><span class="n">preprocessor</span> <span class="o">=</span> <span class="n">ColumnTransformer</span><span class="p">(</span>
    <span class="n">transformers</span><span class="o">=</span><span class="p">[</span>
        <span class="p">(</span><span class="s1">'numeric'</span><span class="p">,</span> <span class="n">numerical_transformer</span><span class="p">,</span> <span class="n">numerical_columns</span><span class="p">),</span>
        <span class="p">(</span><span class="s1">'categorical'</span><span class="p">,</span> <span class="n">categorical_transformer</span><span class="p">,</span> <span class="n">categorical_columns</span><span class="p">)</span>
    <span class="p">])</span>
</pre></div>
<p>Now build and train the model.</p>
<div class="highlight">
<pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">steps</span><span class="o">=</span><span class="p">[(</span><span class="s1">'preprocessor'</span><span class="p">,</span> <span class="n">preprocessor</span><span class="p">),</span>
                           <span class="p">(</span><span class="s1">'model'</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
                           <span class="p">])</span>
<span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_validate</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"MAE: {mean_absolute_error(y_validate, predictions):,}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
MAE: 17,556.51404109589
</pre>
<p>So we improved slightly, but we're still not doing as well as with the numeric only dataset.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org195f57e">
<h3 id="org195f57e">SHAP</h3>
<div class="outline-text-3" id="text-org195f57e">
<div class="highlight">
<pre><span></span><span class="k">with</span> <span class="n">TIMER</span><span class="p">:</span>
    <span class="n">training</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">numerical_columns</span> <span class="o">+</span> <span class="n">categorical_columns</span><span class="p">]</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">preprocessor</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">training</span><span class="p">)</span>
    <span class="n">columns</span> <span class="o">=</span> <span class="p">(</span><span class="n">numerical_columns</span>
               <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">preprocessor</span><span class="o">.</span><span class="n">named_transformers_</span><span class="p">[</span><span class="s2">"categorical"</span><span class="p">][</span><span class="s2">"onehot"</span><span class="p">]</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()))</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
        <span class="n">data</span><span class="p">,</span>
        <span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">)</span>
    <span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">TreeExplainer</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="n">shap_values</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
<pre class="example">
2020-03-01 19:25:58,515 graeae.timers.timer start: Started: 2020-03-01 19:25:58.514631
Setting feature_perturbation = "tree_path_dependent" because no background data was given.
2020-03-01 19:26:16,103 graeae.timers.timer end: Ended: 2020-03-01 19:26:16.103820
2020-03-01 19:26:16,104 graeae.timers.timer end: Elapsed: 0:00:17.589189
</pre>
<div class="highlight">
<pre><span></span><span class="n">shap</span><span class="o">.</span><span class="n">summary_plot</span><span class="p">(</span><span class="n">shap_values</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
<span class="n">figure</span> <span class="o">=</span> <span class="n">pyplot</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">output</span> <span class="o">=</span> <span class="s2">"shap_summary.png"</span>

<span class="n">figure</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">OUTPUT_PATH</span><span class="o">/</span><span class="n">output</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"[[file:{output}]]"</span><span class="p">)</span>
</pre></div>
<div class="figure">
<p><img alt="52fc9fa36e385cc6b1cc5a40b4505610a7dd6c65.png" src="/posts/tutorials/kaggle-intermediate-machine-learning-pipelines/.ob-jupyter/52fc9fa36e385cc6b1cc5a40b4505610a7dd6c65.png"></p>
</div>
<pre class="example">
[[file:shap_summary.png]]
&lt;Figure size 432x288 with 0 Axes&gt;
</pre>
<div class="figure">
<p><img alt="shap_summary.png" src="/posts/tutorials/kaggle-intermediate-machine-learning-pipelines/shap_summary.png"></p>
</div>
<div class="highlight">
<pre><span></span><span class="n">shap</span><span class="o">.</span><span class="n">initjs</span><span class="p">()</span>
<span class="n">html</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">force_plot</span><span class="p">(</span><span class="n">explainer</span><span class="o">.</span><span class="n">expected_value</span><span class="p">,</span> <span class="n">shap_values</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
<span class="n">output_file</span> <span class="o">=</span> <span class="s2">"force_plot.html"</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">OUTPUT_PATH</span><span class="o">/</span><span class="n">output_file</span>
<span class="k">with</span> <span class="n">output</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">"w"</span><span class="p">)</span> <span class="k">as</span> <span class="n">writer</span><span class="p">:</span>
    <span class="n">shap</span><span class="o">.</span><span class="n">save_html</span><span class="p">(</span><span class="n">writer</span><span class="p">,</span> <span class="n">html</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"""</span>
<span class="s2">#+begin_export html</span>
<span class="s2">: &lt;object type="text/html" data="{output_file}" style="width:100%" height=800&gt;</span>
<span class="s2">:   &lt;p&gt;Figure Missing&lt;/p&gt;</span>
<span class="s2">: &lt;/object&gt;</span>
<span class="s2">#+end_export</span>
<span class="s2">"""</span><span class="p">)</span>
</pre></div>
: <object data="/posts/tutorials/kaggle-intermediate-machine-learning-pipelines/force_plot.html" height="800" style="width:100%" type="text/html">:
<p>Figure Missing</p>
:</object></div>
</div>
</div>
<div class="outline-2" id="outline-container-org72a4ae9">
<h2 id="org72a4ae9">End</h2>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="/posts/tutorials/categorical-values/">Categorical Values</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="/posts/tutorials/categorical-values/" rel="bookmark"><time class="published dt-published" datetime="2020-02-20T21:13:09-08:00" itemprop="datePublished" title="2020-02-20 21:13">2020-02-20 21:13</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="/posts/tutorials/categorical-values/#org4fa3f50">Beginning</a>
<ul>
<li><a href="/posts/tutorials/categorical-values/#org1e7eab2">Imports</a>
<ul>
<li><a href="/posts/tutorials/categorical-values/#org26d5821">Python</a></li>
<li><a href="/posts/tutorials/categorical-values/#org279923b">PyPi</a></li>
<li><a href="/posts/tutorials/categorical-values/#org654b1cd">Others</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/categorical-values/#org62cf300">Set Up</a>
<ul>
<li><a href="/posts/tutorials/categorical-values/#org5ca4d2c">Table</a></li>
<li><a href="/posts/tutorials/categorical-values/#org4d1d5e7">Plottting</a></li>
<li><a href="/posts/tutorials/categorical-values/#org8474b1a">The Timer</a></li>
<li><a href="/posts/tutorials/categorical-values/#orgad78c24">Environment</a></li>
<li><a href="/posts/tutorials/categorical-values/#orgdc87c3e">The Data</a></li>
<li><a href="/posts/tutorials/categorical-values/#org1437058">Some Constants</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="/posts/tutorials/categorical-values/#orgfab5597">Middle</a>
<ul>
<li><a href="/posts/tutorials/categorical-values/#orgf004cb9">Setup The Data</a></li>
<li><a href="/posts/tutorials/categorical-values/#orgab9e835">Score Dataset</a></li>
<li><a href="/posts/tutorials/categorical-values/#orge60debb">Step 1: Drop Categorical Columns</a></li>
<li><a href="/posts/tutorials/categorical-values/#org28274ef">Step 2: Label encoding</a>
<ul>
<li><a href="/posts/tutorials/categorical-values/#org36a8876">Drop the Bad Columns</a></li>
<li><a href="/posts/tutorials/categorical-values/#org4544733">Encode the Categorical Values</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/categorical-values/#orgbb7ce8d">Step 3: Investigating cardinality</a>
<ul>
<li><a href="/posts/tutorials/categorical-values/#orgefa5122">Questions</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/categorical-values/#org33016ef">Step 4: One-hot encoding</a></li>
<li><a href="/posts/tutorials/categorical-values/#org1591c0b">Step 5: Generate test predictions and submit your results</a>
<ul>
<li><a href="/posts/tutorials/categorical-values/#orgd57606d">Hyperparameter Tuning</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="/posts/tutorials/categorical-values/#org830b310">End</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org4fa3f50">
<h2 id="org4fa3f50">Beginning</h2>
<div class="outline-text-2" id="text-org4fa3f50">
<blockquote>
<p>Now it's your turn to test your new knowledge of <b>missing values</b> handling. You'll probably find it makes a big difference.</p>
</blockquote>
</div>
<div class="outline-3" id="outline-container-org1e7eab2">
<h3 id="org1e7eab2">Imports</h3>
<div class="outline-text-3" id="text-org1e7eab2"></div>
<div class="outline-4" id="outline-container-org26d5821">
<h4 id="org26d5821">Python</h4>
<div class="outline-text-4" id="text-org26d5821">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org279923b">
<h4 id="org279923b">PyPi</h4>
<div class="outline-text-4" id="text-org279923b">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">eli5.sklearn</span> <span class="kn">import</span> <span class="n">PermutationImportance</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span>
<span class="kn">from</span> <span class="nn">pdpbox</span> <span class="kn">import</span> <span class="n">pdp</span>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.experimental</span> <span class="kn">import</span> <span class="n">enable_iterative_imputer</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">IterativeImputer</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">RandomizedSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span><span class="p">,</span> <span class="n">OneHotEncoder</span>

<span class="kn">from</span> <span class="nn">tabulate</span> <span class="kn">import</span> <span class="n">tabulate</span>

<span class="kn">import</span> <span class="nn">eli5</span>
<span class="kn">import</span> <span class="nn">hvplot.pandas</span>
<span class="kn">import</span> <span class="nn">pandas</span>
<span class="kn">import</span> <span class="nn">shap</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org654b1cd">
<h4 id="org654b1cd">Others</h4>
<div class="outline-text-4" id="text-org654b1cd">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">CountPercentage</span><span class="p">,</span> <span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">EnvironmentLoader</span><span class="p">,</span> <span class="n">Timer</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org62cf300">
<h3 id="org62cf300">Set Up</h3>
<div class="outline-text-3" id="text-org62cf300"></div>
<div class="outline-4" id="outline-container-org5ca4d2c">
<h4 id="org5ca4d2c">Table</h4>
<div class="outline-text-4" id="text-org5ca4d2c">
<div class="highlight">
<pre><span></span><span class="n">TABLE</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">tabulate</span><span class="p">,</span> <span class="n">tablefmt</span><span class="o">=</span><span class="s2">"orgtbl"</span><span class="p">,</span> <span class="n">showindex</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="s2">"keys"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org4d1d5e7">
<h4 id="org4d1d5e7">Plottting</h4>
<div class="outline-text-4" id="text-org4d1d5e7">
<div class="highlight">
<pre><span></span><span class="n">SLUG</span> <span class="o">=</span> <span class="s2">"categorical-values"</span>
<span class="n">OUTPUT_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"../../files/posts/tutorials/"</span><span class="p">)</span><span class="o">/</span><span class="n">SLUG</span>
<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">folder_path</span><span class="o">=</span><span class="n">OUTPUT_PATH</span><span class="p">)</span>
<span class="n">Plot</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org8474b1a">
<h4 id="org8474b1a">The Timer</h4>
<div class="outline-text-4" id="text-org8474b1a">
<div class="highlight">
<pre><span></span><span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgad78c24">
<h4 id="orgad78c24">Environment</h4>
<div class="outline-text-4" id="text-orgad78c24">
<div class="highlight">
<pre><span></span><span class="n">ENVIRONMENT</span> <span class="o">=</span> <span class="n">EnvironmentLoader</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgdc87c3e">
<h4 id="orgdc87c3e">The Data</h4>
<div class="outline-text-4" id="text-orgdc87c3e">
<div class="highlight">
<pre><span></span><span class="n">DATA_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">ENVIRONMENT</span><span class="p">[</span><span class="s2">"HOUSE-PRICES-IOWA"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="n">DATA_PATH</span><span class="o">/</span><span class="s2">"train.csv"</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s2">"Id"</span><span class="p">)</span>

<span class="n">test_data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="n">DATA_PATH</span><span class="o">/</span><span class="s2">"test.csv"</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s2">"Id"</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org1437058">
<h4 id="org1437058">Some Constants</h4>
<div class="outline-text-4" id="text-org1437058">
<div class="highlight">
<pre><span></span><span class="n">Data</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">target</span><span class="o">=</span><span class="s2">"SalePrice"</span><span class="p">,</span>
    <span class="n">train_size</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">random_seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgfab5597">
<h2 id="orgfab5597">Middle</h2>
<div class="outline-text-2" id="text-orgfab5597"></div>
<div class="outline-3" id="outline-container-orgf004cb9">
<h3 id="orgf004cb9">Setup The Data</h3>
<div class="outline-text-3" id="text-orgf004cb9">
<p>Split up the target and features.</p>
<div class="highlight">
<pre><span></span><span class="k">assert</span> <span class="ow">not</span> <span class="n">train_data</span><span class="p">[</span><span class="n">Data</span><span class="o">.</span><span class="n">target</span><span class="p">]</span><span class="o">.</span><span class="n">hasnans</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="n">Data</span><span class="o">.</span><span class="n">target</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="n">Data</span><span class="o">.</span><span class="n">target</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="s2">"columns"</span><span class="p">)</span>
</pre></div>
<p>We know that there's missing data, but since this is about handling categorical data, not missing data, we'll just drop the columns that have missing values.</p>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[[</span><span class="n">column</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">X</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">hasnans</span><span class="p">]]</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
<pre class="example">
(1460, 79)
(1460, 60)
</pre>
<p>So we lost 19 columns - more than I was expecting.</p>
<p>Now do the train-test split.</p>
<div class="highlight">
<pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_validate</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_validate</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
    <span class="n">train_size</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">train_size</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">test_size</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">drop_X_train</span><span class="o">.</span><span class="n">info</span><span class="p">())</span>
</pre></div>
<pre class="example">
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
&lt;ipython-input-13-002dd7ea4a19&gt; in &lt;module&gt;
----&gt; 1 print(drop_X_train.info())

NameError: name 'drop_X_train' is not defined
</pre>
<blockquote>
<p>Notice that the dataset contains both numerical and categorical variables. You'll need to encode the categorical data before training a model.</p>
</blockquote>
</div>
</div>
<div class="outline-3" id="outline-container-orgab9e835">
<h3 id="orgab9e835">Score Dataset</h3>
<div class="outline-text-3" id="text-orgab9e835">
<p>This is the same function used in the missing-values tutorial. It's used to compare different models' Mean Absolute Error (MAE) as we make changes.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">score_dataset</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orge60debb">
<h3 id="orge60debb">Step 1: Drop Categorical Columns</h3>
<div class="outline-text-3" id="text-orge60debb">
<p>The first approach is to just drop all the non-numeric columns.</p>
<div class="highlight">
<pre><span></span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">column</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">X_train</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="nb">object</span><span class="p">]</span>
<span class="n">drop_X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span>
<span class="n">drop_X_validate</span> <span class="o">=</span> <span class="n">X_validate</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span>

<span class="k">print</span><span class="p">(</span><span class="s2">"MAE from Approach 1 (Drop categorical variables):"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{score_dataset(drop_X_train, drop_X_validate, y_train, y_validate):,}"</span><span class="p">)</span>
</pre></div>
<p>Using all the numeric columns does better than we did with our initial subset of columns (20,928.5), but not as good as we did with imputed values (16,656.3).</p>
</div>
</div>
<div class="outline-3" id="outline-container-org28274ef">
<h3 id="org28274ef">Step 2: Label encoding</h3>
<div class="outline-text-3" id="text-org28274ef">
<blockquote>
<p>Before jumping into label encoding, we'll investigate the dataset. Specifically, we'll look at the <code>'Condition2'</code> column. The code cell below prints the unique entries in both the training and validation sets.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">train_counter</span> <span class="o">=</span> <span class="n">CountPercentage</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">Condition2</span><span class="p">,</span> <span class="n">dropna</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">validate_counter</span> <span class="o">=</span> <span class="n">CountPercentage</span><span class="p">(</span><span class="n">X_validate</span><span class="o">.</span><span class="n">Condition2</span><span class="p">,</span> <span class="n">dropna</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">train_counter</span><span class="p">()</span>
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-right">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Value</th>
<th class="org-right" scope="col">Count</th>
<th class="org-right" scope="col">Percent (%)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Norm</td>
<td class="org-right">1160</td>
<td class="org-right">99.32</td>
</tr>
<tr>
<td class="org-left">Feedr</td>
<td class="org-right">4</td>
<td class="org-right">0.34</td>
</tr>
<tr>
<td class="org-left">PosA</td>
<td class="org-right">1</td>
<td class="org-right">0.09</td>
</tr>
<tr>
<td class="org-left">Artery</td>
<td class="org-right">1</td>
<td class="org-right">0.09</td>
</tr>
<tr>
<td class="org-left">RRAe</td>
<td class="org-right">1</td>
<td class="org-right">0.09</td>
</tr>
<tr>
<td class="org-left">PosN</td>
<td class="org-right">1</td>
<td class="org-right">0.09</td>
</tr>
</tbody>
</table>
<div class="highlight">
<pre><span></span><span class="n">validate_counter</span><span class="p">()</span>
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-right">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Value</th>
<th class="org-right" scope="col">Count</th>
<th class="org-right" scope="col">Percent (%)</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Norm</td>
<td class="org-right">285</td>
<td class="org-right">97.60</td>
</tr>
<tr>
<td class="org-left">Feedr</td>
<td class="org-right">2</td>
<td class="org-right">0.68</td>
</tr>
<tr>
<td class="org-left">RRNn</td>
<td class="org-right">2</td>
<td class="org-right">0.68</td>
</tr>
<tr>
<td class="org-left">RRAn</td>
<td class="org-right">1</td>
<td class="org-right">0.34</td>
</tr>
<tr>
<td class="org-left">Artery</td>
<td class="org-right">1</td>
<td class="org-right">0.34</td>
</tr>
<tr>
<td class="org-left">PosN</td>
<td class="org-right">1</td>
<td class="org-right">0.34</td>
</tr>
</tbody>
</table>
<p>It looks like the validation data has values that aren't in the training data (and vice versa), e.g. <code>RRNn</code>, so encoding the training set won't work with the validation set.</p>
<blockquote>
<p>This is a common problem that you'll encounter with real-world data, and there are many approaches to fixing this issue. For instance, you can write a custom label encoder to deal with new categories. The simplest approach, however, is to drop the problematic categorical columns.</p>
<p>Run the code cell below to save the problematic columns to a Python list <code>bad_label_cols</code>. Likewise, columns that can be safely label encoded are stored in <code>good_label_cols</code>.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="c1"># All categorical columns</span>
<span class="n">object_columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">column</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">X_train</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="s2">"object"</span><span class="p">]</span>

<span class="c1"># Columns that can be safely label encoded</span>
<span class="n">good_label_columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">column</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">object_columns</span> <span class="k">if</span> 
                      <span class="nb">set</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">column</span><span class="p">])</span> <span class="o">==</span> <span class="nb">set</span><span class="p">(</span><span class="n">X_validate</span><span class="p">[</span><span class="n">column</span><span class="p">])]</span>

<span class="c1"># Problematic columns that will be dropped from the dataset</span>
<span class="n">bad_label_columns</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">object_columns</span><span class="p">)</span><span class="o">-</span><span class="nb">set</span><span class="p">(</span><span class="n">good_label_columns</span><span class="p">))</span>

<span class="k">print</span><span class="p">(</span><span class="s1">'Categorical columns that will be label encoded:'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">column</span> <span class="ow">in</span>  <span class="n">good_label_columns</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">" - {column}"</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Categorical columns that will be dropped from the dataset:'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">bad_label_columns</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">" - {column}"</span><span class="p">)</span>
</pre></div>
<p>Categorical columns that will be label encoded:</p>
<ul class="org-ul">
<li>MSZoning</li>
<li>Street</li>
<li>LotShape</li>
<li>LandContour</li>
<li>LotConfig</li>
<li>BldgType</li>
<li>HouseStyle</li>
<li>ExterQual</li>
<li>CentralAir</li>
<li>KitchenQual</li>
<li>PavedDrive</li>
<li>SaleCondition</li>
</ul>
<p>Categorical columns that will be dropped from the dataset:</p>
<ul class="org-ul">
<li>Condition1</li>
<li>RoofMatl</li>
<li>HeatingQC</li>
<li>ExterCond</li>
<li>RoofStyle</li>
<li>SaleType</li>
<li>Foundation</li>
<li>Condition2</li>
<li>Exterior2nd</li>
<li>Neighborhood</li>
<li>Heating</li>
<li>LandSlope</li>
<li>Utilities</li>
<li>Functional</li>
<li>Exterior1st</li>
</ul>
</div>
<div class="outline-4" id="outline-container-org36a8876">
<h4 id="org36a8876">Drop the Bad Columns</h4>
<div class="outline-text-4" id="text-org36a8876">
<div class="highlight">
<pre><span></span><span class="n">label_X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">bad_label_columns</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s2">"columns"</span><span class="p">)</span>
<span class="n">label_X_validate</span> <span class="o">=</span> <span class="n">X_validate</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">bad_label_columns</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s2">"columns"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org4544733">
<h4 id="org4544733">Encode the Categorical Values</h4>
<div class="outline-text-4" id="text-org4544733">
<p>We're going to use sklearn's <a href="https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html">LabelEncoder</a>.</p>
<p><b>Note:</b> Sklearn's documentation says that this is meant only for categorical target data (the labels), not the input data like we're doing here. Later on we're going to use one-hot-encoding, which is what sklearn recommends (the LabelEncoder method implies that the numbers are values, not just numeric codes for strings).</p>
<p>It's going to create integer values for each of the unique values in each column.</p>
<div class="highlight">
<pre><span></span><span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">good_label_columns</span><span class="p">:</span>
    <span class="n">encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>    
    <span class="n">label_X_train</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">column</span><span class="p">]</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">label_X_train</span><span class="p">[</span><span class="n">column</span><span class="p">])</span>
    <span class="n">label_X_validate</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="n">column</span><span class="p">]</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">label_X_validate</span><span class="p">[</span><span class="n">column</span><span class="p">])</span>
</pre></div>
<p>Now check how it did.</p>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="s2">"MAE from Approach 2 (Label Encoding):"</span><span class="p">)</span> 
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{score_dataset(label_X_train, label_X_validate, y_train, y_validate):,}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
MAE from Approach 2 (Label Encoding):
17,575.291883561644
</pre>
<p>So it does a little better than the previous approach of just dropping all the categorical data, but not as well as it did when we imputed the missing numeric values.</p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orgbb7ce8d">
<h3 id="orgbb7ce8d">Step 3: Investigating cardinality</h3>
<div class="outline-text-3" id="text-orgbb7ce8d">
<blockquote>
<p>So far, you've tried two different approaches to dealing with categorical variables. And, you've seen that encoding categorical data yields better results than removing columns from the dataset.</p>
<p>Soon, you'll try one-hot encoding. Before then, there's one additional topic we need to cover. Begin by running the next code cell without changes.</p>
</blockquote>
<p>Get number of unique entries in each column with categorical data</p>
<div class="highlight">
<pre><span></span><span class="n">object_nunique</span> <span class="o">=</span> <span class="p">[</span><span class="n">X_train</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">nunique</span><span class="p">()</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">object_columns</span><span class="p">]</span>

<span class="c1">## Print number of unique entries by column, in descending</span>
<span class="n">cardinality</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">Column</span><span class="o">=</span><span class="n">object_columns</span><span class="p">,</span>
                                    <span class="n">Cardinality</span><span class="o">=</span><span class="n">object_nunique</span><span class="p">)</span>
                     <span class="p">)</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s2">"Cardinality"</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">TABLE</span><span class="p">(</span><span class="n">cardinality</span><span class="p">))</span>
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Column</th>
<th class="org-right" scope="col">Cardinality</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Neighborhood</td>
<td class="org-right">25</td>
</tr>
<tr>
<td class="org-left">Exterior2nd</td>
<td class="org-right">16</td>
</tr>
<tr>
<td class="org-left">Exterior1st</td>
<td class="org-right">15</td>
</tr>
<tr>
<td class="org-left">SaleType</td>
<td class="org-right">9</td>
</tr>
<tr>
<td class="org-left">Condition1</td>
<td class="org-right">9</td>
</tr>
<tr>
<td class="org-left">HouseStyle</td>
<td class="org-right">8</td>
</tr>
<tr>
<td class="org-left">RoofMatl</td>
<td class="org-right">7</td>
</tr>
<tr>
<td class="org-left">Functional</td>
<td class="org-right">6</td>
</tr>
<tr>
<td class="org-left">Heating</td>
<td class="org-right">6</td>
</tr>
<tr>
<td class="org-left">Foundation</td>
<td class="org-right">6</td>
</tr>
<tr>
<td class="org-left">RoofStyle</td>
<td class="org-right">6</td>
</tr>
<tr>
<td class="org-left">SaleCondition</td>
<td class="org-right">6</td>
</tr>
<tr>
<td class="org-left">Condition2</td>
<td class="org-right">6</td>
</tr>
<tr>
<td class="org-left">BldgType</td>
<td class="org-right">5</td>
</tr>
<tr>
<td class="org-left">ExterCond</td>
<td class="org-right">5</td>
</tr>
<tr>
<td class="org-left">LotConfig</td>
<td class="org-right">5</td>
</tr>
<tr>
<td class="org-left">HeatingQC</td>
<td class="org-right">5</td>
</tr>
<tr>
<td class="org-left">MSZoning</td>
<td class="org-right">5</td>
</tr>
<tr>
<td class="org-left">ExterQual</td>
<td class="org-right">4</td>
</tr>
<tr>
<td class="org-left">KitchenQual</td>
<td class="org-right">4</td>
</tr>
<tr>
<td class="org-left">LandContour</td>
<td class="org-right">4</td>
</tr>
<tr>
<td class="org-left">LotShape</td>
<td class="org-right">4</td>
</tr>
<tr>
<td class="org-left">LandSlope</td>
<td class="org-right">3</td>
</tr>
<tr>
<td class="org-left">PavedDrive</td>
<td class="org-right">3</td>
</tr>
<tr>
<td class="org-left">Street</td>
<td class="org-right">2</td>
</tr>
<tr>
<td class="org-left">Utilities</td>
<td class="org-right">2</td>
</tr>
<tr>
<td class="org-left">CentralAir</td>
<td class="org-right">2</td>
</tr>
</tbody>
</table>
<blockquote>
<p>The output above shows, for each column with categorical data, the number of unique values in the column. For instance, the <code>'Street'</code> column in the training data has two unique values: <code>'Grvl'</code> and <code>'Pave'</code>, corresponding to a gravel road and a paved road, respectively.</p>
<p>We refer to the number of unique entries of a categorical variable as the <b>cardinality</b> of that categorical variable. For instance, the <code>'Street'</code> variable has cardinality 2.</p>
</blockquote>
</div>
<div class="outline-4" id="outline-container-orgefa5122">
<h4 id="orgefa5122">Questions</h4>
<div class="outline-text-4" id="text-orgefa5122">
<blockquote>
<p>How many categorical variables in the training data have cardinality greater than 10?</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">cardinality</span><span class="p">[</span><span class="n">cardinality</span><span class="o">.</span><span class="n">Cardinality</span> <span class="o">&gt;</span> <span class="mi">10</span><span class="p">]))</span>
</pre></div>
<pre class="example">
3
</pre>
<blockquote>
<p>How many columns are needed to one-hot encode the 'Neighborhood' variable in the training data?</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">cardinality</span><span class="p">[</span><span class="n">cardinality</span><span class="o">.</span><span class="n">Column</span><span class="o">==</span><span class="s2">"Neighborhood"</span><span class="p">]</span><span class="o">.</span><span class="n">Cardinality</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
<pre class="example">
25
</pre>
<blockquote>
<p>For large datasets with many rows, one-hot encoding can greatly expand the size of the dataset. For this reason, we typically will only one-hot encode columns with relatively low cardinality. Then, high cardinality columns can either be dropped from the dataset, or we can use label encoding.</p>
<p>As an example, consider a dataset with 10,000 rows, and containing one categorical column with 100 unique entries.</p>
<ul class="org-ul">
<li>If this column is replaced with the corresponding one-hot encoding, how many entries are added to the dataset?</li>
<li>If we instead replace the column with the label encoding, how many entries are added?</li>
</ul>
</blockquote>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="mi">10000</span> <span class="o">*</span> <span class="mi">100</span> <span class="o">-</span> <span class="mi">10000</span><span class="p">)</span>
</pre></div>
<pre class="example">
990000
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org33016ef">
<h3 id="org33016ef">Step 4: One-hot encoding</h3>
<div class="outline-text-3" id="text-org33016ef">
<blockquote>
<p>In this step, you'll experiment with one-hot encoding. But, instead of encoding all of the categorical variables in the dataset, you'll only create a one-hot encoding for columns with cardinality less than 10.</p>
<p>Run the code cell below without changes to set <code>low_cardinality_cols</code> to a Python list containing the columns that will be one-hot encoded. Likewise, <code>high_cardinality_cols</code> contains a list of categorical columns that will be dropped from the dataset.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">low_cardinality_columns</span> <span class="o">=</span> <span class="n">cardinality</span><span class="p">[</span><span class="n">cardinality</span><span class="o">.</span><span class="n">Cardinality</span> <span class="o">&lt;</span> <span class="mi">10</span><span class="p">]</span><span class="o">.</span><span class="n">Column</span>
<span class="n">high_cardinality_columns</span> <span class="o">=</span> <span class="n">cardinality</span><span class="p">[</span><span class="o">~</span><span class="n">cardinality</span><span class="o">.</span><span class="n">Column</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">low_cardinality_columns</span><span class="p">)]</span><span class="o">.</span><span class="n">Column</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="s2">"Categorical columns that will be one-hot encoded:"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">low_cardinality_columns</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">" - {column}"</span><span class="p">)</span>
</pre></div>
<p>Categorical columns that will be one-hot encoded:</p>
<ul class="org-ul">
<li>SaleType</li>
<li>Condition1</li>
<li>HouseStyle</li>
<li>RoofMatl</li>
<li>Functional</li>
<li>Heating</li>
<li>Foundation</li>
<li>RoofStyle</li>
<li>SaleCondition</li>
<li>Condition2</li>
<li>BldgType</li>
<li>ExterCond</li>
<li>LotConfig</li>
<li>HeatingQC</li>
<li>MSZoning</li>
<li>ExterQual</li>
<li>KitchenQual</li>
<li>LandContour</li>
<li>LotShape</li>
<li>LandSlope</li>
<li>PavedDrive</li>
<li>Street</li>
<li>Utilities</li>
<li>CentralAir</li>
</ul>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="s1">'Categorical columns that will be dropped from the dataset:'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">high_cardinality_columns</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">" - {column}"</span><span class="p">)</span>
</pre></div>
<p>Categorical columns that will be dropped from the dataset:</p>
<ul class="org-ul">
<li>Neighborhood</li>
<li>Exterior2nd</li>
<li>Exterior1st</li>
</ul>
<blockquote>
<p>Use the next code cell to one-hot encode the data in <code>X_train</code> and <code>X_valid</code>. Set the preprocessed DataFrames to <code>OH_X_train</code> and <code>OH_X_valid</code>, respectively.</p>
<ul class="org-ul">
<li>The full list of categorical columns in the dataset can be found in the Python list <code>object_cols</code>.</li>
<li>You should only one-hot encode the categorical columns in <code>low_cardinality_cols</code>. All other categorical columns should be dropped from the dataset.</li>
</ul>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">OH_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">low_cardinality_columns</span><span class="p">]</span>
<span class="n">OH_validate</span> <span class="o">=</span> <span class="n">X_validate</span><span class="p">[</span><span class="n">low_cardinality_columns</span><span class="p">]</span>

<span class="n">encoder</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">handle_unknown</span><span class="o">=</span><span class="s2">"ignore"</span><span class="p">)</span>

<span class="n">OH_train</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">OH_train</span><span class="p">))</span>
<span class="n">OH_validate</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">OH_validate</span><span class="p">))</span>

<span class="n">OH_train</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">index</span>
<span class="n">OH_validate</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="n">X_validate</span><span class="o">.</span><span class="n">index</span>

<span class="n">X_train_numeric</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">object_columns</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s2">"columns"</span><span class="p">)</span>
<span class="n">X_validate_numeric</span> <span class="o">=</span> <span class="n">X_validate</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">object_columns</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s2">"columns"</span><span class="p">)</span>

<span class="n">OH_X_train</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_train_numeric</span><span class="p">,</span> <span class="n">OH_train</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="s2">"columns"</span><span class="p">)</span>
<span class="n">OH_X_validate</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_validate_numeric</span><span class="p">,</span> <span class="n">OH_validate</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="s2">"columns"</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="s2">"MAE from Approach 3 (One-Hot Encoding):"</span><span class="p">)</span> 
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{score_dataset(OH_X_train, OH_X_validate, y_train, y_validate):,}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
MAE from Approach 3 (One-Hot Encoding):
17,429.93404109589
</pre>
<p>So we've improved slightly, but still not as well as the all numeric data with imputed data.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org1591c0b">
<h3 id="org1591c0b">Step 5: Generate test predictions and submit your results</h3>
<div class="outline-text-3" id="text-org1591c0b">
<blockquote>
<p>After you complete Step 4, if you'd like to use what you've learned to submit your results to the leaderboard, you'll need to preprocess the test data before generating predictions.</p>
</blockquote>
<p>To get the imputation working again we need to re-add the columns with missing values. I'm also going to encode the entire dataset before splitting so that everything is encoded, rather than ignoring the values in the validation set that aren't in the training set.</p>
<div class="highlight">
<pre><span></span><span class="n">X_2</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="n">Data</span><span class="o">.</span><span class="n">target</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="s2">"columns"</span><span class="p">)</span>
<span class="n">objects</span> <span class="o">=</span> <span class="p">[</span><span class="n">column</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">X_2</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">X_2</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="o">==</span><span class="nb">object</span><span class="p">]</span>
<span class="n">missing</span> <span class="o">=</span> <span class="p">[</span><span class="n">column</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">objects</span> <span class="k">if</span> <span class="n">X_2</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">hasnans</span><span class="p">]</span>

<span class="n">X_2</span> <span class="o">=</span> <span class="n">X_2</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">missing</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s2">"columns"</span><span class="p">)</span>
<span class="n">OH_X</span> <span class="o">=</span> <span class="n">X_2</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">high_cardinality_columns</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s2">"columns"</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">low_cardinality_columns</span><span class="p">:</span>
    <span class="n">encoder</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="n">encoded</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span>
        <span class="n">OH_X</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">reencoded</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">encoded</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">encoder</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">())</span>
    <span class="n">OH_X</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">OH_X</span><span class="p">,</span> <span class="n">reencoded</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="s2">"columns"</span><span class="p">)</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span>
        <span class="n">column</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s2">"columns"</span><span class="p">)</span>

<span class="n">imputer</span> <span class="o">=</span> <span class="n">IterativeImputer</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
<span class="n">OH_X</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">OH_X</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="n">OH_X</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">OH_X_train</span><span class="p">,</span> <span class="n">OH_X_validate</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_validate</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">OH_X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
    <span class="n">train_size</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">train_size</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">test_size</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">OH_X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">preds_valid</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">OH_X_validate</span><span class="p">)</span>
<span class="n">error</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_validate</span><span class="p">,</span> <span class="n">preds_valid</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"MAE: {error:0.2f}"</span><span class="p">)</span>
</pre></div>
<p>It seems to have gotten worseâ€¦ but maybe that's because we tuned the hyperparameters to the numeric-only model.</p>
</div>
<div class="outline-4" id="outline-container-orgd57606d">
<h4 id="orgd57606d">Hyperparameter Tuning</h4>
<div class="outline-text-4" id="text-orgd57606d">
<div class="highlight">
<pre><span></span><span class="n">estimators</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">max_depth</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span> <span class="o">+</span> <span class="p">[</span><span class="bp">None</span><span class="p">]</span>

<span class="n">grid</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="n">estimators</span><span class="p">,</span>
            <span class="n">max_depth</span><span class="o">=</span><span class="n">max_depth</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">()</span>
<span class="n">search</span> <span class="o">=</span> <span class="n">RandomizedSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                            <span class="n">param_distributions</span><span class="o">=</span><span class="n">grid</span><span class="p">,</span>
                            <span class="n">n_iter</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
                            <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
                            <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">OH_X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">search</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"CV Training R^2: {search.best_score_:0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Training R^2: {model.score(OH_X_train, y_train): 0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Validation R^2: {model.score(OH_X_validate, y_validate):0.2f}"</span><span class="p">)</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">OH_X_validate</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Mean Absolute Error: {mean_absolute_error(y_validate, predictions)}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">search</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
</pre></div>
<pre class="example">
CV Training R^2: 0.86
Training R^2:  0.98
Validation R^2: 0.84
Mean Absolute Error: 17615.31526418787
{'n_estimators': 140, 'max_depth': 60}
</pre>
<p>So it can get a little better, but it doesn't do as well as with just the numeric features. Maybe we don't have enough data to make it work.</p>
<div class="highlight">
<pre><span></span><span class="n">permutor</span> <span class="o">=</span> <span class="n">PermutationImportance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">OH_X_validate</span><span class="p">,</span> <span class="n">y_validate</span><span class="p">)</span>
<span class="n">ipython_html</span> <span class="o">=</span> <span class="n">eli5</span><span class="o">.</span><span class="n">show_weights</span><span class="p">(</span>
    <span class="n">permutor</span><span class="p">,</span>
    <span class="n">feature_names</span><span class="o">=</span><span class="n">OH_X_validate</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
<span class="n">table</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_html</span><span class="p">(</span><span class="n">ipython_html</span><span class="o">.</span><span class="n">data</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="n">TABLE</span><span class="p">(</span><span class="n">table</span><span class="p">))</span>
</pre></div>
<pre class="example">
| Weight           | Feature      |
|------------------+--------------|
| 0.4825  Â± 0.1218 | OverallQual  |
| 0.1019  Â± 0.0350 | GrLivArea    |
| 0.0199  Â± 0.0082 | TotalBsmtSF  |
| 0.0171  Â± 0.0067 | BsmtFinSF1   |
| 0.0131  Â± 0.0062 | 1stFlrSF     |
| 0.0096  Â± 0.0078 | GarageCars   |
| 0.0084  Â± 0.0011 | 2ndFlrSF     |
| 0.0074  Â± 0.0026 | LotArea      |
| 0.0051  Â± 0.0022 | YearRemodAdd |
| 0.0050  Â± 0.0034 | GarageArea   |
| 0.0048  Â± 0.0047 | BedroomAbvGr |
| 0.0036  Â± 0.0009 | LotFrontage  |
| 0.0031  Â± 0.0021 | YearBuilt    |
| 0.0031  Â± 0.0014 | OverallCond  |
| 0.0029  Â± 0.0012 | WoodDeckSF   |
| 0.0021  Â± 0.0021 | MasVnrArea   |
| 0.0014  Â± 0.0016 | OpenPorchSF  |
| 0.0012  Â± 0.0009 | FullBath     |
| 0.0009  Â± 0.0008 | x0_RM        |
| 0.0008  Â± 0.0036 | GarageYrBlt  |
| â€¦ 142 more â€¦     | â€¦ 142 more â€¦ |
</pre>
<p>It looks like the most significant categorical features are <code>LandContour</code> (Bnk and Lvl), either <code>Condition1</code> or <code>Condition2</code> (Norm) and <code>ExterCond</code> (TA). I just took a quick look they don't seem to contribute a whole lot to the model.</p>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org830b310">
<h2 id="org830b310">End</h2>
<div class="outline-text-2" id="text-org830b310">
<p>This was a brief look at handling categorical data.</p>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="/posts/tutorials/missing-values/">Missing Values</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="/posts/tutorials/missing-values/" rel="bookmark"><time class="published dt-published" datetime="2020-02-20T21:07:15-08:00" itemprop="datePublished" title="2020-02-20 21:07">2020-02-20 21:07</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="/posts/tutorials/missing-values/#org7746135">Beginning</a>
<ul>
<li><a href="/posts/tutorials/missing-values/#org2780072">Imports</a>
<ul>
<li><a href="/posts/tutorials/missing-values/#orgaee82e8">Python</a></li>
<li><a href="/posts/tutorials/missing-values/#org9f00c3c">PyPi</a></li>
<li><a href="/posts/tutorials/missing-values/#org9913d32">Others</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/missing-values/#org033988a">Set Up</a>
<ul>
<li><a href="/posts/tutorials/missing-values/#org31d9580">Table</a></li>
<li><a href="/posts/tutorials/missing-values/#orgeb23cd6">Plottting</a></li>
<li><a href="/posts/tutorials/missing-values/#orgd4ef854">The Timer</a></li>
<li><a href="/posts/tutorials/missing-values/#org3e8e10b">Environment</a></li>
<li><a href="/posts/tutorials/missing-values/#orgcb6c7bf">The Data</a></li>
<li><a href="/posts/tutorials/missing-values/#orgfa59782">Some Constants</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="/posts/tutorials/missing-values/#org565362e">Middle</a>
<ul>
<li><a href="/posts/tutorials/missing-values/#org821cf88">Remove Training Data with no Target</a></li>
<li><a href="/posts/tutorials/missing-values/#org4525bd2">Numeric Data Only</a></li>
<li><a href="/posts/tutorials/missing-values/#orgc63a292">Split the Training and Validation Data</a></li>
<li><a href="/posts/tutorials/missing-values/#org191a93d">Step 1: Preliminary investigation</a>
<ul>
<li><a href="/posts/tutorials/missing-values/#orgcd1cf3f">Part A</a></li>
<li><a href="/posts/tutorials/missing-values/#orgee76642">Part B</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/missing-values/#org55bef2c">score_dataset</a></li>
<li><a href="/posts/tutorials/missing-values/#org3355b16">Step 2: Drop columns with missing values</a></li>
<li><a href="/posts/tutorials/missing-values/#orge647768">Step 3: Imputation</a>
<ul>
<li><a href="/posts/tutorials/missing-values/#org039aa4d">Part A</a></li>
<li><a href="/posts/tutorials/missing-values/#org493f5c2">Part B</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/missing-values/#orge30b8c7">Step 4: Generate test predictions</a>
<ul>
<li><a href="/posts/tutorials/missing-values/#org3b1aebc">Part A</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="/posts/tutorials/missing-values/#orgc76b4bb">End</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org7746135">
<h2 id="org7746135">Beginning</h2>
<div class="outline-text-2" id="text-org7746135">
<blockquote>
<p>Now it's your turn to test your new knowledge of <b>missing values</b> handling. You'll probably find it makes a big difference.</p>
</blockquote>
</div>
<div class="outline-3" id="outline-container-org2780072">
<h3 id="org2780072">Imports</h3>
<div class="outline-text-3" id="text-org2780072"></div>
<div class="outline-4" id="outline-container-orgaee82e8">
<h4 id="orgaee82e8">Python</h4>
<div class="outline-text-4" id="text-orgaee82e8">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org9f00c3c">
<h4 id="org9f00c3c">PyPi</h4>
<div class="outline-text-4" id="text-org9f00c3c">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">eli5.sklearn</span> <span class="kn">import</span> <span class="n">PermutationImportance</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span>
<span class="kn">from</span> <span class="nn">pdpbox</span> <span class="kn">import</span> <span class="n">pdp</span>

<span class="kn">import</span> <span class="nn">shap</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.experimental</span> <span class="kn">import</span> <span class="n">enable_iterative_imputer</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">IterativeImputer</span><span class="p">,</span> <span class="n">KNNImputer</span><span class="p">,</span> <span class="n">SimpleImputer</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">tabulate</span> <span class="kn">import</span> <span class="n">tabulate</span>

<span class="kn">import</span> <span class="nn">eli5</span>
<span class="kn">import</span> <span class="nn">hvplot.pandas</span>
<span class="kn">import</span> <span class="nn">pandas</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org9913d32">
<h4 id="org9913d32">Others</h4>
<div class="outline-text-4" id="text-org9913d32">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">EnvironmentLoader</span><span class="p">,</span> <span class="n">Timer</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org033988a">
<h3 id="org033988a">Set Up</h3>
<div class="outline-text-3" id="text-org033988a"></div>
<div class="outline-4" id="outline-container-org31d9580">
<h4 id="org31d9580">Table</h4>
<div class="outline-text-4" id="text-org31d9580">
<div class="highlight">
<pre><span></span><span class="n">TABLE</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">tabulate</span><span class="p">,</span> <span class="n">tablefmt</span><span class="o">=</span><span class="s2">"orgtbl"</span><span class="p">,</span> <span class="n">showindex</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="s2">"keys"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgeb23cd6">
<h4 id="orgeb23cd6">Plottting</h4>
<div class="outline-text-4" id="text-orgeb23cd6">
<div class="highlight">
<pre><span></span><span class="n">SLUG</span> <span class="o">=</span> <span class="s2">"missing-values"</span>
<span class="n">OUTPUT_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"../../files/posts/tutorials/"</span><span class="p">)</span><span class="o">/</span><span class="n">SLUG</span>
<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">folder_path</span><span class="o">=</span><span class="n">OUTPUT_PATH</span><span class="p">)</span>
<span class="n">Plot</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgd4ef854">
<h4 id="orgd4ef854">The Timer</h4>
<div class="outline-text-4" id="text-orgd4ef854">
<div class="highlight">
<pre><span></span><span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org3e8e10b">
<h4 id="org3e8e10b">Environment</h4>
<div class="outline-text-4" id="text-org3e8e10b">
<div class="highlight">
<pre><span></span><span class="n">ENVIRONMENT</span> <span class="o">=</span> <span class="n">EnvironmentLoader</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgcb6c7bf">
<h4 id="orgcb6c7bf">The Data</h4>
<div class="outline-text-4" id="text-orgcb6c7bf">
<div class="highlight">
<pre><span></span><span class="n">DATA_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">ENVIRONMENT</span><span class="p">[</span><span class="s2">"HOUSE-PRICES-IOWA"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="n">DATA_PATH</span><span class="o">/</span><span class="s2">"train.csv"</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s2">"Id"</span><span class="p">)</span>

<span class="n">test_data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="n">DATA_PATH</span><span class="o">/</span><span class="s2">"test.csv"</span><span class="p">,</span> <span class="n">index_col</span><span class="o">=</span><span class="s2">"Id"</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgfa59782">
<h4 id="orgfa59782">Some Constants</h4>
<div class="outline-text-4" id="text-orgfa59782">
<div class="highlight">
<pre><span></span><span class="n">Data</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">target</span><span class="o">=</span><span class="s2">"SalePrice"</span><span class="p">,</span>
    <span class="n">train_size</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">random_seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org565362e">
<h2 id="org565362e">Middle</h2>
<div class="outline-text-2" id="text-org565362e"></div>
<div class="outline-3" id="outline-container-org821cf88">
<h3 id="org821cf88">Remove Training Data with no Target</h3>
<div class="outline-text-3" id="text-org821cf88">
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{len(train_data):,}"</span><span class="p">)</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s2">"rows"</span><span class="p">,</span> <span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="n">Data</span><span class="o">.</span><span class="n">target</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{len(train_data):,}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
1,460
1,460
</pre>
<p>Doesn't look like there were any missing target values.</p>
<div class="highlight">
<pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="n">Data</span><span class="o">.</span><span class="n">target</span><span class="p">]</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="n">Data</span><span class="o">.</span><span class="n">target</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="s2">"columns"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org4525bd2">
<h3 id="org4525bd2">Numeric Data Only</h3>
<div class="outline-text-3" id="text-org4525bd2">
<blockquote>
<p>To keep things simple, we'll use only numerical predictors</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_train</span><span class="o">.</span><span class="n">columns</span><span class="p">))</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">exclude</span><span class="o">=</span><span class="p">[</span><span class="s2">"object"</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">))</span>
</pre></div>
<pre class="example">
79
36
</pre>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_data</span><span class="o">.</span><span class="n">columns</span><span class="p">))</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">test_data</span><span class="o">.</span><span class="n">select_dtypes</span><span class="p">(</span><span class="n">exclude</span><span class="o">=</span><span class="p">[</span><span class="s2">"object"</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x_test</span><span class="o">.</span><span class="n">columns</span><span class="p">))</span>
</pre></div>
<pre class="example">
79
36
</pre></div>
</div>
<div class="outline-3" id="outline-container-orgc63a292">
<h3 id="orgc63a292">Split the Training and Validation Data</h3>
<div class="outline-text-3" id="text-orgc63a292">
<div class="highlight">
<pre><span></span><span class="n">x_train</span><span class="p">,</span> <span class="n">x_validate</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_validate</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
    <span class="n">train_size</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">train_size</span><span class="p">,</span>
    <span class="n">test_size</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">test_size</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org191a93d">
<h3 id="org191a93d">Step 1: Preliminary investigation</h3>
<div class="outline-text-3" id="text-org191a93d">
<div class="highlight">
<pre><span></span><span class="n">missing_by_column</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">isna</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">missed</span> <span class="o">=</span> <span class="n">missing_by_column</span><span class="p">[</span><span class="n">missing_by_column</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="n">TABLE</span><span class="p">(</span><span class="n">missed</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s2">"index"</span><span class="p">:</span> <span class="s2">"Feature"</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="s2">"Missing"</span><span class="p">})))</span>
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Feature</th>
<th class="org-right" scope="col">Missing</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">LotFrontage</td>
<td class="org-right">212</td>
</tr>
<tr>
<td class="org-left">MasVnrArea</td>
<td class="org-right">6</td>
</tr>
<tr>
<td class="org-left">GarageYrBlt</td>
<td class="org-right">58</td>
</tr>
</tbody>
</table>
<p>According to the data description these features are:</p>
<p><b>LotFrontage</b>: Linear feet of street connected to property <b>MasVnrArea:</b> Masonry veneer area in square feet <b>GarageYrBlt</b>: Year garage was built</p>
<div class="highlight">
<pre><span></span><span class="n">Missing</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">frontage</span> <span class="o">=</span> <span class="s2">"LotFrontage"</span><span class="p">,</span>
    <span class="n">masonry</span> <span class="o">=</span> <span class="s2">"MasVnrArea"</span><span class="p">,</span>
    <span class="n">garage</span> <span class="o">=</span> <span class="s2">"GarageYrBlt"</span><span class="p">,</span>
    <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"LotFrontage"</span><span class="p">,</span> <span class="s2">"MasVnrArea"</span><span class="p">,</span> <span class="s2">"GarageYrBlt"</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-orgcd1cf3f">
<h4 id="orgcd1cf3f">Part A</h4>
<div class="outline-text-4" id="text-orgcd1cf3f"></div>
<ul class="org-ul">
<li><a id="org65f5534"></a>How many rows are in the training data?<br>
<div class="outline-text-5" id="text-org65f5534">
<div class="highlight">
<pre><span></span> <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{len(x_train):,}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
1,168
</pre></div>
</li>
<li><a id="org6731737"></a>Fill in the line below: How many columns in the training data have missing values?<br>
<div class="outline-text-5" id="text-org6731737">
<div class="highlight">
<pre><span></span> <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{sum([1 for column in x_train.columns if x_train[column].hasnans])}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
3
</pre></div>
</li>
<li><a id="orgbd30e03"></a>Fill in the line below: How many missing entries are contained in all of the training data?<br>
<div class="outline-text-5" id="text-orgbd30e03">
<div class="highlight">
<pre><span></span> <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{missed.sum()}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
276
</pre>
<p><b>Note:</b> For some reason it doesn't appear to be explicitly mentioned in the notebook, but if you don't deal with the missing values and try and fit the trees to the data you'll end up with an error.</p>
<div class="highlight">
<pre><span></span><span class="k">try</span><span class="p">:</span>
    <span class="n">score_dataset</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">x_validate</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_validate</span><span class="p">)</span>
<span class="k">except</span> <span class="ne">ValueError</span> <span class="k">as</span> <span class="n">error</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>
</pre></div>
<pre class="example">
Input contains NaN, infinity or a value too large for dtype('float32').
</pre></div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-orgee76642">
<h4 id="orgee76642">Part B</h4>
<div class="outline-text-4" id="text-orgee76642">
<blockquote>
<p>Considering your answers above, what do you think is likely the best approach to dealing with the missing values?</p>
</blockquote>
<p>For the cases where there are few missing values I would drop them - e.g. <code>MasVnrArea</code>. For <code>GarageYrBlt</code> I would use the most common value in the same neighborhood and for the <code>LotFrontage</code> I would use the mean or median.</p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org55bef2c">
<h3 id="org55bef2c">score_dataset</h3>
<div class="outline-text-3" id="text-org55bef2c">
<p>This function will help check the Mean Absolute Error (MAE) as we make changes to the dataset.</p>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">score_dataset</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org3355b16">
<h3 id="org3355b16">Step 2: Drop columns with missing values</h3>
<div class="outline-text-3" id="text-org3355b16">
<p>We'll try dropping the columns in the training and validation.</p>
<div class="highlight">
<pre><span></span><span class="n">missing_columns</span> <span class="o">=</span> <span class="n">missed</span><span class="o">.</span><span class="n">index</span>
<span class="n">keep</span> <span class="o">=</span> <span class="p">[</span><span class="n">column</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">x_train</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">x_train</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">hasnans</span><span class="p">]</span>
<span class="n">reduced_X_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="n">keep</span><span class="p">]</span>
<span class="n">reduced_X_valid</span> <span class="o">=</span> <span class="n">x_validate</span><span class="p">[</span><span class="n">keep</span><span class="p">]</span>

<span class="k">print</span><span class="p">(</span><span class="s2">"MAE (Drop columns with missing values):"</span><span class="p">)</span>
<span class="n">drop_columns_error</span> <span class="o">=</span> <span class="n">score_dataset</span><span class="p">(</span><span class="n">reduced_X_train</span><span class="p">,</span> <span class="n">reduced_X_valid</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_validate</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{drop_columns_error:0.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
MAE (Drop columns with missing values):
17837.83
</pre></div>
</div>
<div class="outline-3" id="outline-container-orge647768">
<h3 id="orge647768">Step 3: Imputation</h3>
<div class="outline-text-3" id="text-orge647768"></div>
<div class="outline-4" id="outline-container-org039aa4d">
<h4 id="org039aa4d">Part A</h4>
<div class="outline-text-4" id="text-org039aa4d">
<blockquote>
<p>Use the next code cell to impute missing values with the mean value along each column. Set the preprocessed DataFrames to <code>imputed_X_train</code> and <code>imputed_X_valid</code>. Make sure that the column names match those in <code>X_train</code> and <code>X_valid</code>.</p>
</blockquote>
<p>Here we'll use sklearn's <a href="https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html">SimpleImputer</a> which fills missing values with the means of the columns (by default). It accepts pandas DataFrames but returns a numpy array so we need to rebuild the DataFrame afterward. The notebook suggests you can just re-set the columns, but I don't know what they're expecting, since it isn't a DataFrame. As long as we end up with the same thing in the end I guess it's okay.</p>
<div class="highlight">
<pre><span></span><span class="n">imputer</span> <span class="o">=</span> <span class="n">SimpleImputer</span><span class="p">()</span>
<span class="n">imputed_X_train</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_train</span><span class="p">),</span>
                                   <span class="n">columns</span><span class="o">=</span><span class="n">x_train</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">imputed_X_valid</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">imputer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x_validate</span><span class="p">))</span>
</pre></div>
<p>Now check the Mean Absolute Error for our imputed frames.</p>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="s2">"MAE (Imputation):"</span><span class="p">)</span>
<span class="n">impute_mean_error</span> <span class="o">=</span> <span class="n">score_dataset</span><span class="p">(</span><span class="n">imputed_X_train</span><span class="p">,</span> <span class="n">imputed_X_valid</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_validate</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{impute_mean_error:0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Improvement: {drop_columns_error - impute_mean_error:0.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
MAE (Imputation):
18056.85
Improvement: -219.03
</pre>
<p>So we actually got a little worse using mean imputation.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org493f5c2">
<h4 id="org493f5c2">Part B</h4>
<div class="outline-text-4" id="text-org493f5c2">
<blockquote>
<p>Compare the MAE from each approach. Does anything surprise you about the results? Why do you think one approach performed better than the other?</p>
</blockquote>
<p>As note previously, the imputation did worse than discarding the columns did. It might be that using the mean threw the values off so much that it did worse than just throwing the values away. This might indicate that the values aren't symmetrically distributed so using a central tendency doesn't reflect the data very well.</p>
<div class="highlight">
<pre><span></span><span class="n">plot</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">hvplot</span><span class="o">.</span><span class="n">box</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="s2">"LotFrontage"</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"LotFrontage"</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">source</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"lot_frontage_box"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">source</span><span class="p">)</span>
</pre></div>
: <object data="/posts/tutorials/missing-values/lot_frontage_box.html" height="800" style="width:100%" type="text/html">:
<p>Figure Missing</p>
:</object>
<p>Looking at the plot you can see that it's right-skewed, with an extreme point over 300 square feet well over the mean:</p>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Mean: {x_train.LotFrontage.mean():0.2f} sq ft"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Max: {x_train.LotFrontage.max():0.2f} sq ft"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Mean: 69.61 sq ft
Max: 313.00 sq ft
</pre>
<div class="highlight">
<pre><span></span><span class="n">plot</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">hvplot</span><span class="o">.</span><span class="n">box</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="s2">"GarageYrBlt"</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"GarageYrBlt"</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">source</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"garage_year_built_box"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">source</span><span class="p">)</span>
</pre></div>
: <object data="/posts/tutorials/missing-values/garage_year_built_box.html" height="800" style="width:100%" type="text/html">:
<p>Figure Missing</p>
:</object>
<p>This also looks skewed, but the number of missing points is less so I don't know if it had as much of an effect.</p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orge30b8c7">
<h3 id="orge30b8c7">Step 4: Generate test predictions</h3>
<div class="outline-text-3" id="text-orge30b8c7">
<blockquote>
<p>In this final step, you'll use any approach of your choosing to deal with missing values. Once you've preprocessed the training and validation features, you'll train and evaluate a random forest model. Then, you'll preprocess the test data before generating predictions that can be submitted to the competition.</p>
</blockquote>
</div>
<div class="outline-4" id="outline-container-org3b1aebc">
<h4 id="org3b1aebc">Part A</h4>
<div class="outline-text-4" id="text-org3b1aebc">
<blockquote>
<p>Use the next code cell to preprocess the training and validation data. Set the preprocessed DataFrames to <code>final_X_train</code> and <code>final_X_valid</code>. <b>You can use any approach of your choosing here!</b> in order for this step to be marked as correct, you need only ensure:</p>
<ul class="org-ul">
<li>the preprocessed DataFrames have the same number of columns,</li>
<li>the preprocessed DataFrames have no missing values,</li>
<li><code>final_X_train</code> and <code>y_train</code> have the same number of rows, and</li>
<li><code>final_X_valid</code> and <code>y_valid</code> have the same number of rows.</li>
</ul>
</blockquote>
</div>
<ul class="org-ul">
<li><a id="org0201603"></a>KNN<br>
<div class="outline-text-5" id="text-org0201603">
<p>Let's try using K-Nearest Neighbors to estimate missing values.</p>
<div class="highlight">
<pre><span></span><span class="n">imputer</span> <span class="o">=</span> <span class="n">KNNImputer</span><span class="p">()</span>
<span class="n">final_x_train</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">imputer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_train</span><span class="p">),</span>
                                 <span class="n">columns</span><span class="o">=</span><span class="n">x_train</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">final_x_validate</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">imputer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x_validate</span><span class="p">),</span>
                                 <span class="n">columns</span><span class="o">=</span><span class="n">x_validate</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
</pre></div>
</div>
<ul class="org-ul">
<li><a id="org0af675f"></a>One Last Try<br>
<div class="outline-text-6" id="text-org0af675f">
<blockquote>
<p>Run the next code cell to train and evaluate a random forest model. (<b>Note that we don't use the <code>score_dataset()</code> function above, because we will soon use the trained model to generate test predictions!</b>)</p>
</blockquote>
<p>Define and fit the model.</p>
<div class="highlight">
<pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">final_x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
<p>Get validation predictions and MAE.</p>
<div class="highlight">
<pre><span></span><span class="n">preds_valid</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">final_x_validate</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">"MAE (Your approach):"</span><span class="p">)</span>
<span class="n">final_error</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_validate</span><span class="p">,</span> <span class="n">preds_valid</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{final_error:.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Improvement Over Dropping Columns: {drop_columns_error - final_error:0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Improvement Over Mean: {impute_mean_error - final_error:0.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
MAE (Your approach):
17834.40
Improvement Over Dropping Columns: 3.43
Improvement Over Mean: 222.46
</pre>
<p>So it does a litle better than dropping the columns altogether.</p>
</div>
</li>
</ul>
</li>
<li><a id="orgb82bcbb"></a>Iterative<br>
<div class="outline-text-5" id="text-orgb82bcbb">
<p>This is an experimental imputer from sklearn based on imputation methods from R.</p>
<div class="highlight">
<pre><span></span><span class="n">imputer_2</span> <span class="o">=</span> <span class="n">IterativeImputer</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span>
<span class="n">final_x_train_2</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">imputer_2</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">x_train</span><span class="p">),</span>
                                   <span class="n">columns</span><span class="o">=</span><span class="n">x_train</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">final_x_validate_2</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">imputer_2</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x_validate</span><span class="p">),</span>
                                      <span class="n">columns</span><span class="o">=</span><span class="n">x_validate</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
</pre></div>
</div>
<ul class="org-ul">
<li><a id="org3fd13ae"></a>One Last Try<br>
<div class="outline-text-6" id="text-org3fd13ae">
<blockquote>
<p>Run the next code cell to train and evaluate a random forest model. (<b>Note that we don't use the <code>score_dataset()</code> function above, because we will soon use the trained model to generate test predictions!</b>)</p>
</blockquote>
<p>Define and fit the model.</p>
<div class="highlight">
<pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">final_x_train_2</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
<p>Get validation predictions and MAE.</p>
<div class="highlight">
<pre><span></span><span class="n">preds_valid</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">final_x_validate_2</span><span class="p">)</span>
<span class="n">final_error_2</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_validate</span><span class="p">,</span> <span class="n">preds_valid</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"MAE (Your approach): {final_error_2:0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Improvement Over Dropping Columns: {drop_columns_error - final_error:0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Improvement Over Mean: {impute_mean_error - final_error:0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Improvement over KNN: {final_error - final_error_2: 0.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
MAE (Your approach): 17812.88
Improvement Over Dropping Columns: 3.43
Improvement Over Mean: 222.46
Improvement over KNN:  21.51
</pre>
<p>There's a slight improvement once again (the imputers have hyperparameters themselves that aren't being tuned so they might be even better than what I'm getting).</p>
</div>
</li>
</ul>
</li>
<li><a id="orga2c6027"></a>Permutation Importance<br>
<div class="outline-text-5" id="text-orga2c6027">
<p>Let's look at the the features that were the most important in our model.</p>
<div class="highlight">
<pre><span></span><span class="n">permutor</span> <span class="o">=</span> <span class="n">PermutationImportance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">Data</span><span class="o">.</span><span class="n">random_seed</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">final_x_validate_2</span><span class="p">,</span> <span class="n">y_validate</span><span class="p">)</span>
<span class="n">ipython_html</span> <span class="o">=</span> <span class="n">eli5</span><span class="o">.</span><span class="n">show_weights</span><span class="p">(</span>
    <span class="n">permutor</span><span class="p">,</span>
    <span class="n">feature_names</span><span class="o">=</span><span class="n">final_x_validate_2</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
<span class="n">table</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_html</span><span class="p">(</span><span class="n">ipython_html</span><span class="o">.</span><span class="n">data</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="n">TABLE</span><span class="p">(</span><span class="n">table</span><span class="p">))</span>
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-left"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Weight</th>
<th class="org-left" scope="col">Feature</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">0.4717 Â± 0.0741</td>
<td class="org-left">OverallQual</td>
</tr>
<tr>
<td class="org-left">0.1163 Â± 0.0182</td>
<td class="org-left">GrLivArea</td>
</tr>
<tr>
<td class="org-left">0.0254 Â± 0.0066</td>
<td class="org-left">TotalBsmtSF</td>
</tr>
<tr>
<td class="org-left">0.0209 Â± 0.0040</td>
<td class="org-left">BsmtFinSF1</td>
</tr>
<tr>
<td class="org-left">0.0127 Â± 0.0006</td>
<td class="org-left">2ndFlrSF</td>
</tr>
<tr>
<td class="org-left">0.0112 Â± 0.0042</td>
<td class="org-left">1stFlrSF</td>
</tr>
<tr>
<td class="org-left">0.0090 Â± 0.0072</td>
<td class="org-left">YearRemodAdd</td>
</tr>
<tr>
<td class="org-left">0.0079 Â± 0.0022</td>
<td class="org-left">YearBuilt</td>
</tr>
<tr>
<td class="org-left">0.0069 Â± 0.0036</td>
<td class="org-left">LotArea</td>
</tr>
<tr>
<td class="org-left">0.0046 Â± 0.0018</td>
<td class="org-left">GarageCars</td>
</tr>
<tr>
<td class="org-left">0.0039 Â± 0.0006</td>
<td class="org-left">WoodDeckSF</td>
</tr>
<tr>
<td class="org-left">0.0034 Â± 0.0026</td>
<td class="org-left">GarageYrBlt</td>
</tr>
<tr>
<td class="org-left">0.0031 Â± 0.0009</td>
<td class="org-left">OverallCond</td>
</tr>
<tr>
<td class="org-left">0.0027 Â± 0.0032</td>
<td class="org-left">OpenPorchSF</td>
</tr>
<tr>
<td class="org-left">0.0026 Â± 0.0008</td>
<td class="org-left">LotFrontage</td>
</tr>
<tr>
<td class="org-left">0.0026 Â± 0.0011</td>
<td class="org-left">Fireplaces</td>
</tr>
<tr>
<td class="org-left">0.0016 Â± 0.0009</td>
<td class="org-left">FullBath</td>
</tr>
<tr>
<td class="org-left">0.0015 Â± 0.0010</td>
<td class="org-left">BedroomAbvGr</td>
</tr>
<tr>
<td class="org-left">0.0014 Â± 0.0028</td>
<td class="org-left">BsmtUnfSF</td>
</tr>
<tr>
<td class="org-left">0.0012 Â± 0.0025</td>
<td class="org-left">TotRmsAbvGrd</td>
</tr>
<tr>
<td class="org-left">â€¦ 16 more â€¦</td>
<td class="org-left">â€¦ 16 more â€¦</td>
</tr>
</tbody>
</table>
<p>It's interesting, but the four most important features (<i>OverallQual</i>, <i>GrLivArea</i>, <i>TotalBsmtSF</i>, and <i>BsmtFinSF1</i>) were'nt in our first models. And <i>LotFrontage</i> that we spent all that time in this post filling in is only fifteenth - but looking at our improvements the imputation made, even these seemingly lowm contributiong features helped.</p>
<div class="highlight">
<pre><span></span><span class="n">ipython_html</span> <span class="o">=</span> <span class="n">eli5</span><span class="o">.</span><span class="n">show_weights</span><span class="p">(</span>
    <span class="n">permutor</span><span class="p">,</span>
    <span class="n">top</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span>
    <span class="n">feature_names</span><span class="o">=</span><span class="n">final_x_validate_2</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
<span class="n">table</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_html</span><span class="p">(</span><span class="n">ipython_html</span><span class="o">.</span><span class="n">data</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">table</span><span class="p">[</span><span class="s2">"Weight"</span><span class="p">]</span> <span class="o">=</span> <span class="n">table</span><span class="o">.</span><span class="n">Weight</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">expand</span><span class="o">=</span><span class="bp">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
<span class="n">plot</span> <span class="o">=</span> <span class="n">table</span><span class="o">.</span><span class="n">hvplot</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"Feature"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"Weight"</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">"Permutation Importance"</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
    <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">,</span>
    <span class="n">xrotation</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
<span class="n">source</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"permutation_importance"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">source</span><span class="p">)</span>
</pre></div>
: <object data="/posts/tutorials/missing-values/permutation_importance.html" height="800" style="width:100%" type="text/html">:
<p>Figure Missing</p>
:</object>
<p>Looking at the plot you can see that there's a huge drop from the influence of <code>OverallQuall</code> to the influence of the rest of the features.</p>
<p>Let's look at the features that didn't contribute to the model.</p>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="s2">"| Feature | Weight|"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">"|-+-|"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">table</span><span class="p">[</span><span class="n">table</span><span class="o">.</span><span class="n">Weight</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">itertuples</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"|{row.Feature}| {row.Weight}|"</span><span class="p">)</span>
</pre></div>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-left">
<col class="org-right"></colgroup>
<thead>
<tr>
<th class="org-left" scope="col">Feature</th>
<th class="org-right" scope="col">Weight</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">MiscVal</td>
<td class="org-right">0.0</td>
</tr>
<tr>
<td class="org-left">LowQualFinSF</td>
<td class="org-right">0.0</td>
</tr>
<tr>
<td class="org-left">PoolArea</td>
<td class="org-right">0.0</td>
</tr>
<tr>
<td class="org-left">EnclosedPorch</td>
<td class="org-right">-0.0003</td>
</tr>
<tr>
<td class="org-left">HalfBath</td>
<td class="org-right">-0.0004</td>
</tr>
<tr>
<td class="org-left">YrSold</td>
<td class="org-right">-0.0005</td>
</tr>
<tr>
<td class="org-left">MasVnrArea</td>
<td class="org-right">-0.0015</td>
</tr>
<tr>
<td class="org-left">MoSold</td>
<td class="org-right">-0.0058</td>
</tr>
</tbody>
</table>
<p>So, no point enclosing that porch or expanding your pool, I guess.</p>
</div>
</li>
<li><a id="org863f04c"></a>The Most Important Feature<br>
<div class="outline-text-5" id="text-org863f04c">
<p>This is the <code>data_description</code> entry for <code>OverallQual</code>:</p>
<p><b>OverallQual:</b> Rates the overall material and finish of the house</p>
<table border="2" cellpadding="6" cellspacing="0" frame="hsides" rules="groups">
<colgroup>
<col class="org-right">
<col class="org-left"></colgroup>
<thead>
<tr>
<th class="org-right" scope="col">Value</th>
<th class="org-left" scope="col">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-right">10</td>
<td class="org-left">Very Excellent</td>
</tr>
<tr>
<td class="org-right">9</td>
<td class="org-left">Excellent</td>
</tr>
<tr>
<td class="org-right">8</td>
<td class="org-left">Very Good</td>
</tr>
<tr>
<td class="org-right">7</td>
<td class="org-left">Good</td>
</tr>
<tr>
<td class="org-right">6</td>
<td class="org-left">Above Average</td>
</tr>
<tr>
<td class="org-right">5</td>
<td class="org-left">Average</td>
</tr>
<tr>
<td class="org-right">4</td>
<td class="org-left">Below Average</td>
</tr>
<tr>
<td class="org-right">3</td>
<td class="org-left">Fair</td>
</tr>
<tr>
<td class="org-right">2</td>
<td class="org-left">Poor</td>
</tr>
<tr>
<td class="org-right">1</td>
<td class="org-left">Very Poor</td>
</tr>
</tbody>
</table>
<p>This appears to be an ordinal rather than a continuous variable, interesting how much it dominates.</p>
</div>
<ul class="org-ul">
<li><a id="orgffd3b51"></a>PDP Plot<br>
<div class="outline-text-6" id="text-orgffd3b51">
<p>Here's the amount that the feature changes the sales price as it changes.</p>
<div class="highlight">
<pre><span></span><span class="n">FEATURE</span> <span class="o">=</span> <span class="s2">"OverallQual"</span>
<span class="n">pdp_dist</span> <span class="o">=</span> <span class="n">pdp</span><span class="o">.</span><span class="n">pdp_isolate</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
                           <span class="n">dataset</span><span class="o">=</span><span class="n">final_x_validate_2</span><span class="p">,</span>
                           <span class="n">model_features</span><span class="o">=</span><span class="n">final_x_validate_2</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span>
                           <span class="n">feature</span><span class="o">=</span><span class="n">FEATURE</span><span class="p">)</span>
<span class="n">pdp</span><span class="o">.</span><span class="n">pdp_plot</span><span class="p">(</span><span class="n">pdp_dist</span><span class="p">,</span> <span class="n">FEATURE</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">f</span><span class="s2">"{FEATURE}_pdp_plot.png"</span>
<span class="n">figure</span> <span class="o">=</span> <span class="n">pyplot</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">figure</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">top</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">figure</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">OUTPUT_PATH</span><span class="o">/</span><span class="n">output</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"[[file:{output}]]"</span><span class="p">)</span>
</pre></div>
<div class="figure">
<p><img alt="OverallQual_pdp_plot.png" src="/posts/tutorials/missing-values/OverallQual_pdp_plot.png"></p>
</div>
<p>So it looks like once you hit "Above Average" it's pretty much a linear relationship between the overall quality and the sale price.</p>
</div>
</li>
<li><a id="org7f90cfc"></a>SHAP Summary<br>
<div class="outline-text-6" id="text-org7f90cfc">
<p>Let's take a more visual look at the importance of each feature.</p>
<div class="highlight">
<pre><span></span><span class="n">explainer</span> <span class="o">=</span> <span class="n">shap</span><span class="o">.</span><span class="n">TreeExplainer</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">shap_values</span> <span class="o">=</span> <span class="n">explainer</span><span class="o">.</span><span class="n">shap_values</span><span class="p">(</span><span class="n">final_x_validate_2</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">shap</span><span class="o">.</span><span class="n">summary_plot</span><span class="p">(</span><span class="n">shap_values</span><span class="p">,</span> <span class="n">final_x_validate_2</span><span class="p">)</span>
<span class="n">figure</span> <span class="o">=</span> <span class="n">pyplot</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span>
<span class="n">output</span> <span class="o">=</span> <span class="s2">"shap_summary.png"</span>

<span class="n">figure</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">OUTPUT_PATH</span><span class="o">/</span><span class="n">output</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"[[file:{output}]]"</span><span class="p">)</span>
</pre></div>
<div class="figure">
<p><img alt="shap_summary.png" src="/posts/tutorials/missing-values/shap_summary.png"></p>
</div>
<p>Besides reinforcing the importance of <code>OverallQual</code>, the plot shows how much spread its influence covers. The odd bunches might reflect the fact that it's a discrete, ordinal feature, not a continuous one.</p>
</div>
</li>
</ul>
</li>
</ul>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgc76b4bb">
<h2 id="orgc76b4bb">End</h2>
<div class="outline-text-2" id="text-orgc76b4bb">
<p>Make a kaggle submission.</p>
<div class="highlight">
<pre><span></span><span class="n">final_x_test</span> <span class="o">=</span> <span class="n">imputer_2</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">preds_test</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">final_x_test</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">'Id'</span><span class="p">:</span> <span class="n">x_test</span><span class="o">.</span><span class="n">index</span><span class="p">,</span>
                           <span class="s1">'SalePrice'</span><span class="p">:</span> <span class="n">preds_test</span><span class="p">})</span>
<span class="n">output</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">DATA_PATH</span><span class="o">/</span><span class="s1">'submission.csv'</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
<p>This model gives us an error of 16,656.25822, an improvement over our previous submission where we used only a smaller subset of the features.</p>
<div class="highlight">
<pre><span></span><span class="n">introduction</span> <span class="o">=</span> <span class="mf">27217.91640</span>
<span class="n">previous</span> <span class="o">=</span> <span class="mf">20928.54621</span>
<span class="n">current</span> <span class="o">=</span> <span class="mf">16656.25822</span>

<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Latest Error: {current:,}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Improvement over the introduction ({introduction:,}): {introduction - current:,}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Improvement over the previous model ({previous:,}): {previous - current:,}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Latest Error: 16,656.25822
Improvement over the introduction (27,217.9164): 10,561.658179999999
Improvement over the previous model (20,928.54621): 4,272.287990000001
</pre>
<p>So by adding in the remaining features we were able to reduce our error by quite a bit.</p>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="/posts/tutorials/introduction-intermediate-machine-learning/">Introduction to the Kaggle Intermediate Machine Learning Tutorial</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="/posts/tutorials/introduction-intermediate-machine-learning/" rel="bookmark"><time class="published dt-published" datetime="2020-02-20T20:59:21-08:00" itemprop="datePublished" title="2020-02-20 20:59">2020-02-20 20:59</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="/posts/tutorials/introduction-intermediate-machine-learning/#org60973ec">Beginning</a>
<ul>
<li><a href="/posts/tutorials/introduction-intermediate-machine-learning/#org55c08a7">Imports</a>
<ul>
<li><a href="/posts/tutorials/introduction-intermediate-machine-learning/#org2db9941">Python</a></li>
<li><a href="/posts/tutorials/introduction-intermediate-machine-learning/#org3170e9a">PyPi</a></li>
<li><a href="/posts/tutorials/introduction-intermediate-machine-learning/#org54b25a8">Others</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/introduction-intermediate-machine-learning/#org7d25da2">Set Up</a>
<ul>
<li><a href="/posts/tutorials/introduction-intermediate-machine-learning/#org65964f8">Plottting</a></li>
<li><a href="/posts/tutorials/introduction-intermediate-machine-learning/#org6dfa3dc">The Timer</a></li>
<li><a href="/posts/tutorials/introduction-intermediate-machine-learning/#org16c0ecc">Environment</a></li>
<li><a href="/posts/tutorials/introduction-intermediate-machine-learning/#orgd65067a">The Data</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="/posts/tutorials/introduction-intermediate-machine-learning/#orgc99d5fe">Middle</a>
<ul>
<li><a href="/posts/tutorials/introduction-intermediate-machine-learning/#org2a4fcc2">Preliminary 1: Specify Prediction Target</a></li>
<li><a href="/posts/tutorials/introduction-intermediate-machine-learning/#org3c5a062">Preliminary 2: Create X</a></li>
<li><a href="/posts/tutorials/introduction-intermediate-machine-learning/#org5955705">Preliminary 3: Evaluate Some Models</a></li>
<li><a href="/posts/tutorials/introduction-intermediate-machine-learning/#orgcfca7fe">Preliminary 4: Make Some Predictions</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/introduction-intermediate-machine-learning/#org82311ba">End</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org60973ec">
<h2 id="org60973ec">Beginning</h2>
<div class="outline-text-2" id="text-org60973ec">
<p>This is the introduction to kaggle's intermediate machine learning tutorial.</p>
</div>
<div class="outline-3" id="outline-container-org55c08a7">
<h3 id="org55c08a7">Imports</h3>
<div class="outline-text-3" id="text-org55c08a7"></div>
<div class="outline-4" id="outline-container-org2db9941">
<h4 id="org2db9941">Python</h4>
<div class="outline-text-4" id="text-org2db9941">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org3170e9a">
<h4 id="org3170e9a">PyPi</h4>
<div class="outline-text-4" id="text-org3170e9a">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">train_test_split</span>

<span class="kn">import</span> <span class="nn">hvplot.pandas</span>
<span class="kn">import</span> <span class="nn">pandas</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org54b25a8">
<h4 id="org54b25a8">Others</h4>
<div class="outline-text-4" id="text-org54b25a8">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">EnvironmentLoader</span><span class="p">,</span> <span class="n">Timer</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org7d25da2">
<h3 id="org7d25da2">Set Up</h3>
<div class="outline-text-3" id="text-org7d25da2"></div>
<div class="outline-4" id="outline-container-org65964f8">
<h4 id="org65964f8">Plottting</h4>
<div class="outline-text-4" id="text-org65964f8">
<div class="highlight">
<pre><span></span><span class="n">SLUG</span> <span class="o">=</span> <span class="s2">"introduction-intermediate-machine-learning"</span>
<span class="n">OUTPUT_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"../../files/posts/tutorials/"</span><span class="p">)</span><span class="o">/</span><span class="n">SLUG</span>
<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">folder_path</span><span class="o">=</span><span class="n">OUTPUT_PATH</span><span class="p">)</span>
<span class="n">Plot</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org6dfa3dc">
<h4 id="org6dfa3dc">The Timer</h4>
<div class="outline-text-4" id="text-org6dfa3dc">
<div class="highlight">
<pre><span></span><span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org16c0ecc">
<h4 id="org16c0ecc">Environment</h4>
<div class="outline-text-4" id="text-org16c0ecc">
<div class="highlight">
<pre><span></span><span class="n">ENVIRONMENT</span> <span class="o">=</span> <span class="n">EnvironmentLoader</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgd65067a">
<h4 id="orgd65067a">The Data</h4>
<div class="outline-text-4" id="text-orgd65067a">
<div class="highlight">
<pre><span></span><span class="n">DATA_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">ENVIRONMENT</span><span class="p">[</span><span class="s2">"HOUSE-PRICES-IOWA"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="n">training_data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="n">DATA_PATH</span><span class="o">/</span><span class="s2">"train.csv"</span><span class="p">)</span>

<span class="n">testing_data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="n">DATA_PATH</span><span class="o">/</span><span class="s2">"test.csv"</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgc99d5fe">
<h2 id="orgc99d5fe">Middle</h2>
<div class="outline-text-2" id="text-orgc99d5fe"></div>
<div class="outline-3" id="outline-container-org2a4fcc2">
<h3 id="org2a4fcc2">Preliminary 1: Specify Prediction Target</h3>
<div class="outline-text-3" id="text-org2a4fcc2">
<p>Select the target variable, which corresponds to the sales price. Save this to a new variable called `y`. You'll need to print a list of the columns to find the name of the column you need.</p>
<p>Our target is <i>SalePrice</i>.</p>
<div class="highlight">
<pre><span></span><span class="n">Y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">SalePrice</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org3c5a062">
<h3 id="org3c5a062">Preliminary 2: Create X</h3>
<div class="outline-text-3" id="text-org3c5a062">
<blockquote>
<p>Now you will create a DataFrame called `X` holding the predictive features.</p>
<p>Since you want only some columns from the original data, you'll first create a list with the names of the columns you want in `X`.</p>
<p>You'll use just the following columns in the list (you can copy and paste the whole list to save some typing, though you'll still need to add quotes):</p>
<ul class="org-ul">
<li>LotArea</li>
<li>YearBuilt</li>
<li>1stFlrSF</li>
<li>2ndFlrSF</li>
<li>FullBath</li>
<li>BedroomAbvGr</li>
<li>TotRmsAbvGrd</li>
</ul>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">Training</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">features</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">"1stFlrSF"</span><span class="p">,</span>
        <span class="s2">"2ndFlrSF"</span><span class="p">,</span>
        <span class="s2">"BedroomAbvGr"</span><span class="p">,</span>
        <span class="s2">"FullBath"</span><span class="p">,</span>
        <span class="s2">"LotArea"</span><span class="p">,</span>
        <span class="s2">"TotRmsAbvGrd"</span><span class="p">,</span>
        <span class="s2">"YearBuilt"</span><span class="p">,</span>
    <span class="p">],</span>
    <span class="n">random_seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">train_size</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">training_data</span><span class="p">[</span><span class="n">Training</span><span class="o">.</span><span class="n">features</span><span class="p">]</span>
<span class="n">x_submit</span> <span class="o">=</span> <span class="n">testing_data</span><span class="p">[</span><span class="n">Training</span><span class="o">.</span><span class="n">features</span><span class="p">]</span>
</pre></div>
<p>Split up the data into training and validation sets.</p>
<div class="highlight">
<pre><span></span><span class="n">x_train</span><span class="p">,</span> <span class="n">x_validate</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_validate</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="n">Training</span><span class="o">.</span><span class="n">random_seed</span><span class="p">,</span>
    <span class="n">train_size</span><span class="o">=</span><span class="n">Training</span><span class="o">.</span><span class="n">train_size</span><span class="p">,</span>
    <span class="n">test_size</span><span class="o">=</span><span class="n">Training</span><span class="o">.</span><span class="n">test_size</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org5955705">
<h3 id="org5955705">Preliminary 3: Evaluate Some Models</h3>
<div class="outline-text-3" id="text-org5955705">
<div class="highlight">
<pre><span></span><span class="n">hyperparameters</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
    <span class="n">model_1</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
    <span class="n">model_2</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
    <span class="n">model_3</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s1">'mae'</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
    <span class="n">model_4</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
    <span class="n">model_5</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
    <span class="p">)</span>

<span class="n">models</span> <span class="o">=</span> <span class="p">[</span><span class="n">RandomForestRegressor</span><span class="p">(</span><span class="o">**</span><span class="n">parameters</span><span class="p">)</span> <span class="k">for</span> <span class="n">parameters</span> <span class="ow">in</span> <span class="n">hyperparameters</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">score_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">X_t</span><span class="o">=</span><span class="n">x_train</span><span class="p">,</span> <span class="n">X_v</span><span class="o">=</span><span class="n">x_validate</span><span class="p">,</span> <span class="n">y_t</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_v</span><span class="o">=</span><span class="n">y_validate</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_t</span><span class="p">,</span> <span class="n">y_t</span><span class="p">)</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_v</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_v</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span>

<span class="n">scores</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">([(</span><span class="n">score_model</span><span class="p">(</span><span class="n">model</span><span class="p">),</span> <span class="n">model</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span> <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">model</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">models</span><span class="p">)])</span>

<span class="k">for</span> <span class="n">score</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">scores</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Model {index} MAE: {score:0.2f}"</span><span class="p">)</span>

<span class="n">best</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
<span class="k">print</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Best Model: {best}"</span><span class="p">)</span>
<span class="n">best_model</span> <span class="o">=</span> <span class="n">f</span><span class="s2">"model_{best[2]}"</span>
<span class="n">best_hyperparameters</span> <span class="o">=</span> <span class="n">hyperparameters</span><span class="p">[</span><span class="n">best_model</span><span class="p">]</span>
</pre></div>
<pre class="example">
Model 2 MAE: 23528.78
Model 4 MAE: 23706.67
Model 1 MAE: 23740.98
Model 3 MAE: 23996.68
Model 0 MAE: 24015.49

Best Model: (23528.78421232877, RandomForestRegressor(bootstrap=True, criterion='mae', max_depth=None,
                      max_features='auto', max_leaf_nodes=None,
                      min_impurity_decrease=0.0, min_impurity_split=None,
                      min_samples_leaf=1, min_samples_split=2,
                      min_weight_fraction_leaf=0.0, n_estimators=100,
                      n_jobs=None, oob_score=False, random_state=0, verbose=0,
                      warm_start=False), 2)
</pre></div>
</div>
<div class="outline-3" id="outline-container-orgcfca7fe">
<h3 id="orgcfca7fe">Preliminary 4: Make Some Predictions</h3>
<div class="outline-text-3" id="text-orgcfca7fe">
<div class="highlight">
<pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="o">**</span><span class="n">best_hyperparameters</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>

<span class="n">test_predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_submit</span><span class="p">)</span>

<span class="n">submission</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">Id</span><span class="o">=</span><span class="n">testing_data</span><span class="o">.</span><span class="n">Id</span><span class="p">,</span>
                                   <span class="n">SalePrice</span><span class="o">=</span><span class="n">test_predictions</span><span class="p">))</span>
<span class="n">submission</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">DATA_PATH</span><span class="o">/</span><span class="s2">"submission.csv"</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
<p>This gets a score of <b>20,928.54621</b> compared to the previous error score of <b>*27,217.91640</b>, so it looks like the error is getting better.</p>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org82311ba">
<h2 id="org82311ba">End</h2>
<div class="outline-text-2" id="text-org82311ba">
<p>Now we're back at the point we were at the end of the introduction to machine learning tutorial, except with a slightly improved model.</p>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="/posts/tutorials/machine-learning-competitions/">Machine Learning Competitions</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="/posts/tutorials/machine-learning-competitions/" rel="bookmark"><time class="published dt-published" datetime="2020-02-18T10:16:45-08:00" itemprop="datePublished" title="2020-02-18 10:16">2020-02-18 10:16</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="/posts/tutorials/machine-learning-competitions/#org9a52e0d">Beginning</a>
<ul>
<li><a href="/posts/tutorials/machine-learning-competitions/#orgcbd4b19">Imports</a>
<ul>
<li><a href="/posts/tutorials/machine-learning-competitions/#org679285d">Python</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#orgd112903">PyPi</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#org4c571c9">Others</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/machine-learning-competitions/#org421cf96">Set Up</a>
<ul>
<li><a href="/posts/tutorials/machine-learning-competitions/#org9e1037a">Plottting</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#orgafae373">The Timer</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#orga963382">Environment</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#org19493b4">The Data</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="/posts/tutorials/machine-learning-competitions/#org56d27bc">Middle</a>
<ul>
<li><a href="/posts/tutorials/machine-learning-competitions/#org4945d6d">Preliminary 1: Specify Prediction Target</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#orgfa3f4d1">Preliminary 2: Create X</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#org8efce7d">Preliminary 3: Specify and Fit Model</a>
<ul>
<li><a href="/posts/tutorials/machine-learning-competitions/#orgea12666">A Linear Regression Model</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#orga846545">Decision Tree</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/machine-learning-competitions/#org058e71f">Preliminary 4: Make Some Predictions</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#org92f7b6f">Preliminary 5: Calculate the Mean Absolute Error in Validation Data</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#org92c2c96">Preliminary 6: Compare Different Tree Sizes</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#orgf86a19c">Preliminary 7: Use a Random Forest</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#org9ecbd88">Step 1: Creating a Model For the Competition</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#org9136d42">Step 2: Make Predictions</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#org1a61006">Step 3: Save the Submission</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#org16ac64a">Step 4: Test Your Work</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#org9d779cf">Step 5: Continuing Your Progress</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/machine-learning-competitions/#org8a15682">End</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org9a52e0d">
<h2 id="org9a52e0d">Beginning</h2>
<div class="outline-text-2" id="text-org9a52e0d">
<blockquote>
<p>In this exercise, you will create and submit predictions for a Kaggle competition. You can then improve your model (e.g. by adding features) to improve and see how you stack up to others taking this micro-course.</p>
<p>The steps in this notebook are:</p>
<ol class="org-ol">
<li>Build a Random Forest model with all of your data (<b>X</b> and <b>y</b>)</li>
<li>Read in the "test" data, which doesn't include values for the target. Predict home values in the test data with your Random Forest model.</li>
<li>Submit those predictions to the competition and see your score.</li>
<li>Optionally, come back to see if you can improve your model by adding features or changing your model. Then you can resubmit to see how that stacks up on the competition leaderboard.</li>
</ol>
</blockquote>
</div>
<div class="outline-3" id="outline-container-orgcbd4b19">
<h3 id="orgcbd4b19">Imports</h3>
<div class="outline-text-3" id="text-orgcbd4b19"></div>
<div class="outline-4" id="outline-container-org679285d">
<h4 id="org679285d">Python</h4>
<div class="outline-text-4" id="text-org679285d">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgd112903">
<h4 id="orgd112903">PyPi</h4>
<div class="outline-text-4" id="text-orgd112903">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>

<span class="kn">import</span> <span class="nn">hvplot.pandas</span>
<span class="kn">import</span> <span class="nn">pandas</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org4c571c9">
<h4 id="org4c571c9">Others</h4>
<div class="outline-text-4" id="text-org4c571c9">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">EnvironmentLoader</span><span class="p">,</span> <span class="n">Timer</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org421cf96">
<h3 id="org421cf96">Set Up</h3>
<div class="outline-text-3" id="text-org421cf96"></div>
<div class="outline-4" id="outline-container-org9e1037a">
<h4 id="org9e1037a">Plottting</h4>
<div class="outline-text-4" id="text-org9e1037a">
<div class="highlight">
<pre><span></span><span class="n">SLUG</span> <span class="o">=</span> <span class="s2">"underfitting-and-overfitting-exercise"</span>
<span class="n">OUTPUT_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"../../files/posts/tutorials/"</span><span class="p">)</span><span class="o">/</span><span class="n">SLUG</span>
<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">folder_path</span><span class="o">=</span><span class="n">OUTPUT_PATH</span><span class="p">)</span>
<span class="n">Plot</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgafae373">
<h4 id="orgafae373">The Timer</h4>
<div class="outline-text-4" id="text-orgafae373">
<div class="highlight">
<pre><span></span><span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orga963382">
<h4 id="orga963382">Environment</h4>
<div class="outline-text-4" id="text-orga963382">
<div class="highlight">
<pre><span></span><span class="n">ENVIRONMENT</span> <span class="o">=</span> <span class="n">EnvironmentLoader</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org19493b4">
<h4 id="org19493b4">The Data</h4>
<div class="outline-text-4" id="text-org19493b4">
<div class="highlight">
<pre><span></span><span class="n">DATA_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">ENVIRONMENT</span><span class="p">[</span><span class="s2">"HOUSE-PRICES-IOWA"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="n">DATA_PATH</span><span class="o">/</span><span class="s2">"train.csv"</span><span class="p">)</span>

<span class="n">test_data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="n">DATA_PATH</span><span class="o">/</span><span class="s2">"test.csv"</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org56d27bc">
<h2 id="org56d27bc">Middle</h2>
<div class="outline-text-2" id="text-org56d27bc"></div>
<div class="outline-3" id="outline-container-org4945d6d">
<h3 id="org4945d6d">Preliminary 1: Specify Prediction Target</h3>
<div class="outline-text-3" id="text-org4945d6d">
<p>Select the target variable, which corresponds to the sales price. Save this to a new variable called `y`. You'll need to print a list of the columns to find the name of the column you need.</p>
<p>Our target is <i>SalePrice</i>.</p>
<div class="highlight">
<pre><span></span><span class="n">Y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">SalePrice</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgfa3f4d1">
<h3 id="orgfa3f4d1">Preliminary 2: Create X</h3>
<div class="outline-text-3" id="text-orgfa3f4d1">
<blockquote>
<p>Now you will create a DataFrame called `X` holding the predictive features.</p>
<p>Since you want only some columns from the original data, you'll first create a list with the names of the columns you want in `X`.</p>
<p>You'll use just the following columns in the list (you can copy and paste the whole list to save some typing, though you'll still need to add quotes):</p>
<ul class="org-ul">
<li>LotArea</li>
<li>YearBuilt</li>
<li>1stFlrSF</li>
<li>2ndFlrSF</li>
<li>FullBath</li>
<li>BedroomAbvGr</li>
<li>TotRmsAbvGrd</li>
</ul>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">FEATURES</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">"LotArea"</span><span class="p">,</span>
    <span class="s2">"YearBuilt"</span><span class="p">,</span>
    <span class="s2">"1stFlrSF"</span><span class="p">,</span>
    <span class="s2">"2ndFlrSF"</span><span class="p">,</span>
    <span class="s2">"FullBath"</span><span class="p">,</span>
    <span class="s2">"BedroomAbvGr"</span><span class="p">,</span>
    <span class="s2">"TotRmsAbvGrd"</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">FEATURES</span><span class="p">]</span>
</pre></div>
<p>Split up the data into training and validation sets.</p>
<div class="highlight">
<pre><span></span><span class="n">x_train</span><span class="p">,</span> <span class="n">x_validate</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_validate</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org8efce7d">
<h3 id="org8efce7d">Preliminary 3: Specify and Fit Model</h3>
<div class="outline-text-3" id="text-org8efce7d"></div>
<div class="outline-4" id="outline-container-orgea12666">
<h4 id="orgea12666">A Linear Regression Model</h4>
<div class="outline-text-4" id="text-orgea12666">
<p>As a baseline, I'll fit a simple <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html">Linear Regression</a> (ordinary-least-squares) model.</p>
<div class="highlight">
<pre><span></span><span class="n">regression</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">regression</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{scores.mean():0.2f} (+/- {2 * scores.std():0.2f})"</span><span class="p">)</span>
<span class="n">regression</span> <span class="o">=</span> <span class="n">regression</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Training R^2: {regression.score(x_train, y_train): 0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Validation R^2: {regression.score(x_validate, y_validate):0.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
0.66 (+/- 0.17)
Training R^2:  0.68
Validation R^2: 0.77
</pre></div>
</div>
<div class="outline-4" id="outline-container-orga846545">
<h4 id="orga846545">Decision Tree</h4>
<div class="outline-text-4" id="text-orga846545">
<blockquote>
<p>Create a <code>DecisionTreeRegressor</code> and save it as <code>iowa_model</code>. Ensure you've done the relevant import from sklearn to run this command.</p>
<p>Then fit the model you just created using the data in <code>X</code> and <code>y</code> that you saved above.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">()</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{scores.mean():0.2f} (+/- {2 * scores.std():0.2f})"</span><span class="p">)</span>

<span class="n">tree</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Training R^2: {tree.score(x_train, y_train): 0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Validation R^2: {tree.score(x_validate, y_validate):0.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
0.52 (+/- 0.34)
Training R^2:  1.00
Validation R^2: 0.75
</pre>
<p>So our linear regression actually does better than the tree does. It looks like the tree might be overfitting on the training data.</p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org058e71f">
<h3 id="org058e71f">Preliminary 4: Make Some Predictions</h3>
<div class="outline-text-3" id="text-org058e71f">
<div class="highlight">
<pre><span></span><span class="n">tree_predict</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_validate</span><span class="p">)</span>
<span class="n">regression_predict</span> <span class="o">=</span> <span class="n">regression</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_validate</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org92f7b6f">
<h3 id="org92f7b6f">Preliminary 5: Calculate the Mean Absolute Error in Validation Data</h3>
<div class="outline-text-3" id="text-org92f7b6f">
<div class="highlight">
<pre><span></span><span class="n">tree_mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_validate</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">tree_predict</span><span class="p">)</span>
<span class="n">regression_mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_validate</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">regression_predict</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Tree MAE: {tree_mae: 0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Regression MAE: {regression_mae: 0.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Tree MAE:  28969.44
Regression MAE:  27228.88
</pre>
<p>The tree's error is a little higher than the regression line's.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org92c2c96">
<h3 id="org92c2c96">Preliminary 6: Compare Different Tree Sizes</h3>
<div class="outline-text-3" id="text-org92c2c96">
<blockquote>
<p>Write a loop that tries the following values for <b>max_leaf_nodes</b> from a set of possible values.</p>
<p>Call the <b>get_mae</b> function on each value of max_leaf_nodes. Store the output in some way that allows you to select the value of <code>max_leaf_nodes</code> that gives the most accurate model on your data.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">get_mae</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="p">,</span> <span class="n">train_X</span><span class="o">=</span><span class="n">x_train</span><span class="p">,</span> <span class="n">val_X</span><span class="o">=</span><span class="n">x_validate</span><span class="p">,</span> <span class="n">train_y</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">val_y</span><span class="o">=</span><span class="n">y_validate</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="o">=</span><span class="n">max_leaf_nodes</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>
    <span class="n">preds_val</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">val_X</span><span class="p">)</span>
    <span class="n">mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">val_y</span><span class="p">,</span> <span class="n">preds_val</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mae</span>
</pre></div>
<blockquote>
<p>Write a loop to find the ideal tree size from <code>candidate_max_leaf_nodes</code>.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">candidate_max_leaf_nodes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">250</span><span class="p">,</span> <span class="mi">500</span><span class="p">]</span>
<span class="n">outcomes</span> <span class="o">=</span> <span class="p">[(</span><span class="n">get_mae</span><span class="p">(</span><span class="n">nodes</span><span class="p">),</span> <span class="n">nodes</span><span class="p">)</span> <span class="k">for</span> <span class="n">nodes</span> <span class="ow">in</span> <span class="n">candidate_max_leaf_nodes</span><span class="p">]</span>
<span class="n">best</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">outcomes</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">best</span><span class="p">)</span>
<span class="n">best_tree_size</span> <span class="o">=</span> <span class="n">best</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
<pre class="example">
(27282.50803885739, 100)
</pre>
<div class="highlight">
<pre><span></span><span class="n">mae</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">nodes</span><span class="o">=</span><span class="n">candidate_max_leaf_nodes</span><span class="p">,</span> <span class="n">mae</span> <span class="o">=</span> <span class="p">[</span><span class="n">outcome</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">outcome</span> <span class="ow">in</span> <span class="n">outcomes</span><span class="p">]))</span>
<span class="n">plot</span> <span class="o">=</span> <span class="n">mae</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"nodes"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"mae"</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">"Node Mean Absolute Error"</span><span class="p">,</span>
                                           <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
                                           <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">)</span>
<span class="n">source</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"node_mean_absolute_error"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">source</span><span class="p">)</span>
</pre></div>
: <object data="/posts/tutorials/machine-learning-competitions/node_mean_absolute_error.html" height="800" style="width:100%" type="text/html">:
<p>Figure Missing</p>
:</object>
<p>Looking at the plot you can see that the error drops until you hit 100 nodes and then begins to rise again as it overfits the data with more nodes.</p>
<p>Let's see how much this improves our model using \(r^2\).</p>
<div class="highlight">
<pre><span></span><span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="o">=</span><span class="n">best_tree_size</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{scores.mean():0.2f} (+/- {2 * scores.std():0.2f})"</span><span class="p">)</span>

<span class="n">tree</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Training R^2: {tree.score(x_train, y_train): 0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Validation R^2: {tree.score(x_validate, y_validate):0.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
0.58 (+/- 0.32)
Training R^2:  0.93
Validation R^2: 0.76
</pre>
<p>We've improved it slightly, it's probably still overfitting the model but not as much.</p>
</div>
</div>
<div class="outline-3" id="outline-container-orgf86a19c">
<h3 id="orgf86a19c">Preliminary 7: Use a Random Forest</h3>
<div class="outline-text-3" id="text-orgf86a19c">
<div class="highlight">
<pre><span></span><span class="n">forest</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">forest</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{scores.mean():0.2f} (+/- {2 * scores.std():0.2f})"</span><span class="p">)</span>

<span class="n">tree</span> <span class="o">=</span> <span class="n">forest</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Training R^2: {forest.score(x_train, y_train): 0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Validation R^2: {forest.score(x_validate, y_validate):0.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
0.76 (+/- 0.11)
Training R^2:  0.97
Validation R^2: 0.85
</pre>
<p>So the defaults already beat the regression and decision tree model.</p>
<div class="highlight">
<pre><span></span><span class="n">forest_predictions</span> <span class="o">=</span> <span class="n">forest</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_validate</span><span class="p">)</span>
<span class="n">forest_mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_validate</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">forest_predictions</span><span class="p">)</span>

<span class="n">tree_mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_validate</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">tree_predict</span><span class="p">)</span>
<span class="n">regression_mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_validate</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">regression_predict</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Tree MAE: {tree_mae: 0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Regression MAE: {regression_mae: 0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Forest MAE: {forest_mae:0.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Tree MAE:  28969.44
Regression MAE:  27228.88
Forest MAE: 21857.16
</pre>
<p>So the forest also has a much better Mean Absolute Error than the other two models.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org9ecbd88">
<h3 id="org9ecbd88">Step 1: Creating a Model For the Competition</h3>
<div class="outline-text-3" id="text-org9ecbd88">
<blockquote>
<p>Build a Random Forest model and train it on all of <b>X</b> and <b>y</b>.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">forest</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">forest</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org9136d42">
<h3 id="org9136d42">Step 2: Make Predictions</h3>
<div class="outline-text-3" id="text-org9136d42">
<blockquote>
<p>Read the file of "test" data. And apply your model to make predictions. Then create test_X which comes from test_data but includes only the columns you used for prediction. The list of columns is stored in a variable called features.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">x_test</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[</span><span class="n">FEATURES</span><span class="p">]</span>
</pre></div>
<blockquote>
<p>Make predictions which we will submit.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">forest</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org1a61006">
<h3 id="org1a61006">Step 3: Save the Submission</h3>
<div class="outline-text-3" id="text-org1a61006">
<div class="highlight">
<pre><span></span><span class="n">submission</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">Id</span><span class="o">=</span><span class="n">test_data</span><span class="o">.</span><span class="n">Id</span><span class="p">,</span> <span class="n">SalePrice</span><span class="o">=</span><span class="n">predictions</span><span class="p">))</span>
<span class="n">submission</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">DATA_PATH</span><span class="o">/</span><span class="s2">"submission.csv"</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org16ac64a">
<h3 id="org16ac64a">Step 4: Test Your Work</h3>
<div class="outline-text-3" id="text-org16ac64a">
<blockquote>
<p>To test your results, you'll need to join the competition (if you haven't already). So open a new window by clicking on <a href="https://www.kaggle.com/c/home-data-for-ml-course">this link</a>. Then click on the <b>Join Competition</b> button.</p>
</blockquote>
<p><a href="https://i.imgur.com/wLmFtH3.png">join competition image</a></p>
<blockquote>
<p>Next, follow the instructions below:</p>
<ol class="org-ol">
<li>Begin by clicking on the blue <b>COMMIT</b> button in the top right corner of this window. This will generate a pop-up window.</li>
<li>After your code has finished running, click on the blue <b>Open Version</b> button in the top right of the pop-up window. This brings you into view mode of the same page. You will need to scroll down to get back to these instructions.</li>
<li>Click on the <b>Output</b> tab on the left of the screen. Then, click on the <b>Submit to Competition</b> button to submit your results to the leaderboard.</li>
</ol>
<p>You have now successfully submitted to the competition.</p>
</blockquote>
</div>
</div>
<div class="outline-3" id="outline-container-org9d779cf">
<h3 id="org9d779cf">Step 5: Continuing Your Progress</h3>
<div class="outline-text-3" id="text-org9d779cf">
<blockquote>
<p>There are many ways to improve your model, and <b>experimenting is a great way to learn at this point.</b></p>
<p>The best way to improve your model is to add features. Look at the list of columns and think about what might affect home prices. Some features will cause errors because of issues like missing values or non-numeric data types.</p>
</blockquote>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org8a15682">
<h2 id="org8a15682">End</h2>
<div class="outline-text-2" id="text-org8a15682">
<p>The submission is evaluated using the Root Mean Squared Error of the logarithms of the sale prices. The logarithm makes it so the errors for the cheap houses and the expensive houses are equally bad.</p>
<p>For this model you get a score of <b>*27,217.91640</b>. The current leader has a score of 0, which would seem to imply he downloaded the original set and learned the data, the second best is <i>8,830</i>.</p>
<p>The <b><a href="https://www.kaggle.com/learn/intermediate-machine-learning">Intermediate Machine Learning</a></b> micro-course will teach you how to handle these types of features. You will also learn to use <b>xgboost</b>, a technique giving even better accuracy than Random Forest.</p>
</div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="/posts/tutorials/random-forests/">Random Forests</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="/posts/tutorials/random-forests/" rel="bookmark"><time class="published dt-published" datetime="2020-02-18T10:14:50-08:00" itemprop="datePublished" title="2020-02-18 10:14">2020-02-18 10:14</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="/posts/tutorials/random-forests/#orgf2a8644">Beginning</a>
<ul>
<li><a href="/posts/tutorials/random-forests/#orgedd9ec0">Imports</a>
<ul>
<li><a href="/posts/tutorials/random-forests/#org918bac8">Python</a></li>
<li><a href="/posts/tutorials/random-forests/#orgffd5777">PyPi</a></li>
<li><a href="/posts/tutorials/random-forests/#org8ed8693">Others</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/random-forests/#orga129718">Set Up</a>
<ul>
<li><a href="/posts/tutorials/random-forests/#org097714a">Plottting</a></li>
<li><a href="/posts/tutorials/random-forests/#orgdda5530">The Timer</a></li>
<li><a href="/posts/tutorials/random-forests/#org8daec82">Environment</a></li>
<li><a href="/posts/tutorials/random-forests/#orgfc71b47">The Data</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="/posts/tutorials/random-forests/#orgd749801">Middle</a>
<ul>
<li><a href="/posts/tutorials/random-forests/#org29e714d">Preliminary 1: Specify Prediction Target</a></li>
<li><a href="/posts/tutorials/random-forests/#org1d67d95">Preliminary 2: Create X</a></li>
<li><a href="/posts/tutorials/random-forests/#orgc9f56cd">Preliminary 3: Specify and Fit Model</a>
<ul>
<li><a href="/posts/tutorials/random-forests/#org1e88653">A Linear Regression Model</a></li>
<li><a href="/posts/tutorials/random-forests/#orgfceb1d8">Decision Tree</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/random-forests/#org9beb4ac">Preliminary 4: Make Some Predictions</a></li>
<li><a href="/posts/tutorials/random-forests/#org6676f88">Preliminary 5: Calculate the Mean Absolute Error in Validation Data</a></li>
<li><a href="/posts/tutorials/random-forests/#org1674095">Preliminary 6: Compare Different Tree Sizes</a></li>
<li><a href="/posts/tutorials/random-forests/#org3d8646b">Step 1: Use a Random Forest</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/random-forests/#org549747a">End</a></li>
<li><a href="/posts/tutorials/random-forests/#org92d480c">Raw</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orgf2a8644">
<h2 id="orgf2a8644">Beginning</h2>
<div class="outline-text-2" id="text-orgf2a8644">
<p>This is the fourth part of kaggle's <a href="https://www.kaggle.com/learn/intro-to-machine-learning">Introduction to Machine Learning</a> tutorial - Overfitting and Underfitting.</p>
</div>
<div class="outline-3" id="outline-container-orgedd9ec0">
<h3 id="orgedd9ec0">Imports</h3>
<div class="outline-text-3" id="text-orgedd9ec0"></div>
<div class="outline-4" id="outline-container-org918bac8">
<h4 id="org918bac8">Python</h4>
<div class="outline-text-4" id="text-org918bac8">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgffd5777">
<h4 id="orgffd5777">PyPi</h4>
<div class="outline-text-4" id="text-orgffd5777">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>

<span class="kn">import</span> <span class="nn">hvplot.pandas</span>
<span class="kn">import</span> <span class="nn">pandas</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org8ed8693">
<h4 id="org8ed8693">Others</h4>
<div class="outline-text-4" id="text-org8ed8693">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">EnvironmentLoader</span><span class="p">,</span> <span class="n">Timer</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orga129718">
<h3 id="orga129718">Set Up</h3>
<div class="outline-text-3" id="text-orga129718"></div>
<div class="outline-4" id="outline-container-org097714a">
<h4 id="org097714a">Plottting</h4>
<div class="outline-text-4" id="text-org097714a">
<div class="highlight">
<pre><span></span><span class="n">SLUG</span> <span class="o">=</span> <span class="s2">"underfitting-and-overfitting-exercise"</span>
<span class="n">OUTPUT_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"../../files/posts/tutorials/"</span><span class="p">)</span><span class="o">/</span><span class="n">SLUG</span>
<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">folder_path</span><span class="o">=</span><span class="n">OUTPUT_PATH</span><span class="p">)</span>
<span class="n">Plot</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgdda5530">
<h4 id="orgdda5530">The Timer</h4>
<div class="outline-text-4" id="text-orgdda5530">
<div class="highlight">
<pre><span></span><span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org8daec82">
<h4 id="org8daec82">Environment</h4>
<div class="outline-text-4" id="text-org8daec82">
<div class="highlight">
<pre><span></span><span class="n">ENVIRONMENT</span> <span class="o">=</span> <span class="n">EnvironmentLoader</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgfc71b47">
<h4 id="orgfc71b47">The Data</h4>
<div class="outline-text-4" id="text-orgfc71b47">
<div class="highlight">
<pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="n">Path</span><span class="p">(</span><span class="n">ENVIRONMENT</span><span class="p">[</span><span class="s2">"HOUSE-PRICES-IOWA"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span><span class="o">/</span><span class="s2">"train.csv"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgd749801">
<h2 id="orgd749801">Middle</h2>
<div class="outline-text-2" id="text-orgd749801"></div>
<div class="outline-3" id="outline-container-org29e714d">
<h3 id="org29e714d">Preliminary 1: Specify Prediction Target</h3>
<div class="outline-text-3" id="text-org29e714d">
<p>Select the target variable, which corresponds to the sales price. Save this to a new variable called `y`. You'll need to print a list of the columns to find the name of the column you need.</p>
<p>Our target is <i>SalePrice</i>.</p>
<div class="highlight">
<pre><span></span><span class="n">Y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">SalePrice</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org1d67d95">
<h3 id="org1d67d95">Preliminary 2: Create X</h3>
<div class="outline-text-3" id="text-org1d67d95">
<blockquote>
<p>Now you will create a DataFrame called `X` holding the predictive features.</p>
<p>Since you want only some columns from the original data, you'll first create a list with the names of the columns you want in `X`.</p>
<p>You'll use just the following columns in the list (you can copy and paste the whole list to save some typing, though you'll still need to add quotes):</p>
<ul class="org-ul">
<li>LotArea</li>
<li>YearBuilt</li>
<li>1stFlrSF</li>
<li>2ndFlrSF</li>
<li>FullBath</li>
<li>BedroomAbvGr</li>
<li>TotRmsAbvGrd</li>
</ul>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">FEATURES</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">"LotArea"</span><span class="p">,</span>
    <span class="s2">"YearBuilt"</span><span class="p">,</span>
    <span class="s2">"1stFlrSF"</span><span class="p">,</span>
    <span class="s2">"2ndFlrSF"</span><span class="p">,</span>
    <span class="s2">"FullBath"</span><span class="p">,</span>
    <span class="s2">"BedroomAbvGr"</span><span class="p">,</span>
    <span class="s2">"TotRmsAbvGrd"</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">FEATURES</span><span class="p">]</span>
</pre></div>
<p>Split up the data into training and validation sets.</p>
<div class="highlight">
<pre><span></span><span class="n">x_train</span><span class="p">,</span> <span class="n">x_validate</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_validate</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgc9f56cd">
<h3 id="orgc9f56cd">Preliminary 3: Specify and Fit Model</h3>
<div class="outline-text-3" id="text-orgc9f56cd"></div>
<div class="outline-4" id="outline-container-org1e88653">
<h4 id="org1e88653">A Linear Regression Model</h4>
<div class="outline-text-4" id="text-org1e88653">
<p>As a baseline, I'll fit a simple <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html">Linear Regression</a> (ordinary-least-squares) model.</p>
<div class="highlight">
<pre><span></span><span class="n">regression</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">regression</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{scores.mean():0.2f} (+/- {2 * scores.std():0.2f})"</span><span class="p">)</span>
<span class="n">regression</span> <span class="o">=</span> <span class="n">regression</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Training R^2: {regression.score(x_train, y_train): 0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Validation R^2: {regression.score(x_validate, y_validate):0.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
0.66 (+/- 0.17)
Training R^2:  0.68
Validation R^2: 0.77
</pre></div>
</div>
<div class="outline-4" id="outline-container-orgfceb1d8">
<h4 id="orgfceb1d8">Decision Tree</h4>
<div class="outline-text-4" id="text-orgfceb1d8">
<blockquote>
<p>Create a <code>DecisionTreeRegressor</code> and save it as <code>iowa_model</code>. Ensure you've done the relevant import from sklearn to run this command.</p>
<p>Then fit the model you just created using the data in <code>X</code> and <code>y</code> that you saved above.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">()</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{scores.mean():0.2f} (+/- {2 * scores.std():0.2f})"</span><span class="p">)</span>

<span class="n">tree</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Training R^2: {tree.score(x_train, y_train): 0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Validation R^2: {tree.score(x_validate, y_validate):0.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
0.54 (+/- 0.33)
Training R^2:  1.00
Validation R^2: 0.72
</pre>
<p>So our linear regression actually does better than the tree does. It looks like the tree might be overfitting on the training data.</p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org9beb4ac">
<h3 id="org9beb4ac">Preliminary 4: Make Some Predictions</h3>
<div class="outline-text-3" id="text-org9beb4ac">
<div class="highlight">
<pre><span></span><span class="n">tree_predict</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_validate</span><span class="p">)</span>
<span class="n">regression_predict</span> <span class="o">=</span> <span class="n">regression</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_validate</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org6676f88">
<h3 id="org6676f88">Preliminary 5: Calculate the Mean Absolute Error in Validation Data</h3>
<div class="outline-text-3" id="text-org6676f88">
<div class="highlight">
<pre><span></span><span class="n">tree_mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_validate</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">tree_predict</span><span class="p">)</span>
<span class="n">regression_mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_validate</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">regression_predict</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Tree MAE: {tree_mae: 0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Regression MAE: {regression_mae: 0.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Tree MAE:  30219.18
Regression MAE:  27228.88
</pre>
<p>The tree's error is a little higher than the regression line's.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org1674095">
<h3 id="org1674095">Preliminary 6: Compare Different Tree Sizes</h3>
<div class="outline-text-3" id="text-org1674095">
<blockquote>
<p>Write a loop that tries the following values for <b>max_leaf_nodes</b> from a set of possible values.</p>
<p>Call the <b>get_mae</b> function on each value of max_leaf_nodes. Store the output in some way that allows you to select the value of <code>max_leaf_nodes</code> that gives the most accurate model on your data.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">get_mae</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="p">,</span> <span class="n">train_X</span><span class="o">=</span><span class="n">x_train</span><span class="p">,</span> <span class="n">val_X</span><span class="o">=</span><span class="n">x_validate</span><span class="p">,</span> <span class="n">train_y</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">val_y</span><span class="o">=</span><span class="n">y_validate</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="o">=</span><span class="n">max_leaf_nodes</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>
    <span class="n">preds_val</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">val_X</span><span class="p">)</span>
    <span class="n">mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">val_y</span><span class="p">,</span> <span class="n">preds_val</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mae</span>
</pre></div>
<blockquote>
<p>Write a loop to find the ideal tree size from <code>candidate_max_leaf_nodes</code>.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">candidate_max_leaf_nodes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">250</span><span class="p">,</span> <span class="mi">500</span><span class="p">]</span>
<span class="n">outcomes</span> <span class="o">=</span> <span class="p">[(</span><span class="n">get_mae</span><span class="p">(</span><span class="n">nodes</span><span class="p">),</span> <span class="n">nodes</span><span class="p">)</span> <span class="k">for</span> <span class="n">nodes</span> <span class="ow">in</span> <span class="n">candidate_max_leaf_nodes</span><span class="p">]</span>
<span class="n">best</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">outcomes</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">best</span><span class="p">)</span>
<span class="n">best_tree_size</span> <span class="o">=</span> <span class="n">best</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
<pre class="example">
(27282.50803885739, 100)
</pre>
<div class="highlight">
<pre><span></span><span class="n">mae</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">nodes</span><span class="o">=</span><span class="n">candidate_max_leaf_nodes</span><span class="p">,</span> <span class="n">mae</span> <span class="o">=</span> <span class="p">[</span><span class="n">outcome</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">outcome</span> <span class="ow">in</span> <span class="n">outcomes</span><span class="p">]))</span>
<span class="n">plot</span> <span class="o">=</span> <span class="n">mae</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"nodes"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"mae"</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">"Node Mean Absolute Error"</span><span class="p">,</span>
                                           <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
                                           <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">)</span>
<span class="n">source</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"node_mean_absolute_error"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">source</span><span class="p">)</span>
</pre></div>
: <object data="/posts/tutorials/random-forests/node_mean_absolute_error.html" height="800" style="width:100%" type="text/html">:
<p>Figure Missing</p>
:</object>
<p>Looking at the plot you can see that the error drops until you hit 100 nodes and then begins to rise again as it overfits the data with more nodes.</p>
<p>Let's see how much this improves our model using \(r^2\).</p>
<div class="highlight">
<pre><span></span><span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="o">=</span><span class="n">best_tree_size</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{scores.mean():0.2f} (+/- {2 * scores.std():0.2f})"</span><span class="p">)</span>

<span class="n">tree</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Training R^2: {tree.score(x_train, y_train): 0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Validation R^2: {tree.score(x_validate, y_validate):0.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
0.58 (+/- 0.31)
Training R^2:  0.93
Validation R^2: 0.77
</pre>
<p>We've improved it slightly, it's probably still overfitting the model but not as much.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org3d8646b">
<h3 id="org3d8646b">Step 1: Use a Random Forest</h3>
<div class="outline-text-3" id="text-org3d8646b">
<div class="highlight">
<pre><span></span><span class="n">forest</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">forest</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{scores.mean():0.2f} (+/- {2 * scores.std():0.2f})"</span><span class="p">)</span>

<span class="n">tree</span> <span class="o">=</span> <span class="n">forest</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Training R^2: {forest.score(x_train, y_train): 0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Validation R^2: {forest.score(x_validate, y_validate):0.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
0.76 (+/- 0.11)
Training R^2:  0.97
Validation R^2: 0.85
</pre>
<p>So the defaults already beat the regression and decision tree model.</p>
<div class="highlight">
<pre><span></span><span class="n">forest_predictions</span> <span class="o">=</span> <span class="n">forest</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_validate</span><span class="p">)</span>
<span class="n">forest_mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_validate</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">forest_predictions</span><span class="p">)</span>

<span class="n">tree_mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_validate</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">tree_predict</span><span class="p">)</span>
<span class="n">regression_mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_validate</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">regression_predict</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Tree MAE: {tree_mae: 0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Regression MAE: {regression_mae: 0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Forest MAE: {forest_mae:0.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Tree MAE:  30219.18
Regression MAE:  27228.88
Forest MAE: 21857.16
</pre>
<p>So the forest also has a much better Mean Absolute Error than the other two models.</p>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org549747a">
<h2 id="org549747a">End</h2>
<div class="outline-text-2" id="text-org549747a">
<p>This is the end of the tutorial as far as how to build models. Next is a bit on entering a kaggle competition.</p>
</div>
</div>
<div class="outline-2" id="outline-container-org92d480c">
<h2 id="org92d480c">Raw</h2>
<div class="outline-text-2" id="text-org92d480c">
<pre class="example">


# So far, you have followed specific instructions at each step of your project. This helped learn key ideas and build your first model, but now you know enough to try things on your own. 
# 
# Machine Learning competitions are a great way to try your own ideas and learn more as you independently navigate a machine learning project. 
# 
# # Keep Going
# 
# You are ready for **[Machine Learning Competitions](https://www.kaggle.com/kernels/fork/1259198).**
# 

# ---
# **[Introduction to Machine Learning Home Page](https://www.kaggle.com/learn/intro-to-machine-learning)**
# 
# 
# 
# 
# 
# *Have questions or comments? Visit the [Learn Discussion forum](https://www.kaggle.com/learn-forum) to chat with other Learners.*

</pre></div>
</div>
</div>
</article>
<article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title"><a class="u-url" href="/posts/tutorials/underfitting-and-overfitting-exercise/">Underfitting and Overfitting Exercise</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="/posts/tutorials/underfitting-and-overfitting-exercise/" rel="bookmark"><time class="published dt-published" datetime="2020-02-18T10:11:19-08:00" itemprop="datePublished" title="2020-02-18 10:11">2020-02-18 10:11</time></a></p>
</div>
</header>
<div class="e-content entry-content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#orga3f6c28">Beginning</a>
<ul>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#orgccc06b3">Imports</a>
<ul>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#orga688237">Python</a></li>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#org983b4da">PyPi</a></li>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#org23d164c">Others</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#org001561e">Set Up</a>
<ul>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#orgdc2e781">Plottting</a></li>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#org653f308">The Timer</a></li>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#org66874fd">Environment</a></li>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#org427ab1c">The Data</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#org485e33f">Middle</a>
<ul>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#org95a153a">Preliminary 1: Specify Prediction Target</a></li>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#orgf543d0a">Preliminary 2: Create X</a></li>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#orgf3233ea">Preliminary 3: Specify and Fit Model</a>
<ul>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#orga6f15d4">A Linear Regression Model</a></li>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#org97c204f">Decision Tree</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#org94258ee">Preliminary 4: Make Some Predictions</a></li>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#org9e2044c">Preliminary 5: Calculate the Mean Absolute Error in Validation Data</a></li>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#org1d81d88">Step 1: Compare Different Tree Sizes</a></li>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#org11908a9">Step 2: Fit Model Using All Data</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#orgdcfb05d">End</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-orga3f6c28">
<h2 id="orga3f6c28">Beginning</h2>
<div class="outline-text-2" id="text-orga3f6c28">
<p>This is the fourth part of kaggle's <a href="https://www.kaggle.com/learn/intro-to-machine-learning">Introduction to Machine Learning</a> tutorial - Overfitting and Underfitting.</p>
</div>
<div class="outline-3" id="outline-container-orgccc06b3">
<h3 id="orgccc06b3">Imports</h3>
<div class="outline-text-3" id="text-orgccc06b3"></div>
<div class="outline-4" id="outline-container-orga688237">
<h4 id="orga688237">Python</h4>
<div class="outline-text-4" id="text-orga688237">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org983b4da">
<h4 id="org983b4da">PyPi</h4>
<div class="outline-text-4" id="text-org983b4da">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>

<span class="kn">import</span> <span class="nn">hvplot.pandas</span>
<span class="kn">import</span> <span class="nn">pandas</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org23d164c">
<h4 id="org23d164c">Others</h4>
<div class="outline-text-4" id="text-org23d164c">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">EnvironmentLoader</span><span class="p">,</span> <span class="n">Timer</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org001561e">
<h3 id="org001561e">Set Up</h3>
<div class="outline-text-3" id="text-org001561e"></div>
<div class="outline-4" id="outline-container-orgdc2e781">
<h4 id="orgdc2e781">Plottting</h4>
<div class="outline-text-4" id="text-orgdc2e781">
<div class="highlight">
<pre><span></span><span class="n">SLUG</span> <span class="o">=</span> <span class="s2">"underfitting-and-overfitting-exercise"</span>
<span class="n">OUTPUT_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"../../files/posts/tutorials/"</span><span class="p">)</span><span class="o">/</span><span class="n">SLUG</span>
<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">folder_path</span><span class="o">=</span><span class="n">OUTPUT_PATH</span><span class="p">)</span>
<span class="n">Plot</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org653f308">
<h4 id="org653f308">The Timer</h4>
<div class="outline-text-4" id="text-org653f308">
<div class="highlight">
<pre><span></span><span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org66874fd">
<h4 id="org66874fd">Environment</h4>
<div class="outline-text-4" id="text-org66874fd">
<div class="highlight">
<pre><span></span><span class="n">ENVIRONMENT</span> <span class="o">=</span> <span class="n">EnvironmentLoader</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org427ab1c">
<h4 id="org427ab1c">The Data</h4>
<div class="outline-text-4" id="text-org427ab1c">
<div class="highlight">
<pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="n">Path</span><span class="p">(</span><span class="n">ENVIRONMENT</span><span class="p">[</span><span class="s2">"HOUSE-PRICES-IOWA"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span><span class="o">/</span><span class="s2">"train.csv"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org485e33f">
<h2 id="org485e33f">Middle</h2>
<div class="outline-text-2" id="text-org485e33f"></div>
<div class="outline-3" id="outline-container-org95a153a">
<h3 id="org95a153a">Preliminary 1: Specify Prediction Target</h3>
<div class="outline-text-3" id="text-org95a153a">
<p>Select the target variable, which corresponds to the sales price. Save this to a new variable called `y`. You'll need to print a list of the columns to find the name of the column you need.</p>
<p>Our target is <i>SalePrice</i>.</p>
<div class="highlight">
<pre><span></span><span class="n">Y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">SalePrice</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgf543d0a">
<h3 id="orgf543d0a">Preliminary 2: Create X</h3>
<div class="outline-text-3" id="text-orgf543d0a">
<blockquote>
<p>Now you will create a DataFrame called `X` holding the predictive features.</p>
<p>Since you want only some columns from the original data, you'll first create a list with the names of the columns you want in `X`.</p>
<p>You'll use just the following columns in the list (you can copy and paste the whole list to save some typing, though you'll still need to add quotes):</p>
<ul class="org-ul">
<li>LotArea</li>
<li>YearBuilt</li>
<li>1stFlrSF</li>
<li>2ndFlrSF</li>
<li>FullBath</li>
<li>BedroomAbvGr</li>
<li>TotRmsAbvGrd</li>
</ul>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">FEATURES</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">"LotArea"</span><span class="p">,</span>
    <span class="s2">"YearBuilt"</span><span class="p">,</span>
    <span class="s2">"1stFlrSF"</span><span class="p">,</span>
    <span class="s2">"2ndFlrSF"</span><span class="p">,</span>
    <span class="s2">"FullBath"</span><span class="p">,</span>
    <span class="s2">"BedroomAbvGr"</span><span class="p">,</span>
    <span class="s2">"TotRmsAbvGrd"</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">FEATURES</span><span class="p">]</span>
</pre></div>
<p>Split up the data into training and validation sets.</p>
<div class="highlight">
<pre><span></span><span class="n">x_train</span><span class="p">,</span> <span class="n">x_validate</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_validate</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgf3233ea">
<h3 id="orgf3233ea">Preliminary 3: Specify and Fit Model</h3>
<div class="outline-text-3" id="text-orgf3233ea"></div>
<div class="outline-4" id="outline-container-orga6f15d4">
<h4 id="orga6f15d4">A Linear Regression Model</h4>
<div class="outline-text-4" id="text-orga6f15d4">
<p>As a baseline, I'll fit a simple <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html">Linear Regression</a> (ordinary-least-squares) model.</p>
<div class="highlight">
<pre><span></span><span class="n">regression</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">regression</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{scores.mean():0.2f} (+/- {2 * scores.std():0.2f})"</span><span class="p">)</span>
<span class="n">regression</span> <span class="o">=</span> <span class="n">regression</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Training R^2: {regression.score(x_train, y_train): 0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Validation R^2: {regression.score(x_validate, y_validate):0.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
0.66 (+/- 0.17)
Training R^2:  0.68
Validation R^2: 0.77
</pre></div>
</div>
<div class="outline-4" id="outline-container-org97c204f">
<h4 id="org97c204f">Decision Tree</h4>
<div class="outline-text-4" id="text-org97c204f">
<blockquote>
<p>Create a <code>DecisionTreeRegressor</code> and save it as <code>iowa_model</code>. Ensure you've done the relevant import from sklearn to run this command.</p>
<p>Then fit the model you just created using the data in <code>X</code> and <code>y</code> that you saved above.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">()</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{scores.mean():0.2f} (+/- {2 * scores.std():0.2f})"</span><span class="p">)</span>

<span class="n">tree</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Training R^2: {tree.score(x_train, y_train): 0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Validation R^2: {tree.score(x_validate, y_validate):0.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
0.54 (+/- 0.32)
Training R^2:  1.00
Validation R^2: 0.75
</pre>
<p>So our linear regression actually does better than the tree does. It looks like the tree might be overfitting on the training data.</p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org94258ee">
<h3 id="org94258ee">Preliminary 4: Make Some Predictions</h3>
<div class="outline-text-3" id="text-org94258ee">
<div class="highlight">
<pre><span></span><span class="n">tree_predict</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_validate</span><span class="p">)</span>
<span class="n">regression_predict</span> <span class="o">=</span> <span class="n">regression</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_validate</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org9e2044c">
<h3 id="org9e2044c">Preliminary 5: Calculate the Mean Absolute Error in Validation Data</h3>
<div class="outline-text-3" id="text-org9e2044c">
<div class="highlight">
<pre><span></span><span class="n">tree_mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_validate</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">tree_predict</span><span class="p">)</span>
<span class="n">regression_mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_validate</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">regression_predict</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Tree MAE: {tree_mae: 0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Regression MAE: {regression_mae: 0.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Tree MAE:  29371.52
Regression MAE:  27228.88
</pre>
<p>The tree's error is a little higher than the regression line's.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org1d81d88">
<h3 id="org1d81d88">Step 1: Compare Different Tree Sizes</h3>
<div class="outline-text-3" id="text-org1d81d88">
<blockquote>
<p>Write a loop that tries the following values for <b>max_leaf_nodes</b> from a set of possible values.</p>
<p>Call the <b>get_mae</b> function on each value of max_leaf_nodes. Store the output in some way that allows you to select the value of <code>max_leaf_nodes</code> that gives the most accurate model on your data.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">get_mae</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="p">,</span> <span class="n">train_X</span><span class="o">=</span><span class="n">x_train</span><span class="p">,</span> <span class="n">val_X</span><span class="o">=</span><span class="n">x_validate</span><span class="p">,</span> <span class="n">train_y</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">val_y</span><span class="o">=</span><span class="n">y_validate</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="o">=</span><span class="n">max_leaf_nodes</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>
    <span class="n">preds_val</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">val_X</span><span class="p">)</span>
    <span class="n">mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">val_y</span><span class="p">,</span> <span class="n">preds_val</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mae</span>
</pre></div>
<blockquote>
<p>Write a loop to find the ideal tree size from <code>candidate_max_leaf_nodes</code>.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">candidate_max_leaf_nodes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">250</span><span class="p">,</span> <span class="mi">500</span><span class="p">]</span>
<span class="n">outcomes</span> <span class="o">=</span> <span class="p">[(</span><span class="n">get_mae</span><span class="p">(</span><span class="n">nodes</span><span class="p">),</span> <span class="n">nodes</span><span class="p">)</span> <span class="k">for</span> <span class="n">nodes</span> <span class="ow">in</span> <span class="n">candidate_max_leaf_nodes</span><span class="p">]</span>
<span class="n">best</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">outcomes</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">best</span><span class="p">)</span>
<span class="n">best_tree_size</span> <span class="o">=</span> <span class="n">best</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
<pre class="example">
(27282.50803885739, 100)
</pre>
<div class="highlight">
<pre><span></span><span class="n">mae</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">nodes</span><span class="o">=</span><span class="n">candidate_max_leaf_nodes</span><span class="p">,</span> <span class="n">mae</span> <span class="o">=</span> <span class="p">[</span><span class="n">outcome</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">outcome</span> <span class="ow">in</span> <span class="n">outcomes</span><span class="p">]))</span>
<span class="n">plot</span> <span class="o">=</span> <span class="n">mae</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"nodes"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"mae"</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">"Node Mean Absolute Error"</span><span class="p">,</span>
                                           <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
                                           <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">)</span>
<span class="n">source</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"node_mean_absolute_error"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">source</span><span class="p">)</span>
</pre></div>
: <object data="/posts/tutorials/underfitting-and-overfitting-exercise/node_mean_absolute_error.html" height="800" style="width:100%" type="text/html">:
<p>Figure Missing</p>
:</object>
<p>Looking at the plot you can see that the error drops until you hit 100 nodes and then begins to rise again as it overfits the data with more nodes.</p>
<p>Let's see how much this improves our model using \(r^2\).</p>
<div class="highlight">
<pre><span></span><span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="o">=</span><span class="n">best_tree_size</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"{scores.mean():0.2f} (+/- {2 * scores.std():0.2f})"</span><span class="p">)</span>

<span class="n">tree</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Training R^2: {tree.score(x_train, y_train): 0.2f}"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"Validation R^2: {tree.score(x_validate, y_validate):0.2f}"</span><span class="p">)</span>
</pre></div>
<pre class="example">
0.60 (+/- 0.26)
Training R^2:  0.93
Validation R^2: 0.76
</pre>
<p>We've improved it slightly, it's probably still overfitting the model but not as much.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org11908a9">
<h3 id="org11908a9">Step 2: Fit Model Using All Data</h3>
<div class="outline-text-3" id="text-org11908a9">
<blockquote>
<p>You know the best tree size. If you were going to deploy this model in practice, you would make it even more accurate by using all of the data and keeping that tree size. That is, you don't need to hold out the validation data now that you've made all your modeling decisions.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">final_model</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span> <span class="o">=</span> <span class="n">best_tree_size</span><span class="p">)</span>
<span class="n">final_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">predictions_first</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">predictions_final</span> <span class="o">=</span> <span class="n">final_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="n">x_y_tree</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">predicted</span><span class="o">=</span><span class="n">predictions_first</span><span class="p">,</span> <span class="n">actual</span><span class="o">=</span><span class="n">Y</span><span class="p">))</span>
<span class="n">x_y_line</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">predicted</span><span class="o">=</span><span class="n">predictions_final</span><span class="p">,</span> <span class="n">actual</span><span class="o">=</span><span class="n">Y</span><span class="p">))</span>
<span class="n">ideal</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">Y</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">Y</span><span class="p">))</span>

<span class="n">tree_plot</span> <span class="o">=</span> <span class="n">x_y_tree</span><span class="o">.</span><span class="n">hvplot</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"actual"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"predicted"</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Default"</span><span class="p">)</span>
<span class="n">line_plot</span> <span class="o">=</span> <span class="n">x_y_line</span><span class="o">.</span><span class="n">hvplot</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"actual"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"predicted"</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Tuned"</span><span class="p">)</span>
<span class="n">ideal_plot</span> <span class="o">=</span> <span class="n">ideal</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"x"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"y"</span><span class="p">)</span>
<span class="n">plot</span> <span class="o">=</span> <span class="p">(</span><span class="n">tree_plot</span> <span class="o">*</span> <span class="n">line_plot</span> <span class="o">*</span> <span class="n">ideal_plot</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">"Decision Tree Actual Vs Predictions"</span><span class="p">,</span>
                                    <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
                                    <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">)</span>
<span class="n">source</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"decision_tree_actual_vs_predicted"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">source</span><span class="p">)</span>
</pre></div>
: <object data="/posts/tutorials/underfitting-and-overfitting-exercise/decision_tree_actual_vs_predicted.html" height="800" style="width:100%" type="text/html">:
<p>Figure Missing</p>
:</object>
<p>The tuned model seems closer to the predicted.</p>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgdcfb05d">
<h2 id="orgdcfb05d">End</h2>
<div class="outline-text-2" id="text-orgdcfb05d">
<p>That's a basic way to tune hyperparameters to improve your model. But our decision tree still isn't doing as well as the regression line. Next up we'll try an ensemble method - Random Forests.</p>
</div>
</div>
</div>
</article>
</div>
<ul class="pager postindexpager clearfix">
<li class="next"><a href="/index-6.html" rel="next">Older posts</a></li>
</ul>
<!--End of body content-->
<footer id="footer">Contents Â© 2020 <a href="mailto:necromuralist@protonmail.com">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a></footer>
</div>
</div>
<script src="/assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
</script> 
</body>
</html>
