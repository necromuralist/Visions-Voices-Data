<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Visions, Voices, Data (Posts about Machine Learning)</title><link>https://necromuralist.github.io/Visions-Voices-Data/</link><description></description><atom:link href="https://necromuralist.github.io/Visions-Voices-Data/categories/cat_machine-learning.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents Â© 2021 &lt;a href="mailto:necromuralist@protonmail.com"&gt;Cloistered Monkey&lt;/a&gt; </copyright><lastBuildDate>Sun, 26 Dec 2021 00:14:09 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>SHAP Values</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values/#org9970b87"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values/#orgc9f1e69"&gt;Imports&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values/#org7500fae"&gt;Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values/#org01158d8"&gt;PyPi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values/#org5f38ef4"&gt;Others&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values/#org8847746"&gt;Set Up&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values/#orgf5bdb87"&gt;Plotting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values/#org1e67b01"&gt;The Timer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values/#org642cac4"&gt;Environment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values/#orgdc34a77"&gt;The Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values/#org99c16b4"&gt;Middle&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values/#org25d770d"&gt;A Single Row&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values/#org802e57f"&gt;End&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values/#orgc8998e2"&gt;See Also&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org9970b87" class="outline-2"&gt;
&lt;h2 id="org9970b87"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org9970b87"&gt;
&lt;p&gt;
SHAP values interpret the impact of a certain value for a given feature when compared to the prediction you'd make if that feature instead took a baseline value. This helps us interpret predictions given specific values for our features. We'll do this using the &lt;a href="https://github.com/slundberg/shap"&gt;SHAP&lt;/a&gt; library, naturally.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgc9f1e69" class="outline-3"&gt;
&lt;h3 id="orgc9f1e69"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgc9f1e69"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7500fae" class="outline-4"&gt;
&lt;h4 id="org7500fae"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org7500fae"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from argparse import Namespace
from pathlib import Path
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org01158d8" class="outline-4"&gt;
&lt;h4 id="org01158d8"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org01158d8"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from matplotlib import pyplot
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier

import numpy
import pandas
import seaborn
import shap
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org5f38ef4" class="outline-4"&gt;
&lt;h4 id="org5f38ef4"&gt;Others&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org5f38ef4"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from graeae import EnvironmentLoader, Timer
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org8847746" class="outline-3"&gt;
&lt;h3 id="org8847746"&gt;Set Up&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org8847746"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgf5bdb87" class="outline-4"&gt;
&lt;h4 id="orgf5bdb87"&gt;Plotting&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgf5bdb87"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;SLUG = "shap-values"
OUTPUT_PATH = Path("../../files/posts/tutorials/")/SLUG
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;get_ipython().run_line_magic('matplotlib', 'inline')
get_ipython().run_line_magic('config', "InlineBackend.figure_format = 'retina'")
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org1e67b01" class="outline-4"&gt;
&lt;h4 id="org1e67b01"&gt;The Timer&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org1e67b01"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;TIMER = Timer()
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org642cac4" class="outline-4"&gt;
&lt;h4 id="org642cac4"&gt;Environment&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org642cac4"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ENVIRONMENT = EnvironmentLoader()
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgdc34a77" class="outline-4"&gt;
&lt;h4 id="orgdc34a77"&gt;The Data&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgdc34a77"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;data = pandas.read_csv(Path(ENVIRONMENT["FIFA-2018"]).expanduser())
y = data["Man of the Match"] == "Yes"
FEATURES = [column for column in data.columns if data[column].dtype == numpy.int64]
X = data[FEATURES]
x_train, x_validate, y_train, y_validate = train_test_split(X, y, random_state=1)


model = RandomForestClassifier()

estimators = list(range(50, 200, 10))
max_depth = list(range(10, 100, 10)) + [None]

grid = dict(n_estimators=estimators,
	    max_depth=max_depth)
search = RandomizedSearchCV(estimator=model,
			    param_distributions=grid,
			    n_iter=40,
			    n_jobs=-1,
			    random_state=1)
with TIMER:
    search.fit(x_train, y_train)
first_model = search.best_estimator_
print(f"CV Training R^2: {search.best_score_:0.2f}")
print(f"Training R^2: {first_model.score(x_train, y_train): 0.2f}")
print(f"Validation R^2: {first_model.score(x_validate, y_validate):0.2f}")
print(search.best_params_)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
2020-02-10 18:09:33,716 graeae.timers.timer start: Started: 2020-02-10 18:09:33.716565
The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.
2020-02-10 18:09:36,830 graeae.timers.timer end: Ended: 2020-02-10 18:09:36.830883
2020-02-10 18:09:36,832 graeae.timers.timer end: Elapsed: 0:00:03.114318
CV Training R^2: 0.70
Training R^2:  1.00
Validation R^2: 0.69
{'n_estimators': 100, 'max_depth': 30}
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org99c16b4" class="outline-2"&gt;
&lt;h2 id="org99c16b4"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org99c16b4"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org25d770d" class="outline-3"&gt;
&lt;h3 id="org25d770d"&gt;A Single Row&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org25d770d"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ROW = 5
row_data = x_validate.iloc[ROW]
row_data_matrix = row_data.values.reshape(1, -1)
print(first_model.classes_)
print(first_model.predict_proba(row_data_matrix))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
[False  True]
[[0.25 0.75]]
&lt;/pre&gt;


&lt;p&gt;
The &lt;a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.predict_proba"&gt;&lt;code&gt;predict_proba&lt;/code&gt;&lt;/a&gt; method tells us the probability for the data for each class. So this team has a 70% chance that they do have a man of the match.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;explainer = shap.TreeExplainer(first_model)
shap_values = explainer.shap_values(row_data_matrix)
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;print(explainer.shap_values.__doc__)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Estimate the SHAP values for a set of samples.

       Parameters
       ----------
       X : numpy.array, pandas.DataFrame or catboost.Pool (for catboost)
           A matrix of samples (# samples x # features) on which to explain the model's output.

       y : numpy.array
           An array of label values for each sample. Used when explaining loss functions.

       tree_limit : None (default) or int
           Limit the number of trees used by the model. By default None means no use the limit of the
           original model, and -1 means no limit.

       approximate : bool
           Run fast, but only roughly approximate the Tree SHAP values. This runs a method
           previously proposed by Saabas which only considers a single feature ordering. Take care
           since this does not have the consistency guarantees of Shapley values and places too
           much weight on lower splits in the tree.

       check_additivity : bool
           Run a validation check that the sum of the SHAP values equals the output of the model. This
           check takes only a small amount of time, and will catch potential unforeseen errors.
           Note that this check only runs right now when explaining the margin of the model.

       Returns
       -------
       For models with a single output this returns a matrix of SHAP values
       (# samples x # features). Each row sums to the difference between the model output for that
       sample and the expected value of the model output (which is stored in the expected_value
       attribute of the explainer when it is constant). For models with vector outputs this returns
       a list of such matrices, one for each output.

&lt;/pre&gt;

&lt;p&gt;
The array returned by the &lt;code&gt;shap_values&lt;/code&gt; method has two rows - one for each of our target classes. In this case we're asking if a team had a man of the match so we'll just look at the second array.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;shap.initjs()
figure = shap.force_plot(explainer.expected_value[1],
			 shap_values[1],
			 row_data_matrix,
			 feature_names=FEATURES,
			 matplotlib=True, show=False)
filename = "shap_one.png"

figure.savefig(OUTPUT_PATH/filename)
print(f"[[file:{filename}]]")
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values/shap_one.png" alt="shap_one.png"&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;
Our predicted probability that this team had a man of the match was 0.7, but the base-value for the set as a whole is 0.4979 (you can't see it in this plot for some reason), so our team is more likely to have one than most teams. The pink section of the plot shows the features that increased the probability and the part in blue shows the features that decreased the probability. The size of each feature's block is proportional to the amount the feature contributed, so the biggest block (&lt;i&gt;Goal Scored&lt;/i&gt;) contributed the most. The greatest negative feature was &lt;i&gt;Ball Possession %&lt;/i&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org802e57f" class="outline-2"&gt;
&lt;h2 id="org802e57f"&gt;End&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org802e57f"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgc8998e2" class="outline-3"&gt;
&lt;h3 id="orgc8998e2"&gt;See Also&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgc8998e2"&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;The &lt;a href="https://shap.readthedocs.io/en/latest/"&gt;SHAP&lt;/a&gt; Documentation&lt;/li&gt;
&lt;li&gt;The &lt;a href="https://github.com/slundberg/shap"&gt;SHAP github repository&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Lundberg SM, Lee SI. A unified approach to interpreting model predictions. InAdvances in neural information processing systems 2017 (pp. 4765-4774). (&lt;a href="https://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predicti"&gt;PDF Available Here&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>interpret</category><category>machine learning</category><category>tutorial</category><category>visualization</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/shap-values/</guid><pubDate>Mon, 10 Feb 2020 01:07:12 GMT</pubDate></item><item><title>Exercise In Partial Dependence Plots</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/#orgafe9408"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/#org5d09e6f"&gt;Imports&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/#org4ce7c45"&gt;Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/#org13e2e90"&gt;PyPi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/#org56505e4"&gt;Others&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/#org8a9de00"&gt;Set Up&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/#orgf8162be"&gt;The Environment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/#org66421d2"&gt;The Timer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/#org8881bef"&gt;Plotting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/#orgd0cd035"&gt;The Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/#orge9acf01"&gt;Middle&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/#org90a040a"&gt;The First Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/#orgd8bcdcf"&gt;Question 1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/#org4ce1345"&gt;Question 2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/#orgadd6843"&gt;Question 3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/#org3517059"&gt;Question 4&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/#org2b98d04"&gt;Question 5&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgafe9408" class="outline-2"&gt;
&lt;h2 id="orgafe9408"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgafe9408"&gt;
&lt;p&gt;
This is my re-working of the Kaggle &lt;a href="https://www.kaggle.com/learn/machine-learning-explainability"&gt;Machine Learning Explainability&lt;/a&gt; exercise in Partial Dependece Plots. It uses data from the &lt;a href="https://www.kaggle.com/c/new-york-city-taxi-fare-prediction"&gt;Taxi Fare Prediction&lt;/a&gt; competition.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-org5d09e6f" class="outline-3"&gt;
&lt;h3 id="org5d09e6f"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org5d09e6f"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org4ce7c45" class="outline-4"&gt;
&lt;h4 id="org4ce7c45"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org4ce7c45"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from pathlib import Path
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org13e2e90" class="outline-4"&gt;
&lt;h4 id="org13e2e90"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org13e2e90"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from matplotlib import pyplot
from matplotlib.pyplot import rcParams
from pdpbox import pdp
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split, RandomizedSearchCV

import pandas
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org56505e4" class="outline-4"&gt;
&lt;h4 id="org56505e4"&gt;Others&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org56505e4"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from graeae import EnvironmentLoader, Timer
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org8a9de00" class="outline-3"&gt;
&lt;h3 id="org8a9de00"&gt;Set Up&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org8a9de00"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgf8162be" class="outline-4"&gt;
&lt;h4 id="orgf8162be"&gt;The Environment&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgf8162be"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ENVIRONMENT = EnvironmentLoader()
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org66421d2" class="outline-4"&gt;
&lt;h4 id="org66421d2"&gt;The Timer&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org66421d2"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;TIMER = Timer()
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org8881bef" class="outline-4"&gt;
&lt;h4 id="org8881bef"&gt;Plotting&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org8881bef"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;SLUG = "exercise-in-partial-dependence-plots"
OUTPUT_PATH = Path("../../files/posts/tutorials/")/SLUG

rcParams["figure.figsize"] = (6, 4)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgd0cd035" class="outline-4"&gt;
&lt;h4 id="orgd0cd035"&gt;The Data&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgd0cd035"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;ROWS = 5 * 10**4
data = pandas.read_csv(Path(ENVIRONMENT["NY-TAXI"]).expanduser()/"train.csv",
		       nrows=ROWS)
data = data.query('pickup_latitude &amp;gt; 40.7 and pickup_latitude &amp;lt; 40.8 and ' +
		  'dropoff_latitude &amp;gt; 40.7 and dropoff_latitude &amp;lt; 40.8 and ' +
		  'pickup_longitude &amp;gt; -74 and pickup_longitude &amp;lt; -73.9 and ' +
		  'dropoff_longitude &amp;gt; -74 and dropoff_longitude &amp;lt; -73.9 and ' +
		  'fare_amount &amp;gt; 0'
		  )
y = data.fare_amount
base_features = ['pickup_longitude',
		 'pickup_latitude',
		 'dropoff_longitude',
		 'dropoff_latitude']

X = data[base_features]

x_train, x_validate, y_train, y_validate = train_test_split(X, y, random_state=1)
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orge9acf01" class="outline-2"&gt;
&lt;h2 id="orge9acf01"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orge9acf01"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org90a040a" class="outline-3"&gt;
&lt;h3 id="org90a040a"&gt;The First Model&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org90a040a"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;first_model = RandomForestRegressor(n_estimators=180,
				    max_depth=50, random_state=1).fit(x_train, y_train)
print(f"Training R^2: {first_model.score(x_train, y_train):0.2f}")
print(f"Validation R^2: {first_model.score(x_validate, y_validate):0.2f}")
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Training R^2: 0.92
Validation R^2: 0.43
&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-orgd8bcdcf" class="outline-3"&gt;
&lt;h3 id="orgd8bcdcf"&gt;Question 1&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgd8bcdcf"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;FEATURE = 'pickup_longitude'
pdp_dist = pdp.pdp_isolate(model=first_model,
			   dataset=x_validate,
			   model_features=base_features,
			   feature=FEATURE)
pdp.pdp_plot(pdp_dist, FEATURE)
output = f"{FEATURE}_pdp_plot.png"
pyplot.savefig(OUTPUT_PATH/output)
print(f"[[file:{output}]]")
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
[[file:pickup_longitude_pdp_plot.png]]
&lt;/pre&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/.ob-jupyter/eb446225f180346680b332c924342792de7e5135.png" alt="eb446225f180346680b332c924342792de7e5135.png"&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;
&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/pickup_longitude_pdp_plot.png" alt="pickup_longitude_pdp_plot.png"&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/.ob-jupyter/eb446225f180346680b332c924342792de7e5135.png" alt="eb446225f180346680b332c924342792de7e5135.png"&gt;
&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;
Why does the partial dependence plot have this U-shape?
&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;
At the extremes you have the locations that can potentially travel the furthest, creating the biggest fairs, but as you move to the center you reduce the amount you can possibly travel - although the change isn't symmetric so this isn't the only explanation, otherwise if it were then you would expect the two ends to have the highest values and the nadir to be at the halfway point (-73.95).
&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;
Does your explanation suggest what shape to expect in the partial dependence plots for the other features?
&lt;/p&gt;

&lt;p&gt;
Create all other partial plots.
&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;for FEATURE in base_features:
    pdp_dist = pdp.pdp_isolate(model=first_model,
			       dataset=x_validate,
			       model_features=base_features,
			       feature=FEATURE)
    pdp.pdp_plot(pdp_dist, FEATURE)
    output = f"{FEATURE}_pdp_plot.png"
    pyplot.savefig(OUTPUT_PATH/output)
    print(f"[[file:{output}]]")
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
[[file:pickup_longitude_pdp_plot.png]]
[[file:pickup_latitude_pdp_plot.png]]
[[file:dropoff_longitude_pdp_plot.png]]
[[file:dropoff_latitude_pdp_plot.png]]
&lt;/pre&gt;

&lt;p&gt;
&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/.ob-jupyter/eb446225f180346680b332c924342792de7e5135.png" alt="eb446225f180346680b332c924342792de7e5135.png"&gt;
&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/.ob-jupyter/f2c9b641a0b8f044729d15efd208f672e3ecb7c1.png" alt="f2c9b641a0b8f044729d15efd208f672e3ecb7c1.png"&gt;
&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/.ob-jupyter/6334156ec3931ff43161785fde6f1f27a460bccd.png" alt="6334156ec3931ff43161785fde6f1f27a460bccd.png"&gt;
&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/.ob-jupyter/4417e1dcc2d023ce83c886e006ce5de690bfe97b.png" alt="4417e1dcc2d023ce83c886e006ce5de690bfe97b.png"&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/pickup_latitude_pdp_plot.png" alt="pickup_latitude_pdp_plot.png"&gt;
&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/dropoff_longitude_pdp_plot.png" alt="dropoff_longitude_pdp_plot.png"&gt;
&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/dropoff_latitude_pdp_plot.png" alt="dropoff_latitude_pdp_plot.png"&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/.ob-jupyter/eb446225f180346680b332c924342792de7e5135.png" alt="eb446225f180346680b332c924342792de7e5135.png"&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org4ce1345" class="outline-3"&gt;
&lt;h3 id="org4ce1345"&gt;Question 2&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org4ce1345"&gt;
&lt;p&gt;
Now you will run a 2D partial dependence plot.  As a reminder, here is the code from the tutorial.  
&lt;/p&gt;

&lt;p&gt;
Create a 2D plot for the features &lt;code&gt;pickup_longitude&lt;/code&gt; and &lt;code&gt;dropoff_longitude&lt;/code&gt;.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;FEATURES = "pickup_longitude dropoff_longitude".split()
interaction  =  pdp.pdp_interact(model=first_model,
				 dataset=x_validate,
				 model_features=base_features,
				 features=FEATURES)
pdp.pdp_interact_plot(pdp_interact_out=interaction,
		      feature_names=FEATURES, plot_type='contour')
output = "longitude_interaction.png"
pyplot.savefig(OUTPUT_PATH/output)
print(f"[[file:{output}]]")
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
[[file:longitude_interaction.png]]
&lt;/pre&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/.ob-jupyter/744ca56de862b725f3b5132f1c80c9bf41837026.png" alt="744ca56de862b725f3b5132f1c80c9bf41837026.png"&gt;
&lt;/p&gt;
&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/longitude_interaction.png" alt="longitude_interaction.png"&gt;
&lt;/p&gt;
&lt;/div&gt;


&lt;p&gt;
Our plot shows that the fares are highest at the top-left and bottom-right corners, as you might expect, since this would be the furthest distance from pickup to dropoff.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgadd6843" class="outline-3"&gt;
&lt;h3 id="orgadd6843"&gt;Question 3&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgadd6843"&gt;
&lt;blockquote&gt;
&lt;p&gt;
Consider a ride starting at longitude -73.92 and ending at longitude -74. Using the graph from the last question, estimate how much money the rider would have saved if they'd started the ride at longitude -73.98 instead?
&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;
I don't exactly agree with the interpretation given by the kaggle notebook. Looking at the plot, -73.92 to -74 appears to cost 27, while a -73.92 to -74 would cost 9 - but the notebook says that -73.92 to -74 costs 24. So I would say there would be a saving of 18 while the given answer is 15. To reconcile the difference (kind of) we might say that -73.92 to -74 costs 12, not 9 - it's not really easy to tell by the plot, in which case I would also say the savings is 15.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org3517059" class="outline-3"&gt;
&lt;h3 id="org3517059"&gt;Question 4&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org3517059"&gt;
&lt;blockquote&gt;
&lt;p&gt;
In the PDP's you've seen so far, location features have primarily served as a proxy to capture distance traveled. In the permutation importance lessons, you added the features `abs_lon_change` and `abs_lat_change` as a more direct measure of distance.
&lt;/p&gt;

&lt;p&gt;
Create these features again here.
&lt;/p&gt;

&lt;p&gt;
After you run it, identify the most important difference between this partial dependence plot and the one you got without absolute value features. The code to generate the PDP without absolute value features is at the top of this code cell.
&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;FEATURE = 'pickup_longitude'
pdp_dist_original = pdp.pdp_isolate(model=first_model,
				    dataset=x_validate,
				    model_features=base_features,
				    feature=FEATURE)
pdp.pdp_plot(pdp_dist_original, FEATURE)
output = "pre_distance.png"
pyplot.savefig(OUTPUT_PATH/output)
print(f"[[file:{output}]]")
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/pre_distance.png" alt="pre_distance.png"&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/.ob-jupyter/eb446225f180346680b332c924342792de7e5135.png" alt="eb446225f180346680b332c924342792de7e5135.png"&gt;
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;data['abs_lon_change'] = abs(data.pickup_longitude - data.dropoff_longitude)
data['abs_lat_change'] = abs(data.pickup_latitude - data.dropoff_longitude)

features_2  = ['pickup_longitude',
	       'pickup_latitude',
	       'dropoff_longitude',
	       'dropoff_latitude',
	       'abs_lat_change',
	       'abs_lon_change']

X = data[features_2]
new_x_train, new_x_validate, new_y_train, new_y_validate = train_test_split(X, y, random_state=1)

estimators = list(range(50, 200, 10))
max_depth = list(range(10, 100, 10)) + [None]

grid = dict(n_estimators=estimators,
	    max_depth=max_depth)

model = RandomForestRegressor()
search = RandomizedSearchCV(estimator=model,
			    param_distributions=grid,
			    n_iter=40,
			    n_jobs=-1,
			    random_state=1)
with TIMER:
    search.fit(new_x_train, new_y_train)
second_model = search.best_estimator_
print(f"CV Training R^2: {search.best_score_:0.2f}")
print(f"Training R^2: {first_model.score(x_train, y_train): 0.2f}")
print(f"Validation R^2: {first_model.score(x_validate, y_validate):0.2f}")
print(search.best_params_)
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
2020-02-09 17:36:14,915 graeae.timers.timer start: Started: 2020-02-09 17:36:14.915123
2020-02-09 17:43:16,053 graeae.timers.timer end: Ended: 2020-02-09 17:43:16.053011
2020-02-09 17:43:16,053 graeae.timers.timer end: Elapsed: 0:07:01.137888
CV Training R^2: 0.46
Training R^2:  0.92
Validation R^2: 0.43
{'n_estimators': 190, 'max_depth': 30}
&lt;/pre&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;FEATURE = 'pickup_longitude'
pdp_dist = pdp.pdp_isolate(model=second_model,
			   dataset=new_x_validate,
			   model_features=features_2,
			   feature=FEATURE)

pdp.pdp_plot(pdp_dist, FEATURE)
output = "pickup_longitude_with_distance_added.png"
pyplot.savefig(OUTPUT_PATH/output)
print(f"[[file:{output}]]")
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;
&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/pickup_longitude_with_distance_added.png" alt="pickup_longitude_with_distance_added.png"&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/.ob-jupyter/98c17657a972a412bc6d33619b6e23ee5818b884.png" alt="98c17657a972a412bc6d33619b6e23ee5818b884.png"&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org2b98d04" class="outline-3"&gt;
&lt;h3 id="org2b98d04"&gt;Question 5&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org2b98d04"&gt;
&lt;blockquote&gt;
&lt;p&gt;
Consider a scenario where you have only 2 predictive features, which we will call `feat_A` and `feat_B`. Both features have minimum values of -1 and maximum values of 1.  The partial dependence plot for `feat_A` increases steeply over its whole range, whereas the partial dependence plot for feature B increases at a slower rate (less steeply) over its whole range.
Does this guarantee that `feat_A` will have a higher permutation importance than `feat_B`.  Why or why not?
&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;
It doesn't - the partial dependence plot shows how the predictions change based on the inputs, but it isn't the same thing as the feature importance - it might be the case that a few inputs create a large difference but most points don't, in which case the feature importance won't be very large.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>interpret</category><category>machine learning</category><category>tutorial</category><category>visualization</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/exercise-in-partial-dependence-plots/</guid><pubDate>Sun, 09 Feb 2020 21:26:37 GMT</pubDate></item><item><title>Partial Dependence Plots</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/#org4813171"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/#org72819da"&gt;What is this about?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/#orgeacccb1"&gt;How does it work?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/#orga8be25d"&gt;Imports&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/#orgf2ac510"&gt;Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/#org5742226"&gt;PyPi&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/#org69f1850"&gt;Set Up&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/#org112c92b"&gt;Plotting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/#org0a75ea0"&gt;The Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/#org7373a01"&gt;Middle&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/#org8e10dcf"&gt;A Decision Tree Model&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/#org8aecdba"&gt;Visualizing the Decision Tree&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/#org0cd0c80"&gt;Partial Dependency Plot&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/#org7c424e1"&gt;Distance Covered&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/#orge217981"&gt;A Random Forest Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/#org91116bf"&gt;2D Partial Dependence Plots&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/#org6d1efb0"&gt;Forest From the Trees&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/#org337cb68"&gt;End&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org4813171" class="outline-2"&gt;
&lt;h2 id="org4813171"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org4813171"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org72819da" class="outline-3"&gt;
&lt;h3 id="org72819da"&gt;What is this about?&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org72819da"&gt;
&lt;p&gt;
These are my notes/re-write of the &lt;a href="https://www.kaggle.com/dansbecker/partial-plots"&gt;Partial Dependence Plots&lt;/a&gt; tutorial on kaggle. Partial Dependence Plots are a complement to Permutation Importance in that Permutation Importance can tell you which features are contributing to the model but don't tell you how features change with different inputs. Given that they have the word "Plot" in their name you can guess that this is a visualization method and since humans have a hard time visualizing things with more than three dimensions, using them requires selecting a subset of features (or maybe just one feature) to visualize at a time, so the fact that Permutation Importance ranks features by their contribution might come in handy in deciding which features to use.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgeacccb1" class="outline-3"&gt;
&lt;h3 id="orgeacccb1"&gt;How does it work?&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgeacccb1"&gt;
&lt;p&gt;
In a simplistic view we might say that it takes input data and then repeatedly alters the values in our feature of choice, freezing the other values so that we can see how varying the feature changes the prediction. You can then repeat this for multiple rows of data and take the average prediction for each value of our feature.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orga8be25d" class="outline-3"&gt;
&lt;h3 id="orga8be25d"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orga8be25d"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgf2ac510" class="outline-4"&gt;
&lt;h4 id="orgf2ac510"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgf2ac510"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pathlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org5742226" class="outline-4"&gt;
&lt;h4 id="org5742226"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org5742226"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;dotenv&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;load_dotenv&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;matplotlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;pyplot&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pdpbox&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;pdp&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;get_dataset&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;info_plots&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.model_selection&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.ensemble&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;RandomForestClassifier&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn.tree&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;DecisionTreeClassifier&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sklearn&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;tree&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;graphviz&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;pandas&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org69f1850" class="outline-3"&gt;
&lt;h3 id="org69f1850"&gt;Set Up&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org69f1850"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org112c92b" class="outline-4"&gt;
&lt;h4 id="org112c92b"&gt;Plotting&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org112c92b"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;SLUG&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"partial-dependence-plots"&lt;/span&gt;
&lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"../../files/posts/tutorials/"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;SLUG&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org0a75ea0" class="outline-4"&gt;
&lt;h4 id="org0a75ea0"&gt;The Data&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org0a75ea0"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"~/.env"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expanduser&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;load_dotenv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;override&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;data&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pandas&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read_csv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Path&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getenv&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"FIFA-2018"&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;expanduser&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org7373a01" class="outline-2"&gt;
&lt;h2 id="org7373a01"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org7373a01"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org8e10dcf" class="outline-3"&gt;
&lt;h3 id="org8e10dcf"&gt;A Decision Tree Model&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org8e10dcf"&gt;
&lt;p&gt;
The data is the same set from the Permutation Importance exercise (team data to predict whether one of them would become the &lt;i&gt;Budweiser Man of the Match&lt;/i&gt;). Out initial model will be a shallow decision tree so that we can compare its structure to the plots.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"Man of the Match"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;"Yes"&lt;/span&gt;
&lt;span class="n"&gt;features&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;column&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;column&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;columns&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;column&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dtype&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;numpy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int64&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;X&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_validate&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;train_test_split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;tree_model&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;DecisionTreeClassifier&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;max_depth&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;min_samples_split&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org8aecdba" class="outline-4"&gt;
&lt;h4 id="org8aecdba"&gt;Visualizing the Decision Tree&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org8aecdba"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;tree_graph&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;tree&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;export_graphviz&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tree_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;out_file&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;None&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;feature_names&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;graph&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;graphviz&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Source&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tree_graph&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"decision_tree.dot"&lt;/span&gt;
&lt;span class="n"&gt;graph&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;render&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;format&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"png"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"[[file:&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;.png]]"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/decision_tree.dot.png" alt="decision_tree.dot.png"&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org0cd0c80" class="outline-4"&gt;
&lt;h4 id="org0cd0c80"&gt;Partial Dependency Plot&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org0cd0c80"&gt;
&lt;p&gt;
To create the plot we can use the &lt;a href="https://pdpbox.readthedocs.io/en/latest/"&gt;PDPBox library&lt;/a&gt;.
&lt;/p&gt;
&lt;/div&gt;

&lt;ul class="org-ul"&gt;
&lt;li&gt;&lt;a id="org293ae7d"&gt;&lt;/a&gt;Create the Data to Plot&lt;br&gt;
&lt;div class="outline-text-5" id="text-org293ae7d"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;FEATURE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"Goal Scored"&lt;/span&gt;
&lt;span class="n"&gt;pdp_goals&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pdp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pdp_isolate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tree_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			    &lt;span class="n"&gt;model_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;feature&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;FEATURE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/li&gt;

&lt;li&gt;&lt;a id="org4cdc0d1"&gt;&lt;/a&gt;Plot It&lt;br&gt;
&lt;div class="outline-text-5" id="text-org4cdc0d1"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;pdp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pdp_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pdp_goals&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;FEATURE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"pdp_goals_scored.png"&lt;/span&gt;
&lt;span class="n"&gt;pyplot&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;savefig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"[[file:&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;]]"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/pdp_goals_scored.png" alt="pdp_goals_scored.png"&gt;
&lt;/p&gt;
&lt;/div&gt;


&lt;p&gt;
Looking at the plot we can interpret it as saying that scoring that first goal is helpful in getting someone on the team the Man of the Match, but after that, more goals doesn't help. The PDPBox documentation has no real information about interpreting the output (or anything they provide, really), but according to the Kaggle tutorial the y-axis is the change in the prediction from the baseline as x changes.
&lt;/p&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id="outline-container-org7c424e1" class="outline-4"&gt;
&lt;h4 id="org7c424e1"&gt;Distance Covered&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org7c424e1"&gt;
&lt;p&gt;
We can also look at how much the distance the players cover on the field matters.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;FEATURE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"Distance Covered (Kms)"&lt;/span&gt;
&lt;span class="n"&gt;pdp_distance&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pdp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pdp_isolate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tree_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			       &lt;span class="n"&gt;model_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;feature&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;FEATURE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;pdp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pdp_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pdp_distance&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;FEATURE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"pdp_distance.png"&lt;/span&gt;
&lt;span class="n"&gt;pyplot&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;savefig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"[[file:&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;]]"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/pdp_distance.png" alt="pdp_distance.png"&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;
It looks like there's one distance at which the probabilities increase and then going further doesn't matter.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pdp_distance&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;feature_grids&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
102.0
&lt;/pre&gt;


&lt;p&gt;
So you want your team to cover at least 102 Kilometers, but covering more won't help you.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orge217981" class="outline-3"&gt;
&lt;h3 id="orge217981"&gt;A Random Forest Model&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orge217981"&gt;
&lt;p&gt;
The Decision Tree was useful because the simplicity made it easy to interpret, but an ensemble method like a Random Forest probably makes a better model so let's see what it reveals.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;forest&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;RandomForestClassifier&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;random_state&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fit&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x_train&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_train&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;FEATURE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"Goal Scored"&lt;/span&gt;
&lt;span class="n"&gt;pdp_goals&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pdp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pdp_isolate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;forest&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			    &lt;span class="n"&gt;model_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;feature&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;FEATURE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;pdp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pdp_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pdp_goals&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;FEATURE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"pdp_forest_goals_scored.png"&lt;/span&gt;
&lt;span class="n"&gt;pyplot&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;savefig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"[[file:&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;]]"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/pdp_forest_goals_scored.png" alt="pdp_forest_goals_scored.png"&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;
So, our random forest says that the greatest gain comes from the first goal, but there is in fact a greater probability as you increase the number of goals scored.
&lt;/p&gt;

&lt;p&gt;
What about distance covered?
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;FEATURE&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"Distance Covered (Kms)"&lt;/span&gt;
&lt;span class="n"&gt;pdp_distance&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pdp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pdp_isolate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;forest&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			       &lt;span class="n"&gt;model_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;feature&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;FEATURE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;pdp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pdp_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pdp_distance&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;FEATURE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"pdp_forest_distance.png"&lt;/span&gt;
&lt;span class="n"&gt;pyplot&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;savefig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"[[file:&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;]]"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/pdp_forest_distance.png" alt="pdp_forest_distance.png"&gt;
&lt;/p&gt;
&lt;/div&gt;


&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pdp_distance&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;feature_grids&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;pdp_distance&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pdp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmax&lt;/span&gt;&lt;span class="p"&gt;()])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
102.0
&lt;/pre&gt;


&lt;p&gt;
Our forest says that, once again, covering 102 kilometers maximizes the probability, but in this case it appears that going beyond that actually decreases the probability that your team would have the man of the match.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org91116bf" class="outline-3"&gt;
&lt;h3 id="org91116bf"&gt;2D Partial Dependence Plots&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org91116bf"&gt;
&lt;p&gt;
Rather than plot a single feature against the probability of becoming the man of the match you can plot how two features interact to affect the probability.
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;FEATURES&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"Goal Scored"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"Distance Covered (Kms)"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;interaction&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pdp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pdp_interact&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;tree_model&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			       &lt;span class="n"&gt;model_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			       &lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;FEATURES&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;pdp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pdp_interact_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pdp_interact_out&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;interaction&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;feature_names&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;FEATURES&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
		      &lt;span class="n"&gt;plot_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"contour"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"goals_vs_distance.png"&lt;/span&gt;
&lt;span class="n"&gt;pyplot&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;savefig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"[[file:&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;]]"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/goals_vs_distance.png" alt="goals_vs_distance.png"&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;
&lt;b&gt;Note:&lt;/b&gt; The version of PDPBox on pypi currently has a bug (as of February 8, 2020) that won't let you create the previous plot, install it from github instead.
&lt;/p&gt;

&lt;p&gt;
The plot shows a more succinct version of the two plots we had seen before - the optimal point for these two features is 1 goal and 102 Kms covered.
&lt;/p&gt;
&lt;/div&gt;

&lt;div id="outline-container-org6d1efb0" class="outline-4"&gt;
&lt;h4 id="org6d1efb0"&gt;Forest From the Trees&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org6d1efb0"&gt;
&lt;p&gt;
Let's re-run the same plot using the Random Forest instead of the Decision Tree.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;FEATURES&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;"Goal Scored"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"Distance Covered (Kms)"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;interaction&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;pdp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pdp_interact&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;model&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;forest&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dataset&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;x_validate&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			       &lt;span class="n"&gt;model_features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
			       &lt;span class="n"&gt;features&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;FEATURES&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;pdp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pdp_interact_plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pdp_interact_out&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;interaction&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;feature_names&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;FEATURES&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
		      &lt;span class="n"&gt;plot_type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"contour"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"forest_goals_vs_distance.png"&lt;/span&gt;
&lt;span class="n"&gt;pyplot&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;savefig&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;OUTPUT_PATH&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="sa"&gt;f&lt;/span&gt;&lt;span class="s2"&gt;"[[file:&lt;/span&gt;&lt;span class="si"&gt;{&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;]]"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="figure"&gt;
&lt;p&gt;&lt;img src="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/forest_goals_vs_distance.png" alt="forest_goals_vs_distance.png"&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;
The random forest suggests a slightly different scenario - here you want 2 gooalds and between 100 and 110 Kms (or thereabouts) covered to get the best probability.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org337cb68" class="outline-2"&gt;
&lt;h2 id="org337cb68"&gt;End&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org337cb68"&gt;
&lt;p&gt;
This showed how to use the PDPBox library to create Partial Dependence Plots to look at how input values for features affects the predicted outcomes. Unfortunately it looks like PDPBox might have been abandoned, but while it works it's a nice library.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>interpret</category><category>machine learning</category><category>tutorial</category><category>visualization</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/</guid><pubDate>Sat, 08 Feb 2020 20:48:50 GMT</pubDate></item></channel></rss>