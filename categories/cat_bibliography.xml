<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Visions, Voices, Data (Posts about Bibliography)</title><link>https://necromuralist.github.io/Visions-Voices-Data/</link><description></description><atom:link href="https://necromuralist.github.io/Visions-Voices-Data/categories/cat_bibliography.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents Â© 2023 &lt;a href="mailto:cloisteredmonkey.jmark@slmail.me"&gt;Cloistered Monkey&lt;/a&gt; </copyright><lastBuildDate>Thu, 21 Dec 2023 03:29:21 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Galton, Pearson, and the Peas</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/galton-pearson-and-the-peas/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents" role="doc-toc"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents" role="doc-toc"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/galton-pearson-and-the-peas/#orgefe9a9d"&gt;Abstract Summary&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/galton-pearson-and-the-peas/#org517760d"&gt;Bullets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/galton-pearson-and-the-peas/#orge11a146"&gt;The Sweet Peas&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/galton-pearson-and-the-peas/#org182c166"&gt;Galton and Correlation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/galton-pearson-and-the-peas/#org6b667f1"&gt;Other Stuff&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/galton-pearson-and-the-peas/#org32b953b"&gt;So, what again?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/galton-pearson-and-the-peas/#org68ce29d"&gt;Source&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgefe9a9d" class="outline-2"&gt;
&lt;h2 id="orgefe9a9d"&gt;Abstract Summary&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgefe9a9d"&gt;
&lt;p&gt;
Most textbooks explain correlation before linear regression, but the publications of &lt;a href="https://en.wikipedia.org/wiki/Francis_Galton"&gt;Francis Galton&lt;/a&gt; and &lt;a href="https://en.wikipedia.org/wiki/Karl_Pearson"&gt;Karl Pearson&lt;/a&gt; indicate that Galton's work studying the inheritance of &lt;a href="https://en.wikipedia.org/wiki/Sweet_pea"&gt;sweet pea&lt;/a&gt; characteristics lead to his initial concept of linear regression first and the development of correlation and multiple regression came from later work by Galton and Pearson. So this paper gives a history of how Galton came up with linear regression which instructors can use to introduce linear regression.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org517760d" class="outline-2"&gt;
&lt;h2 id="org517760d"&gt;Bullets&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org517760d"&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;Galton came up with the concepts of linear regression and correlation (he wasn't the first, but this is about Galton and Pearson's discoveries) but Pearson developed it mathematically so it is commonly known as the &lt;a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient"&gt;Pearson Correlation Coefficient&lt;/a&gt; (or some variant of that), leading many students to think that Pearson came up with it (see also &lt;a href="https://en.wikipedia.org/wiki/Auguste_Bravais"&gt;Auguste Bravais&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;Galton's Question: How much influence does a generation have on the characteristics of the next?&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orge11a146" class="outline-2"&gt;
&lt;h2 id="orge11a146"&gt;The Sweet Peas&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orge11a146"&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;1875: Galton gave seven friends 700 sweet pea seeds. The friends planted the seeds, harvested the peas, and returned them to Galton.&lt;/li&gt;
&lt;li&gt;Galton chose sweet peas because they can self-fertilize so he didn't have to deal with the influence of two parents.&lt;/li&gt;
&lt;li&gt;Galton found that the median size of daughter seeds for each mother's seed size plotted a straight(ish) line with a positive slope less than one (0.33) - the first regression line&lt;/li&gt;
&lt;li&gt;Galton: Slope &amp;lt; 1 shows "Regression Towards Mediocrity" - daughter's sizes are closer to the mean than parent's sizes are to the mean&lt;/li&gt;
&lt;li&gt;If slope had been 1, then parent and child means were the same&lt;/li&gt;
&lt;li&gt;If slope had been horizontal, then child didn't inherit size from parent&lt;/li&gt;
&lt;li&gt;Slope between 0 and 1 meant that there was some influence from parent&lt;/li&gt;
&lt;li&gt;Since he had 700 seeds and no calculator (and maybe for other reasons too) Galton used the median and semi-interquartile range \(\left( \frac{\textrm{Inter Quartile Range}}{2} \right)\) instead of mean and deviation&lt;/li&gt;
&lt;li&gt;Galton estimated the regression line using the scatterplot, not by calculating the slope&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org182c166" class="outline-2"&gt;
&lt;h2 id="org182c166"&gt;Galton and Correlation&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org182c166"&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;If the correlation for the characteristic between the parent and child are the same for different data but the slope is different then the variance is what is causing the difference&lt;/li&gt;
&lt;li&gt;The more difference there is in the variance, the steeper the slope of the line&lt;/li&gt;
&lt;li&gt;Believed he had found that correlation between generations was a constant even for different characteristics (not something that is currently believed)&lt;/li&gt;
&lt;li&gt;Although he was wrong about the correlation being constant, thinking about it led him to develop his ideas about regression and correlation&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;
The equation he was working toward that Pearson eventually came up with was:
&lt;/p&gt;

\begin{align}
y &amp;amp;= mx \\
  &amp;amp;= \left(\frac{S_y}{S_x} \right) x
\end{align}

&lt;p&gt;
Where &lt;i&gt;r&lt;/i&gt; is the correlation between the parent and child's size, \(S_y\) is the sample standard deviation of the Daughter seed-sizes and \(S_x\) is the sample standard deviation of the Parent seed-sizes. There's a slope intercept too, but the point of it was to show how the spread for the two data variables affects the slope. The less variance there is for the daughter seeds, the smaller the slope would be (of course the same is true of the correlation, but Galton thought this was a fixed value anyway).
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org6b667f1" class="outline-2"&gt;
&lt;h2 id="org6b667f1"&gt;Other Stuff&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org6b667f1"&gt;
&lt;p&gt;
It also touches on the fact that Galton recognized that prior generations also affected the size of the daughter's seeds, giving rise to the idea of multiple regression. And there is a table of the original measurements that Galton gathered for the seeds.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org32b953b" class="outline-2"&gt;
&lt;h2 id="org32b953b"&gt;So, what again?&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org32b953b"&gt;
&lt;p&gt;
Galton's &lt;i&gt;Regression Towards Mediocrity&lt;/i&gt; - or &lt;i&gt;Regression to the Mean&lt;/i&gt; as it's more commonly referred to nowadays shows why humans don't split up into giants and little people. A person who is much larger than the mean might have a child that's also larger than the mean, but that child is likely to be closer to the mean than the parent was, just as parents that are smaller than the mean will tend to have children that are larger than they are.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org68ce29d" class="outline-2"&gt;
&lt;h2 id="org68ce29d"&gt;Source&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org68ce29d"&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;Stanton JM. Galton, Pearson, and the peas: A brief history of linear regression for statistics instructors. Journal of Statistics Education. 2001 Jan 1;9(3). (&lt;a href="http://jse.amstat.org/v9n3/stanton.html"&gt;Link&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>bibliography</category><category>history</category><category>linear regression</category><category>statistics</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/galton-pearson-and-the-peas/</guid><pubDate>Wed, 03 Mar 2021 22:59:36 GMT</pubDate></item><item><title>State Zip Code GeoJSON Repository</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/state-zip-code-geojson-repository/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="outline-container-orgee1904f" class="outline-2"&gt;
&lt;h2 id="orgee1904f"&gt;Citation&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgee1904f"&gt;
&lt;ol class="org-ol"&gt;
&lt;li&gt;GitHub - OpenDataDE/State-zip-code-GeoJSON: Zip code boundaries for each of the 50 states [Internet]. [cited 2020 Nov 20]. Available from: &lt;a href="https://github.com/OpenDataDE/State-zip-code-GeoJSON"&gt;https://github.com/OpenDataDE/State-zip-code-GeoJSON&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>citation</category><category>geojson</category><category>zip code</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/state-zip-code-geojson-repository/</guid><pubDate>Sat, 21 Nov 2020 03:06:30 GMT</pubDate></item><item><title>Secrets of Mental Math</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/secrets-of-mental-math/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="outline-container-orgaaf5b49" class="outline-2"&gt;
&lt;h2 id="orgaaf5b49"&gt;Citation&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgaaf5b49"&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;Benjamin A, Shermer M, Benjamin A, 3M Cloud Library. Secrets of mental math: the mathemagicianâs guide to lightning calculation and amazing math tricks [Internet]. Place of publication not identified: Crown Publishing Group; 2006 [cited 2020 Nov 9].&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>bibliography</category><category>math</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/secrets-of-mental-math/</guid><pubDate>Tue, 10 Nov 2020 02:07:40 GMT</pubDate></item><item><title>Bibliography for Think Complexity</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/think-complexity/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="outline-container-org20ea305" class="outline-2"&gt;
&lt;h2 id="org20ea305"&gt;Citation&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org20ea305"&gt;
&lt;ol class="org-ol"&gt;
&lt;li&gt;Downey A. Think complexity: complexity science and computational modeling. Second edition. Beijingâ¯; Boston: OâReilly; 2018. 185 p.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgf0ee734" class="outline-2"&gt;
&lt;h2 id="orgf0ee734"&gt;Comments&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgf0ee734"&gt;
&lt;p&gt;
This is a creative commons book that is for sale but is also available to read online or as a free PDF from &lt;a href="https://greenteapress.com/wp/think-complexity-2e/"&gt;Green Tea Press&lt;/a&gt;. There is also a github repository &lt;a href="https://github.com/AllenDowney/ThinkComplexity2"&gt;here&lt;/a&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>bibliography</category><category>citation</category><category>complexity</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/think-complexity/</guid><pubDate>Sat, 24 Oct 2020 02:17:59 GMT</pubDate></item><item><title>Opportunity Cost Neglect</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/opportunity-cost-neglect/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="outline-container-orgd091981" class="outline-2"&gt;
&lt;h2 id="orgd091981"&gt;Citation&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-orgd091981"&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;Frederick S, Novemsky N, Wang J, Dhar R, Nowlis S. Opportunity cost neglect. Journal of Consumer Research. 2009 Dec 1;36(4):553-61.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org337a5c4" class="outline-2"&gt;
&lt;h2 id="org337a5c4"&gt;Abstract&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org337a5c4"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org9694f62" class="outline-3"&gt;
&lt;h3 id="org9694f62"&gt;And&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org9694f62"&gt;
&lt;p&gt;
To properly consider the opportunity costs of a purchase, consumers must actively generate the alternatives that it would displace. 
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgeb77624" class="outline-3"&gt;
&lt;h3 id="orgeb77624"&gt;But&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgeb77624"&gt;
&lt;p&gt;
The current research suggests that consumers often fail to do so. Even under conditions promoting cognitive effort, various cues to consider opportunity costs reduce purchase rates and increase the choice share of more affordable options. Sensitivity to such cues varies with chronic dispositional differences in spending attitudes. 
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orga7f1009" class="outline-3"&gt;
&lt;h3 id="orga7f1009"&gt;Therefore&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orga7f1009"&gt;
&lt;p&gt;
We discuss the implications of these results for the marketing strategies of economy and premium brands.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>bibliography</category><category>opportunity cost</category><category>psychology</category><category>statistics</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/opportunity-cost-neglect/</guid><pubDate>Sun, 27 Sep 2020 01:34:45 GMT</pubDate></item><item><title>Introductory Statistics with Randomization and Simulation</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/introductory-statistics-with-randomization-and-simulation/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="outline-container-org64cd2c7" class="outline-2"&gt;
&lt;h2 id="org64cd2c7"&gt;Citation&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org64cd2c7"&gt;
&lt;ul class="org-ul"&gt;
&lt;li&gt;Diez DM, Barr CD, Ãetinkaya-Rundel M. Introductory statistics with randomization and simulation. OpenIntro.org; 2014. 348 p.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>bibliography</category><category>simulation</category><category>statistics</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/introductory-statistics-with-randomization-and-simulation/</guid><pubDate>Tue, 22 Sep 2020 23:53:36 GMT</pubDate></item></channel></rss>