<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Visions, Voices, Data (Posts about web-scraping)</title><link>https://necromuralist.github.io/Visions-Voices-Data/</link><description></description><atom:link href="https://necromuralist.github.io/Visions-Voices-Data/categories/cat_web-scraping.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents Â© 2019 &lt;a href="mailto:necromuralist@protonmail.com"&gt;Cloistered Monkey&lt;/a&gt; </copyright><lastBuildDate>Sat, 03 Aug 2019 19:41:48 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Web Scraping Assignment 1</title><link>https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/</link><dc:creator>Cloistered Monkey</dc:creator><description>&lt;div id="table-of-contents"&gt;
&lt;h2&gt;Table of Contents&lt;/h2&gt;
&lt;div id="text-table-of-contents"&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#org352760d"&gt;Beginning&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#orgfe04f84"&gt;Imports&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#orge2145f2"&gt;Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#org04feb6f"&gt;PyPi&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#orgaa63aee"&gt;Setup&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#org640bff9"&gt;The URLs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#org4102cd8"&gt;The Expected&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#org0ba3141"&gt;Middle&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#org284d163"&gt;The Sample&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#org143fc40"&gt;The Way I Would Do It&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#org6b8841a"&gt;The Assignment Way&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#org2e101c6"&gt;The Assignment&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#orgd60f7b6"&gt;Requests HTML&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#org9d4bed2"&gt;Urllib&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/#org772756e"&gt;End&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org352760d" class="outline-2"&gt;
&lt;h2 id="org352760d"&gt;Beginning&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org352760d"&gt;
&lt;p&gt;
The goal of this exercise is to find all the &lt;code&gt;&amp;lt;span&amp;gt;&lt;/code&gt; tags on a page and sum the numbers they contain.
&lt;/p&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgfe04f84" class="outline-3"&gt;
&lt;h3 id="orgfe04f84"&gt;Imports&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgfe04f84"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orge2145f2" class="outline-4"&gt;
&lt;h4 id="orge2145f2"&gt;Python&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orge2145f2"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;import urllib
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org04feb6f" class="outline-4"&gt;
&lt;h4 id="org04feb6f"&gt;PyPi&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org04feb6f"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;from bs4 import BeautifulSoup
from expects import (
    equal,
    expect,
    be_true,
)
from requests_html import HTMLSession
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgaa63aee" class="outline-3"&gt;
&lt;h3 id="orgaa63aee"&gt;Setup&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-orgaa63aee"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org640bff9" class="outline-4"&gt;
&lt;h4 id="org640bff9"&gt;The URLs&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org640bff9"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;SAMPLE_URL = " http://py4e-data.dr-chuck.net/comments_42.html"
ACTUAL_URL = "http://py4e-data.dr-chuck.net/comments_260442.html"
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org4102cd8" class="outline-4"&gt;
&lt;h4 id="org4102cd8"&gt;The Expected&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org4102cd8"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;SAMPLE_EXPECTED = 2553
ACTUAL_EXPECTED_LAST_DIGIT = 5
&lt;/pre&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org0ba3141" class="outline-2"&gt;
&lt;h2 id="org0ba3141"&gt;Middle&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org0ba3141"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org284d163" class="outline-3"&gt;
&lt;h3 id="org284d163"&gt;The Sample&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org284d163"&gt;
&lt;/div&gt;
&lt;div id="outline-container-org143fc40" class="outline-4"&gt;
&lt;h4 id="org143fc40"&gt;The Way I Would Do It&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org143fc40"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def using_requests(url: str) -&amp;gt; int:
    """get the span total

    Args:
     url: The URL for the page

    Returns:
     the total sum
    """
    session = HTMLSession()
    response = session.get(url)
    expect(response.ok).to(be_true)
    total = 0

    for count, span in enumerate(response.html.find("span")):
	total += int(span.text)

    print(f"Count: {count + 1}")
    print(f"Sum: {total}")
    return total
&lt;/pre&gt;&lt;/div&gt;

&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;total = using_requests(SAMPLE_URL)
expect(total).to(equal(SAMPLE_EXPECTED))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Count: 50
Sum: 2553

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org6b8841a" class="outline-4"&gt;
&lt;h4 id="org6b8841a"&gt;The Assignment Way&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org6b8841a"&gt;
&lt;p&gt;
For this kind of thing, using urllib isn't really much more work, I'm used to the older python 2 version which (maybe only seemed at the time) was more complicated to use.
&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;def using_urllib(url: str) -&amp;gt; int:
    """get the span total with urllib and beautiful soup

    Args:
     url: the URL for the page

    Returns:
     the total of the span contents
    """
    response = urllib.request.urlopen(url)
    soup = BeautifulSoup(response.read(), "html.parser")
    total = 0
    for count, span in enumerate(soup.find_all("span")):
	total += int(span.text)

    print(f"Count: {count + 1}")
    print(f"Sum: {total}")
    return total
&lt;/pre&gt;&lt;/div&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;total = using_urllib(SAMPLE_URL)
expect(total).to(equal(SAMPLE_EXPECTED))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Count: 50
Sum: 2553

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org2e101c6" class="outline-3"&gt;
&lt;h3 id="org2e101c6"&gt;The Assignment&lt;/h3&gt;
&lt;div class="outline-text-3" id="text-org2e101c6"&gt;
&lt;/div&gt;
&lt;div id="outline-container-orgd60f7b6" class="outline-4"&gt;
&lt;h4 id="orgd60f7b6"&gt;Requests HTML&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-orgd60f7b6"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;total = using_requests(ACTUAL_URL)
expect(int(str(total)[-1])).to(equal(ACTUAL_EXPECTED_LAST_DIGIT))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Count: 50
Sum: 2305

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id="outline-container-org9d4bed2" class="outline-4"&gt;
&lt;h4 id="org9d4bed2"&gt;Urllib&lt;/h4&gt;
&lt;div class="outline-text-4" id="text-org9d4bed2"&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;total = using_urllib(ACTUAL_URL)
expect(int(str(total)[-1])).to(equal(ACTUAL_EXPECTED_LAST_DIGIT))
&lt;/pre&gt;&lt;/div&gt;

&lt;pre class="example"&gt;
Count: 50
Sum: 2305

&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

&lt;div id="outline-container-org772756e" class="outline-2"&gt;
&lt;h2 id="org772756e"&gt;End&lt;/h2&gt;
&lt;div class="outline-text-2" id="text-org772756e"&gt;
&lt;p&gt;
Although I normally use &lt;code&gt;requests&lt;/code&gt; or &lt;code&gt;requests-html&lt;/code&gt;, I must say that the &lt;code&gt;urllib&lt;/code&gt; version with &lt;a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/"&gt;BeautifulSoup&lt;/a&gt; for this particular exercise wasn't much different.
&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;</description><category>web-scraping</category><guid>https://necromuralist.github.io/Visions-Voices-Data/posts/web-scraping/web-scraping-assignment-1/</guid><pubDate>Sat, 03 Aug 2019 19:07:56 GMT</pubDate></item></channel></rss>