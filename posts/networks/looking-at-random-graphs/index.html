<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content="Looking at random graphs." name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>Looking at random graphs | Visions, Voices, Data</title>
<link href="../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="../../../rss.xml" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/looking-at-random-graphs/" rel="canonical"><!--[if lt IE 9]><script src="../../../assets/js/html5.js"></script><![endif]-->
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script><!--
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/0.9.0/p5.min.js"
</script>
-->
<script async src="../../../assets/javascript/p5.min.js" type="text/javascript"></script>
<meta content="Cloistered Monkey" name="author">
<link href="/posts/networks/selecting-the-e-mail-model/" rel="prev" title="Selecting the E-Mail Model" type="text/html">
<link href="/posts/notes/the-origin-of-bayes-theorem/" rel="next" title="The Origin of Bayes Theorem" type="text/html">
<meta content="Visions, Voices, Data" property="og:site_name">
<meta content="Looking at random graphs" property="og:title">
<meta content="https://necromuralist.github.io/Visions-Voices-Data/posts/networks/looking-at-random-graphs/" property="og:url">
<meta content="Looking at random graphs." property="og:description">
<meta content="article" property="og:type">
<meta content="2019-04-13T11:59:44-07:00" property="article:published_time">
<meta content="networks" property="article:tag">
<meta content="random graphs" property="article:tag">
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="https://necromuralist.github.io/Visions-Voices-Data/"><span id="blog-title">Visions, Voices, Data</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="/archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="/categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="/rss.xml">RSS feed</a></li>
<li class="nav-item dropdown"><a aria-expanded="false" aria-haspopup="true" class="nav-link dropdown-toggle" data-toggle="dropdown" href="#">Pages</a>
<div class="dropdown-menu"><a class="dropdown-item" href="https://necromuralist.github.io/">Cloistered Monkey</a> <a class="dropdown-item" href="/pages/giss/giss-yearly-anomalies-by-climate-zone">GISS Anomalies</a></div>
</li>
</ul>
<!-- DuckDuckGo custom search -->
<form action="https://duckduckgo.com/" class="navbar-form pull-left" id="search" method="get" name="search"><input name="sites" type="hidden" value="https://necromuralist.github.io/Visions-Voices-Data/"> <input name="k8" type="hidden" value="#444444"> <input name="k9" type="hidden" value="#D51920"> <input name="kt" type="hidden" value="h"> <input class="span2" maxlength="255" name="q" placeholder="Search…" type="text"> <input style="visibility: hidden;display:none" type="submit" value="DuckDuckGo Search"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right">
<li class="nav-item"><a class="nav-link" href="/posts/networks/looking-at-random-graphs/index.org" id="sourcelink">Source</a></li>
</ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title" itemprop="headline name"><a class="u-url" href="/posts/networks/looking-at-random-graphs/">Looking at random graphs</a></h1>
<div class="metadata">
<p class="byline author vcard"><span class="byline-name fn" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="/posts/networks/looking-at-random-graphs/" rel="bookmark"><time class="published dt-published" datetime="2019-04-13T11:59:44-07:00" itemprop="datePublished" title="2019-04-13 11:59">2019-04-13 11:59</time></a></p>
<p class="sourceline"><a class="sourcelink" href="/posts/networks/looking-at-random-graphs/index.org">Source</a></p>
</div>
</header>
<div class="e-content entry-content" itemprop="articleBody text">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="/posts/networks/looking-at-random-graphs/#org1b898cf">Imports</a></li>
<li><a href="/posts/networks/looking-at-random-graphs/#org74a2156">Part 1 - Random Graph Identification</a>
<ul>
<li><a href="/posts/networks/looking-at-random-graphs/#orgc3de31c">Load the data</a></li>
<li><a href="/posts/networks/looking-at-random-graphs/#orged95f0b">Graph Identification</a></li>
</ul>
</li>
<li><a href="/posts/networks/looking-at-random-graphs/#orgc875065">Part 2 - Company Emails</a>
<ul>
<li><a href="/posts/networks/looking-at-random-graphs/#org6e75e0f">Part 2A - Salary Prediction</a></li>
<li><a href="/posts/networks/looking-at-random-graphs/#org55cad8d">Part 2B - New Connections Prediction</a></li>
<li><a href="/posts/networks/looking-at-random-graphs/#orgb3ef176">Separate the Target and Training Sets</a></li>
<li><a href="/posts/networks/looking-at-random-graphs/#orgad08b9a">Scaling the Data</a></li>
<li><a href="/posts/networks/looking-at-random-graphs/#org8ac5901">Feature Selection</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org1b898cf">
<h2 id="org1b898cf">Imports</h2>
<div class="outline-text-2" id="text-org1b898cf">
<div class="highlight">
<pre><span></span># python standard library
import os
import pickle

# from pypi
import networkx
import numpy
import pandas

from sklearn.linear_model import LogisticRegressionCV
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import (
    ExtraTreesClassifier,
    RandomForestClassifier,
    )
from sklearn.feature_selection import (
    RFECV,
    SelectFromModel,
)
from sklearn.model_selection import (
    GridSearchCV,
    StratifiedKFold,
    train_test_split,
    )
</pre></div>
<div class="highlight">
<pre><span></span>% matplotlib inline
</pre></div>
</div>
</div>
<div class="outline-2" id="outline-container-org74a2156">
<h2 id="org74a2156">Part 1 - Random Graph Identification</h2>
<div class="outline-text-2" id="text-org74a2156">
<p>For the first part of this assignment you will analyze randomly generated graphs and determine which algorithm created them.</p>
</div>
<div class="outline-3" id="outline-container-orgc3de31c">
<h3 id="orgc3de31c">Load the data</h3>
<div class="outline-text-3" id="text-orgc3de31c">
<div class="highlight">
<pre><span></span>part_one_graphs = pickle.load(open('A4_graphs','rb'))
print(len(part_one_graphs))
print(type(part_one_graphs[0]))
</pre></div>
<p><code>part_one_graphs</code> is a list containing 5 networkx graphs. Each of these graphs were generated by one of three possible algorithms:</p>
<ul class="org-ul">
<li>Preferential Attachment (`'PA'`)</li>
<li>Small World with low probability of rewiring (`'SW<sub>L</sub>'`)</li>
<li>Small World with high probability of rewiring (`'SW<sub>H</sub>'`)</li>
</ul>
<p>Analyze each of the 5 graphs and determine which of the three algorithms generated the graph.</p>
<p><b>The `graph<sub>identification</sub>` function should return a list of length 5 where each element in the list is either `'PA'`, `'SW<sub>L</sub>'`, or `'SW<sub>H</sub>'`.</b></p>
</div>
</div>
<div class="outline-3" id="outline-container-orged95f0b">
<h3 id="orged95f0b">Graph Identification</h3>
<div class="outline-text-3" id="text-orged95f0b">
<div class="highlight">
<pre><span></span>def graph_identification():
    """Identifies the type of graph each of the graphs is

    Returns:
     list: string identifiers for the type of graph
    """
    graph_types = []
    for graph in part_one_graphs:
        path = networkx.average_shortest_path_length(graph)
        coefficient = networkx.average_clustering(graph)
        if path &gt; 6:
            if coefficient &lt; 0.5:
                graph_types.append("SW_L")
            else:
                raise Exception("unexpected type")
        else:
            if coefficient &lt; 0.5:
                graph_types.append("PA")
            else:
                graph_types.append("SW_H")
    return graph_types
</pre></div>
<p>This was marked wrong by the grader.</p>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgc875065">
<h2 id="orgc875065">Part 2 - Company Emails</h2>
<div class="outline-text-2" id="text-orgc875065">
<p>For the second part of this assignment you will be working with a company's email network where each node corresponds to a person at the company, and each edge indicates that at least one email has been sent between two people.</p>
<p>The network also contains the node attributes `Department` and `ManagementSalary`.</p>
<p>`Department` indicates the department in the company which the person belongs to, and `ManagementSalary` indicates whether that person is receiving a managment position salary.</p>
<div class="highlight">
<pre><span></span>email = networkx.read_gpickle('email_prediction.txt')
print(networkx.info(email))
</pre></div>
</div>
<div class="outline-3" id="outline-container-org6e75e0f">
<h3 id="org6e75e0f">Part 2A - Salary Prediction</h3>
<div class="outline-text-3" id="text-org6e75e0f">
<p>Using network `email`, identify the people in the network with missing values for the node attribute `ManagementSalary` and predict whether or not these individuals are receiving a managment position salary.</p>
<p>To accomplish this, you will need to create a matrix of node features using networkx, train a sklearn classifier on nodes that have `ManagementSalary` data, and predict a probability of the node receiving a managment salary for nodes where `ManagementSalary` is missing.</p>
<p>Your predictions will need to be given as the probability that the corresponding employee is receiving a managment position salary.</p>
<p>The evaluation metric for this assignment is the Area Under the ROC Curve (AUC).</p>
<p>Your grade will be based on the AUC score computed for your classifier. A model which with an AUC of 0.75 or higher will receive full points.</p>
<p>Using your trained classifier, return a series of length 252 with the data being the probability of receiving managment salary, and the index being the node id.</p>
<pre class="example">
1       1.0
2       0.0
5       0.8
8       1.0
    ...
996     0.7
1000    0.5
1001    0.0
Length: 252, dtype: float64
</pre></div>
<div class="outline-4" id="outline-container-org233ab2e">
<h4 id="org233ab2e">The Data Frame</h4>
<div class="outline-text-4" id="text-org233ab2e">
<div class="highlight">
<pre><span></span>if not os.path.isfile("email_data.h5"):
    data = pandas.DataFrame(index=email.nodes())
    data["department"] = pandas.Series(networkx.get_node_attributes(email, "Department"))
    data["management"] = pandas.Series(networkx.get_node_attributes(email, "ManagementSalary"))
    data["clustering"] = pandas.Series(networkx.clustering(email))
    data["degree"] = pandas.Series(email.degree())
    data["degree_centrality"] = pandas.Series(networkx.degree_centrality(email))
    data["closeness_centrality"] = pandas.Series(networkx.closeness_centrality(email))
    data["betweenness_centrality"] = pandas.Series(networkx.betweenness_centrality(email))
    data["pagerank"] = pandas.Series(networkx.pagerank(email))
    _, authority = networkx.hits(email)
    data["authority"] = pandas.Series(authority)
    data.to_hdf("email_data.h5","df" )
else:
    data = pandas.read_hdf('email_data.h5', "df")
print(data.head())    
</pre></div>
<div class="highlight">
<pre><span></span>print(data.management.unique())
print(data.department.unique())
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org4e3aa18">
<h4 id="org4e3aa18">Department Dummy Variables</h4>
<div class="outline-text-4" id="text-org4e3aa18">
<p>Even though I don't think it's going to prove useful, the <code>department</code> feature is actually categorical, despite the use of integers so we'll have to use One-Hot-Encoding to add dummy variables for it.</p>
<div class="highlight">
<pre><span></span>dummies_data = pandas.get_dummies(data, columns=["department"])
print(dummies_data.head(1))
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org62645a2">
<h4 id="org62645a2">Separating the Training and Prediction Sets</h4>
<div class="outline-text-4" id="text-org62645a2">
<p>We're going to use the model to predict what the missing <code>management</code> values are so I'm going to separate the missing and non-missing sets.</p>
<div class="highlight">
<pre><span></span>training_data = dummies_data[pandas.notnull(dummies_data.management)]
prediction_data = dummies_data[pandas.isnull(dummies_data.management)]
print(training_data.shape)
print(prediction_data.shape)
</pre></div>
<p>The problem description tells us that the answer should have 252 entries so this is a safe assertion.</p>
<div class="highlight">
<pre><span></span>assert len(prediction_data) == 252
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org8500437">
<h4 id="org8500437">Training and Target Data</h4>
<div class="outline-text-4" id="text-org8500437">
<p>To train the model we'll need to separate out the <code>management</code> column (and remove it entirely from the <code>prediction</code> set).</p>
<div class="highlight">
<pre><span></span>non_management = [column for column in training_data.columns if column != "management"]
y_train = training_data.management
x_train = training_data[non_management]
x_predict = prediction_data[non_management]
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org68cbaf5">
<h4 id="org68cbaf5">Scaling</h4>
<div class="outline-text-4" id="text-org68cbaf5">
<p>I don't think the Random Forest model that I'm going to use needs it, but I'm going to standardize the data.</p>
<div class="highlight">
<pre><span></span>scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_predict = pandas.DataFrame(scaler.transform(x_predict), index=x_predict.index)
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org1a136ba">
<h4 id="org1a136ba">Feature Selection</h4>
<div class="outline-text-4" id="text-org1a136ba">
<p>Since we now have so many features, I'm going to do some feature selection.</p>
<div class="highlight">
<pre><span></span>print(x_train.shape)
print(x_predict.shape)
trees = ExtraTreesClassifier(n_estimators=10)
eliminator = RFECV(estimator=trees, cv=StratifiedKFold(10), scoring="roc_auc")
eliminator.fit(x_train, y_train)
x_train_reduced = eliminator.transform(x_train)
x_predict_reduced = pandas.DataFrame(eliminator.transform(x_predict), index=x_predict.index)
print(x_train_reduced.shape)
print(x_predict_reduced.shape)
</pre></div>
<p>When I used the train-test-split training model it left 17 columns. I wonder if using the whole training set messes it up.</p>
</div>
</div>
<div class="outline-4" id="outline-container-org671a17a">
<h4 id="org671a17a">Logistic Regression</h4>
<div class="outline-text-4" id="text-org671a17a">
<div class="highlight">
<pre><span></span>model = LogisticRegressionCV(penalty="l1", scoring="roc_auc",
                             solver="liblinear", cv=StratifiedKFold(10))
model.fit(x_train_reduced, y_train)
print(model.scores_[1.0].mean())
print(model.scores_[1.0].std())
</pre></div>
<p>It seems to be doing much worse than when I used the train-test split.</p>
</div>
</div>
<div class="outline-4" id="outline-container-orgf4a25a4">
<h4 id="orgf4a25a4">Random Forests</h4>
<div class="outline-text-4" id="text-orgf4a25a4">
<div class="highlight">
<pre><span></span>parameter_grid = dict(n_estimators=range(10, 100, 10))
search = GridSearchCV(RandomForestClassifier(), parameter_grid,
                      cv=StratifiedKFold(10), scoring="roc_auc")
search.fit(x_train_reduced, y_train)
print(search.best_score_)
</pre></div>
<div class="highlight">
<pre><span></span>class RandomForest(object):
    """builds the random forest

    Args:
     x_train(array): data to train on
     y_train(array): targets for training
     start (int): start value for number of estimators
     stop (int): upper value for range of estimators
     step (int): increment for range of estimators
     folds (int): K-folds for cross-validation    
    """
    def __init__(self, x_train, y_train,
                 start=10, stop=100, step=10, folds=10):
        self.x_train = x_train
        self.y_train = y_train
        self.start = start
        self.stop = stop
        self.step = step
        self.folds = folds
        self._parameters = None
        self._search = None
        self._model = None
        return

    @property
    def parameters(self):
        """parameters for the grid-search"""
        if self._parameters is None:
            self._parameters = dict(n_estimators=range(self.start,
                                                       self.stop,
                                                       self.step))
        return self._parameters

    @property
    def search(self):
        """fitted grid search to find hyper-parameters"""
        if self._search is None:
            self._search = GridSearchCV(RandomForestClassifier(),
                                        self.parameters,
                                        cv=StratifiedKFold(self.folds),
                                        scoring="roc_auc")
            self._search.fit(self.x_train, self.y_train)
        return self._search

    @property
    def model(self):
        """best model found by the grid search"""
        if self._model is None:
            self._model = self.search.best_estimator_
        return self._model
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org139c2a7">
<h4 id="org139c2a7">Data Loader</h4>
<div class="outline-text-4" id="text-org139c2a7">
<p>Since having all these org-babel things around makes things kind of hard I'm going to make a class to bundle everything together.</p>
<div class="highlight">
<pre><span></span>class DataLoader(object):
    """loads and transforms the data
    Args:
     estimators (int): number of trees to use for feature elimination
    """
    def __init__(self, estimators=10):
        self.estimators = estimators
        self._data = None
        self._dummies_data = None
        self._training_data = None
        self._prediction_data = None
        self._non_management = None
        self._y_train = None
        self._x_train = None
        self._x_predict = None
        self._scaler = None
        self._x_train_scaled = None
        self._x_predict_scaled = None
        self._eliminator = None
        self._x_train_reduced = None
        self._x_predict_reduced = None
        return

    @property
    def data(self):
        """The initial data"""
        if self._data is None:
            if not os.path.isfile("email_data.h5"):
                data = pandas.DataFrame(index=email.nodes())
                data["department"] = pandas.Series(networkx.get_node_attributes(email, "Department"))
                data["management"] = pandas.Series(networkx.get_node_attributes(email, "ManagementSalary"))
                data["clustering"] = pandas.Series(networkx.clustering(email))
                data["degree"] = pandas.Series(email.degree())
                data["degree_centrality"] = pandas.Series(networkx.degree_centrality(email))
                data["closeness_centrality"] = pandas.Series(networkx.closeness_centrality(email))
                data["betweenness_centrality"] = pandas.Series(networkx.betweenness_centrality(email))
                data["pagerank"] = pandas.Series(networkx.pagerank(email))
                _, authority = networkx.hits(email)
                data["authority"] = pandas.Series(authority)
                data.to_hdf("email_data.h5","df" )
                self._data = data
            else:
                self._data = pandas.read_hdf('email_data.h5', "df")
        return self._data

    @property
    def dummies_data(self):
        """one-hot-encoded data"""
        if self._dummies_data is None:
            self._dummies_data = pandas.get_dummies(self.data, columns=["department"])
        return self._dummies_data

    @property
    def training_data(self):
        """data with management information"""
        if self._training_data is None:
            self._training_data = self.dummies_data[pandas.notnull(
                self.dummies_data.management)]
        return self._training_data

    @property
    def prediction_data(self):
        """data missing management information"""
        if self._prediction_data is None:
            self._prediction_data = self.dummies_data[pandas.isnull(
                self.dummies_data.management)]
            assert len(self._prediction_data) == 252
        return self._prediction_data

    @property
    def non_management(self):
        """list of columns minus management"""
        if self._non_management is None:
            self._non_management = [
                column for column in self.training_data.columns
                if column != "management"]
        return self._non_management

    @property
    def y_train(self):
        """target-data for training"""
        if self._y_train is None:
            self._y_train = self.training_data.management
        return self._y_train

    @property
    def x_train(self):
        """data for training"""
        if self._x_train is None:
            self._x_train = self.training_data[self.non_management]
        return self._x_train

    @property
    def x_predict(self):
        """set to make predictions"""
        if self._x_predict is None:
            self._x_predict = self.prediction_data[self.non_management]
        return self._x_predict

    @property
    def scaler(self):
        """standard scaler"""
        if self._scaler is None:
            self._scaler = StandardScaler()
        return self._scaler

    @property
    def x_train_scaled(self):
        """training data scaled to 1 std, 0 mean"""
        if self._x_train_scaled is None:
            self._x_train_scaled = self.scaler.fit_transform(self.x_train)
        return self._x_train_scaled

    @property
    def x_predict_scaled(self):
        """prediction data with mean 0, std 1

        The answer requires the index so this is a dataframe
        instead of an array

        Returns:
         pandas.DataFrame: scaled data with index preserved
        """
        if self._x_predict_scaled is None:
            self._x_predict_scaled = pandas.DataFrame(
                self.scaler.transform(self.x_predict),
                index=self.x_predict.index)
        return self._x_predict_scaled

    @property
    def eliminator(self):
        """recursive feature eliminator"""
        if self._eliminator is None:
            trees = ExtraTreesClassifier(n_estimators=10)
            self._eliminator = RFECV(estimator=trees, cv=StratifiedKFold(10), 
                                     scoring="roc_auc")
            self._eliminator.fit(self.x_train_scaled, self.y_train)
        return self._eliminator

    @property
    def x_train_reduced(self):
        """training data with features eliminated"""
        if self._x_train_reduced is None:
            self._x_train_reduced = self.eliminator.transform(
                self.x_train_scaled)
        return self._x_train_reduced

    @property
    def x_predict_reduced(self):
        """prediction data with features eliminated"""
        if self._x_predict_reduced is None:
            self._x_predict_reduced = pandas.DataFrame(
                self.eliminator.transform(self.x_predict_scaled),
                index=self.x_predict_scaled.index)
        return self._x_predict_reduced
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org05e74ea">
<h4 id="org05e74ea">Submission</h4>
<div class="outline-text-4" id="text-org05e74ea">
<div class="highlight">
<pre><span></span>def salary_predictions():
    """Prediction that employee is management

    Calculates the probability that an employee is management

    Returns:
     pandas.Series: Node ID, probability of node
    """
    data = DataLoader()
    forest = RandomForest(data.x_train_reduced, data.y_train)
    # probabilites is an array with rows of 
    # [&lt;probability not management&gt;, &lt;probability management&gt;]
    # see forest.model.classes_ to see what each entry represents
    probabilities = forest.model.predict_proba(data.x_predict_reduced)
    return pandas.Series(probabilities[:, 1], index=data.x_predict_reduced.index)
</pre></div>
<div class="highlight">
<pre><span></span>output = salary_predictions()
print(output.head())
</pre></div>
<div class="highlight">
<pre><span></span>assert all(output.index == DataLoader().prediction_data.index)
assert len(output) == 252
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org55cad8d">
<h3 id="org55cad8d">Part 2B - New Connections Prediction</h3>
<div class="outline-text-3" id="text-org55cad8d">
<p>For the last part of this assignment, you will predict future connections between employees of the network. The future connections information has been loaded into the variable `future<sub>connections</sub>`. The index is a tuple indicating a pair of nodes that currently do not have a connection, and the `Future Connection` column indicates if an edge between those two nodes will exist in the future, where a value of 1.0 indicates a future connection.</p>
<div class="highlight">
<pre><span></span>future_connections = pandas.read_csv('Future_Connections.csv', index_col=0, converters={0: eval})
</pre></div>
<div class="highlight">
<pre><span></span>print(future_connections.head(10))
</pre></div>
<div class="highlight">
<pre><span></span>print(future_connections['Future Connection'].value_counts())
</pre></div>
<p>Using network `G` and `future<sub>connections</sub>`, identify the edges in `future<sub>connections</sub>` with missing values and predict whether or not these edges will have a future connection.</p>
<p>To accomplish this, you will need to create a matrix of features for the edges found in `future<sub>connections</sub>` using networkx, train a sklearn classifier on those edges in `future<sub>connections</sub>` that have `Future Connection` data, and predict a probability of the edge being a future connection for those edges in `future<sub>connections</sub>` where `Future Connection` is missing.</p>
<p>Your predictions will need to be given as the probability of the corresponding edge being a future connection.</p>
<p>The evaluation metric for this assignment is the Area Under the ROC Curve (AUC).</p>
<p>Your grade will be based on the AUC score computed for your classifier. A model which with an AUC of 0.75 or higher will receive full points.</p>
<p>Using your trained classifier, return a series of length 122112 with the data being the probability of the edge being a future connection, and the index being the edge as represented by a tuple of nodes.</p>
<pre class="example">
(107, 348)    0.35
(542, 751)    0.40
(20, 426)     0.55
(50, 989)     0.35
          ...
(939, 940)    0.15
(555, 905)    0.35
(75, 101)     0.65
Length: 122112, dtype: float64
</pre></div>
<div class="outline-4" id="outline-container-orgdefe904">
<h4 id="orgdefe904">Add Network Features</h4>
<div class="outline-text-4" id="text-orgdefe904">
<div class="highlight">
<pre><span></span>class Futures(object):
    target = "Future Connection"
    data_file = "Future_Connections.csv"
    graph_file = "email_prediction.txt"
    networkx_data_index = 2
    folds = 10
</pre></div>
<div class="highlight">
<pre><span></span>class DataNames(object):
    resource_allocation = 'resource_allocation'
    jaccard = 'jaccard_coefficient'
    adamic = "adamic_adar"
    preferential = "preferential_attachment"
</pre></div>
<div class="highlight">
<pre><span></span>def add_networkx_data(adder, name, graph=email, frame=future_connections):
    """Adds networkx data to the frame

    The networkx link-prediction functions return generators of triples:
     (first-node, second-node, value)

    This will use the index of the frame that's passed in as the source of 
    node-pairs for the networkx function (called `ebunch` in the networkx
    documentation) and the add only the value we want back to the frame

    Args:
     adder: networkx function to call to get the new data
     name: column-name to add to the frame
     graph: networkx graph to pass to the function
     frame (pandas.DataFrame): frame with node-pairs as index to add data to
    """
    frame[name] = [output[Futures.networkx_data_index]
                   for output in adder(graph, frame.index)]
    return frame
</pre></div>
</div>
<div class="outline-5" id="outline-container-orgc4ca998">
<h5 id="orgc4ca998">Adding A Resource Allocation Index</h5>
<div class="outline-text-5" id="text-orgc4ca998">
<div class="highlight">
<pre><span></span>add_networkx_data(networkx.resource_allocation_index,
                  DataNames.resource_allocation)
</pre></div>
<div class="highlight">
<pre><span></span>print(future_connections.head(1))
</pre></div>
</div>
</div>
<div class="outline-5" id="outline-container-org58f379f">
<h5 id="org58f379f">Adding the Jaccard Coefficient</h5>
<div class="outline-text-5" id="text-org58f379f">
<div class="highlight">
<pre><span></span>add_networkx_data(networkx.jaccard_coefficient, DataNames.jaccard)
</pre></div>
<div class="highlight">
<pre><span></span>print(future_connections.head(1))
</pre></div>
</div>
</div>
<div class="outline-5" id="outline-container-org92d86da">
<h5 id="org92d86da">Adamic Adar</h5>
<div class="outline-text-5" id="text-org92d86da">
<div class="highlight">
<pre><span></span>add_networkx_data(networkx.adamic_adar_index, DataNames.adamic)
</pre></div>
<div class="highlight">
<pre><span></span>print(future_connections.head(1))
</pre></div>
</div>
</div>
<div class="outline-5" id="outline-container-org3e4025c">
<h5 id="org3e4025c">Preferential Attachment</h5>
<div class="outline-text-5" id="text-org3e4025c">
<div class="highlight">
<pre><span></span>add_networkx_data(networkx.preferential_attachment, DataNames.preferential)
</pre></div>
<div class="highlight">
<pre><span></span>print(future_connections.head(1))
</pre></div>
</div>
</div>
</div>
<div class="outline-4" id="outline-container-orgc16d60b">
<h4 id="orgc16d60b">Setup the Training and Testing Data</h4>
<div class="outline-text-4" id="text-orgc16d60b"></div>
<div class="outline-5" id="outline-container-org1c3a250">
<h5 id="org1c3a250">Separating the Edges Without 'Future Connection' Values</h5>
<div class="outline-text-5" id="text-org1c3a250">
<p>We are going to train on the values in the data with predictions and then make predictions for those that don't.</p>
<div class="highlight">
<pre><span></span>prediction_set = future_connections[future_connections[Futures.target].isnull()]
training_set = future_connections[future_connections[Futures.target].notnull()]
</pre></div>
<div class="highlight">
<pre><span></span>print(prediction_set.shape)
print(training_set.shape)
assert len(prediction_set) + len(training_set) == len(future_connections)
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orgb3ef176">
<h3 id="orgb3ef176">Separate the Target and Training Sets</h3>
<div class="outline-text-3" id="text-orgb3ef176">
<div class="highlight">
<pre><span></span>non_target = [column for column in future_connections.columns
              if column != Futures.target]
x_train = training_set[non_target]
y_train = training_set[Futures.target]
x_predict = prediction_set[non_target]
</pre></div>
<div class="highlight">
<pre><span></span>assert all(x_train.columns == x_predict.columns)
assert len(x_train) == len(x_test)
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgad08b9a">
<h3 id="orgad08b9a">Scaling the Data</h3>
<div class="outline-text-3" id="text-orgad08b9a">
<p>To enable the use of linear models I'm going to scale the data so the mean is 0 and the variance is 1.</p>
<div class="highlight">
<pre><span></span>scaler = StandardScaler()
x_train_scaled = scaler.fit_transform(x_train)
x_predict_scaled = scaler.transform(x_predict)

x_train_frame = pandas.DataFrame(x_train_scaled, columns=x_train.columns)
x_predict_frame = pandas.DataFrame(x_predict_scaled, columns=x_predict.columns)
</pre></div>
<div class="highlight">
<pre><span></span>print(training.describe())
print(predictions.describe())
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org8ac5901">
<h3 id="org8ac5901">Feature Selection</h3>
<div class="outline-text-3" id="text-org8ac5901">
<p>To reduce the dimensionality I'm going to use model-based selection with Extra Trees.</p>
<div class="highlight">
<pre><span></span>estimator = ExtraTreesClassifier()
estimator.fit(x_train_scaled, y_train)
selector = SelectFromModel(estimator, prefit=True)
x_train_trees_sfm = selector.transform(x_train_scaled)
x_predict_sfm = selector.transform(x_predict_scaled)
print(estimator.feature_importances_)
</pre></div>
<div class="highlight">
<pre><span></span>print(x_train_trees_sfm.shape)
</pre></div>
</div>
<div class="outline-4" id="outline-container-org46db689">
<h4 id="org46db689">Missing Future Connections</h4>
<div class="outline-text-4" id="text-org46db689">
<div class="highlight">
<pre><span></span>model = LogisticRegressionCV(n_jobs=-1, scoring='roc_auc', solver='liblinear',
                             cv=StratifiedKFold())
model.fit(x_train_trees_sfm, y_train)
</pre></div>
<div class="highlight">
<pre><span></span>for scores in model.scores_[1.0]:
    print(max(scores))
</pre></div>
<div class="highlight">
<pre><span></span>print(model.classes_)
</pre></div>
<div class="highlight">
<pre><span></span>def new_connections_predictions():    
    probabilities = model.predict_proba(x_predict_sfm)
    return pandas.Series(probabilities[:, 1], index=prediction_set.index)
</pre></div>
<div class="highlight">
<pre><span></span>outcome = new_connections_predictions()
assert len(outcome) == 122112, len(outcome)
print(outcome.head())
</pre></div>
</div>
</div>
</div>
</div>
</div>
<aside class="postpromonav">
<nav>
<ul class="tags" itemprop="keywords">
<li><a class="tag p-category" href="/categories/networks/" rel="tag">networks</a></li>
<li><a class="tag p-category" href="/categories/random-graphs/" rel="tag">random graphs</a></li>
</ul>
<ul class="pager hidden-print">
<li class="previous"><a href="/posts/networks/selecting-the-e-mail-model/" rel="prev" title="Selecting the E-Mail Model">Previous post</a></li>
<li class="next"><a href="/posts/notes/the-origin-of-bayes-theorem/" rel="next" title="The Origin of Bayes Theorem">Next post</a></li>
</ul>
</nav>
</aside>
</article>
<!--End of body content-->
<footer id="footer">Contents © 2019 <a href="mailto:necromuralist@protonmail.com">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a></footer>
</div>
</div>
<script src="/assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
</script> 
</body>
</html>
