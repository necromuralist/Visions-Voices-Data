#+BEGIN_COMMENT
.. title: Kaggle On Time-Series Visualization
.. slug: kaggle-on-time-series-visualization
.. date: 2019-01-20 13:12:55 UTC-08:00
.. tags: kaggle,tutorial,time-series
.. category: Time Series
.. link: 
.. description: Walking in the footsteps of the Kaggle notebook on visualizing time-series data.
.. type: text

#+END_COMMENT
#+OPTIONS: ^:{}
#+TOC: headlines 3
#+BEGIN_SRC python :session kaggle :results none :exports none
%load_ext autoreload
%autoreload 2
#+END_SRC
* Introduction
  This is a walk-through of the kaggle notebook on [[https://www.kaggle.com/residentmario/time-series-plotting-optional][Time-Series Plotting]] by Aleksey Bilogur.
* Set Up
** Imports
*** From Python
#+BEGIN_SRC python :session kaggle :results none
from datetime import datetime
from functools import partial
from pathlib import Path
import os
#+END_SRC
*** From PyPi
#+BEGIN_SRC python :session kaggle :results none
from dotenv import load_dotenv
from bokeh.io.doc import curdoc
from bokeh.models import CrosshairTool, HoverTool
from bokeh.themes import Theme
from bokeh.palettes import Category20
from holoviews import opts
from holoviews.plotting.links import RangeToolLink
from hvplot import hvPlot
from pandas.plotting import autocorrelation_plot, lag_plot
from tabulate import tabulate
import holoviews
import matplotlib
import matplotlib.pyplot as pyplot
import pandas
import seaborn
#+END_SRC
*** My Projects
#+begin_src python :session kaggle :results none
from bartleby_the_penguin.tangles.embed_bokeh import EmbedBokeh
from graeae.tables import CountPercentage
#+end_src
** Plotting
#+BEGIN_SRC python :session kaggle :results none
get_ipython().run_line_magic('matplotlib', 'inline')
get_ipython().run_line_magic('config', "InlineBackend.figure_format = 'retina'")
seaborn.set(style="whitegrid",
            rc={"axes.grid": False,
                "font.family": ["sans-serif"],
                "font.sans-serif": ["Open Sans", "Latin Modern Sans", "Lato"],
                "figure.figsize": (8, 6)},
            font_scale=1)
#+END_SRC
*** Holoviews Backend
#+begin_src python :session kaggle :results none
holoviews.extension("bokeh")
#+end_src
*** Bokeh
#+BEGIN_SRC python :session kaggle :results none
class Plots:
    width = 1100
    height = 600
    font = "Open Sans"
    font_size = "24pt"
    line_width = 3
    tools =  ["hover"]
    blue = seaborn.color_palette()[0]
    light_blue = Category20[3][1]
    red = seaborn.color_palette()[3]
    yellow = seaborn.color_palette()[1]
    green = seaborn.color_palette()[2]
    gray = seaborn.color_palette()[7]

theme = Theme(json={
    "attrs": {
        "Figure": {
            "text_font": "Open Sans",
            "text_font_size": "18pt",
            "line_color": Category20[3][0],
            "plot_width": Plots.width,
            "plot_height": Plots.height,
            "tools": ["pan", "zoom_in", "hover", "reset"],
        },
        "Title": {
            "text_font_style": "bold",
        },
    },
})
curdoc().theme = theme
#+END_SRC

** Setup Libraries
#+BEGIN_SRC python :session kaggle :results none
load_dotenv()
table = partial(tabulate, headers="keys", tablefmt="orgtbl")
kaggle_path = Path(os.environ.get("KAGGLE")).expanduser()
assert kaggle_path.is_dir()
#+END_SRC

** The Embedder
#+begin_src python :session kaggle :results none
Embed = partial(
    EmbedBokeh, 
    folder_path="../../files/posts/tutorials/kaggle-on-time-series-visualization/")
#+end_src
* The Data
** New York Stock Exchange Prices
#+BEGIN_SRC python :session kaggle :results none
nyse_path = kaggle_path.joinpath("nyse/prices.csv")
assert nyse_path.is_file()
nyse = pandas.read_csv(nyse_path, parse_dates=["date"])
#+END_SRC

#+BEGIN_SRC python :session kaggle :results output :exports both
nyse.info()
#+END_SRC

#+RESULTS:
#+begin_example
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 851264 entries, 0 to 851263
Data columns (total 7 columns):
date      851264 non-null datetime64[ns]
symbol    851264 non-null object
open      851264 non-null float64
close     851264 non-null float64
low       851264 non-null float64
high      851264 non-null float64
volume    851264 non-null float64
dtypes: datetime64[ns](1), float64(5), object(1)
memory usage: 45.5+ MB
#+end_example

#+BEGIN_SRC python :session kaggle :results output raw :exports both
nyse = nyse.set_index("date")
print(table(nyse.head()))
#+END_SRC

#+RESULTS:
| date                | symbol |   open |  close |    low |   high |     volume |
|---------------------+--------+--------+--------+--------+--------+------------|
| 2016-01-05 00:00:00 | WLTW   | 123.43 | 125.84 | 122.31 | 126.25 | 2.1636e+06 |
| 2016-01-06 00:00:00 | WLTW   | 125.24 | 119.98 | 119.94 | 125.54 | 2.3864e+06 |
| 2016-01-07 00:00:00 | WLTW   | 116.38 | 114.95 | 114.93 | 119.74 | 2.4895e+06 |
| 2016-01-08 00:00:00 | WLTW   | 115.48 | 116.62 |  113.5 | 117.44 | 2.0063e+06 |
| 2016-01-11 00:00:00 | WLTW   | 117.01 | 114.97 | 114.09 | 117.33 | 1.4086e+06 |

The notebook describes this as an example of a "strong" date case because the dates act as an explicit index for the data and are, in this case, an aggregate for a day of trading.

*** UPS
   Some of the correlational plots don't show anything meaningful when you use the market as a whole (I guess because different stocks are moving in different directions) so I'm going to pull out the UPS stock information to use later.

#+BEGIN_SRC python :session kaggle :results output :exports both
ups = nyse[nyse.symbol=="UPS"]
print(ups.shape)
#+END_SRC

#+RESULTS:
: (1762, 6)

** Shelter Outcomes
#+BEGIN_SRC python :session kaggle :results none
shelter_path = kaggle_path.joinpath(
    "austin-animal-center-shelter-outcomes/aac_shelter_outcomes.csv")
assert shelter_path.is_file()
shelter = pandas.read_csv(shelter_path, parse_dates=["datetime", "date_of_birth"])
#+END_SRC

#+BEGIN_SRC python :session kaggle :results output :exports both
shelter.info()
#+END_SRC

#+RESULTS:
#+begin_example
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 78256 entries, 0 to 78255
Data columns (total 12 columns):
age_upon_outcome    78248 non-null object
animal_id           78256 non-null object
animal_type         78256 non-null object
breed               78256 non-null object
color               78256 non-null object
date_of_birth       78256 non-null datetime64[ns]
datetime            78256 non-null datetime64[ns]
monthyear           78256 non-null object
name                54370 non-null object
outcome_subtype     35963 non-null object
outcome_type        78244 non-null object
sex_upon_outcome    78254 non-null object
dtypes: datetime64[ns](2), object(10)
memory usage: 7.2+ MB
#+end_example

Some of the columns are only identifiers (like a name) so we'll drop them to make it easier to inspect the data (although we aren't really going to do anything with it here anyway).

#+BEGIN_SRC python :session kaggle :results output raw :exports both
shelter = shelter[["outcome_type", "age_upon_outcome", "datetime",
                   "animal_type", "breed", "color", "sex_upon_outcome",
                   "date_of_birth"]]
print(table(shelter.head(), showindex=False))
#+END_SRC

#+RESULTS:
| outcome_type | age_upon_outcome | datetime            | animal_type | breed                   | color        | sex_upon_outcome | date_of_birth       |
|--------------+------------------+---------------------+-------------+-------------------------+--------------+------------------+---------------------|
| Transfer     | 2 weeks          | 2014-07-22 16:04:00 | Cat         | Domestic Shorthair Mix  | Orange Tabby | Intact Male      | 2014-07-07 00:00:00 |
| Transfer     | 1 year           | 2013-11-07 11:47:00 | Dog         | Beagle Mix              | White/Brown  | Spayed Female    | 2012-11-06 00:00:00 |
| Adoption     | 1 year           | 2014-06-03 14:20:00 | Dog         | Pit Bull                | Blue/White   | Neutered Male    | 2013-03-31 00:00:00 |
| Transfer     | 9 years          | 2014-06-15 15:50:00 | Dog         | Miniature Schnauzer Mix | White        | Neutered Male    | 2005-06-02 00:00:00 |
| Euthanasia   | 5 months         | 2014-07-07 14:04:00 | Other       | Bat Mix                 | Brown        | Unknown          | 2014-01-07 00:00:00 |

The notebook describes this as an example of a "weak" date case because the dates are only there for record-keeping and, while they might be significant for modeling, aren't acting as an index for the records.
** Cryptocurrency
#+BEGIN_SRC python :session kaggle :results none
currency_path = kaggle_path.joinpath("all-crypto-currencies/crypto-markets.csv")
assert currency_path.is_file()
currency = pandas.read_csv(currency_path, parse_dates=["date"])
currency = currency.set_index("date")
#+END_SRC

#+begin_src python :session kaggle :results output raw :exports both
print(table(currency.head(), showindex=True))
#+end_src

#+RESULTS:
| date                | slug    | symbol | name    | ranknow |   open |   high |    low |  close | volume |      market | close_ratio | spread |
|---------------------+---------+--------+---------+---------+--------+--------+--------+--------+--------+-------------+-------------+--------|
| 2013-04-28 00:00:00 | bitcoin | BTC    | Bitcoin |       1 |  135.3 | 135.98 |  132.1 | 134.21 |      0 | 1.48857e+09 |      0.5438 |   3.88 |
| 2013-04-29 00:00:00 | bitcoin | BTC    | Bitcoin |       1 | 134.44 | 147.49 |    134 | 144.54 |      0 | 1.60377e+09 |      0.7813 |  13.49 |
| 2013-04-30 00:00:00 | bitcoin | BTC    | Bitcoin |       1 |    144 | 146.93 | 134.05 |    139 |      0 | 1.54281e+09 |      0.3843 |  12.88 |
| 2013-05-01 00:00:00 | bitcoin | BTC    | Bitcoin |       1 |    139 | 139.89 | 107.72 | 116.99 |      0 | 1.29895e+09 |      0.2882 |  32.17 |
| 2013-05-02 00:00:00 | bitcoin | BTC    | Bitcoin |       1 | 116.38 |  125.6 |  92.28 | 105.21 |      0 | 1.16852e+09 |      0.3881 |  33.32 |

* Grouping
** Birth Dates
*** Per Date
   Here's a plot of the birth dates of the animals in the shelter.

#+BEGIN_SRC python :session kaggle :results none
births = shelter.date_of_birth.value_counts()
births_peak = births.idxmax()
births = births.reset_index().sort_values(by="index")
births.columns = ["birth_date", "Births"]
#+END_SRC

#+BEGIN_SRC python :session kaggle :results output raw :exports both
hover = HoverTool(
tooltips=[
    ("Date", "@birth_date{%Y-%m-%d}"),
    ("Births", "@Births{0,0}"),
],
    formatters= {"birth_date": "datetime", 
                 "Births": "numeral"},
    mode="vline",
)
line = holoviews.VLine(births_peak)
curve = holoviews.Curve(
    births, ("birth_date", "Date of Birth"), "Births",
)

main = curve.relabel("Count of Births By Date").opts(labelled=["y"], 
                                                     tools=[hover], 
                                                     height=Plots.height, 
                                                     ylabel="Births", 
                                                     xaxis=None)
range_finder = curve.opts(height=100, yaxis=None, default_tools=[], 
                          xlabel="Birth Dates")

link = RangeToolLink(range_finder, main)

combination = (main * line + range_finder * line)

layout = combination.opts(
    opts.Layout(shared_axes=False, merge_tools=False, fontsize=Plots.font_size),
    opts.Curve(width=Plots.width, 
               color=Category20[3][0], 
               fontsize=Plots.font_size,
               line_width=Plots.line_width),
    opts.VLine(color=Plots.red, line_dash="dotted")
).cols(1)
Embed(layout, "shelter_births")()
#+END_SRC

#+RESULTS:
#+begin_export html
<script src="shelter_births.js" id="d1793db5-32ff-47c4-ba11-83d1393fd041"></script>
#+end_export

It lools like there was an upward trend until about 2016 when it started to taper off, but since we're counting by days there's a lot of variance so we're going to group the data using pandas' [[https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.resample.html][resample]] method.

#+begin_quote
*Note:* One interesting problem I found is that unless I zoom in I can't get my mouse to trigger the hover-tool for the day with the greatest value (May 5, 2014).
#+end_quote

There's a couple of different ways to do the grouping of the days, but the simplest way is to take the count for each date using [[https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.value_counts.html][value_counts]]. This will leave us with a [[https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html][Series]] with the dates in the index and the counts as values. Once we have this we can aggregate the dates by year and then count how many births there were per year.

*** By Year
First I'll get the counts for each day using =value_counts= and print off the first values to see what it looks like. Calling =reset_index= changes the Series to a DataFrame with the dates as a column.

#+BEGIN_SRC python :session kaggle :results output raw :exports both
counts = shelter.date_of_birth.value_counts()
print(table(counts.head().reset_index(), showindex=False))
#+END_SRC

#+RESULTS:
| index               | date_of_birth |
|---------------------+---------------|
| 2014-05-05 00:00:00 |           112 |
| 2015-09-01 00:00:00 |           110 |
| 2014-04-21 00:00:00 |           105 |
| 2015-04-28 00:00:00 |           104 |
| 2016-05-01 00:00:00 |           102 |

Now we can aggregate the birth-counts by year using [[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.resample.html][resample]].

#+BEGIN_SRC python :session kaggle :results output :exports both
year_counts = counts.resample("Y")
print(year_counts)
#+END_SRC

#+RESULTS:
: DatetimeIndexResampler [freq=<YearEnd: month=12>, axis=0, closed=right, label=right, convention=start, base=0]

#+begin_quote
Note that this is a grouper, we don't get what we want until we call a method (like =count=) on it. In this case since we have value counts we want to sum all of the counts for a year (so we need =sum=).
#+end_quote

Now I'm going to aggregate the yearly counts using the =sum= method.
#+BEGIN_SRC python :session kaggle :results none
sums = year_counts.sum()
#+END_SRC

Calling =sum= gives us a Series with the dates in the index and the sums as the values.

#+BEGIN_SRC python :session kaggle :results output :exports both
print(sums.head())
#+END_SRC

#+RESULTS:
: 1991-12-31    1
: 1992-12-31    1
: 1993-12-31    1
: 1994-12-31    9
: 1995-12-31    7
: Freq: A-DEC, Name: date_of_birth, dtype: int64

The [[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.idxmax.html][=idxmax=]] method gives us the index of the greatest value and since the dates are in the index, using it will give us the date of the year with the most births, which I'll call =sum_peak=.
#+begin_src python :session kaggle :results none
sum_peak = sums.idxmax()
#+END_SRC

As you may have noticed, all the dates are set for December 31, but for plotting it's better to have them set to January 1 so I'll set it here and do a some other cleanup.

#+begin_src python :session kaggle :results none
sums = sums.reset_index()
sums.columns = ["birth_date", "Births"]
sum_peak = datetime(sum_peak.year, 1, 1)
sums["birth_date"] = sums.birth_date.apply(lambda date: datetime(date.year, 1, 1))
#+END_SRC

And now for the plot.

**** The Tools
First set up the tools

#+begin_src python :session kaggle :results none
hover = HoverTool(
tooltips=[
    ("Year", "@birth_date{%Y}"),
    ("Births", "@Births{0,0}"),
],
    formatters= {"birth_date": "datetime", 
                 "Births": "numeral"},
    mode="vline",
)
#+end_src

**** The Plot Parts
Now I'll create our plotting objects.

The vertical line will mark the peak year.
#+begin_src python :session kaggle :results none
line = holoviews.VLine(sum_peak, label=sum_peak.strftime("%Y"))
#+end_src

And I'm going to add an annotation to it.

#+begin_src python :session kaggle :results none
x = datetime(sum_peak.year, 3, 1)
text = holoviews.Text(x, sums.max()[1]/4,
                      "Max Year: {}".format(sum_peak.year), 
                      halign="left")
#+end_src

Now our data-curve.

#+begin_src python :session kaggle :results none
curve = holoviews.Curve(
    sums, ("birth_date", "Date of Birth"), "Births",
)
#+end_src

Next I'll make two copies of the curve - =main= will be the larger curve and =range_finder= will 
create a plot below it to let us select a range of dates which get linked using the =RangeToolLink=.

#+begin_src python :session kaggle :results none
main = curve.relabel("Births Per Year (1991- 2017)").opts(
    labelled=["y"], 
    tools=[hover], 
    xaxis=None,
    ylabel="Births",
    height=Plots.height)
range_finder = curve.opts(height=100, yaxis=None, 
                          default_tools=[],
                          xlabel="Year")

link = RangeToolLink(range_finder, main)
#+end_src

Now combine the parts to make our visible plot.

#+begin_src python :session kaggle :results none
combination = (line * main * text + line * range_finder)
#+end_src

This next bit is to set some styling on the plot.
**** The Options
#+begin_src python :session kaggle :results none
layout = combination.opts(
    opts.Layout(shared_axes=False, merge_tools=False, fontsize=Plots.font_size),
    opts.Curve(width=Plots.width, 
               color=Plots.blue,
               padding=0.01,
               fontsize=Plots.font_size, 
               line_width=Plots.line_width),
    opts.VLine(color=Plots.red, line_dash="dotted")
).cols(1)
#+end_src
**** Embed
Finally, create the javascript and embed it in this notebook.

#+BEGIN_SRC python :session kaggle :results output raw :exports both
Embed(layout, "shelter_births_per_year")()
#+END_SRC

#+RESULTS:
#+begin_export html
<script src="shelter_births_per_year.js" id="108235f3-e4fc-4afa-b724-a53c18323b6f"></script>
#+end_export

*** Lollipop Plot
An alternative way to look at this would be a lollipop plot.

#+BEGIN_SRC python :session kaggle :results output raw :exports both
# The Tools
hover = HoverTool(
tooltips=[
    ("Year", "@birth_date{%Y}"),
    ("Births", "@Births{0,0}"),
],
    formatters= {"birth_date": "datetime", 
                 "Births": "numeral"},
    mode="vline",
)

# The Parts
line = holoviews.VLine(sum_peak, label=peak.strftime("%Y"))
spikes = holoviews.Spikes(sums, ("birth_date", "Date of Birth"), "Births")
circles = holoviews.Scatter(sums, "birth_date", "Births")

# The Range Finder
main = circles.relabel().opts(
    labelled=["y"], 
    tools=[hover], 
    xaxis=None,
    ylabel="Births",
    height=Plots.height,
    size=10,
    padding=(0, (0, 0.1)))
range_finder = circles.opts(height=100, 
                            yaxis=None, 
                            default_tools=[],
                            size=5,
                            fontsize={"ticks": "14pt"},
                            xlabel="Year of Birth")

link = RangeToolLink(range_finder, main)

# The Layout
combination = (spikes * line * main + spikes * line * range_finder)

# The Styling Options
layout = combination.opts(
    opts.Layout(shared_axes=False, 
                merge_tools=False,
                title="Shelter Animal Births Per Year (1991- 2017)",
                show_title=True,
                fontsize=Plots.font_size),
    opts.Spikes(width=Plots.width, 
                color=Plots.red, 
                fontsize=Plots.font_size,
                line_width=Plots.line_width),
    opts.Scatter(color=Plots.blue, fontsize={"ticks": "14pt"}, legend_position="left"),
    opts.VLine(color=Plots.green),
).cols(1)

# The HTML and Javascript
Embed(layout, "births_per_year_spikes")()
#+END_SRC

#+RESULTS:
#+begin_export html
<script src="births_per_year_spikes.js" id="479c8e63-eba4-439f-946b-5a087796c709"></script>
#+end_export

#+begin_quote
Note that putting the title in the Layout changes the font. I was trying to set it to Open Sans but HoloViews is horribly documented for most things so I couldn't figure out how to do it.
#+end_quote
** Animal Shelter Outcomes
   While knowing the birthdates of the animals in the shelter is interesting, what about the dates when their cases were resolved? I originally called this /Animal Shelter Adoptions/ but "outcome" doesn't always mean "adopted", unfortunately.

#+BEGIN_SRC python :session kaggle :results output raw :exports both
CountPercentage(shelter.outcome_type)()
#+END_SRC

#+RESULTS:
| Value           | Count | Percentage |
|-----------------+-------+------------|
| Adoption        | 33112 |      42.32 |
| Transfer        | 23499 |      30.03 |
| Return to Owner | 14354 |      18.35 |
| Euthanasia      |  6080 |       7.77 |
| Died            |   680 |       0.87 |
| Disposal        |   307 |       0.39 |
| Rto-Adopt       |   150 |       0.19 |
| Missing         |    46 |       0.06 |
| Relocate        |    16 |       0.02 |

I don't know what /Disposal/ means, but it doesn't sound good. Neither does /Missing/, really, especially if there are any restaurants nearby. Anyway, on to the plotting. I'll aggregate the outcome-counts by year.

#+BEGIN_SRC python :session kaggle :results output raw :exports both
outcome_counts = shelter.datetime.value_counts()
outcomes = outcome_counts.resample("Y").sum()
print(table(outcome_counts.head().reset_index(), showindex=False))
outcomes = outcomes.reset_index()
outcomes.columns = ["date", "count"]
outcomes["date"] = outcomes.date.apply(lambda date: datetime(date.year, 1, 1))
#+END_SRC

#+RESULTS:
| index               | datetime |
|---------------------+----------|
| 2016-04-18 00:00:00 |       39 |
| 2015-08-11 00:00:00 |       25 |
| 2017-10-17 00:00:00 |       25 |
| 2015-11-17 00:00:00 |       22 |
| 2015-07-02 00:00:00 |       22 |

This next part isn't really necessary but I think keeping the names consistent is helpful, especially since I was struggling so much with HoloViews and didn't need the extra confusion about column-names being wrong.

#+BEGIN_SRC python :session kaggle :results none
sums = sums.rename(columns=dict(birth_date="date", Births="count"))
#+END_SRC

This is going to be like the previous plot but I'm going to add a crosshair tool to make it easier to see how things line up with the axis.

#+BEGIN_SRC python :session kaggle :results output raw :exports both
# The Tools
hover = HoverTool(
tooltips=[
    ("Year", "@date{%Y}"),
    ("Count", "@count{0,0}"),
],
    formatters= {"date": "datetime", 
                 "count": "numeral"},
    mode="vline",
)
crosshairs = CrosshairTool(line_color=Plots.light_blue)

# The Parts
births = holoviews.Scatter(sums, "date", "count", label="Births")
outcome_circles = holoviews.Scatter(outcomes, "date", "count", 
                                    group="outcome", label="Outcomes")
spikes = holoviews.Spikes(outcomes, ("date", 'Year'), ("count", "Count"), 
                          group="outcome")

# The Layout
combination = spikes * outcome_circles * births

# The Styling
layout = combination.opts(
    opts.Layout(shared_axes=False,
                height=Plots.height,
                merge_tools=False,
                show_title=True,
                fontsize=Plots.font_size),
    opts.Spikes(width=Plots.width, 
                height=Plots.height,
                title="Shelter Animal Births vs Outcomes Per Year",
                show_title=True,
                fontsize=Plots.font_size,
                padding=(0, (0, .1)),
                color=Plots.blue,
                line_width=Plots.line_width),
    opts.Scatter("outcome", color=Plots.blue, size=10, legend_position="top_left"),
    opts.Scatter(fontsize={"ticks": "14pt"}, color=Plots.red, size=10, 
                 tools=[hover, crosshairs]),
)

# The HTML
Embed(layout, "outcome_lollipops")()
#+END_SRC

#+RESULTS:
#+begin_export html
<script src="outcome_lollipops.js" id="6ca452e8-d318-45b0-bd37-b3ed8d32fe8b"></script>
#+end_export

You can see that there are only six years of adoption outcomes although there are sixteen years of birth dates, with a sudden uptick to the peak year of 2014. It's interesting that the births drop off much faster than the outcomes - the animals seemed to be getting older for some reason.

** Trading Volume
   
The previous plot was a count-plot. You can also use other summary-statistics like a mean to see how things changed over time. I'll plot the mean volume per year for the New York Stock Exchange.

#+begin_src python :session kaggle :results none
volume = nyse.volume.resample("Y")
means = volume.mean().reset_index()
means["date"] = means.date.apply(lambda date: datetime(date.year, 1, 1))
#+end_src

Along with the standard deviations.

#+begin_src python :session kaggle :results none
deviations = volume.std().reset_index()
means["two_sigma"] = means.volume + 2 * deviations.volume
#+end_src

And now our plot.

#+BEGIN_SRC python :session kaggle :results output raw :exports both
# The Tools
hover = HoverTool(
tooltips=[
    ("Year", "@date{%Y}"),
    ("Volume", "@volume{0,0.00}"),
],
    formatters= {"date": "datetime", 
                 "volume": "numeral",
    },
    mode="vline",
)

# The Parts
top_spread = holoviews.ErrorBars((means.date, means.volume, means.two_sigma),
                              group="volume")

volume_curve = holoviews.Curve(means, 
                               ("date", "Year"), 
                               ("volume", "Volume"), 
                               group="volume")

zero_line = holoviews.HLine(0)

# The Layout
layout = volume_curve * top_spread * zero_line

# The Styling
layout = layout.opts(
    opts.Layout(shared_axes=False,
                height=Plots.height,
                merge_tools=False,
                show_title=True,
                fontsize=Plots.font_size),
    opts.Curve(width=Plots.width, 
               height=Plots.height,
               title="Mean NYSE Trading Volume Per Year",
               show_title=True,
               fontsize=Plots.font_size,
               padding=(0, (0, .1)),
               color=Plots.blue,
               line_width=Plots.line_width,
               tools=[hover]),
    opts.HLine(line_color=Plots.gray)
)

# The HTML
Embed(layout, "stock_mean_volume")()
#+END_SRC

#+RESULTS:
#+begin_export html
<script src="stock_mean_volume.js" id="7e7ad56b-bc40-47f2-81df-211c792cc2aa"></script>
#+end_export

While the standard deviation is important, in this case it's so large that it smashes the mean down flat (although maybe the fact that it's so large tells us that the mean isn't so accurate).

#+BEGIN_SRC python :session kaggle :results output raw :exports both
hover = HoverTool(
tooltips=[
    ("Year", "@date{%Y}"),
    ("Volume", "@volume{0,0.00}"),
],
    formatters= {"date": "datetime", 
                 "volume": "numeral"},
    mode="vline",
)

volume_circles = holoviews.Scatter(means, "date", "volume")
volume_spikes = holoviews.Spikes(means, ("date", "Date"), 
                                 ("volume", "Volume"))
combination = volume_spikes * volume_circles
crosshairs = CrosshairTool(line_color=Plots.light_blue, dimensions="height")

layout = combination.opts(
    opts.Layout(shared_axes=False,
                height=Plots.height,
                merge_tools=False,
                show_title=True,
                fontsize=Plots.font_size),
    opts.Spikes(width=Plots.width, 
                height=Plots.height,
                title="NYSE Mean Annual Trading Volume",
                show_title=True,
                fontsize=Plots.font_size,
                padding=(0, (0, .1)),
                color=Plots.blue,
                line_width=Plots.line_width),
    opts.Scatter(color=Plots.blue,
                 size=10, 
                 tools=[hover, crosshairs]),
)
Embed(layout, "stock_lollipops")()
#+END_SRC

#+RESULTS:
#+begin_export html
<script src="stock_lollipops.js" id="188e1b48-71ce-4867-925f-a3c183fbcd8a"></script>
#+end_export

#+begin_quote
I took the cross-hairs out of the plot with the standard deviations but it was (a little) more helpful for the lollipop plots because you have to be directly above the points to trigger the hover tool, whereas you can be above any part of a segment in the =Curve= plot and it triggers the hover tool.
#+end_quote
* Lag Plots
  The [[https://pandas.pydata.org/pandas-docs/stable/visualization.html#lag-plot][Lag Plot]] helps you check if there is a significance to the ordering of the data. You are plotting the value in the inputs vs the next value (e.g. one day against the following day). If there is no significance to the ordering then the plot will look random.
** NYSE
   The =lag_plot= function isn't one of the DataFrame methods so I don't think it will work with HoloViews, although I haven't tried yet.
#+BEGIN_SRC python :session kaggle :results none
volume = nyse.volume.resample("D")
#+END_SRC

#+BEGIN_SRC python :session kaggle :results raw drawer :ipyfile ../../files/posts/tutorials/kaggle-on-time-series-visualization/lag_plot.png
figure, axe = pyplot.subplots()
figure.suptitle("NYSE Volume Lag Plot", weight="bold")
subplot = lag_plot(volume.sum().tail(365), ax=axe)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[249]:
[[file:../../files/posts/tutorials/kaggle-on-time-series-visualization/lag_plot.png]]
:END:

[[file:lag_plot.png]]

So, the center points do seem to show a relationship, as the next-days volume goes up along with the previous day's volume, but I don't know what those bands around 0 are. One thing I noticed is that there are holidays in the data.

#+BEGIN_SRC python :session kaggle :results output :exports both
print(volume.sum().index[-6])
#+END_SRC

#+RESULTS:
: 2016-12-25 00:00:00

And there are also weekends in there.

#+BEGIN_SRC python :session kaggle :results output :exports both
print(volume.sum().index[-13].strftime("%a"))
#+END_SRC

#+RESULTS:
: Sun

So it's likely that there are days in there where there was no trading and so they won't correlate with the days that preceded the start of a break or the ones that followed the end of a break. I think. I don't really know if there's trading all year round.

#+BEGIN_SRC python :session kaggle :results output :exports both
volume_sums = volume.sum()
for day in volume_sums[volume_sums==0][-9:].index:
    print("{} {}".format(day.strftime("%a"), day))
#+END_SRC

#+RESULTS:
: Sat 2016-12-03 00:00:00
: Sun 2016-12-04 00:00:00
: Sat 2016-12-10 00:00:00
: Sun 2016-12-11 00:00:00
: Sat 2016-12-17 00:00:00
: Sun 2016-12-18 00:00:00
: Sat 2016-12-24 00:00:00
: Sun 2016-12-25 00:00:00
: Mon 2016-12-26 00:00:00

So it does look like the zeros are weekends and holidays.

** UPS
   Here's what just the UPS trading volumes look like.
#+BEGIN_SRC python :session kaggle :results raw drawer :ipyfile ../../files/posts/tutorials/kaggle-on-time-series-visualization/ups_lag_plot.png
figure, axe = pyplot.subplots()
figure.suptitle("UPS Trading Volume Lag Plot", weight="bold")
subplot = lag_plot(ups.volume, ax=axe)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[22]:
[[file:../../files/posts/tutorials/kaggle-on-time-series-visualization/ups_lag_plot.png]]
:END:

[[file:ups_lag_plot.png]]

I don't know why but that makes it look better. I guess the market as a whole doesn't move quite so well together day by day as a single stock does.
* Autcorrelation Plot
** UPS
#+BEGIN_SRC python :session kaggle :results raw drawer :ipyfile ../../files/posts/tutorials/kaggle-on-time-series-visualization/autocorrelation.png
figure, axe = pyplot.subplots()
figure.suptitle("UPS Trading Volume Daily Autocorrelation", weight="bold")
subplot = autocorrelation_plot(ups.volume, ax=axe)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[24]:
[[file:../../files/posts/tutorials/kaggle-on-time-series-visualization/autocorrelation.png]]
:END:

[[file:autocorrelation.png]]

  This plot shows the lag in relationship to correlation over different lag intervals. It looks like up to about 500 days of lag the correlation is positive but it starts to become more negative after that.  The horizontal lines are the confidence intervals - the solid grey lines are the 95 % interval and the dashed grey lines are the 99% interval. The points that fall outside of these intervals are statistically significant.
* Cryptocurrency
** Lag Plot

#+BEGIN_SRC python :session kaggle :results raw drawer :ipyfile ../../files/posts/tutorials/kaggle-on-time-series-visualization/crypto_lag.png
crypto_daily = currency.volume.resample("D")
figure, axe = pyplot.subplots()
figure.suptitle("Cryptocurrency Volume Lag Plot", weight="bold")
subplot = lag_plot(crypto_daily.sum(), ax=axe)
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[78]:
[[file:../../files/posts/tutorials/kaggle-on-time-series-visualization/crypto_lag.png]]
:END:

[[file:crypto_lag.png]]

Unlike the stock-exchange, the cryptocurrencies seem to move together and don't take days off.

** Autocorrelation Plot
#+BEGIN_SRC python :session kaggle :results raw drawer :ipyfile ../../files/posts/tutorials/kaggle-on-time-series-visualization/currency_autocorrelation.png
figure, axe = pyplot.subplots()
figure.suptitle("Dogecoin Auto Correlation", weight="bold")
dogecoin = currency[currency.name=="Dogecoin"]
subplot = autocorrelation_plot(dogecoin.volume, ax=axe)
#+END_SRC

#+RESULTS:
:results:
# Out[31]:
[[file:../../files/posts/tutorials/kaggle-on-time-series-visualization/currency_autocorrelation.png]]
:end:

[[file:currency_autocorrelation.png]]

If my understanding of how this plot works is correct, there is some kind of significance to lags of 125 and 250 days. Is this really true? Possibly.
