#+BEGIN_COMMENT
.. title: Exercise in Permutation Importance
.. slug: exercise-in-permutation-importance
.. date: 2020-02-06 10:45:53 UTC-08:00
.. tags: tutorial,feature selection,permutation importance
.. category: Permutation Importance
.. link: 
.. description: An exercise in Permutation Importance
.. type: text
.. status: 
.. updated: 

#+END_COMMENT
#+OPTIONS: ^:{}
#+TOC: headlines 
* Beginning
  This is my re-do of the [[https://www.kaggle.com/learn/machine-learning-explainability][Machine Learning Explainability]] Permutation Importance exercise on kaggle. It uses the data from the [[https://www.kaggle.com/c/new-york-city-taxi-fare-prediction/data][New York City Taxi Fare Prediction]] dataset on kaggle.
** Imports
*** From Python
#+BEGIN_SRC python :session permutation :results none
from argparse import Namespace
from functools import partial
from pathlib import Path
#+end_src
*** From PyPi
#+BEGIN_SRC python :session permutation :results none
from eli5.sklearn import PermutationImportance

from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from tabulate import tabulate

import eli5
import hvplot.pandas
import numpy
import pandas
#+END_SRC
*** Others
#+BEGIN_SRC python :session permutation :results none
from graeae import EmbedHoloviews, EnvironmentLoader, Timer
#+end_src
** Set Up
*** A Timer
#+BEGIN_SRC python :session permutation :results none
TIMER = Timer()
#+end_src
*** Plotting
#+BEGIN_SRC python :session permutation :results none
SLUG = "exercise-in-permutation-importance"
PATH = Path("../../files/posts/tutorials/")/SLUG
Plot = Namespace(
    width=1000,
    height=800,
    )
Embed = partial(EmbedHoloviews, folder_path=PATH)
#+end_src
*** The Environment
#+BEGIN_SRC python :session permutation :results none
ENVIRONMENT = EnvironmentLoader()
#+end_src
*** Table Printer
#+BEGIN_SRC python :session permutation :results none
TABLE = partial(tabulate, tablefmt="orgtbl", headers="keys", showindex=False)
#+end_src
* Middle
*** The Dataset
    Since this is about permutation importance we're just going to load a subset (there are over five million rows in the dataset) and use previously discovered values to get rid of outliers.

#+BEGIN_SRC python :session permutation :results none
ROWS = 5 * 10**4
PATH = Path(ENVIRONMENT["NY-TAXI"]).expanduser()
assert PATH.is_dir()
data = pandas.read_csv(PATH/"train.csv", nrows=ROWS)
#+end_src

#+BEGIN_SRC python :session permutation :results output raw :exports both
print(TABLE(data.iloc[0].reset_index().rename(columns={
    "index": "Column", 0: "Value"})))
#+end_src

#+RESULTS:
| Column            |                       Value |
|-------------------+-----------------------------|
| key               | 2009-06-15 17:26:21.0000001 |
| fare_amount       |                         4.5 |
| pickup_datetime   |     2009-06-15 17:26:21 UTC |
| pickup_longitude  |                  -73.844311 |
| pickup_latitude   |                   40.721319 |
| dropoff_longitude |                   -73.84161 |
| dropoff_latitude  |          40.712278000000005 |
| passenger_count   |                           1 |
# Out[9]:

**** Trim Outliers
#+BEGIN_SRC python :session permutation :results output raw :exports both
print(TABLE(data.describe(), showindex=True))
#+END_SRC

#+RESULTS:
|       |   fare_amount |   pickup_longitude |   pickup_latitude |   dropoff_longitude |   dropoff_latitude |   passenger_count |
|-------+---------------+--------------------+-------------------+---------------------+--------------------+-------------------|
| count |   50000       |         50000      |       50000       |          50000      |        50000       |       50000       |
| mean  |      11.3642  |           -72.5098 |          39.9338  |            -72.5046 |           39.9263  |           1.66784 |
| std   |       9.68556 |            10.3939 |           6.22486 |             10.4076 |            6.01474 |           1.28919 |
| min   |      -5       |           -75.4238 |         -74.0069  |            -84.6542 |          -74.0064  |           0       |
| 25%   |       6       |           -73.9921 |          40.7349  |            -73.9912 |           40.7344  |           1       |
| 50%   |       8.5     |           -73.9818 |          40.7527  |            -73.9801 |           40.7534  |           1       |
| 75%   |      12.5     |           -73.9671 |          40.7674  |            -73.9636 |           40.7682  |           2       |
| max   |     200       |            40.7835 |         401.083   |             40.851  |           43.4152  |           6       |

#+BEGIN_SRC python :session permutation :results output raw :exports both
to_plot = data[[column for column in data.columns
                if "latitude" in column or "longitude" in column]]
plot = to_plot.hvplot.box().opts(title="Column Box-Plots",
                                 width=Plot.width,
                                 height=Plot.height)
Embed(plot=plot, file_name="column_box_plots")()
#+END_SRC

#+RESULTS:
#+begin_export html
<object type="text/html" data="column_box_plots.html" style="width:100%" height=800>
  <p>Figure Missing</p>
</object>
#+end_export

So you can see that there are negative fares, which seems wrong, and some outliers.

This uses the pandas [[https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.query.html][query]] method which let's you write slightly more readable code for boolean slicing.

#+BEGIN_SRC python :session permutation :results output :exports both
print(f"{len(data):,}")
data = data.query("pickup_latitude > 40.7 and pickup_latitude < 40.8 and " +
                  "dropoff_latitude > 40.7 and dropoff_latitude < 40.8 and " +
                  "pickup_longitude > -74 and pickup_longitude < -73.9 and " +
                  "dropoff_longitude > -74 and dropoff_longitude < -73.9 and " +
                  "fare_amount > 0"
                  )
print(f"{len(data):,}")
#+END_SRC

#+RESULTS:
: 50,000
: 31,289

*** Set Up the Training and Test Sets
#+BEGIN_SRC python :session permutation :results output :exports both
y = data.fare_amount
base_features = ['pickup_longitude',
                 'pickup_latitude',
                 'dropoff_longitude',
                 'dropoff_latitude',
                 'passenger_count']

X = data[base_features]
x_train, x_validate, y_train, y_validate = train_test_split(X, y, random_state=1)

print(f"{len(x_train):,}")
print(f"{len(x_validate):,}")
#+END_SRC

#+RESULTS:
: 23,466
: 7,823
** Build and Train the Model
#+begin_src python :session permutation :results output :exports both
estimators = list(range(50, 200, 10))
max_depth = list(range(10, 100, 10)) + [None]

grid = dict(n_estimators=estimators,
            max_depth=max_depth)

model = RandomForestRegressor()
search = RandomizedSearchCV(estimator=model,
                            param_distributions=grid,
                            n_iter=40,
                            n_jobs=-1,
                            random_state=1)
with TIMER:
    search.fit(x_train, y_train)
first_model = search.best_estimator_
print(f"CV Training R^2: {search.best_score_:0.2f}")
print(f"Training R^2: {first_model.score(x_train, y_train): 0.2f}")
print(f"Validation R^2: {first_model.score(x_validate, y_validate):0.2f}")
print(search.best_params_)
#+end_src

#+RESULTS:
#+begin_example
2020-02-10 13:40:59,617 graeae.timers.timer start: Started: 2020-02-10 13:40:59.616742
/home/brunhilde/.virtualenvs/Visions-Voices-Data/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.
  warnings.warn(CV_WARNING, FutureWarning)
/home/brunhilde/.virtualenvs/Visions-Voices-Data/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  "timeout or by a memory leak.", UserWarning
2020-02-10 13:42:04,387 graeae.timers.timer end: Ended: 2020-02-10 13:42:04.387425
2020-02-10 13:42:04,390 graeae.timers.timer end: Elapsed: 0:01:04.770683
CV Training R^2: 0.45
Training R^2:  0.92
Validation R^2: 0.42
{'n_estimators': 170, 'max_depth': 70}
#+end_example

So it isn't really a great model, but we'll ignore that for now.

** Questions
*** Question 1
#+begin_quote
 The first model uses the following features:
 - pickup_longitude
 - pickup_latitude
 - dropoff_longitude
 - dropoff_latitude
 - passenger_count

Before running any code... which variables seem potentially useful for predicting taxi fares? Do you think permutation importance will necessarily identify these features as important?
#+end_quote

I think that pickup and dropoff latitude might be important, since this would reflect where in the city the person was and wanted to go. Passenger count might make a difference as well, but I don't know if there's a greater charge for more people. Longitude might also be useful, but my guess would be that the North-South location is more indicative of the type of place you are in (uptown or downtown) and thus how far you have to travel (I have a vague notion that New York City is longer vertically than horizontally, but I don't know if this is true). This would be even more important if the fares change by location, but I don't know if that's the case.

#+BEGIN_SRC python :session permutation :results output :exports both
with TIMER:
    permutor = PermutationImportance(first_model, random_state=1).fit(
        x_validate, y_validate)
#+end_src

#+BEGIN_SRC python :session permutation :results output raw :exports both
ipython_html = eli5.show_weights(permutor,
                                 feature_names=x_validate.columns.tolist())
table = pandas.read_html(ipython_html.data)[0]
print(TABLE(table))
#+END_SRC

#+RESULTS:
| Weight            | Feature           |
|-------------------+-------------------|
| 0.8413  ± 0.0171  | dropoff_latitude  |
| 0.8135  ± 0.0223  | pickup_latitude   |
| 0.5723  ± 0.0370  | pickup_longitude  |
| 0.5324  ± 0.0257  | dropoff_longitude |
| -0.0014  ± 0.0015 | passenger_count   |

So it looks like latitude and longitude are important, with latitude a little more important than longitude and passenger count isn't important.
** A New Model
*** Question 4
#+begin_quote
Without detailed knowledge of New York City, it's difficult to rule out most hypotheses about why latitude features matter more than longitude.

A good next step is to disentangle the effect of being in certain parts of the city from the effect of total distance traveled.  

The code below creates new features for longitudinal and latitudinal distance. It then builds a model that adds these new features to those you already had.
#+end_quote

*** Feature Engineering
    We're going to estimate the distance traveled by using the differences in latitude and longitude from the pickup to the dropoff. This should give us a taxicab-distance estimate.

#+BEGIN_SRC python :session permutation :results output :exports both
data['absolute_change_longitude'] = abs(
    data.dropoff_longitude - data.pickup_longitude)
data['absolute_change_latitude'] = abs(
    data.dropoff_latitude - data.pickup_latitude)

features_2  = ['pickup_longitude',
               'pickup_latitude',
               'dropoff_longitude',
               'dropoff_latitude',
               'absolute_change_latitude',
               'absolute_change_longitude']

X = data[features_2]
new_x_train, new_x_validate, new_y_train, new_y_validate = train_test_split(
    X, y, random_state=1)

estimators = list(range(100, 250, 10))
max_depth = list(range(10, 50, 10)) + [None]
model = RandomForestRegressor()
search = RandomizedSearchCV(estimator=model,
                            param_distributions=grid,
                            n_jobs=-1,
                            random_state=1)
with TIMER:
    search.fit(new_x_train, new_y_train)

second_model = search.best_estimator_
print(f"Mean Cross-Validation Training R^2: {search.best_score_:0.2f}")
print(f"Training R^2: {second_model.score(new_x_train, new_y_train): 0.2f}")
print("Validation R^2: "
      f"{second_model.score(new_x_validate, new_y_validate):0.2f}")
print(search.best_params_)
#+end_src

#+RESULTS:
: 2020-02-10 13:42:52,104 graeae.timers.timer start: Started: 2020-02-10 13:42:52.104493
: /home/brunhilde/.virtualenvs/Visions-Voices-Data/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.
:   warnings.warn(CV_WARNING, FutureWarning)
: 2020-02-10 13:43:24,554 graeae.timers.timer end: Ended: 2020-02-10 13:43:24.554581
: 2020-02-10 13:43:24,556 graeae.timers.timer end: Elapsed: 0:00:32.450088
: Mean Cross-Validation Training R^2: 0.48
: Training R^2:  0.70
: Validation R^2: 0.47
: {'n_estimators': 190, 'max_depth': 10}

Still a pretty bad model, but that's not the point, I guess.
*** The Permutation Importance
#+BEGIN_SRC python :session permutation :results output raw :exports both
permutor = PermutationImportance(second_model, random_state=1).fit(
    new_x_validate, new_y_validate)
ipython_html = eli5.show_weights(permutor,
                                 feature_names=new_x_validate.columns.tolist())
table = pandas.read_html(ipython_html.data)[0]
print(TABLE(table))
#+END_SRC

#+RESULTS:
| Weight           | Feature                   |
|------------------+---------------------------|
| 0.5976  ± 0.0306 | absolute_change_latitude  |
| 0.4429  ± 0.0496 | absolute_change_longitude |
| 0.0339  ± 0.0216 | pickup_latitude           |
| 0.0232  ± 0.0032 | dropoff_latitude          |
| 0.0214  ± 0.0068 | dropoff_longitude         |
| 0.0159  ± 0.0055 | pickup_longitude          |

The distance traveled seems to be the most important feature for the fare, even more than the actual locations, probably because taxis charge by distance.

*** Question 5
    This question is about the scale of the parameters. Here's a sample.

#+BEGIN_SRC python :session permutation :results output raw :exports both
print(TABLE(new_x_train.sample(random_state=1).iloc[0].reset_index()))
#+END_SRC

#+RESULTS:
| index                     |    31975 |
|---------------------------+----------|
| pickup_longitude          | -73.9706 |
| pickup_latitude           |  40.7613 |
| dropoff_longitude         | -73.9806 |
| dropoff_latitude          |  40.7483 |
| absolute_change_latitude  |  0.01302 |
| absolute_change_longitude | 0.010067 |

And here's some statistics about each.
#+BEGIN_SRC python :session permutation :results output :exports both
print(new_x_validate.describe())
#+END_SRC

#+RESULTS:
#+begin_example
       pickup_longitude  pickup_latitude  dropoff_longitude  dropoff_latitude  \
count       7823.000000      7823.000000        7823.000000       7823.000000   
mean         -73.976957        40.756877         -73.975293         40.757591   
std            0.014663         0.018064           0.015877          0.018669   
min          -73.999977        40.700400         -73.999992         40.700293   
25%          -73.988180        40.745044         -73.987078         40.746345   
50%          -73.979933        40.757881         -73.978427         40.758602   
75%          -73.968008        40.769486         -73.966296         40.770561   
max          -73.900123        40.799865         -73.901790         40.799984   

       absolute_change_latitude  absolute_change_longitude  
count               7823.000000                7823.000000  
mean                   0.015091                   0.013029  
std                    0.012508                   0.011554  
min                    0.000000                   0.000000  
25%                    0.006089                   0.004968  
50%                    0.011745                   0.010110  
75%                    0.020781                   0.017798  
max                    0.084413                   0.087337  
#+end_example

#+begin_quote
 A colleague observes that the values for =absolute_change_longitude= and =absolute_change_latitude= are pretty small (all values are between -0.1 and 0.1), whereas other variables have larger values.  Do you think this could explain why those coordinates had larger permutation importance values in this case?  

Consider an alternative where you created and used a feature that was 100X as large for these features, and used that larger feature for training and importance calculations. Would this change the outputted permutation importance values?

Why or why not?
#+end_quote

#+BEGIN_SRC python :session permutation :results output :exports both
for column in ("pickup_longitude pickup_latitude dropoff_longitude "
               "dropoff_latitude absolute_change_latitude "
               "absolute_change_longitude").split():
    print(f"{column}: {new_x_validate[column].max() - new_x_validate[column].min():0.3f}")
#+END_SRC

#+RESULTS:
: pickup_longitude: 0.100
: pickup_latitude: 0.099
: dropoff_longitude: 0.098
: dropoff_latitude: 0.100
: absolute_change_latitude: 0.084
: absolute_change_longitude: 0.087

Intuitively I would think that the difference in the scales would make a difference.

#+begin_src python :session permutation :results output :exports both
data["bigger_pickup_longitude"] = data.pickup_longitude * 100
data["bigger_absolute_change_longitude"] = data.absolute_change_longitude * 100
features_3  = ['pickup_longitude',
               'pickup_latitude',
               'dropoff_longitude',
               'dropoff_latitude',
               'absolute_change_latitude',
               'absolute_change_longitude',
               'bigger_pickup_longitude',
               'bigger_absolute_change_longitude'
               ]

X = data[features_3]
big_x_train, big_x_validate, big_y_train, big_y_validate = train_test_split(
    X, y, random_state=1)
model = RandomForestRegressor()
search = RandomizedSearchCV(estimator=model,
                            param_distributions=grid,
                            n_jobs=-1,
                            random_state=1)
with TIMER:
    search.fit(big_x_train, big_y_train)
big_model = search.best_estimator_
print(f"Mean Cross-Validation Training R^2: {search.best_score_:0.2f}")
print(f"Training R^2: {big_model.score(big_x_train, big_y_train): 0.2f}")
print("Validation R^2: "
      f"{big_model.score(big_x_validate, big_y_validate):0.2f}")
print(search.best_params_)
#+end_src

#+RESULTS:
: 2020-02-09 15:06:45,693 graeae.timers.timer start: Started: 2020-02-09 15:06:45.693742
: /home/athena/.virtualenvs/Visions-Voices-Data/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
:   "timeout or by a memory leak.", UserWarning
: 2020-02-09 15:09:15,559 graeae.timers.timer end: Ended: 2020-02-09 15:09:15.559561
: 2020-02-09 15:09:15,560 graeae.timers.timer end: Elapsed: 0:02:29.865819
: Mean Cross-Validation Training R^2: 0.49
: Training R^2:  0.70
: Validation R^2: 0.47
: {'n_estimators': 190, 'max_depth': 10}

#+BEGIN_SRC python :session permutation :results output raw :exports both
permutor = PermutationImportance(big_model, random_state=1).fit(
    big_x_validate, big_y_validate)
ipython_html = eli5.show_weights(permutor,
                                 feature_names=big_x_validate.columns.tolist())
table = pandas.read_html(ipython_html.data)[0]
print(TABLE(table))
#+END_SRC

#+RESULTS:
| Weight           | Feature                          |
|------------------+----------------------------------|
| 0.6034  ± 0.0436 | absolute_change_latitude         |
| 0.1794  ± 0.0126 | bigger_absolute_change_longitude |
| 0.1366  ± 0.0062 | absolute_change_longitude        |
| 0.0326  ± 0.0217 | pickup_latitude                  |
| 0.0242  ± 0.0040 | dropoff_latitude                 |
| 0.0194  ± 0.0083 | dropoff_longitude                |
| 0.0188  ± 0.0085 | pickup_longitude                 |
| 0.0116  ± 0.0018 | bigger_pickup_longitude          |

Making the pickup longitude  didn't change its ranking relative to the other features so I wouldn't say that the scale had an effect.

*** Question 6
#+begin_quote
You've seen that the feature importance for latitudinal distance is greater than the importance of longitudinal distance. From this, can we conclude whether travelling a fixed latitudinal distance tends to be more expensive than traveling the same longitudinal distance?
#+end_quote

No, the feature importance indicates that it is useful in predicting fares, but it doesn't automatically mean that the fares will increase with the change in latitude. It might be the case that the change in longitude affects the cost of a change in latitude as well, so a fixed latitude distance might change depending on the longitude or latitude + longitude combination.
** Euclidean Distance
   Instead of keeping latitudinal and longitudinal distances separate, what if we used the euclidean distance?

#+BEGIN_SRC python :session permutation :results output :exports both
data["euclidean_distance"] = numpy.sqrt(data.absolute_change_latitude**2
                                        + data.absolute_change_longitude**2)
features  = ['pickup_longitude',
               'pickup_latitude',
               'dropoff_longitude',
               'dropoff_latitude',
               'absolute_change_latitude',
               'absolute_change_longitude',
               "euclidean_distance",
               ]

X = data[features]
euclid_x_train, euclid_x_validate, euclid_y_train, euclid_y_validate = train_test_split(X, y, random_state=1)
model = RandomForestRegressor()
search = RandomizedSearchCV(estimator=model,
                            param_distributions=grid,
                            n_jobs=-1,
                            random_state=1)
with TIMER:
    search.fit(euclid_x_train, euclid_y_train)
euclidean_model = search.best_estimator_
print(f"Mean Cross-Validation Training R^2: {search.best_score_:0.2f}")
print(f"Training R^2: {euclidean_model.score(euclid_x_train, euclid_y_train): 0.2f}")
print("Validation R^2: "
      f"{euclidean_model.score(euclid_x_validate, euclid_y_validate):0.2f}")
print(search.best_params_)
#+END_SRC

#+RESULTS:
: 2020-02-10 14:23:41,605 graeae.timers.timer start: Started: 2020-02-10 14:23:41.605310
: /home/brunhilde/.virtualenvs/Visions-Voices-Data/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.
:   warnings.warn(CV_WARNING, FutureWarning)
: 2020-02-10 14:24:20,385 graeae.timers.timer end: Ended: 2020-02-10 14:24:20.385580
: 2020-02-10 14:24:20,388 graeae.timers.timer end: Elapsed: 0:00:38.780270
: Mean Cross-Validation Training R^2: 0.48
: Training R^2:  0.74
: Validation R^2: 0.48
: {'n_estimators': 190, 'max_depth': 10}

Interestingly, the training \(R^2\) score went down although there was a slight improvement in the validation \(R^2\).
#+BEGIN_SRC python :session permutation :results output raw :exports both
permutor = PermutationImportance(euclidean_model, random_state=1).fit(
    euclid_x_validate, euclid_y_validate)
ipython_html = eli5.show_weights(
    permutor,
    feature_names=euclid_x_validate.columns.tolist())
table = pandas.read_html(ipython_html.data)[0]
print(TABLE(table))
#+END_SRC

#+RESULTS:
| Weight           | Feature                   |
|------------------+---------------------------|
| 1.3370  ± 0.0469 | euclidean_distance        |
| 0.3031  ± 0.0076 | absolute_change_latitude  |
| 0.1179  ± 0.0046 | absolute_change_longitude |
| 0.0261  ± 0.0045 | dropoff_latitude          |
| 0.0224  ± 0.0140 | dropoff_longitude         |
| 0.0219  ± 0.0041 | pickup_longitude          |
| 0.0183  ± 0.0051 | pickup_latitude           |

According to the permutation importance, euclidean distance is much more important than the separate distances.
* End
  The suggested next tutorial is about [[https://www.kaggle.com/dansbecker/partial-plots][Partial Dependence Plots]].

