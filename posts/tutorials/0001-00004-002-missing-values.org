#+BEGIN_COMMENT
.. title: Missing Values
.. slug: missing-values
.. date: 2020-02-20 21:07:15 UTC-08:00
.. tags: kaggle,tutorial,cleaning
.. category: Tutorial
.. link: 
.. description: Part two of kaggle's intermediate machine learning tutorial.
.. type: text
.. status: 
.. updated: 

#+END_COMMENT
#+OPTIONS: ^:{}
#+TOC: headlines 
#+PROPERTY: header-args :session /run/user/1000/jupyter/kernel-eccdecf3-9100-47e8-99d5-c11af61b8a9f.json
* Beginning
#+begin_quote
Now it's your turn to test your new knowledge of **missing values** handling. You'll probably find it makes a big difference.
#+end_quote
** Imports
*** Python
#+begin_src python :results none
from argparse import Namespace
from datetime import datetime
from functools import partial
from pathlib import Path
#+end_src
*** PyPi
#+begin_src python :results none
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import cross_val_score, train_test_split
from tabulate import tabulate

import hvplot.pandas
import pandas
#+end_src
*** Others
#+begin_src python :results none
from graeae import EmbedHoloviews, EnvironmentLoader, Timer
#+end_src
** Set Up
*** Table
#+begin_src python :results none
TABLE = partial(tabulate, tablefmt="orgtbl", showindex=False)
#+end_src
*** Plottting
#+begin_src python :results none
SLUG = "missing-values"
OUTPUT_PATH = Path("../../files/posts/tutorials/")/SLUG
Embed = partial(EmbedHoloviews, folder_path=OUTPUT_PATH)
Plot = Namespace(
    height=800,
    width=1000,
)
#+end_src
*** The Timer
#+begin_src python :results none
TIMER = Timer()
#+end_src
*** Environment
#+begin_src python :results none
ENVIRONMENT = EnvironmentLoader()
#+end_src
*** The Data
#+begin_src python :results none
DATA_PATH = Path(ENVIRONMENT["HOUSE-PRICES-IOWA"]).expanduser()
train_data = pandas.read_csv(
    DATA_PATH/"train.csv", index_col="Id")

test_data = pandas.read_csv(
    DATA_PATH/"test.csv", index_col="Id"
)
#+end_src
*** Some Constants
#+begin_src python :results none
Data = Namespace(
    target="SalePrice",
    train_size=0.8,
    test_size=0.2,
    random_seed=0,
)
#+end_src
* Middle
** Remove Training Data with no Target
#+begin_src python :results output :exports both
print(f"{len(train_data):,}")
train_data = train_data.dropna(axis="rows", subset=[Data.target])
print(f"{len(train_data):,}")
#+end_src

#+RESULTS:
: 1,460
: 1,460

Doesn't look like there were any missing target values.

#+begin_src python :results none
y = train_data[Data.target]
x_train = train_data.drop([Data.target], axis="columns")
#+end_src

** Numeric Data Only
#+begin_quote
To keep things simple, we'll use only numerical predictors
#+end_quote

#+begin_src python :results output :exports both
print(len(x_train.columns))
X = x_train.select_dtypes(exclude=["object"])
print(len(X.columns))
#+end_src

#+RESULTS:
: 79
: 36

#+begin_src python :results output :exports both
print(len(test_data.columns))
x_test = test_data.select_dtypes(exclude=["object"])
print(len(x_test.columns))
#+end_src

#+RESULTS:
: 79
: 36
** Split the Training and Validation Data

#+begin_src python :results none
x_train, x_validate, y_train, y_validate = train_test_split(
    X, y,
    train_size=Data.train_size,
    test_size=Data.test_size,
    random_state=Data.random_seed)
#+end_src

** Step 1: Preliminary investigation

#+begin_src python :results none
missing_by_column = x_train.isna().sum()
missed = missing_by_column[missing_by_column > 0]
print(TABLE(missed, headers=["Column", "Missing"]))
#+end_src

#+RESULTS:
# [goto error]

* Raw
#+begin_example


# In[ ]:


# Shape of training data (num_rows, num_columns)
print(X_train.shape)

# Number of missing values in each column of training data
missing_val_count_by_column = (X_train.isnull().sum())
print(missing_val_count_by_column[missing_val_count_by_column > 0])


# ### Part A
# 
# Use the above output to answer the questions below.

# In[ ]:


# Fill in the line below: How many rows are in the training data?
num_rows = ____

# Fill in the line below: How many columns in the training data
# have missing values?
num_cols_with_missing = ____

# Fill in the line below: How many missing entries are contained in 
# all of the training data?
tot_missing = ____

# Check your answers
step_1.a.check()


# In[ ]:


# Lines below will give you a hint or solution code
#step_1.a.hint()
#step_1.a.solution()


# ### Part B
# Considering your answers above, what do you think is likely the best approach to dealing with the missing values?

# In[ ]:


#step_1.b.hint()


# In[ ]:


# Check your answer (Run this code cell to receive credit!)
step_1.b.solution()


# To compare different approaches to dealing with missing values, you'll use the same `score_dataset()` function from the tutorial.  This function reports the [mean absolute error](https://en.wikipedia.org/wiki/Mean_absolute_error) (MAE) from a random forest model.

# In[ ]:


from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error

# Function for comparing different approaches
def score_dataset(X_train, X_valid, y_train, y_valid):
    model = RandomForestRegressor(n_estimators=100, random_state=0)
    model.fit(X_train, y_train)
    preds = model.predict(X_valid)
    return mean_absolute_error(y_valid, preds)


# # Step 2: Drop columns with missing values
# 
# In this step, you'll preprocess the data in `X_train` and `X_valid` to remove columns with missing values.  Set the preprocessed DataFrames to `reduced_X_train` and `reduced_X_valid`, respectively.  

# In[ ]:


# Fill in the line below: get names of columns with missing values
____ # Your code here

# Fill in the lines below: drop columns in training and validation data
reduced_X_train = ____
reduced_X_valid = ____

# Check your answers
step_2.check()


# In[ ]:


# Lines below will give you a hint or solution code
#step_2.hint()
#step_2.solution()


# Run the next code cell without changes to obtain the MAE for this approach.

# In[ ]:


print("MAE (Drop columns with missing values):")
print(score_dataset(reduced_X_train, reduced_X_valid, y_train, y_valid))


# # Step 3: Imputation
# 
# ### Part A
# 
# Use the next code cell to impute missing values with the mean value along each column.  Set the preprocessed DataFrames to `imputed_X_train` and `imputed_X_valid`.  Make sure that the column names match those in `X_train` and `X_valid`.

# In[ ]:


from sklearn.impute import SimpleImputer

# Fill in the lines below: imputation
____ # Your code here
imputed_X_train = ____
imputed_X_valid = ____

# Fill in the lines below: imputation removed column names; put them back
imputed_X_train.columns = ____
imputed_X_valid.columns = ____

# Check your answers
step_3.a.check()


# In[ ]:


# Lines below will give you a hint or solution code
#step_3.a.hint()
#step_3.a.solution()


# Run the next code cell without changes to obtain the MAE for this approach.

# In[ ]:


print("MAE (Imputation):")
print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))


# ### Part B
# 
# Compare the MAE from each approach.  Does anything surprise you about the results?  Why do you think one approach performed better than the other?

# In[ ]:


#step_3.b.hint()


# In[ ]:


# Check your answer (Run this code cell to receive credit!)
step_3.b.solution()


# # Step 4: Generate test predictions
# 
# In this final step, you'll use any approach of your choosing to deal with missing values.  Once you've preprocessed the training and validation features, you'll train and evaluate a random forest model.  Then, you'll preprocess the test data before generating predictions that can be submitted to the competition!
# 
# ### Part A
# 
# Use the next code cell to preprocess the training and validation data.  Set the preprocessed DataFrames to `final_X_train` and `final_X_valid`.  **You can use any approach of your choosing here!**  in order for this step to be marked as correct, you need only ensure:
# - the preprocessed DataFrames have the same number of columns,
# - the preprocessed DataFrames have no missing values, 
# - `final_X_train` and `y_train` have the same number of rows, and
# - `final_X_valid` and `y_valid` have the same number of rows.

# In[ ]:


# Preprocessed training and validation features
final_X_train = ____
final_X_valid = ____

# Check your answers
step_4.a.check()


# In[ ]:


# Lines below will give you a hint or solution code
#step_4.a.hint()
#step_4.a.solution()


# Run the next code cell to train and evaluate a random forest model.  (*Note that we don't use the `score_dataset()` function above, because we will soon use the trained model to generate test predictions!*)

# In[ ]:


# Define and fit model
model = RandomForestRegressor(n_estimators=100, random_state=0)
model.fit(final_X_train, y_train)

# Get validation predictions and MAE
preds_valid = model.predict(final_X_valid)
print("MAE (Your approach):")
print(mean_absolute_error(y_valid, preds_valid))


# ### Part B
# 
# Use the next code cell to preprocess your test data.  Make sure that you use a method that agrees with how you preprocessed the training and validation data, and set the preprocessed test features to `final_X_test`.
# 
# Then, use the preprocessed test features and the trained model to generate test predictions in `preds_test`.
# 
# In order for this step to be marked correct, you need only ensure:
# - the preprocessed test DataFrame has no missing values, and
# - `final_X_test` has the same number of rows as `X_test`.

# In[ ]:


# Fill in the line below: preprocess test data
final_X_test = ____

# Fill in the line below: get test predictions
preds_test = ____

step_4.b.check()


# In[ ]:


# Lines below will give you a hint or solution code
#step_4.b.hint()
#step_4.b.solution()


# Run the next code cell without changes to save your results to a CSV file that can be submitted directly to the competition.

# In[ ]:


# Save test predictions to file
output = pd.DataFrame({'Id': X_test.index,
                       'SalePrice': preds_test})
output.to_csv('submission.csv', index=False)


# # Step 5: Submit your results
# 
# Once you have successfully completed Step 4, you're ready to submit your results to the leaderboard!  (_You also learned how to do this in the previous exercise.  If you need a reminder of how to do this, please use the instructions below._)  
# 
# First, you'll need to join the competition if you haven't already.  So open a new window by clicking on [this link](https://www.kaggle.com/c/home-data-for-ml-course).  Then click on the **Join Competition** button.
# 
# ![join competition image](https://i.imgur.com/wLmFtH3.png)
# 
# Next, follow the instructions below:
# - Begin by clicking on the blue **COMMIT** button in the top right corner.  This will generate a pop-up window.  
# - After your code has finished running, click on the blue **Open Version** button in the top right of the pop-up window.  This brings you into view mode of the same page. You will need to scroll down to get back to these instructions.
# - Click on the **Output** tab on the left of the screen.  Then, click on the **Submit to Competition** button to submit your results to the leaderboard.
# - If you want to keep working to improve your performance, select the blue **Edit** button in the top right of the screen. Then you can change your model and repeat the process.
# 
# # Keep going
# 
# Move on to learn what **[categorical variables](https://www.kaggle.com/alexisbcook/categorical-variables)** are, along with how to incorporate them into your machine learning models.  Categorical variables are very common in real-world data, but you'll get an error if you try to plug them into your models without processing them first!

# ---
# **[Intermediate Machine Learning Home Page](https://www.kaggle.com/learn/intermediate-machine-learning)**
# 
# 
# 
# 
# 
# *Have questions or comments? Visit the [Learn Discussion forum](https://www.kaggle.com/learn-forum) to chat with other Learners.*
#+end_example
