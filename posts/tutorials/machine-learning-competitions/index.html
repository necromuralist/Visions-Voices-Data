<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content="The final part of the Kaggle Introduction to Machine Learning tutorial." name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>Machine Learning Competitions | Visions, Voices, Data</title>
<link href="../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="../../../rss.xml" hreflang="en" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/machine-learning-competitions/" rel="canonical"><!--[if lt IE 9]><script src="../../../assets/js/html5.js"></script><![endif]-->
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script><!--
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/0.9.0/p5.min.js"
</script>
-->
<script async src="../../../assets/javascript/p5.min.js" type="text/javascript"></script>
<meta content="Cloistered Monkey" name="author">
<link href="/posts/tutorials/random-forests/" rel="prev" title="Random Forests" type="text/html">
<link href="/posts/tutorials/introduction-intermediate-machine-learning/" rel="next" title="Introduction to the Kaggle Intermediate Machine Learning Tutorial" type="text/html">
<meta content="Visions, Voices, Data" property="og:site_name">
<meta content="Machine Learning Competitions" property="og:title">
<meta content="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/machine-learning-competitions/" property="og:url">
<meta content="The final part of the Kaggle Introduction to Machine Learning tutorial." property="og:description">
<meta content="article" property="og:type">
<meta content="2020-02-18T10:16:45-08:00" property="article:published_time">
<meta content="kaggle" property="article:tag">
<meta content="tutorial" property="article:tag">
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="/"><span id="blog-title">Visions, Voices, Data</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="/archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="/categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="/rss.xml">RSS feed</a></li>
<li class="nav-item dropdown"><a aria-expanded="false" aria-haspopup="true" class="nav-link dropdown-toggle" data-toggle="dropdown" href="#">Monkey Pages</a>
<div class="dropdown-menu"><a class="dropdown-item" href="https://necromuralist.github.io/">Cloistered Monkey</a> <a class="dropdown-item" href="https://necromuralist.github.io/Ape-Iron/">Ape Iron</a> <a class="dropdown-item" href="https://necromuralist.github.io/Beach-Pig-Thigh/">Beach Pig Rump & Thigh</a> <a class="dropdown-item" href="https://necromuralist.github.io/Bowling-For-Data/">Bowling For Data</a> <a class="dropdown-item" href="https://necromuralist.github.io/Give-The-Fish/">Give the Fish</a> <a class="dropdown-item" href="https://necromuralist.github.io/Neurotic-Networking/">Neurotic Networking</a> <a class="dropdown-item" href="https://necromuralist.github.io/Terribilis-Ludum/">Terribilis Ludum</a> <a class="dropdown-item" href="https://necromuralist.github.io/Visions-Voices-Data/">Visions, Voices, Data</a></div>
</li>
</ul>
<!-- DuckDuckGo custom search -->
<form action="https://duckduckgo.com/" class="navbar-form pull-left" id="search" method="get" name="search"><input name="sites" type="hidden" value="https://necromuralist.github.io/Visions-Voices-Data/"> <input name="k8" type="hidden" value="#444444"> <input name="k9" type="hidden" value="#D51920"> <input name="kt" type="hidden" value="h"> <input class="span2" maxlength="255" name="q" placeholder="Search…" type="text"> <input style="visibility: hidden;display:none" type="submit" value="DuckDuckGo Search"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right">
<li class="nav-item"><a class="nav-link" href="/posts/tutorials/machine-learning-competitions/index.org" id="sourcelink">Source</a></li>
</ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title" itemprop="headline name"><a class="u-url" href="/posts/tutorials/machine-learning-competitions/">Machine Learning Competitions</a></h1>
<div class="metadata">
<p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="/posts/tutorials/machine-learning-competitions/" rel="bookmark"><time class="published dt-published" datetime="2020-02-18T10:16:45-08:00" itemprop="datePublished" title="2020-02-18 10:16">2020-02-18 10:16</time></a></p>
<p class="sourceline"><a class="sourcelink" href="/posts/tutorials/machine-learning-competitions/index.org">Source</a></p>
</div>
</header>
<div class="e-content entry-content" itemprop="articleBody text">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="/posts/tutorials/machine-learning-competitions/#org4e88e40">Beginning</a>
<ul>
<li><a href="/posts/tutorials/machine-learning-competitions/#org4b69ceb">Imports</a>
<ul>
<li><a href="/posts/tutorials/machine-learning-competitions/#org1a24fcf">Python</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#orga3746b9">PyPi</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#org35a15f7">Others</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/machine-learning-competitions/#org8fa7394">Set Up</a>
<ul>
<li><a href="/posts/tutorials/machine-learning-competitions/#org8cf8b15">Plottting</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#org66967a6">The Timer</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#org907bbe4">Environment</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#orgc362eff">The Data</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="/posts/tutorials/machine-learning-competitions/#orge08eefd">Middle</a>
<ul>
<li><a href="/posts/tutorials/machine-learning-competitions/#org12164da">Preliminary 1: Specify Prediction Target</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#org5c28052">Preliminary 2: Create X</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#org7b903f3">Preliminary 3: Specify and Fit Model</a>
<ul>
<li><a href="/posts/tutorials/machine-learning-competitions/#org5151bdd">A Linear Regression Model</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#org6053f7a">Decision Tree</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/machine-learning-competitions/#orgb411b66">Preliminary 4: Make Some Predictions</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#orgd355f84">Preliminary 5: Calculate the Mean Absolute Error in Validation Data</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#org6da6da5">Preliminary 6: Compare Different Tree Sizes</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#org41b3496">Preliminary 7: Use a Random Forest</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#orge144580">Step 1: Creating a Model For the Competition</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#orgc1bcf3c">Step 2: Make Predictions</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#org8fb46e1">Step 3: Save the Submission</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#org0e6ffff">Step 4: Test Your Work</a></li>
<li><a href="/posts/tutorials/machine-learning-competitions/#orgf50b1d0">Step 5: Continuing Your Progress</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/machine-learning-competitions/#org638b059">End</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org4e88e40">
<h2 id="org4e88e40">Beginning</h2>
<div class="outline-text-2" id="text-org4e88e40">
<blockquote>
<p>In this exercise, you will create and submit predictions for a Kaggle competition. You can then improve your model (e.g. by adding features) to improve and see how you stack up to others taking this micro-course.</p>
<p>The steps in this notebook are:</p>
<ol class="org-ol">
<li>Build a Random Forest model with all of your data (<b>X</b> and <b>y</b>)</li>
<li>Read in the "test" data, which doesn't include values for the target. Predict home values in the test data with your Random Forest model.</li>
<li>Submit those predictions to the competition and see your score.</li>
<li>Optionally, come back to see if you can improve your model by adding features or changing your model. Then you can resubmit to see how that stacks up on the competition leaderboard.</li>
</ol>
</blockquote>
</div>
<div class="outline-3" id="outline-container-org4b69ceb">
<h3 id="org4b69ceb">Imports</h3>
<div class="outline-text-3" id="text-org4b69ceb"></div>
<div class="outline-4" id="outline-container-org1a24fcf">
<h4 id="org1a24fcf">Python</h4>
<div class="outline-text-4" id="text-org1a24fcf">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orga3746b9">
<h4 id="orga3746b9">PyPi</h4>
<div class="outline-text-4" id="text-orga3746b9">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>

<span class="kn">import</span> <span class="nn">hvplot.pandas</span>
<span class="kn">import</span> <span class="nn">pandas</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org35a15f7">
<h4 id="org35a15f7">Others</h4>
<div class="outline-text-4" id="text-org35a15f7">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">EnvironmentLoader</span><span class="p">,</span> <span class="n">Timer</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org8fa7394">
<h3 id="org8fa7394">Set Up</h3>
<div class="outline-text-3" id="text-org8fa7394"></div>
<div class="outline-4" id="outline-container-org8cf8b15">
<h4 id="org8cf8b15">Plottting</h4>
<div class="outline-text-4" id="text-org8cf8b15">
<div class="highlight">
<pre><span></span><span class="n">SLUG</span> <span class="o">=</span> <span class="s2">"underfitting-and-overfitting-exercise"</span>
<span class="n">OUTPUT_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"../../files/posts/tutorials/"</span><span class="p">)</span><span class="o">/</span><span class="n">SLUG</span>
<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">folder_path</span><span class="o">=</span><span class="n">OUTPUT_PATH</span><span class="p">)</span>
<span class="n">Plot</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org66967a6">
<h4 id="org66967a6">The Timer</h4>
<div class="outline-text-4" id="text-org66967a6">
<div class="highlight">
<pre><span></span><span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org907bbe4">
<h4 id="org907bbe4">Environment</h4>
<div class="outline-text-4" id="text-org907bbe4">
<div class="highlight">
<pre><span></span><span class="n">ENVIRONMENT</span> <span class="o">=</span> <span class="n">EnvironmentLoader</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-orgc362eff">
<h4 id="orgc362eff">The Data</h4>
<div class="outline-text-4" id="text-orgc362eff">
<div class="highlight">
<pre><span></span><span class="n">DATA_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">ENVIRONMENT</span><span class="p">[</span><span class="s2">"HOUSE-PRICES-IOWA"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="n">DATA_PATH</span><span class="o">/</span><span class="s2">"train.csv"</span><span class="p">)</span>

<span class="n">test_data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="n">DATA_PATH</span><span class="o">/</span><span class="s2">"test.csv"</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orge08eefd">
<h2 id="orge08eefd">Middle</h2>
<div class="outline-text-2" id="text-orge08eefd"></div>
<div class="outline-3" id="outline-container-org12164da">
<h3 id="org12164da">Preliminary 1: Specify Prediction Target</h3>
<div class="outline-text-3" id="text-org12164da">
<p>Select the target variable, which corresponds to the sales price. Save this to a new variable called `y`. You'll need to print a list of the columns to find the name of the column you need.</p>
<p>Our target is <i>SalePrice</i>.</p>
<div class="highlight">
<pre><span></span><span class="n">Y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">SalePrice</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org5c28052">
<h3 id="org5c28052">Preliminary 2: Create X</h3>
<div class="outline-text-3" id="text-org5c28052">
<blockquote>
<p>Now you will create a DataFrame called `X` holding the predictive features.</p>
<p>Since you want only some columns from the original data, you'll first create a list with the names of the columns you want in `X`.</p>
<p>You'll use just the following columns in the list (you can copy and paste the whole list to save some typing, though you'll still need to add quotes):</p>
<ul class="org-ul">
<li>LotArea</li>
<li>YearBuilt</li>
<li>1stFlrSF</li>
<li>2ndFlrSF</li>
<li>FullBath</li>
<li>BedroomAbvGr</li>
<li>TotRmsAbvGrd</li>
</ul>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">FEATURES</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">"LotArea"</span><span class="p">,</span>
    <span class="s2">"YearBuilt"</span><span class="p">,</span>
    <span class="s2">"1stFlrSF"</span><span class="p">,</span>
    <span class="s2">"2ndFlrSF"</span><span class="p">,</span>
    <span class="s2">"FullBath"</span><span class="p">,</span>
    <span class="s2">"BedroomAbvGr"</span><span class="p">,</span>
    <span class="s2">"TotRmsAbvGrd"</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">FEATURES</span><span class="p">]</span>
</pre></div>
<p>Split up the data into training and validation sets.</p>
<div class="highlight">
<pre><span></span><span class="n">x_train</span><span class="p">,</span> <span class="n">x_validate</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_validate</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org7b903f3">
<h3 id="org7b903f3">Preliminary 3: Specify and Fit Model</h3>
<div class="outline-text-3" id="text-org7b903f3"></div>
<div class="outline-4" id="outline-container-org5151bdd">
<h4 id="org5151bdd">A Linear Regression Model</h4>
<div class="outline-text-4" id="text-org5151bdd">
<p>As a baseline, I'll fit a simple <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html">Linear Regression</a> (ordinary-least-squares) model.</p>
<div class="highlight">
<pre><span></span><span class="n">regression</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">regression</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2"> (+/- </span><span class="si">{</span><span class="mi">2</span> <span class="o">*</span> <span class="n">scores</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">)"</span><span class="p">)</span>
<span class="n">regression</span> <span class="o">=</span> <span class="n">regression</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Training R^2: </span><span class="si">{</span><span class="n">regression</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span><span class="si">:</span><span class="s2"> 0.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Validation R^2: </span><span class="si">{</span><span class="n">regression</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_validate</span><span class="p">,</span> <span class="n">y_validate</span><span class="p">)</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
0.66 (+/- 0.17)
Training R^2:  0.68
Validation R^2: 0.77
</pre></div>
</div>
<div class="outline-4" id="outline-container-org6053f7a">
<h4 id="org6053f7a">Decision Tree</h4>
<div class="outline-text-4" id="text-org6053f7a">
<blockquote>
<p>Create a <code>DecisionTreeRegressor</code> and save it as <code>iowa_model</code>. Ensure you've done the relevant import from sklearn to run this command.</p>
<p>Then fit the model you just created using the data in <code>X</code> and <code>y</code> that you saved above.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">()</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2"> (+/- </span><span class="si">{</span><span class="mi">2</span> <span class="o">*</span> <span class="n">scores</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">)"</span><span class="p">)</span>

<span class="n">tree</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Training R^2: </span><span class="si">{</span><span class="n">tree</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span><span class="si">:</span><span class="s2"> 0.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Validation R^2: </span><span class="si">{</span><span class="n">tree</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_validate</span><span class="p">,</span> <span class="n">y_validate</span><span class="p">)</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
0.52 (+/- 0.34)
Training R^2:  1.00
Validation R^2: 0.75
</pre>
<p>So our linear regression actually does better than the tree does. It looks like the tree might be overfitting on the training data.</p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orgb411b66">
<h3 id="orgb411b66">Preliminary 4: Make Some Predictions</h3>
<div class="outline-text-3" id="text-orgb411b66">
<div class="highlight">
<pre><span></span><span class="n">tree_predict</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_validate</span><span class="p">)</span>
<span class="n">regression_predict</span> <span class="o">=</span> <span class="n">regression</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_validate</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgd355f84">
<h3 id="orgd355f84">Preliminary 5: Calculate the Mean Absolute Error in Validation Data</h3>
<div class="outline-text-3" id="text-orgd355f84">
<div class="highlight">
<pre><span></span><span class="n">tree_mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_validate</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">tree_predict</span><span class="p">)</span>
<span class="n">regression_mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_validate</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">regression_predict</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Tree MAE: </span><span class="si">{</span><span class="n">tree_mae</span><span class="si">:</span><span class="s2"> 0.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Regression MAE: </span><span class="si">{</span><span class="n">regression_mae</span><span class="si">:</span><span class="s2"> 0.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Tree MAE:  28969.44
Regression MAE:  27228.88
</pre>
<p>The tree's error is a little higher than the regression line's.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org6da6da5">
<h3 id="org6da6da5">Preliminary 6: Compare Different Tree Sizes</h3>
<div class="outline-text-3" id="text-org6da6da5">
<blockquote>
<p>Write a loop that tries the following values for <b>max_leaf_nodes</b> from a set of possible values.</p>
<p>Call the <b>get_mae</b> function on each value of max_leaf_nodes. Store the output in some way that allows you to select the value of <code>max_leaf_nodes</code> that gives the most accurate model on your data.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">get_mae</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="p">,</span> <span class="n">train_X</span><span class="o">=</span><span class="n">x_train</span><span class="p">,</span> <span class="n">val_X</span><span class="o">=</span><span class="n">x_validate</span><span class="p">,</span> <span class="n">train_y</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">val_y</span><span class="o">=</span><span class="n">y_validate</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="o">=</span><span class="n">max_leaf_nodes</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>
    <span class="n">preds_val</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">val_X</span><span class="p">)</span>
    <span class="n">mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">val_y</span><span class="p">,</span> <span class="n">preds_val</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mae</span>
</pre></div>
<blockquote>
<p>Write a loop to find the ideal tree size from <code>candidate_max_leaf_nodes</code>.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">candidate_max_leaf_nodes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">250</span><span class="p">,</span> <span class="mi">500</span><span class="p">]</span>
<span class="n">outcomes</span> <span class="o">=</span> <span class="p">[(</span><span class="n">get_mae</span><span class="p">(</span><span class="n">nodes</span><span class="p">),</span> <span class="n">nodes</span><span class="p">)</span> <span class="k">for</span> <span class="n">nodes</span> <span class="ow">in</span> <span class="n">candidate_max_leaf_nodes</span><span class="p">]</span>
<span class="n">best</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">outcomes</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">best</span><span class="p">)</span>
<span class="n">best_tree_size</span> <span class="o">=</span> <span class="n">best</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
<pre class="example">
(27282.50803885739, 100)
</pre>
<div class="highlight">
<pre><span></span><span class="n">mae</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">nodes</span><span class="o">=</span><span class="n">candidate_max_leaf_nodes</span><span class="p">,</span> <span class="n">mae</span> <span class="o">=</span> <span class="p">[</span><span class="n">outcome</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">outcome</span> <span class="ow">in</span> <span class="n">outcomes</span><span class="p">]))</span>
<span class="n">plot</span> <span class="o">=</span> <span class="n">mae</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"nodes"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"mae"</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">"Node Mean Absolute Error"</span><span class="p">,</span>
                                           <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
                                           <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">)</span>
<span class="n">source</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"node_mean_absolute_error"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">source</span><span class="p">)</span>
</pre></div>
: <object data="/posts/tutorials/machine-learning-competitions/node_mean_absolute_error.html" height="800" style="width:100%" type="text/html">:
<p>Figure Missing</p>
:</object>
<p>Looking at the plot you can see that the error drops until you hit 100 nodes and then begins to rise again as it overfits the data with more nodes.</p>
<p>Let's see how much this improves our model using \(r^2\).</p>
<div class="highlight">
<pre><span></span><span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="o">=</span><span class="n">best_tree_size</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2"> (+/- </span><span class="si">{</span><span class="mi">2</span> <span class="o">*</span> <span class="n">scores</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">)"</span><span class="p">)</span>

<span class="n">tree</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Training R^2: </span><span class="si">{</span><span class="n">tree</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span><span class="si">:</span><span class="s2"> 0.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Validation R^2: </span><span class="si">{</span><span class="n">tree</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_validate</span><span class="p">,</span> <span class="n">y_validate</span><span class="p">)</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
0.58 (+/- 0.32)
Training R^2:  0.93
Validation R^2: 0.76
</pre>
<p>We've improved it slightly, it's probably still overfitting the model but not as much.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org41b3496">
<h3 id="org41b3496">Preliminary 7: Use a Random Forest</h3>
<div class="outline-text-3" id="text-org41b3496">
<div class="highlight">
<pre><span></span><span class="n">forest</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">forest</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2"> (+/- </span><span class="si">{</span><span class="mi">2</span> <span class="o">*</span> <span class="n">scores</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">)"</span><span class="p">)</span>

<span class="n">tree</span> <span class="o">=</span> <span class="n">forest</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Training R^2: </span><span class="si">{</span><span class="n">forest</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span><span class="si">:</span><span class="s2"> 0.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Validation R^2: </span><span class="si">{</span><span class="n">forest</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_validate</span><span class="p">,</span> <span class="n">y_validate</span><span class="p">)</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
0.76 (+/- 0.11)
Training R^2:  0.97
Validation R^2: 0.85
</pre>
<p>So the defaults already beat the regression and decision tree model.</p>
<div class="highlight">
<pre><span></span><span class="n">forest_predictions</span> <span class="o">=</span> <span class="n">forest</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_validate</span><span class="p">)</span>
<span class="n">forest_mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_validate</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">forest_predictions</span><span class="p">)</span>

<span class="n">tree_mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_validate</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">tree_predict</span><span class="p">)</span>
<span class="n">regression_mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_validate</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">regression_predict</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Tree MAE: </span><span class="si">{</span><span class="n">tree_mae</span><span class="si">:</span><span class="s2"> 0.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Regression MAE: </span><span class="si">{</span><span class="n">regression_mae</span><span class="si">:</span><span class="s2"> 0.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Forest MAE: </span><span class="si">{</span><span class="n">forest_mae</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Tree MAE:  28969.44
Regression MAE:  27228.88
Forest MAE: 21857.16
</pre>
<p>So the forest also has a much better Mean Absolute Error than the other two models.</p>
</div>
</div>
<div class="outline-3" id="outline-container-orge144580">
<h3 id="orge144580">Step 1: Creating a Model For the Competition</h3>
<div class="outline-text-3" id="text-orge144580">
<blockquote>
<p>Build a Random Forest model and train it on all of <b>X</b> and <b>y</b>.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">forest</span> <span class="o">=</span> <span class="n">RandomForestRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">forest</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgc1bcf3c">
<h3 id="orgc1bcf3c">Step 2: Make Predictions</h3>
<div class="outline-text-3" id="text-orgc1bcf3c">
<blockquote>
<p>Read the file of "test" data. And apply your model to make predictions. Then create test_X which comes from test_data but includes only the columns you used for prediction. The list of columns is stored in a variable called features.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">x_test</span> <span class="o">=</span> <span class="n">test_data</span><span class="p">[</span><span class="n">FEATURES</span><span class="p">]</span>
</pre></div>
<blockquote>
<p>Make predictions which we will submit.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">predictions</span> <span class="o">=</span> <span class="n">forest</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org8fb46e1">
<h3 id="org8fb46e1">Step 3: Save the Submission</h3>
<div class="outline-text-3" id="text-org8fb46e1">
<div class="highlight">
<pre><span></span><span class="n">submission</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">Id</span><span class="o">=</span><span class="n">test_data</span><span class="o">.</span><span class="n">Id</span><span class="p">,</span> <span class="n">SalePrice</span><span class="o">=</span><span class="n">predictions</span><span class="p">))</span>
<span class="n">submission</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">DATA_PATH</span><span class="o">/</span><span class="s2">"submission.csv"</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org0e6ffff">
<h3 id="org0e6ffff">Step 4: Test Your Work</h3>
<div class="outline-text-3" id="text-org0e6ffff">
<blockquote>
<p>To test your results, you'll need to join the competition (if you haven't already). So open a new window by clicking on <a href="https://www.kaggle.com/c/home-data-for-ml-course">this link</a>. Then click on the <b>Join Competition</b> button.</p>
</blockquote>
<p><a href="https://i.imgur.com/wLmFtH3.png">join competition image</a></p>
<blockquote>
<p>Next, follow the instructions below:</p>
<ol class="org-ol">
<li>Begin by clicking on the blue <b>COMMIT</b> button in the top right corner of this window. This will generate a pop-up window.</li>
<li>After your code has finished running, click on the blue <b>Open Version</b> button in the top right of the pop-up window. This brings you into view mode of the same page. You will need to scroll down to get back to these instructions.</li>
<li>Click on the <b>Output</b> tab on the left of the screen. Then, click on the <b>Submit to Competition</b> button to submit your results to the leaderboard.</li>
</ol>
<p>You have now successfully submitted to the competition.</p>
</blockquote>
</div>
</div>
<div class="outline-3" id="outline-container-orgf50b1d0">
<h3 id="orgf50b1d0">Step 5: Continuing Your Progress</h3>
<div class="outline-text-3" id="text-orgf50b1d0">
<blockquote>
<p>There are many ways to improve your model, and <b>experimenting is a great way to learn at this point.</b></p>
<p>The best way to improve your model is to add features. Look at the list of columns and think about what might affect home prices. Some features will cause errors because of issues like missing values or non-numeric data types.</p>
</blockquote>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org638b059">
<h2 id="org638b059">End</h2>
<div class="outline-text-2" id="text-org638b059">
<p>The submission is evaluated using the Root Mean Squared Error of the logarithms of the sale prices. The logarithm makes it so the errors for the cheap houses and the expensive houses are equally bad.</p>
<p>For this model you get a score of <b>*27,217.91640</b>. The current leader has a score of 0, which would seem to imply he downloaded the original set and learned the data, the second best is <i>8,830</i>.</p>
<p>The <b><a href="https://www.kaggle.com/learn/intermediate-machine-learning">Intermediate Machine Learning</a></b> micro-course will teach you how to handle these types of features. You will also learn to use <b>xgboost</b>, a technique giving even better accuracy than Random Forest.</p>
</div>
</div>
</div>
<aside class="postpromonav">
<nav>
<ul class="tags" itemprop="keywords">
<li><a class="tag p-category" href="/categories/kaggle/" rel="tag">kaggle</a></li>
<li><a class="tag p-category" href="/categories/tutorial/" rel="tag">tutorial</a></li>
</ul>
<ul class="pager hidden-print">
<li class="previous"><a href="/posts/tutorials/random-forests/" rel="prev" title="Random Forests">Previous post</a></li>
<li class="next"><a href="/posts/tutorials/introduction-intermediate-machine-learning/" rel="next" title="Introduction to the Kaggle Intermediate Machine Learning Tutorial">Next post</a></li>
</ul>
</nav>
</aside>
</article>
<!--End of body content-->
<footer id="footer">Contents © 2023 <a href="mailto:cloisteredmonkey.jmark@slmail.me">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a></footer>
</div>
</div>
<script src="/assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
</script> 
</body>
</html>
