<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content="Part 4 of the Kaggle Introduction to Machine Learning tutorial." name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>Underfitting and Overfitting Exercise | Visions, Voices, Data</title>
<link href="../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="../../../rss.xml" hreflang="en" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/underfitting-and-overfitting-exercise/" rel="canonical"><!--[if lt IE 9]><script src="../../../assets/js/html5.js"></script><![endif]-->
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script><!--
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/0.9.0/p5.min.js"
</script>
-->
<script async src="../../../assets/javascript/p5.min.js" type="text/javascript"></script>
<meta content="Cloistered Monkey" name="author">
<link href="/posts/tutorials/model-validation-exercise/" rel="prev" title="Model Validation Exercise" type="text/html">
<link href="/posts/tutorials/random-forests/" rel="next" title="Random Forests" type="text/html">
<meta content="Visions, Voices, Data" property="og:site_name">
<meta content="Underfitting and Overfitting Exercise" property="og:title">
<meta content="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/underfitting-and-overfitting-exercise/" property="og:url">
<meta content="Part 4 of the Kaggle Introduction to Machine Learning tutorial." property="og:description">
<meta content="article" property="og:type">
<meta content="2020-02-18T10:11:19-08:00" property="article:published_time">
<meta content="kaggle" property="article:tag">
<meta content="tutorial" property="article:tag">
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="/"><span id="blog-title">Visions, Voices, Data</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="/archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="/categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="/rss.xml">RSS feed</a></li>
<li class="nav-item dropdown"><a aria-expanded="false" aria-haspopup="true" class="nav-link dropdown-toggle" data-toggle="dropdown" href="#">Monkey Pages</a>
<div class="dropdown-menu"><a class="dropdown-item" href="https://necromuralist.github.io/">Cloistered Monkey</a> <a class="dropdown-item" href="https://necromuralist.github.io/Ape-Iron/">Ape Iron</a> <a class="dropdown-item" href="https://necromuralist.github.io/Beach-Pig-Thigh/">Beach Pig Rump & Thigh</a> <a class="dropdown-item" href="https://necromuralist.github.io/Bowling-For-Data/">Bowling For Data</a> <a class="dropdown-item" href="https://necromuralist.github.io/Give-The-Fish/">Give the Fish</a> <a class="dropdown-item" href="https://necromuralist.github.io/Neurotic-Networking/">Neurotic Networking</a> <a class="dropdown-item" href="https://necromuralist.github.io/Terribilis-Ludum/">Terribilis Ludum</a> <a class="dropdown-item" href="https://necromuralist.github.io/Visions-Voices-Data/">Visions, Voices, Data</a></div>
</li>
</ul>
<!-- DuckDuckGo custom search -->
<form action="https://duckduckgo.com/" class="navbar-form pull-left" id="search" method="get" name="search"><input name="sites" type="hidden" value="https://necromuralist.github.io/Visions-Voices-Data/"> <input name="k8" type="hidden" value="#444444"> <input name="k9" type="hidden" value="#D51920"> <input name="kt" type="hidden" value="h"> <input class="span2" maxlength="255" name="q" placeholder="Search…" type="text"> <input style="visibility: hidden;display:none" type="submit" value="DuckDuckGo Search"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right">
<li class="nav-item"><a class="nav-link" href="/posts/tutorials/underfitting-and-overfitting-exercise/index.org" id="sourcelink">Source</a></li>
</ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title" itemprop="headline name"><a class="u-url" href="/posts/tutorials/underfitting-and-overfitting-exercise/">Underfitting and Overfitting Exercise</a></h1>
<div class="metadata">
<p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="/posts/tutorials/underfitting-and-overfitting-exercise/" rel="bookmark"><time class="published dt-published" datetime="2020-02-18T10:11:19-08:00" itemprop="datePublished" title="2020-02-18 10:11">2020-02-18 10:11</time></a></p>
<p class="sourceline"><a class="sourcelink" href="/posts/tutorials/underfitting-and-overfitting-exercise/index.org">Source</a></p>
</div>
</header>
<div class="e-content entry-content" itemprop="articleBody text">
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#org1add555">Beginning</a>
<ul>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#org3dc7cea">Imports</a>
<ul>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#org50e1ee2">Python</a></li>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#org9851391">PyPi</a></li>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#org2b53621">Others</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#org8c682a3">Set Up</a>
<ul>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#org00d3af9">Plottting</a></li>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#org716bca6">The Timer</a></li>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#org1425828">Environment</a></li>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#org5678675">The Data</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#org94bf382">Middle</a>
<ul>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#org2ea9f52">Preliminary 1: Specify Prediction Target</a></li>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#orgd3b573c">Preliminary 2: Create X</a></li>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#orgb407781">Preliminary 3: Specify and Fit Model</a>
<ul>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#orgefc444a">A Linear Regression Model</a></li>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#org9a64f0e">Decision Tree</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#orge5110e3">Preliminary 4: Make Some Predictions</a></li>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#org45cad69">Preliminary 5: Calculate the Mean Absolute Error in Validation Data</a></li>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#org5e6418a">Step 1: Compare Different Tree Sizes</a></li>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#orgb124f4a">Step 2: Fit Model Using All Data</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/underfitting-and-overfitting-exercise/#org5c6a059">End</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org1add555">
<h2 id="org1add555">Beginning</h2>
<div class="outline-text-2" id="text-org1add555">
<p>This is the fourth part of kaggle's <a href="https://www.kaggle.com/learn/intro-to-machine-learning">Introduction to Machine Learning</a> tutorial - Overfitting and Underfitting.</p>
</div>
<div class="outline-3" id="outline-container-org3dc7cea">
<h3 id="org3dc7cea">Imports</h3>
<div class="outline-text-3" id="text-org3dc7cea"></div>
<div class="outline-4" id="outline-container-org50e1ee2">
<h4 id="org50e1ee2">Python</h4>
<div class="outline-text-4" id="text-org50e1ee2">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">argparse</span> <span class="kn">import</span> <span class="n">Namespace</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org9851391">
<h4 id="org9851391">PyPi</h4>
<div class="outline-text-4" id="text-org9851391">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>

<span class="kn">import</span> <span class="nn">hvplot.pandas</span>
<span class="kn">import</span> <span class="nn">pandas</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org2b53621">
<h4 id="org2b53621">Others</h4>
<div class="outline-text-4" id="text-org2b53621">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">graeae</span> <span class="kn">import</span> <span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">EnvironmentLoader</span><span class="p">,</span> <span class="n">Timer</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-org8c682a3">
<h3 id="org8c682a3">Set Up</h3>
<div class="outline-text-3" id="text-org8c682a3"></div>
<div class="outline-4" id="outline-container-org00d3af9">
<h4 id="org00d3af9">Plottting</h4>
<div class="outline-text-4" id="text-org00d3af9">
<div class="highlight">
<pre><span></span><span class="n">SLUG</span> <span class="o">=</span> <span class="s2">"underfitting-and-overfitting-exercise"</span>
<span class="n">OUTPUT_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"../../files/posts/tutorials/"</span><span class="p">)</span><span class="o">/</span><span class="n">SLUG</span>
<span class="n">Embed</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">EmbedHoloviews</span><span class="p">,</span> <span class="n">folder_path</span><span class="o">=</span><span class="n">OUTPUT_PATH</span><span class="p">)</span>
<span class="n">Plot</span> <span class="o">=</span> <span class="n">Namespace</span><span class="p">(</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">800</span><span class="p">,</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org716bca6">
<h4 id="org716bca6">The Timer</h4>
<div class="outline-text-4" id="text-org716bca6">
<div class="highlight">
<pre><span></span><span class="n">TIMER</span> <span class="o">=</span> <span class="n">Timer</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org1425828">
<h4 id="org1425828">Environment</h4>
<div class="outline-text-4" id="text-org1425828">
<div class="highlight">
<pre><span></span><span class="n">ENVIRONMENT</span> <span class="o">=</span> <span class="n">EnvironmentLoader</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org5678675">
<h4 id="org5678675">The Data</h4>
<div class="outline-text-4" id="text-org5678675">
<div class="highlight">
<pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="n">Path</span><span class="p">(</span><span class="n">ENVIRONMENT</span><span class="p">[</span><span class="s2">"HOUSE-PRICES-IOWA"</span><span class="p">])</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span><span class="o">/</span><span class="s2">"train.csv"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org94bf382">
<h2 id="org94bf382">Middle</h2>
<div class="outline-text-2" id="text-org94bf382"></div>
<div class="outline-3" id="outline-container-org2ea9f52">
<h3 id="org2ea9f52">Preliminary 1: Specify Prediction Target</h3>
<div class="outline-text-3" id="text-org2ea9f52">
<p>Select the target variable, which corresponds to the sales price. Save this to a new variable called `y`. You'll need to print a list of the columns to find the name of the column you need.</p>
<p>Our target is <i>SalePrice</i>.</p>
<div class="highlight">
<pre><span></span><span class="n">Y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">SalePrice</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgd3b573c">
<h3 id="orgd3b573c">Preliminary 2: Create X</h3>
<div class="outline-text-3" id="text-orgd3b573c">
<blockquote>
<p>Now you will create a DataFrame called `X` holding the predictive features.</p>
<p>Since you want only some columns from the original data, you'll first create a list with the names of the columns you want in `X`.</p>
<p>You'll use just the following columns in the list (you can copy and paste the whole list to save some typing, though you'll still need to add quotes):</p>
<ul class="org-ul">
<li>LotArea</li>
<li>YearBuilt</li>
<li>1stFlrSF</li>
<li>2ndFlrSF</li>
<li>FullBath</li>
<li>BedroomAbvGr</li>
<li>TotRmsAbvGrd</li>
</ul>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">FEATURES</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">"LotArea"</span><span class="p">,</span>
    <span class="s2">"YearBuilt"</span><span class="p">,</span>
    <span class="s2">"1stFlrSF"</span><span class="p">,</span>
    <span class="s2">"2ndFlrSF"</span><span class="p">,</span>
    <span class="s2">"FullBath"</span><span class="p">,</span>
    <span class="s2">"BedroomAbvGr"</span><span class="p">,</span>
    <span class="s2">"TotRmsAbvGrd"</span><span class="p">,</span>
<span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">FEATURES</span><span class="p">]</span>
</pre></div>
<p>Split up the data into training and validation sets.</p>
<div class="highlight">
<pre><span></span><span class="n">x_train</span><span class="p">,</span> <span class="n">x_validate</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_validate</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-orgb407781">
<h3 id="orgb407781">Preliminary 3: Specify and Fit Model</h3>
<div class="outline-text-3" id="text-orgb407781"></div>
<div class="outline-4" id="outline-container-orgefc444a">
<h4 id="orgefc444a">A Linear Regression Model</h4>
<div class="outline-text-4" id="text-orgefc444a">
<p>As a baseline, I'll fit a simple <a href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html">Linear Regression</a> (ordinary-least-squares) model.</p>
<div class="highlight">
<pre><span></span><span class="n">regression</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">regression</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2"> (+/- </span><span class="si">{</span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">scores</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">)"</span><span class="p">)</span>
<span class="n">regression</span> <span class="o">=</span> <span class="n">regression</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Training R^2: </span><span class="si">{</span><span class="n">regression</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="w"> </span><span class="n">y_train</span><span class="p">)</span><span class="si">:</span><span class="s2"> 0.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Validation R^2: </span><span class="si">{</span><span class="n">regression</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_validate</span><span class="p">,</span><span class="w"> </span><span class="n">y_validate</span><span class="p">)</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
0.66 (+/- 0.17)
Training R^2:  0.68
Validation R^2: 0.77
</pre></div>
</div>
<div class="outline-4" id="outline-container-org9a64f0e">
<h4 id="org9a64f0e">Decision Tree</h4>
<div class="outline-text-4" id="text-org9a64f0e">
<blockquote>
<p>Create a <code>DecisionTreeRegressor</code> and save it as <code>iowa_model</code>. Ensure you've done the relevant import from sklearn to run this command.</p>
<p>Then fit the model you just created using the data in <code>X</code> and <code>y</code> that you saved above.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">()</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2"> (+/- </span><span class="si">{</span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">scores</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">)"</span><span class="p">)</span>

<span class="n">tree</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Training R^2: </span><span class="si">{</span><span class="n">tree</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="w"> </span><span class="n">y_train</span><span class="p">)</span><span class="si">:</span><span class="s2"> 0.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Validation R^2: </span><span class="si">{</span><span class="n">tree</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_validate</span><span class="p">,</span><span class="w"> </span><span class="n">y_validate</span><span class="p">)</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
0.54 (+/- 0.32)
Training R^2:  1.00
Validation R^2: 0.75
</pre>
<p>So our linear regression actually does better than the tree does. It looks like the tree might be overfitting on the training data.</p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orge5110e3">
<h3 id="orge5110e3">Preliminary 4: Make Some Predictions</h3>
<div class="outline-text-3" id="text-orge5110e3">
<div class="highlight">
<pre><span></span><span class="n">tree_predict</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_validate</span><span class="p">)</span>
<span class="n">regression_predict</span> <span class="o">=</span> <span class="n">regression</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_validate</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="outline-3" id="outline-container-org45cad69">
<h3 id="org45cad69">Preliminary 5: Calculate the Mean Absolute Error in Validation Data</h3>
<div class="outline-text-3" id="text-org45cad69">
<div class="highlight">
<pre><span></span><span class="n">tree_mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_validate</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">tree_predict</span><span class="p">)</span>
<span class="n">regression_mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="o">=</span><span class="n">y_validate</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">=</span><span class="n">regression_predict</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Tree MAE: </span><span class="si">{</span><span class="n">tree_mae</span><span class="si">:</span><span class="s2"> 0.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Regression MAE: </span><span class="si">{</span><span class="n">regression_mae</span><span class="si">:</span><span class="s2"> 0.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
Tree MAE:  29371.52
Regression MAE:  27228.88
</pre>
<p>The tree's error is a little higher than the regression line's.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org5e6418a">
<h3 id="org5e6418a">Step 1: Compare Different Tree Sizes</h3>
<div class="outline-text-3" id="text-org5e6418a">
<blockquote>
<p>Write a loop that tries the following values for <b>max_leaf_nodes</b> from a set of possible values.</p>
<p>Call the <b>get_mae</b> function on each value of max_leaf_nodes. Store the output in some way that allows you to select the value of <code>max_leaf_nodes</code> that gives the most accurate model on your data.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="k">def</span> <span class="nf">get_mae</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="p">,</span> <span class="n">train_X</span><span class="o">=</span><span class="n">x_train</span><span class="p">,</span> <span class="n">val_X</span><span class="o">=</span><span class="n">x_validate</span><span class="p">,</span> <span class="n">train_y</span><span class="o">=</span><span class="n">y_train</span><span class="p">,</span> <span class="n">val_y</span><span class="o">=</span><span class="n">y_validate</span><span class="p">):</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="o">=</span><span class="n">max_leaf_nodes</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_X</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>
    <span class="n">preds_val</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">val_X</span><span class="p">)</span>
    <span class="n">mae</span> <span class="o">=</span> <span class="n">mean_absolute_error</span><span class="p">(</span><span class="n">val_y</span><span class="p">,</span> <span class="n">preds_val</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mae</span>
</pre></div>
<blockquote>
<p>Write a loop to find the ideal tree size from <code>candidate_max_leaf_nodes</code>.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">candidate_max_leaf_nodes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">250</span><span class="p">,</span> <span class="mi">500</span><span class="p">]</span>
<span class="n">outcomes</span> <span class="o">=</span> <span class="p">[(</span><span class="n">get_mae</span><span class="p">(</span><span class="n">nodes</span><span class="p">),</span> <span class="n">nodes</span><span class="p">)</span> <span class="k">for</span> <span class="n">nodes</span> <span class="ow">in</span> <span class="n">candidate_max_leaf_nodes</span><span class="p">]</span>
<span class="n">best</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">outcomes</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">best</span><span class="p">)</span>
<span class="n">best_tree_size</span> <span class="o">=</span> <span class="n">best</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
<pre class="example">
(27282.50803885739, 100)
</pre>
<div class="highlight">
<pre><span></span><span class="n">mae</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">nodes</span><span class="o">=</span><span class="n">candidate_max_leaf_nodes</span><span class="p">,</span> <span class="n">mae</span> <span class="o">=</span> <span class="p">[</span><span class="n">outcome</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">outcome</span> <span class="ow">in</span> <span class="n">outcomes</span><span class="p">]))</span>
<span class="n">plot</span> <span class="o">=</span> <span class="n">mae</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"nodes"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"mae"</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">"Node Mean Absolute Error"</span><span class="p">,</span>
                                           <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
                                           <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">)</span>
<span class="n">source</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"node_mean_absolute_error"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">source</span><span class="p">)</span>
</pre></div>
: <object data="/posts/tutorials/underfitting-and-overfitting-exercise/node_mean_absolute_error.html" height="800" style="width:100%" type="text/html">:
<p>Figure Missing</p>
:</object>
<p>Looking at the plot you can see that the error drops until you hit 100 nodes and then begins to rise again as it overfits the data with more nodes.</p>
<p>Let's see how much this improves our model using \(r^2\).</p>
<div class="highlight">
<pre><span></span><span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span><span class="o">=</span><span class="n">best_tree_size</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2"> (+/- </span><span class="si">{</span><span class="mi">2</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">scores</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">)"</span><span class="p">)</span>

<span class="n">tree</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Training R^2: </span><span class="si">{</span><span class="n">tree</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="w"> </span><span class="n">y_train</span><span class="p">)</span><span class="si">:</span><span class="s2"> 0.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Validation R^2: </span><span class="si">{</span><span class="n">tree</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_validate</span><span class="p">,</span><span class="w"> </span><span class="n">y_validate</span><span class="p">)</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
<pre class="example">
0.60 (+/- 0.26)
Training R^2:  0.93
Validation R^2: 0.76
</pre>
<p>We've improved it slightly, it's probably still overfitting the model but not as much.</p>
</div>
</div>
<div class="outline-3" id="outline-container-orgb124f4a">
<h3 id="orgb124f4a">Step 2: Fit Model Using All Data</h3>
<div class="outline-text-3" id="text-orgb124f4a">
<blockquote>
<p>You know the best tree size. If you were going to deploy this model in practice, you would make it even more accurate by using all of the data and keeping that tree size. That is, you don't need to hold out the validation data now that you've made all your modeling decisions.</p>
</blockquote>
<div class="highlight">
<pre><span></span><span class="n">final_model</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_leaf_nodes</span> <span class="o">=</span> <span class="n">best_tree_size</span><span class="p">)</span>
<span class="n">final_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="n">predictions_first</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">predictions_final</span> <span class="o">=</span> <span class="n">final_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="n">x_y_tree</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">predicted</span><span class="o">=</span><span class="n">predictions_first</span><span class="p">,</span> <span class="n">actual</span><span class="o">=</span><span class="n">Y</span><span class="p">))</span>
<span class="n">x_y_line</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">predicted</span><span class="o">=</span><span class="n">predictions_final</span><span class="p">,</span> <span class="n">actual</span><span class="o">=</span><span class="n">Y</span><span class="p">))</span>
<span class="n">ideal</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">Y</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">Y</span><span class="p">))</span>

<span class="n">tree_plot</span> <span class="o">=</span> <span class="n">x_y_tree</span><span class="o">.</span><span class="n">hvplot</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"actual"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"predicted"</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Default"</span><span class="p">)</span>
<span class="n">line_plot</span> <span class="o">=</span> <span class="n">x_y_line</span><span class="o">.</span><span class="n">hvplot</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"actual"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"predicted"</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Tuned"</span><span class="p">)</span>
<span class="n">ideal_plot</span> <span class="o">=</span> <span class="n">ideal</span><span class="o">.</span><span class="n">hvplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">"x"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">"y"</span><span class="p">)</span>
<span class="n">plot</span> <span class="o">=</span> <span class="p">(</span><span class="n">tree_plot</span> <span class="o">*</span> <span class="n">line_plot</span> <span class="o">*</span> <span class="n">ideal_plot</span><span class="p">)</span><span class="o">.</span><span class="n">opts</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s2">"Decision Tree Actual Vs Predictions"</span><span class="p">,</span>
                                    <span class="n">width</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">width</span><span class="p">,</span>
                                    <span class="n">height</span><span class="o">=</span><span class="n">Plot</span><span class="o">.</span><span class="n">height</span><span class="p">)</span>
<span class="n">source</span> <span class="o">=</span> <span class="n">Embed</span><span class="p">(</span><span class="n">plot</span><span class="o">=</span><span class="n">plot</span><span class="p">,</span> <span class="n">file_name</span><span class="o">=</span><span class="s2">"decision_tree_actual_vs_predicted"</span><span class="p">)()</span>
</pre></div>
<div class="highlight">
<pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">source</span><span class="p">)</span>
</pre></div>
: <object data="/posts/tutorials/underfitting-and-overfitting-exercise/decision_tree_actual_vs_predicted.html" height="800" style="width:100%" type="text/html">:
<p>Figure Missing</p>
:</object>
<p>The tuned model seems closer to the predicted.</p>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org5c6a059">
<h2 id="org5c6a059">End</h2>
<div class="outline-text-2" id="text-org5c6a059">
<p>That's a basic way to tune hyperparameters to improve your model. But our decision tree still isn't doing as well as the regression line. Next up we'll try an ensemble method - Random Forests.</p>
</div>
</div>
</div>
<aside class="postpromonav">
<nav>
<ul class="tags" itemprop="keywords">
<li><a class="tag p-category" href="/categories/kaggle/" rel="tag">kaggle</a></li>
<li><a class="tag p-category" href="/categories/tutorial/" rel="tag">tutorial</a></li>
</ul>
<ul class="pager hidden-print">
<li class="previous"><a href="/posts/tutorials/model-validation-exercise/" rel="prev" title="Model Validation Exercise">Previous post</a></li>
<li class="next"><a href="/posts/tutorials/random-forests/" rel="next" title="Random Forests">Next post</a></li>
</ul>
</nav>
</aside>
</article>
<!--End of body content-->
<footer id="footer">Contents © 2023 <a href="mailto:cloisteredmonkey.jmark@slmail.me">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a></footer>
</div>
</div>
<script src="/assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
</script> 
</body>
</html>
