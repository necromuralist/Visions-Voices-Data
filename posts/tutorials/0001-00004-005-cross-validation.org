#+BEGIN_COMMENT
.. title: Cross Validation
.. slug: cross-validation
.. date: 2020-02-20 21:15:04 UTC-08:00
.. tags: tutorial,cross-validation
.. category: Tutorial
.. link: 
.. description: Kaggle's intermediate Machine Learning tutorial on Cross-Validation. 
.. type: text
.. status: 
.. updated: 

#+END_COMMENT
#+OPTIONS: ^:{}
#+TOC: headlines 5
#+PROPERTY: header-args :session /run/user/1000/jupyter/kernel-a8bf7909-7263-4fb6-bcf3-3e55bfa79017.json
* Beginning
#+begin_quote
In this exercise, you will leverage what you've learned to tune a machine learning model with **cross-validation**.
#+end_quote
** Imports
*** Python
#+begin_src python :results none
from argparse import Namespace
from functools import partial
from pathlib import Path
#+end_src
*** PyPi
#+begin_src python :results none
from eli5.sklearn import PermutationImportance
from matplotlib import pyplot

from sklearn.compose import ColumnTransformer
from sklearn.ensemble import RandomForestRegressor
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
from sklearn.impute import SimpleImputer
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import cross_val_score, train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder

from tabulate import tabulate

import eli5
import pandas
import shap
#+end_src
*** Others
#+begin_src python :results none
from graeae import CountPercentage, EmbedHoloviews, EnvironmentLoader, Timer
#+end_src
** Set Up
*** Table
#+begin_src python :results none
TABLE = partial(tabulate, tablefmt="orgtbl", showindex=False, headers="keys")
#+end_src
*** Plottting
#+begin_src python :results none
SLUG = "cross-validation"
OUTPUT_PATH = Path("../../files/posts/tutorials/")/SLUG
if not OUTPUT_PATH.is_dir():
    OUTPUT_PATH.mkdir()
Embed = partial(EmbedHoloviews, folder_path=OUTPUT_PATH)
Plot = Namespace(
    height=800,
    width=1000,
)
#+end_src
*** The Timer
#+begin_src python :results none
TIMER = Timer()
#+end_src
*** Environment
#+begin_src python :results none
ENVIRONMENT = EnvironmentLoader()
#+end_src
*** The Data
#+begin_src python :results none
DATA_PATH = Path(ENVIRONMENT["HOUSE-PRICES-IOWA"]).expanduser()
train_data = pandas.read_csv(
    DATA_PATH/"train.csv", index_col="Id")

test_data = pandas.read_csv(
    DATA_PATH/"test.csv", index_col="Id"
)
X_test = test_data
#+end_src
*** Some Constants
#+begin_src python :results none
Data = Namespace(
    target="SalePrice",
    train_size=0.8,
    test_size=0.2,
    random_seed=0,
)
#+end_src
** Setup The Data
   Split up the target and features.
#+begin_src python :results none
assert not train_data[Data.target].hasnans
y = train_data[Data.target]
X = train_data.drop([Data.target], axis="columns")
#+end_src

#+begin_src python :results none
X_train, X_validate, y_train, y_validate = train_test_split(
    X, y,
    train_size=Data.train_size, test_size=Data.test_size,
    random_state=Data.random_seed)
#+end_src
*** Drop Categorical Columns
#+begin_src python :results output :exports both
numeric_columns = [column for column in X_train.columns if not X_train[column].dtype == "object"]
rows_0, columns_0 = X_train.shape
X_train = X_train[numeric_columns].copy()
row, columns = X_train.shape
print(f"Keeping {columns} columns, dropped ({columns_0 - columns})")
X_validate = X_validate[numeric_columns.copy()]
#+end_src

#+RESULTS:
: Keeping 36 columns, dropped (43)
** Some Pipelines
#+begin_quote
So far, you've learned how to build pipelines with scikit-learn.  For instance, the pipeline below will use [[https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html][=SimpleImputer()=]] to replace missing values in the data, before using [[https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html][=RandomForestRegressor()=]] to train a random forest model to make predictions.  We set the number of trees in the random forest model with the =n_estimators= parameter, and setting =random_state= ensures reproducibility.
#+end_quote

#+begin_src python :results none
pipeline = Pipeline(steps=[
    ('preprocessor', SimpleImputer()),
    ('model', RandomForestRegressor(n_estimators=50, random_state=Data.random_seed))
])
#+end_src

#+begin_quote
You have also learned how to use pipelines in cross-validation.  The code below uses the [[https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html][=cross_val_score()=]] function to obtain the mean absolute error (MAE), averaged across five different folds.  Recall we set the number of folds with the =cv= parameter.
#+end_quote

#+begin_src python :results output :exports both
# Multiply by -1 since sklearn calculates *negative* MAE
scores = -1 * cross_val_score(pipeline, X_train, y_train,
                              cv=5,
                              scoring='neg_mean_absolute_error')

print("Average MAE score:", scores.mean())

#+end_src

#+RESULTS:
: Average MAE score: 18185.310086448284

*** Trim the columns
#+begin_src python :results none
# Select categorical columns with relatively low cardinality (convenient but arbitrary)
categorical_columns = [column for column in X_train.columns if
                       X_train[column].nunique() < 10 and 
                       X_train[column].dtype == object]

# Select numerical columns
numerical_columns = [column for column in X_train.columns if 
                     X_train[column].dtype in ['int64', 'float64']]

# Keep selected columns only
columns = categorical_columns + numerical_columns
X_train = X_train[columns].copy()
X_validate = X_validate[columns].copy()
X_test = X_test[columns].copy()
#+end_src
* Middle
** Preprocess Data and Train the Model
   The missing numeric values will be filled in with a simple imputer. When the =strategy= is set to constant then it will fill missing values with a single value (which is 0 by default).

#+begin_src python :results none
numerical_transformer = SimpleImputer(strategy='constant')
#+end_src

Now the categorical data transformer. We'll use the most frequent value in any column with missing values to fill them in and the do one-hot encoding.

#+begin_src python :results none
categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])
#+end_src

Now we can bundle them together into a single transformer.
#+begin_src python :results none
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_columns),
        ('cat', categorical_transformer, categorical_columns)
    ])
#+end_src

*** Define The Model
#+begin_src python :results none
model = RandomForestRegressor(n_estimators=100, random_state=0)
#+end_src
*** Build the Pipeline
#+begin_src python :results none
pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                      ('model', model)
                     ])
#+end_src
*** Fit the Model
#+begin_src python :results none
# Preprocessing of training data, fit model 
pipeline.fit(X_train, y_train)
#+end_src
*** Score the Model
#+begin_src python :results output :exports both
preds = pipeline.predict(X_validate)

print(f"MAE: {mean_absolute_error(y_validate, preds):,}")
#+end_src

#+RESULTS:
: MAE: 17,861.780102739725

** Improving the Performance
#+begin_quote
Now, it's your turn!  In the code cell below, define your own preprocessing steps and random forest model.  Fill in values for the following variables:
 - =numerical_transformer=
 - =categorical_transformer=
 - =model=
#+end_quote

#+begin_src python :results none
numerical_transformer = IterativeImputer(random_state=Data.random_seed)
#+end_src

I'll use the same categorical imputer.

#+begin_src python :results none
categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])
#+end_src

And now we bundle them together.
#+begin_src python :results none
preprocessor = ColumnTransformer(
    transformers=[
        ('numeric', numerical_transformer, numerical_columns),
        ('categorical', categorical_transformer, categorical_columns)
    ])
#+end_src

Now build and train the model.

#+begin_src python :results none
model = RandomForestRegressor(n_estimators=50, max_depth=60, random_state=0)
pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                           ('model', model)
                           ])
pipeline.fit(X_train, y_train)
#+end_src

#+begin_src python :results output raw :exports both
predictions = pipeline.predict(X_validate)

print(f"MAE: {mean_absolute_error(y_validate, predictions):,}")
#+end_src

#+RESULTS:
: MAE: 17,710.33568493151

So we improved slightly, but we're still not doing as well as with the numeric only dataset.

** SHAP
#+begin_src python :results output :exports both
with TIMER:
    training = X_train[numerical_columns + categorical_columns]
    data = preprocessor.fit_transform(training)
    columns = (numerical_columns
               + list(preprocessor.named_transformers_["categorical"]["onehot"].get_feature_names()))
    data = pandas.DataFrame(
        data,
        columns=columns)
    explainer = shap.TreeExplainer(model)
    shap_values = explainer.shap_values(data)
#+end_src

#+RESULTS:
: 2020-02-26 13:41:13,081 graeae.timers.timer start: Started: 2020-02-26 13:41:13.080281
: Setting feature_perturbation = "tree_path_dependent" because no background data was given.
: 2020-02-26 13:41:43,900 graeae.timers.timer end: Ended: 2020-02-26 13:41:43.900277
: 2020-02-26 13:41:43,901 graeae.timers.timer end: Elapsed: 0:00:30.819996

#+begin_src python :results output :exports both
shap.summary_plot(shap_values, data)
figure = pyplot.gcf()
output = "shap_summary.png"

figure.savefig(OUTPUT_PATH/output)
print(f"[[file:{output}]]")
#+end_src

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/01255561813b70d3f5923ec3f7c33040efeabb42.png]]
: [[file:shap_summary.png]]
: <Figure size 432x288 with 0 Axes>
:END:

 [[file:shap_summary.png]]

#+begin_src python :results none
shap.initjs()
html = shap.force_plot(explainer.expected_value, shap_values, data)
output_file = "force_plot.html"
output = OUTPUT_PATH/output_file
with output.open("w") as writer:
    shap.save_html(writer, html, False)

print(f"""
,#+begin_export html
: <object type="text/html" data="{output_file}" style="width:100%" height=800>
:   <p>Figure Missing</p>
: </object>
,#+end_export
""")
#+end_src

 #+begin_export html
 : <object type="text/html" data="force_plot.html" style="width:100%" height=800>
 :   <p>Figure Missing</p>
 : </object>
 #+end_export
 
* Raw
#+begin_example


# # Step 1: Write a useful function
# 
# In this exercise, you'll use cross-validation to select parameters for a machine learning model.
# 
# Begin by writing a function =get_score()= that reports the average (over three cross-validation folds) MAE of a machine learning pipeline that uses:
# - the data in =X= and =y= to create folds,
# - =SimpleImputer()= (with all parameters left as default) to replace missing values, and
# - =RandomForestRegressor()= (with =random_state=0=) to fit a random forest model.
# 
# The =n_estimators= parameter supplied to =get_score()= is used when setting the number of trees in the random forest model.  

# In[ ]:


def get_score(n_estimators):
    """Return the average MAE over 3 CV folds of random forest model.
    
    Keyword argument:
    n_estimators -- the number of trees in the forest
    """
    # Replace this body with your own code
    pass

# Check your answer
step_1.check()


# In[ ]:


# Lines below will give you a hint or solution code
#step_1.hint()
#step_1.solution()


# # Step 2: Test different parameter values
# 
# Now, you will use the function that you defined in Step 1 to evaluate the model performance corresponding to eight different values for the number of trees in the random forest: 50, 100, 150, ..., 300, 350, 400.
# 
# Store your results in a Python dictionary =results=, where =results[i]= is the average MAE returned by =get_scores(i)=.

# In[ ]:


results = ____ # Your code here

# Check your answer
step_2.check()


# In[ ]:


# Lines below will give you a hint or solution code
#step_2.hint()
#step_2.solution()


# # Step 3: Find the best parameter value
# 
# Use the next cell to visualize your results from Step 2.  Run the code without changes.

# In[ ]:


import matplotlib.pyplot as plt
get_ipython().run_line_magic('matplotlib', 'inline')

plt.plot(results.keys(), results.values())
plt.show()


# Given the results, which value for =n_estimators= seems best for the random forest model?  Use your answer to set the value of =n_estimators_best=.

# In[ ]:


n_estimators_best = ____

# Check your answer
step_3.check()


# In[ ]:


# Lines below will give you a hint or solution code
#step_3.hint()
#step_3.solution()


# In this exercise, you have explored one method for choosing appropriate parameters in a machine learning model.  
# 
# If you'd like to learn more about [hyperparameter optimization](https://en.wikipedia.org/wiki/Hyperparameter_optimization), you're encouraged to start with **grid search**, which is a straightforward method for determining the best _combination_ of parameters for a machine learning model.  Thankfully, scikit-learn also contains a built-in function [=GridSearchCV()=](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) that can make your grid search code very efficient!
# 
# # Keep going
# 
# Continue to learn about **[gradient boosting](https://www.kaggle.com/alexisbcook/xgboost)**, a powerful technique that achieves state-of-the-art results on a variety of datasets.

# ---
# **[Intermediate Machine Learning Home Page](https://www.kaggle.com/learn/intermediate-machine-learning)**
# 
# 
# 
# 
# 
# *Have questions or comments? Visit the [Learn Discussion forum](https://www.kaggle.com/learn-forum) to chat with other Learners.*
#+end_example
