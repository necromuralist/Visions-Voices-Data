<!DOCTYPE html>
<html lang="en" prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#">
<head>
<meta charset="utf-8">
<meta content="The Kaggle tutorial on Partial Dependence Plots." name="description">
<meta content="width=device-width, initial-scale=1" name="viewport">
<title>Partial Dependence Plots | Visions, Voices, Data</title>
<link href="../../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta content="#5670d4" name="theme-color">
<meta content="Nikola (getnikola.com)" name="generator">
<link href="../../../rss.xml" hreflang="en" rel="alternate" title="RSS" type="application/rss+xml">
<link href="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/" rel="canonical"><!--[if lt IE 9]><script src="../../../assets/js/html5.js"></script><![endif]-->
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML" type="text/javascript"></script><!--
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/0.9.0/p5.min.js"
</script>
-->
<script async src="../../../assets/javascript/p5.min.js" type="text/javascript"></script>
<meta content="Cloistered Monkey" name="author">
<link href="/posts/tutorials/exercise-in-permutation-importance/" rel="prev" title="Exercise in Permutation Importance" type="text/html">
<link href="/posts/tutorials/exercise-in-partial-dependence-plots/" rel="next" title="Exercise In Partial Dependence Plots" type="text/html">
<meta content="Visions, Voices, Data" property="og:site_name">
<meta content="Partial Dependence Plots" property="og:title">
<meta content="https://necromuralist.github.io/Visions-Voices-Data/posts/tutorials/partial-dependence-plots/" property="og:url">
<meta content="The Kaggle tutorial on Partial Dependence Plots." property="og:description">
<meta content="article" property="og:type">
<meta content="2020-02-08T12:48:50-08:00" property="article:published_time">
<meta content="interpret" property="article:tag">
<meta content="machine learning" property="article:tag">
<meta content="tutorial" property="article:tag">
<meta content="visualization" property="article:tag">
</head>
<body>
<a class="sr-only sr-only-focusable" href="#content">Skip to main content</a> <!-- Menubar -->
<nav class="navbar navbar-expand-md static-top mb-4 navbar-light bg-light">
<div class="container"><!-- This keeps the margins nice -->
 <a class="navbar-brand" href="/"><span id="blog-title">Visions, Voices, Data</span></a> <button aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler" data-target="#bs-navbar" data-toggle="collapse" type="button"><span class="navbar-toggler-icon"></span></button>
<div class="collapse navbar-collapse" id="bs-navbar">
<ul class="navbar-nav mr-auto">
<li class="nav-item"><a class="nav-link" href="/archive.html">Archive</a></li>
<li class="nav-item"><a class="nav-link" href="/categories/">Tags</a></li>
<li class="nav-item"><a class="nav-link" href="/rss.xml">RSS feed</a></li>
<li class="nav-item dropdown"><a aria-expanded="false" aria-haspopup="true" class="nav-link dropdown-toggle" data-toggle="dropdown" href="#">Pages</a>
<div class="dropdown-menu"><a class="dropdown-item" href="https://necromuralist.github.io/">Cloistered Monkey</a> <a class="dropdown-item" href="/pages/giss/giss-yearly-anomalies-by-climate-zone">GISS Anomalies</a></div>
</li>
</ul>
<!-- DuckDuckGo custom search -->
<form action="https://duckduckgo.com/" class="navbar-form pull-left" id="search" method="get" name="search"><input name="sites" type="hidden" value="https://necromuralist.github.io/Visions-Voices-Data/"> <input name="k8" type="hidden" value="#444444"> <input name="k9" type="hidden" value="#D51920"> <input name="kt" type="hidden" value="h"> <input class="span2" maxlength="255" name="q" placeholder="Search…" type="text"> <input style="visibility: hidden;display:none" type="submit" value="DuckDuckGo Search"></form>
<!-- End of custom search -->
<ul class="navbar-nav navbar-right">
<li class="nav-item"><a class="nav-link" href="/posts/tutorials/partial-dependence-plots/index.org" id="sourcelink">Source</a></li>
</ul>
</div>
<!-- /.navbar-collapse --></div>
<!-- /.container --></nav>
<!-- End of Menubar -->
<div class="container" id="content" role="main">
<div class="body-content"><!--Body content-->
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article">
<header>
<h1 class="p-name entry-title" itemprop="headline name"><a class="u-url" href="/posts/tutorials/partial-dependence-plots/">Partial Dependence Plots</a></h1>
<div class="metadata">
<p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">Cloistered Monkey</span></p>
<p class="dateline"><a href="/posts/tutorials/partial-dependence-plots/" rel="bookmark"><time class="published dt-published" datetime="2020-02-08T12:48:50-08:00" itemprop="datePublished" title="2020-02-08 12:48">2020-02-08 12:48</time></a></p>
<p class="sourceline"><a class="sourcelink" href="/posts/tutorials/partial-dependence-plots/index.org">Source</a></p>
</div>
</header>
<div class="e-content entry-content" itemprop="articleBody text">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="/posts/tutorials/partial-dependence-plots/#org9058cd8">Beginning</a>
<ul>
<li><a href="/posts/tutorials/partial-dependence-plots/#org7d925ee">What is this about?</a></li>
<li><a href="/posts/tutorials/partial-dependence-plots/#org6ccad9b">How does it work?</a></li>
<li><a href="/posts/tutorials/partial-dependence-plots/#orgff0adba">Imports</a>
<ul>
<li><a href="/posts/tutorials/partial-dependence-plots/#org642eb62">Python</a></li>
<li><a href="/posts/tutorials/partial-dependence-plots/#org2fc8359">PyPi</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/partial-dependence-plots/#orgc45f027">Set Up</a>
<ul>
<li><a href="/posts/tutorials/partial-dependence-plots/#orgb644dc4">Plotting</a></li>
<li><a href="/posts/tutorials/partial-dependence-plots/#org254a07f">The Data</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="/posts/tutorials/partial-dependence-plots/#org6600694">Middle</a>
<ul>
<li><a href="/posts/tutorials/partial-dependence-plots/#orge4cff41">A Decision Tree Model</a>
<ul>
<li><a href="/posts/tutorials/partial-dependence-plots/#org89c8dba">Visualizing the Decision Tree</a></li>
<li><a href="/posts/tutorials/partial-dependence-plots/#orga078313">Partial Dependency Plot</a></li>
<li><a href="/posts/tutorials/partial-dependence-plots/#orgcf56137">Distance Covered</a></li>
</ul>
</li>
<li><a href="/posts/tutorials/partial-dependence-plots/#orgd0de1c5">A Random Forest Model</a></li>
<li><a href="/posts/tutorials/partial-dependence-plots/#orgc64d61e">2D Partial Dependence Plots</a>
<ul>
<li><a href="/posts/tutorials/partial-dependence-plots/#org7dad8a8">Forest From the Trees</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="/posts/tutorials/partial-dependence-plots/#orgc1be96d">End</a></li>
</ul>
</div>
</div>
<div class="outline-2" id="outline-container-org9058cd8">
<h2 id="org9058cd8">Beginning</h2>
<div class="outline-text-2" id="text-org9058cd8"></div>
<div class="outline-3" id="outline-container-org7d925ee">
<h3 id="org7d925ee">What is this about?</h3>
<div class="outline-text-3" id="text-org7d925ee">
<p>These are my notes/re-write of the <a href="https://www.kaggle.com/dansbecker/partial-plots">Partial Dependence Plots</a> tutorial on kaggle. Partial Dependence Plots are a complement to Permutation Importance in that Permutation Importance can tell you which features are contributing to the model but don't tell you how features change with different inputs. Given that they have the word "Plot" in their name you can guess that this is a visualization method and since humans have a hard time visualizing things with more than three dimensions, using them requires selecting a subset of features (or maybe just one feature) to visualize at a time, so the fact that Permutation Importance ranks features by their contribution might come in handy in deciding which features to use.</p>
</div>
</div>
<div class="outline-3" id="outline-container-org6ccad9b">
<h3 id="org6ccad9b">How does it work?</h3>
<div class="outline-text-3" id="text-org6ccad9b">
<p>In a simplistic view we might say that it takes input data and then repeatedly alters the values in our feature of choice, freezing the other values so that we can see how varying the feature changes the prediction. You can then repeat this for multiple rows of data and take the average prediction for each value of our feature.</p>
</div>
</div>
<div class="outline-3" id="outline-container-orgff0adba">
<h3 id="orgff0adba">Imports</h3>
<div class="outline-text-3" id="text-orgff0adba"></div>
<div class="outline-4" id="outline-container-org642eb62">
<h4 id="org642eb62">Python</h4>
<div class="outline-text-4" id="text-org642eb62">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="kn">import</span> <span class="nn">os</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org2fc8359">
<h4 id="org2fc8359">PyPi</h4>
<div class="outline-text-4" id="text-org2fc8359">
<div class="highlight">
<pre><span></span><span class="kn">from</span> <span class="nn">dotenv</span> <span class="kn">import</span> <span class="n">load_dotenv</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span>
<span class="kn">from</span> <span class="nn">pdpbox</span> <span class="kn">import</span> <span class="n">pdp</span><span class="p">,</span> <span class="n">get_dataset</span><span class="p">,</span> <span class="n">info_plots</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">tree</span>

<span class="kn">import</span> <span class="nn">graphviz</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">pandas</span>
</pre></div>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orgc45f027">
<h3 id="orgc45f027">Set Up</h3>
<div class="outline-text-3" id="text-orgc45f027"></div>
<div class="outline-4" id="outline-container-orgb644dc4">
<h4 id="orgb644dc4">Plotting</h4>
<div class="outline-text-4" id="text-orgb644dc4">
<div class="highlight">
<pre><span></span><span class="n">SLUG</span> <span class="o">=</span> <span class="s2">"partial-dependence-plots"</span>
<span class="n">OUTPUT_PATH</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"../../files/posts/tutorials/"</span><span class="p">)</span><span class="o">/</span><span class="n">SLUG</span>
</pre></div>
</div>
</div>
<div class="outline-4" id="outline-container-org254a07f">
<h4 id="org254a07f">The Data</h4>
<div class="outline-text-4" id="text-org254a07f">
<div class="highlight">
<pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">"~/.env"</span><span class="p">)</span><span class="o">.</span><span class="n">expanduser</span><span class="p">()</span>
<span class="n">load_dotenv</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">override</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pandas</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">Path</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">"FIFA-2018"</span><span class="p">))</span><span class="o">.</span><span class="n">expanduser</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-org6600694">
<h2 id="org6600694">Middle</h2>
<div class="outline-text-2" id="text-org6600694"></div>
<div class="outline-3" id="outline-container-orge4cff41">
<h3 id="orge4cff41">A Decision Tree Model</h3>
<div class="outline-text-3" id="text-orge4cff41">
<p>The data is the same set from the Permutation Importance exercise (team data to predict whether one of them would become the <i>Budweiser Man of the Match</i>). Out initial model will be a shallow decision tree so that we can compare its structure to the plots.</p>
<div class="highlight">
<pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s2">"Man of the Match"</span><span class="p">]</span> <span class="o">==</span> <span class="s2">"Yes"</span>
<span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="n">column</span> <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">data</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">numpy</span><span class="o">.</span><span class="n">int64</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>

<span class="n">x_train</span><span class="p">,</span> <span class="n">x_validate</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_validate</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">tree_model</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
<div class="outline-4" id="outline-container-org89c8dba">
<h4 id="org89c8dba">Visualizing the Decision Tree</h4>
<div class="outline-text-4" id="text-org89c8dba">
<div class="highlight">
<pre><span></span><span class="n">tree_graph</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">export_graphviz</span><span class="p">(</span><span class="n">tree_model</span><span class="p">,</span> <span class="n">out_file</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">feature_names</span><span class="o">=</span><span class="n">features</span><span class="p">)</span>
<span class="n">graph</span> <span class="o">=</span> <span class="n">graphviz</span><span class="o">.</span><span class="n">Source</span><span class="p">(</span><span class="n">tree_graph</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="s2">"decision_tree.dot"</span>
<span class="n">graph</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="n">OUTPUT_PATH</span><span class="o">/</span><span class="n">output</span><span class="p">,</span> <span class="n">format</span><span class="o">=</span><span class="s2">"png"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"[[file:{output}.png]]"</span><span class="p">)</span>
</pre></div>
<div class="figure">
<p><img alt="decision_tree.dot.png" src="/posts/tutorials/partial-dependence-plots/decision_tree.dot.png"></p>
</div>
</div>
</div>
<div class="outline-4" id="outline-container-orga078313">
<h4 id="orga078313">Partial Dependency Plot</h4>
<div class="outline-text-4" id="text-orga078313">
<p>To create the plot we can use the <a href="https://pdpbox.readthedocs.io/en/latest/">PDPBox library</a>.</p>
</div>
<ul class="org-ul">
<li><a id="org3e11fdc"></a>Create the Data to Plot<br>
<div class="outline-text-5" id="text-org3e11fdc">
<div class="highlight">
<pre><span></span><span class="n">FEATURE</span> <span class="o">=</span> <span class="s2">"Goal Scored"</span>
<span class="n">pdp_goals</span> <span class="o">=</span> <span class="n">pdp</span><span class="o">.</span><span class="n">pdp_isolate</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">tree_model</span><span class="p">,</span> <span class="n">dataset</span><span class="o">=</span><span class="n">x_validate</span><span class="p">,</span>
                            <span class="n">model_features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span> <span class="n">feature</span><span class="o">=</span><span class="n">FEATURE</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><a id="org80fc5bc"></a>Plot It<br>
<div class="outline-text-5" id="text-org80fc5bc">
<div class="highlight">
<pre><span></span><span class="n">pdp</span><span class="o">.</span><span class="n">pdp_plot</span><span class="p">(</span><span class="n">pdp_goals</span><span class="p">,</span> <span class="n">FEATURE</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="s2">"pdp_goals_scored.png"</span>
<span class="n">pyplot</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">OUTPUT_PATH</span><span class="o">/</span><span class="n">output</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"[[file:{output}]]"</span><span class="p">)</span>
</pre></div>
<div class="figure">
<p><img alt="pdp_goals_scored.png" src="/posts/tutorials/partial-dependence-plots/pdp_goals_scored.png"></p>
</div>
<p>Looking at the plot we can interpret it as saying that scoring that first goal is helpful in getting someone on the team the Man of the Match, but after that, more goals doesn't help. The PDPBox documentation has no real information about interpreting the output (or anything they provide, really), but according to the Kaggle tutorial the y-axis is the change in the prediction from the baseline as x changes.</p>
</div>
</li>
</ul>
</div>
<div class="outline-4" id="outline-container-orgcf56137">
<h4 id="orgcf56137">Distance Covered</h4>
<div class="outline-text-4" id="text-orgcf56137">
<p>We can also look at how much the distance the players cover on the field matters.</p>
<div class="highlight">
<pre><span></span><span class="n">FEATURE</span> <span class="o">=</span> <span class="s2">"Distance Covered (Kms)"</span>
<span class="n">pdp_distance</span> <span class="o">=</span> <span class="n">pdp</span><span class="o">.</span><span class="n">pdp_isolate</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">tree_model</span><span class="p">,</span> <span class="n">dataset</span><span class="o">=</span><span class="n">x_validate</span><span class="p">,</span>
                               <span class="n">model_features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span> <span class="n">feature</span><span class="o">=</span><span class="n">FEATURE</span><span class="p">)</span>
<span class="n">pdp</span><span class="o">.</span><span class="n">pdp_plot</span><span class="p">(</span><span class="n">pdp_distance</span><span class="p">,</span> <span class="n">FEATURE</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="s2">"pdp_distance.png"</span>
<span class="n">pyplot</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">OUTPUT_PATH</span><span class="o">/</span><span class="n">output</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"[[file:{output}]]"</span><span class="p">)</span>
</pre></div>
<div class="figure">
<p><img alt="pdp_distance.png" src="/posts/tutorials/partial-dependence-plots/pdp_distance.png"></p>
</div>
<p>It looks like there's one distance at which the probabilities increase and then going further doesn't matter.</p>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">pdp_distance</span><span class="o">.</span><span class="n">feature_grids</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
</pre></div>
<pre class="example">
102.0
</pre>
<p>So you want your team to cover at least 102 Kilometers, but covering more won't help you.</p>
</div>
</div>
</div>
<div class="outline-3" id="outline-container-orgd0de1c5">
<h3 id="orgd0de1c5">A Random Forest Model</h3>
<div class="outline-text-3" id="text-orgd0de1c5">
<p>The Decision Tree was useful because the simplicity made it easy to interpret, but an ensemble method like a Random Forest probably makes a better model so let's see what it reveals.</p>
<div class="highlight">
<pre><span></span><span class="n">forest</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">FEATURE</span> <span class="o">=</span> <span class="s2">"Goal Scored"</span>
<span class="n">pdp_goals</span> <span class="o">=</span> <span class="n">pdp</span><span class="o">.</span><span class="n">pdp_isolate</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">forest</span><span class="p">,</span> <span class="n">dataset</span><span class="o">=</span><span class="n">x_validate</span><span class="p">,</span>
                            <span class="n">model_features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span> <span class="n">feature</span><span class="o">=</span><span class="n">FEATURE</span><span class="p">)</span>
<span class="n">pdp</span><span class="o">.</span><span class="n">pdp_plot</span><span class="p">(</span><span class="n">pdp_goals</span><span class="p">,</span> <span class="n">FEATURE</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="s2">"pdp_forest_goals_scored.png"</span>
<span class="n">pyplot</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">OUTPUT_PATH</span><span class="o">/</span><span class="n">output</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"[[file:{output}]]"</span><span class="p">)</span>
</pre></div>
<div class="figure">
<p><img alt="pdp_forest_goals_scored.png" src="/posts/tutorials/partial-dependence-plots/pdp_forest_goals_scored.png"></p>
</div>
<p>So, our random forest says that the greatest gain comes from the first goal, but there is in fact a greater probability as you increase the number of goals scored.</p>
<p>What about distance covered?</p>
<div class="highlight">
<pre><span></span><span class="n">FEATURE</span> <span class="o">=</span> <span class="s2">"Distance Covered (Kms)"</span>
<span class="n">pdp_distance</span> <span class="o">=</span> <span class="n">pdp</span><span class="o">.</span><span class="n">pdp_isolate</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">forest</span><span class="p">,</span> <span class="n">dataset</span><span class="o">=</span><span class="n">x_validate</span><span class="p">,</span>
                               <span class="n">model_features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span> <span class="n">feature</span><span class="o">=</span><span class="n">FEATURE</span><span class="p">)</span>
<span class="n">pdp</span><span class="o">.</span><span class="n">pdp_plot</span><span class="p">(</span><span class="n">pdp_distance</span><span class="p">,</span> <span class="n">FEATURE</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="s2">"pdp_forest_distance.png"</span>
<span class="n">pyplot</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">OUTPUT_PATH</span><span class="o">/</span><span class="n">output</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"[[file:{output}]]"</span><span class="p">)</span>
</pre></div>
<div class="figure">
<p><img alt="pdp_forest_distance.png" src="/posts/tutorials/partial-dependence-plots/pdp_forest_distance.png"></p>
</div>
<div class="highlight">
<pre><span></span><span class="k">print</span><span class="p">(</span><span class="n">pdp_distance</span><span class="o">.</span><span class="n">feature_grids</span><span class="p">[</span><span class="n">pdp_distance</span><span class="o">.</span><span class="n">pdp</span><span class="o">.</span><span class="n">argmax</span><span class="p">()])</span>
</pre></div>
<pre class="example">
102.0
</pre>
<p>Our forest says that, once again, covering 102 kilometers maximizes the probability, but in this case it appears that going beyond that actually decreases the probability that your team would have the man of the match.</p>
</div>
</div>
<div class="outline-3" id="outline-container-orgc64d61e">
<h3 id="orgc64d61e">2D Partial Dependence Plots</h3>
<div class="outline-text-3" id="text-orgc64d61e">
<p>Rather than plot a single feature against the probability of becoming the man of the match you can plot how two features interact to affect the probability.</p>
<div class="highlight">
<pre><span></span><span class="n">FEATURES</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"Goal Scored"</span><span class="p">,</span> <span class="s2">"Distance Covered (Kms)"</span><span class="p">]</span>
<span class="n">interaction</span> <span class="o">=</span> <span class="n">pdp</span><span class="o">.</span><span class="n">pdp_interact</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">tree_model</span><span class="p">,</span> <span class="n">dataset</span><span class="o">=</span><span class="n">x_validate</span><span class="p">,</span>
                               <span class="n">model_features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
                               <span class="n">features</span><span class="o">=</span><span class="n">FEATURES</span><span class="p">)</span>

<span class="n">pdp</span><span class="o">.</span><span class="n">pdp_interact_plot</span><span class="p">(</span><span class="n">pdp_interact_out</span><span class="o">=</span><span class="n">interaction</span><span class="p">,</span> <span class="n">feature_names</span><span class="o">=</span><span class="n">FEATURES</span><span class="p">,</span>
                      <span class="n">plot_type</span><span class="o">=</span><span class="s2">"contour"</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="s2">"goals_vs_distance.png"</span>
<span class="n">pyplot</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">OUTPUT_PATH</span><span class="o">/</span><span class="n">output</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"[[file:{output}]]"</span><span class="p">)</span>
</pre></div>
<div class="figure">
<p><img alt="goals_vs_distance.png" src="/posts/tutorials/partial-dependence-plots/goals_vs_distance.png"></p>
</div>
<p><b>Note:</b> The version of PDPBox on pypi currently has a bug (as of February 8, 2020) that won't let you create the previous plot, install it from github instead.</p>
<p>The plot shows a more succinct version of the two plots we had seen before - the optimal point for these two features is 1 goal and 102 Kms covered.</p>
</div>
<div class="outline-4" id="outline-container-org7dad8a8">
<h4 id="org7dad8a8">Forest From the Trees</h4>
<div class="outline-text-4" id="text-org7dad8a8">
<p>Let's re-run the same plot using the Random Forest instead of the Decision Tree.</p>
<div class="highlight">
<pre><span></span><span class="n">FEATURES</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"Goal Scored"</span><span class="p">,</span> <span class="s2">"Distance Covered (Kms)"</span><span class="p">]</span>
<span class="n">interaction</span> <span class="o">=</span> <span class="n">pdp</span><span class="o">.</span><span class="n">pdp_interact</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">forest</span><span class="p">,</span> <span class="n">dataset</span><span class="o">=</span><span class="n">x_validate</span><span class="p">,</span>
                               <span class="n">model_features</span><span class="o">=</span><span class="n">features</span><span class="p">,</span>
                               <span class="n">features</span><span class="o">=</span><span class="n">FEATURES</span><span class="p">)</span>

<span class="n">pdp</span><span class="o">.</span><span class="n">pdp_interact_plot</span><span class="p">(</span><span class="n">pdp_interact_out</span><span class="o">=</span><span class="n">interaction</span><span class="p">,</span> <span class="n">feature_names</span><span class="o">=</span><span class="n">FEATURES</span><span class="p">,</span>
                      <span class="n">plot_type</span><span class="o">=</span><span class="s2">"contour"</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="s2">"forest_goals_vs_distance.png"</span>
<span class="n">pyplot</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">OUTPUT_PATH</span><span class="o">/</span><span class="n">output</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">"[[file:{output}]]"</span><span class="p">)</span>
</pre></div>
<div class="figure">
<p><img alt="forest_goals_vs_distance.png" src="/posts/tutorials/partial-dependence-plots/forest_goals_vs_distance.png"></p>
</div>
<p>The random forest suggests a slightly different scenario - here you want 2 gooalds and between 100 and 110 Kms (or thereabouts) covered to get the best probability.</p>
</div>
</div>
</div>
</div>
<div class="outline-2" id="outline-container-orgc1be96d">
<h2 id="orgc1be96d">End</h2>
<div class="outline-text-2" id="text-orgc1be96d">
<p>This showed how to use the PDPBox library to create Partial Dependence Plots to look at how input values for features affects the predicted outcomes. Unfortunately it looks like PDPBox might have been abandoned, but while it works it's a nice library.</p>
</div>
</div>
</div>
<aside class="postpromonav">
<nav>
<ul class="tags" itemprop="keywords">
<li><a class="tag p-category" href="/categories/interpret/" rel="tag">interpret</a></li>
<li><a class="tag p-category" href="/categories/machine-learning/" rel="tag">machine learning</a></li>
<li><a class="tag p-category" href="/categories/tutorial/" rel="tag">tutorial</a></li>
<li><a class="tag p-category" href="/categories/visualization/" rel="tag">visualization</a></li>
</ul>
<ul class="pager hidden-print">
<li class="previous"><a href="/posts/tutorials/exercise-in-permutation-importance/" rel="prev" title="Exercise in Permutation Importance">Previous post</a></li>
<li class="next"><a href="/posts/tutorials/exercise-in-partial-dependence-plots/" rel="next" title="Exercise In Partial Dependence Plots">Next post</a></li>
</ul>
</nav>
</aside>
</article>
<!--End of body content-->
<footer id="footer">Contents © 2020 <a href="mailto:necromuralist@protonmail.com">Cloistered Monkey</a> - Powered by <a href="https://getnikola.com" rel="nofollow">Nikola</a></footer>
</div>
</div>
<script src="/assets/js/all-nocdn.js"></script>
<script>

    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
</script> 
</body>
</html>
