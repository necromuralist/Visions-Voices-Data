#+BEGIN_COMMENT
.. title: SHAP Values
.. slug: shap-values
.. date: 2020-02-09 17:07:12 UTC-08:00
.. tags: interpret,machine learning,visualization,tutorial
.. category: Machine Learning
.. link: 
.. description: SHapley Additive exPlanations
.. type: text
.. status: 
.. updated: 
#+END_COMMENT
#+OPTIONS: ^:{}
#+TOC: headlines 
* Beginning
  SHAP values interpret the impact of a certain value for a given feature when compared to the prediction you'd make if that feature instead took a baseline value. This helps us interpret predictions given specific values for our features. We'll do this using the [[https://github.com/slundberg/shap][SHAP]] library, naturally.
** Imports
*** Python
#+begin_src jupyter-python :session shap :results none
from argparse import Namespace
from pathlib import Path
#+end_src
*** PyPi
#+begin_src jupyter-python :session shap :results none
from matplotlib import pyplot
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier

import numpy
import pandas
import seaborn
import shap
#+end_src
*** Others
#+begin_src jupyter-python :session shap :results none
from graeae import EnvironmentLoader, Timer
#+end_src
** Set Up
*** Plotting
#+begin_src jupyter-python :session shap :results none
SLUG = "shap-values"
OUTPUT_PATH = Path("../../files/posts/tutorials/")/SLUG
#+end_src

#+begin_src jupyter-python :session shap :results none
get_ipython().run_line_magic('matplotlib', 'inline')
get_ipython().run_line_magic('config', "InlineBackend.figure_format = 'retina'")
#+end_src
*** The Timer
#+begin_src jupyter-python :session shap :results none
TIMER = Timer()
#+end_src
*** Environment
#+begin_src jupyter-python :session shap :results none
ENVIRONMENT = EnvironmentLoader()
#+end_src
*** The Data
#+begin_src jupyter-python :session shap :results output :exports both
data = pandas.read_csv(Path(ENVIRONMENT["FIFA-2018"]).expanduser())
y = data["Man of the Match"] == "Yes"
FEATURES = [column for column in data.columns if data[column].dtype == numpy.int64]
X = data[FEATURES]
x_train, x_validate, y_train, y_validate = train_test_split(X, y, random_state=1)


model = RandomForestClassifier()

estimators = list(range(50, 200, 10))
max_depth = list(range(10, 100, 10)) + [None]

grid = dict(n_estimators=estimators,
            max_depth=max_depth)
search = RandomizedSearchCV(estimator=model,
                            param_distributions=grid,
                            n_iter=40,
                            n_jobs=-1,
                            random_state=1)
with TIMER:
    search.fit(x_train, y_train)
first_model = search.best_estimator_
print(f"CV Training R^2: {search.best_score_:0.2f}")
print(f"Training R^2: {first_model.score(x_train, y_train): 0.2f}")
print(f"Validation R^2: {first_model.score(x_validate, y_validate):0.2f}")
print(search.best_params_)
#+end_src

#+RESULTS:
: 2020-02-10 18:09:33,716 graeae.timers.timer start: Started: 2020-02-10 18:09:33.716565
: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.
: 2020-02-10 18:09:36,830 graeae.timers.timer end: Ended: 2020-02-10 18:09:36.830883
: 2020-02-10 18:09:36,832 graeae.timers.timer end: Elapsed: 0:00:03.114318
: CV Training R^2: 0.70
: Training R^2:  1.00
: Validation R^2: 0.69
: {'n_estimators': 100, 'max_depth': 30}

* Middle
** A Single Row
#+begin_src jupyter-python :session shap :results output :exports both
ROW = 5
row_data = x_validate.iloc[ROW]
row_data_matrix = row_data.values.reshape(1, -1)
print(first_model.classes_)
print(first_model.predict_proba(row_data_matrix))
#+end_src

#+RESULTS:
: [False  True]
: [[0.25 0.75]]

The [[https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.predict_proba][=predict_proba=]] method tells us the probability for the data for each class. So this team has a 70% chance that they do have a man of the match.

#+begin_src jupyter-python :session shap :results none
explainer = shap.TreeExplainer(first_model)
shap_values = explainer.shap_values(row_data_matrix)
#+end_src

#+begin_src jupyter-python :session shap :results output :exports both
print(explainer.shap_values.__doc__)
#+end_src

#+RESULTS:
#+begin_example
 Estimate the SHAP values for a set of samples.

        Parameters
        ----------
        X : numpy.array, pandas.DataFrame or catboost.Pool (for catboost)
            A matrix of samples (# samples x # features) on which to explain the model's output.

        y : numpy.array
            An array of label values for each sample. Used when explaining loss functions.

        tree_limit : None (default) or int
            Limit the number of trees used by the model. By default None means no use the limit of the
            original model, and -1 means no limit.

        approximate : bool
            Run fast, but only roughly approximate the Tree SHAP values. This runs a method
            previously proposed by Saabas which only considers a single feature ordering. Take care
            since this does not have the consistency guarantees of Shapley values and places too
            much weight on lower splits in the tree.

        check_additivity : bool
            Run a validation check that the sum of the SHAP values equals the output of the model. This
            check takes only a small amount of time, and will catch potential unforeseen errors.
            Note that this check only runs right now when explaining the margin of the model.

        Returns
        -------
        For models with a single output this returns a matrix of SHAP values
        (# samples x # features). Each row sums to the difference between the model output for that
        sample and the expected value of the model output (which is stored in the expected_value
        attribute of the explainer when it is constant). For models with vector outputs this returns
        a list of such matrices, one for each output.
        
#+end_example

The array returned by the =shap_values= method has two rows - one for each of our target classes. In this case we're asking if a team had a man of the match so we'll just look at the second array.
#+begin_src jupyter-python :session shap :results output raw :exports both
shap.initjs()
figure = shap.force_plot(explainer.expected_value[1],
                         shap_values[1],
                         row_data_matrix,
                         feature_names=FEATURES,
                         matplotlib=True, show=False)
filename = "shap_one.png"

figure.savefig(OUTPUT_PATH/filename)
print(f"[[file:{filename}]]")
#+end_src

#+RESULTS:
[[file:shap_one.png]]

Our predicted probability that this team had a man of the match was 0.7, but the base-value for the set as a whole is 0.4979 (you can't see it in this plot for some reason), so our team is more likely to have one than most teams. The pink section of the plot shows the features that increased the probability and the part in blue shows the features that decreased the probability. The size of each feature's block is proportional to the amount the feature contributed, so the biggest block (/Goal Scored/) contributed the most. The greatest negative feature was /Ball Possession %/.

* End
** See Also
   - The [[https://shap.readthedocs.io/en/latest/][SHAP]] Documentation
   - The [[https://github.com/slundberg/shap][SHAP github repository]]
   - Lundberg SM, Lee SI. A unified approach to interpreting model predictions. InAdvances in neural information processing systems 2017 (pp. 4765-4774). ([[https://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predicti][PDF Available Here]])
