#+BEGIN_COMMENT
.. title: Categorical Values
.. slug: categorical-values
.. date: 2020-02-20 21:13:09 UTC-08:00
.. tags: tutorial,kaggle,categorical
.. category: Tutorial
.. link: 
.. description: Kaggle's intermediate machine learning tutorial on handling categorical values.
.. type: text
.. status: 
.. updated: 

#+END_COMMENT
#+OPTIONS: ^:{}
#+TOC: headlines 5
#+PROPERTY: header-args :session /run/user/1000/jupyter/kernel-ceab7861-c725-433e-bda0-8e0a69dfee85.json
* Beginning
#+begin_quote
Now it's your turn to test your new knowledge of **missing values** handling. You'll probably find it makes a big difference.
#+end_quote
** Imports
*** Python
#+begin_src python :results none
from argparse import Namespace
from datetime import datetime
from functools import partial
from pathlib import Path
#+end_src
*** PyPi
#+begin_src python :results none
from eli5.sklearn import PermutationImportance
from matplotlib import pyplot
from pdpbox import pdp

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import cross_val_score, train_test_split
from sklearn.preprocessing import LabelEncoder, OneHotEncoder

from tabulate import tabulate

import eli5
import hvplot.pandas
import pandas
import shap
#+end_src
*** Others
#+begin_src python :results none
from graeae import CountPercentage, EmbedHoloviews, EnvironmentLoader, Timer
#+end_src
** Set Up
*** Table
#+begin_src python :results none
TABLE = partial(tabulate, tablefmt="orgtbl", showindex=False, headers="keys")
#+end_src
*** Plottting
#+begin_src python :results none
SLUG = "categorical-values"
OUTPUT_PATH = Path("../../files/posts/tutorials/")/SLUG
Embed = partial(EmbedHoloviews, folder_path=OUTPUT_PATH)
Plot = Namespace(
    height=800,
    width=1000,
)
#+end_src
*** The Timer
#+begin_src python :results none
TIMER = Timer()
#+end_src
*** Environment
#+begin_src python :results none
ENVIRONMENT = EnvironmentLoader()
#+end_src
*** The Data
#+begin_src python :results none
DATA_PATH = Path(ENVIRONMENT["HOUSE-PRICES-IOWA"]).expanduser()
train_data = pandas.read_csv(
    DATA_PATH/"train.csv", index_col="Id")

test_data = pandas.read_csv(
    DATA_PATH/"test.csv", index_col="Id"
)
#+end_src
*** Some Constants
#+begin_src python :results none
Data = Namespace(
    target="SalePrice",
    train_size=0.8,
    test_size=0.2,
    random_seed=0,
)
#+end_src
* Middle
** Setup The Data
   Split up the target and features.
#+begin_src python :results none
assert not train_data[Data.target].hasnans
y = train_data[Data.target]
X = train_data.drop([Data.target], axis="columns")
#+end_src
We know that there's missing data, but since this is about handling categorical data, not missing data, we'll just drop the columns that have missing values.

#+begin_src python :results output :exports both
print(X.shape)
X = X[[column for column in X.columns if not X[column].hasnans]]
test_data = test_data[drop_X.columns]
print(X.shape)
#+end_src

#+RESULTS:
: (1460, 79)
: (1460, 60)

So we lost 19 columns - more than I was expecting.

Now do the train-test split.

#+begin_src python :results none
X_train, X_validate, y_train, y_validate = train_test_split(
    X, y,
    train_size=Data.train_size, test_size=Data.test_size,
    random_state=Data.random_seed)
#+end_src

#+begin_src python :results output :exports both
print(drop_X_train.info())
#+end_src

#+RESULTS:
#+begin_example
<class 'pandas.core.frame.DataFrame'>
Int64Index: 1168 entries, 619 to 685
Data columns (total 79 columns):
MSSubClass       1168 non-null int64
MSZoning         1168 non-null object
LotFrontage      956 non-null float64
LotArea          1168 non-null int64
Street           1168 non-null object
Alley            71 non-null object
LotShape         1168 non-null object
LandContour      1168 non-null object
Utilities        1168 non-null object
LotConfig        1168 non-null object
LandSlope        1168 non-null object
Neighborhood     1168 non-null object
Condition1       1168 non-null object
Condition2       1168 non-null object
BldgType         1168 non-null object
HouseStyle       1168 non-null object
OverallQual      1168 non-null int64
OverallCond      1168 non-null int64
YearBuilt        1168 non-null int64
YearRemodAdd     1168 non-null int64
RoofStyle        1168 non-null object
RoofMatl         1168 non-null object
Exterior1st      1168 non-null object
Exterior2nd      1168 non-null object
MasVnrType       1162 non-null object
MasVnrArea       1162 non-null float64
ExterQual        1168 non-null object
ExterCond        1168 non-null object
Foundation       1168 non-null object
BsmtQual         1140 non-null object
BsmtCond         1140 non-null object
BsmtExposure     1140 non-null object
BsmtFinType1     1140 non-null object
BsmtFinSF1       1168 non-null int64
BsmtFinType2     1139 non-null object
BsmtFinSF2       1168 non-null int64
BsmtUnfSF        1168 non-null int64
TotalBsmtSF      1168 non-null int64
Heating          1168 non-null object
HeatingQC        1168 non-null object
CentralAir       1168 non-null object
Electrical       1167 non-null object
1stFlrSF         1168 non-null int64
2ndFlrSF         1168 non-null int64
LowQualFinSF     1168 non-null int64
GrLivArea        1168 non-null int64
BsmtFullBath     1168 non-null int64
BsmtHalfBath     1168 non-null int64
FullBath         1168 non-null int64
HalfBath         1168 non-null int64
BedroomAbvGr     1168 non-null int64
KitchenAbvGr     1168 non-null int64
KitchenQual      1168 non-null object
TotRmsAbvGrd     1168 non-null int64
Functional       1168 non-null object
Fireplaces       1168 non-null int64
FireplaceQu      617 non-null object
GarageType       1110 non-null object
GarageYrBlt      1110 non-null float64
GarageFinish     1110 non-null object
GarageCars       1168 non-null int64
GarageArea       1168 non-null int64
GarageQual       1110 non-null object
GarageCond       1110 non-null object
PavedDrive       1168 non-null object
WoodDeckSF       1168 non-null int64
OpenPorchSF      1168 non-null int64
EnclosedPorch    1168 non-null int64
3SsnPorch        1168 non-null int64
ScreenPorch      1168 non-null int64
PoolArea         1168 non-null int64
PoolQC           4 non-null object
Fence            214 non-null object
MiscFeature      49 non-null object
MiscVal          1168 non-null int64
MoSold           1168 non-null int64
YrSold           1168 non-null int64
SaleType         1168 non-null object
SaleCondition    1168 non-null object
dtypes: float64(3), int64(33), object(43)
memory usage: 730.0+ KB
None
#+end_example
#+begin_quote
Notice that the dataset contains both numerical and categorical variables.  You'll need to encode the categorical data before training a model.
#+end_quote
** Score Dataset
   This is the same function used in the missing-values tutorial. It's used to compare different models' Mean Absolute Error (MAE) as we make changes.
#+begin_src python :results none
def score_dataset(X_train, X_valid, y_train, y_valid):
    model = RandomForestRegressor(n_estimators=100, random_state=0)
    model.fit(X_train, y_train)
    preds = model.predict(X_valid)
    return mean_absolute_error(y_valid, preds)
#+end_src

** Step 1: Drop Categorical Columns
   The first approach is to just drop all the non-numeric columns.

#+begin_src python :results output exports both
columns = [column for column in X_train.columns if X_train[column].dtype != object]
drop_X_train = X_train[columns]
drop_X_validate = X_validate[columns]

print("MAE from Approach 1 (Drop categorical variables):")
print(f"{score_dataset(drop_X_train, drop_X_validate, y_train, y_validate):,}")
#+end_src

#+RESULTS:
: MAE from Approach 1 (Drop categorical variables):
: 17,837.82570776256

Using all the numeric columns does better than we did with our initial subset of columns (20,928.5), but not as good as we did with imputed values (16,656.3).

** Step 2: Label encoding
#+begin_quote
Before jumping into label encoding, we'll investigate the dataset.  Specifically, we'll look at the ='Condition2'= column.  The code cell below prints the unique entries in both the training and validation sets.
#+end_quote


#+begin_src python :results output raw :exports both
train_counter = CountPercentage(X_train.Condition2, dropna=False)
validate_counter = CountPercentage(X_validate.Condition2, dropna=False)
train_counter()
#+end_src

#+RESULTS:
| Value   |   Count |   Percent (%) |
|---------+---------+---------------|
| Norm    |    1160 |         99.32 |
| Feedr   |       4 |          0.34 |
| Artery  |       1 |          0.09 |
| PosN    |       1 |          0.09 |
| RRAe    |       1 |          0.09 |
| PosA    |       1 |          0.09 |

#+begin_src python :results output raw :exports both
validate_counter()
#+end_src

#+RESULTS:
| Value   |   Count |   Percent (%) |
|---------+---------+---------------|
| Norm    |     285 |         97.60 |
| RRNn    |       2 |          0.68 |
| Feedr   |       2 |          0.68 |
| PosN    |       1 |          0.34 |
| RRAn    |       1 |          0.34 |
| Artery  |       1 |          0.34 |

It looks like the validation data has values that aren't in the training data (and vice versa), e.g. =RRNn=, so encoding the training set won't work with the validation set.

#+begin_quote
This is a common problem that you'll encounter with real-world data, and there are many approaches to fixing this issue.  For instance, you can write a custom label encoder to deal with new categories.  The simplest approach, however, is to drop the problematic categorical columns.  

Run the code cell below to save the problematic columns to a Python list =bad_label_cols=.  Likewise, columns that can be safely label encoded are stored in =good_label_cols=.
#+end_quote

#+begin_src python :results output raw :exports both
# All categorical columns
object_columns = [column for column in X_train.columns if X_train[column].dtype == "object"]

# Columns that can be safely label encoded
good_label_columns = [column for column in object_columns if 
                      set(X_train[column]) == set(X_validate[column])]
        
# Problematic columns that will be dropped from the dataset
bad_label_columns = list(set(object_columns)-set(good_label_columns))
        
print('Categorical columns that will be label encoded:')
for column in  good_label_columns:
    print(f" - {column}")

print('\nCategorical columns that will be dropped from the dataset:')
for column in bad_label_columns:
    print(f" - {column}")
#+end_src

#+RESULTS:
Categorical columns that will be label encoded:
 - MSZoning
 - Street
 - LotShape
 - LandContour
 - LotConfig
 - BldgType
 - HouseStyle
 - ExterQual
 - CentralAir
 - KitchenQual
 - PavedDrive
 - SaleCondition

Categorical columns that will be dropped from the dataset:
 - SaleType
 - Foundation
 - Exterior1st
 - LandSlope
 - Condition2
 - Condition1
 - RoofMatl
 - Functional
 - Utilities
 - Neighborhood
 - HeatingQC
 - Heating
 - Exterior2nd
 - RoofStyle
 - ExterCond

*** Drop the Bad Columns

#+begin_src python :results none
label_X_train = X_train.drop(bad_label_columns, axis="columns")
label_X_validate = X_validate.drop(bad_label_columns, axis="columns")
#+end_src

*** Encode the Categorical Values
    We're going to use sklearn's [[https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html][LabelEncoder]].

**Note:** Sklearn's documentation says that this is meant only for categorical target data (the labels), not the input data like we're doing here. Later on we're going to use one-hot-encoding, which is what sklearn recommends (the LabelEncoder method implies that the numbers are values, not just numeric codes for strings).

It's going to create integer values for each of the unique values in each column.

#+begin_src python :results none
for column in good_label_columns:
    encoder = LabelEncoder()    
    label_X_train.loc[:, column] = encoder.fit_transform(label_X_train[column])
    label_X_validate.loc[:, column] = encoder.fit_transform(label_X_validate[column])
#+end_src

Now check how it did.

#+begin_src python :results output :exports both
print("MAE from Approach 2 (Label Encoding):") 
print(f"{score_dataset(label_X_train, label_X_validate, y_train, y_validate):,}")
#+end_src

#+RESULTS:
: MAE from Approach 2 (Label Encoding):
: 17,575.291883561644

So it does a little better than the previous approach of just dropping all the categorical data, but not as well as it did when we imputed the missing numeric values.
** Step 3: Investigating cardinality
#+begin_quote
So far, you've tried two different approaches to dealing with categorical variables.  And, you've seen that encoding categorical data yields better results than removing columns from the dataset.

Soon, you'll try one-hot encoding.  Before then, there's one additional topic we need to cover.  Begin by running the next code cell without changes.  
#+end_quote

Get number of unique entries in each column with categorical data

#+begin_src python :results output raw :exports both
object_nunique = [X_train[column].nunique() for column in object_columns]

## Print number of unique entries by column, in descending
cardinality = pandas.DataFrame(dict(Column=object_columns,
                                    Cardinality=object_nunique)
                     ).sort_values(by="Cardinality", ascending=False)
print(TABLE(cardinality))
#+end_src

#+RESULTS:
| Column        |   Cardinality |
|---------------+---------------|
| Neighborhood  |            25 |
| Exterior2nd   |            16 |
| Exterior1st   |            15 |
| SaleType      |             9 |
| Condition1    |             9 |
| HouseStyle    |             8 |
| RoofMatl      |             7 |
| Functional    |             6 |
| Heating       |             6 |
| Foundation    |             6 |
| RoofStyle     |             6 |
| SaleCondition |             6 |
| Condition2    |             6 |
| BldgType      |             5 |
| ExterCond     |             5 |
| LotConfig     |             5 |
| HeatingQC     |             5 |
| MSZoning      |             5 |
| ExterQual     |             4 |
| KitchenQual   |             4 |
| LandContour   |             4 |
| LotShape      |             4 |
| LandSlope     |             3 |
| PavedDrive    |             3 |
| Street        |             2 |
| Utilities     |             2 |
| CentralAir    |             2 |

#+begin_quote
The output above shows, for each column with categorical data, the number of unique values in the column.  For instance, the ='Street'= column in the training data has two unique values: ='Grvl'= and ='Pave'=, corresponding to a gravel road and a paved road, respectively.

We refer to the number of unique entries of a categorical variable as the **cardinality** of that categorical variable.  For instance, the ='Street'= variable has cardinality 2.
#+end_quote
*** Questions
#+begin_quote
How many categorical variables in the training data have cardinality greater than 10?
#+end_quote

#+begin_src python :results output :exports both
print(len(cardinality[cardinality.Cardinality > 10]))
#+end_src

#+RESULTS:
: 3

#+begin_src python :results output :exports both
How many columns are needed to one-hot encode the 'Neighborhood' variable in the training data?
#+end_src

#+begin_src python :results output :exports both
print(cardinality[cardinality.Column=="Neighborhood"].Cardinality.iloc[0])
#+end_src

#+RESULTS:
: 25

#+begin_quote
For large datasets with many rows, one-hot encoding can greatly expand the size of the dataset.  For this reason, we typically will only one-hot encode columns with relatively low cardinality.  Then, high cardinality columns can either be dropped from the dataset, or we can use label encoding.

As an example, consider a dataset with 10,000 rows, and containing one categorical column with 100 unique entries.  
 - If this column is replaced with the corresponding one-hot encoding, how many entries are added to the dataset?  
 - If we instead replace the column with the label encoding, how many entries are added?
#+end_quote

If "entries" refers to columns then the one-hot-encoding will add 99 new columns (assuming the original is dropped) while the label-encoding won't add any columns.

**Step 4: One-hot encoding
#+begin_quote
In this step, you'll experiment with one-hot encoding.  But, instead of encoding all of the categorical variables in the dataset, you'll only create a one-hot encoding for columns with cardinality less than 10.

Run the code cell below without changes to set =low_cardinality_cols= to a Python list containing the columns that will be one-hot encoded.  Likewise, =high_cardinality_cols= contains a list of categorical columns that will be dropped from the dataset.
#+end_quote

#+begin_src python :results none
# low_cardinality_columns = [column for column in object_columns if X_train[column].nunique() < 10]
#high_cardinality_cols = list(set(object_cols)-set(low_cardinality_cols))

low_cardinality_columns = cardinality[cardinality.Cardinality < 10].Column
high_cardinality_columns = cardinality[~cardinality.Column.isin(low_cardinality_columns)].Column
#+end_src

#+begin_src python :results output raw :exports both
print("Categorical columns that will be one-hot encoded:")
for column in low_cardinality_columns:
    print(f" - {column}")
#+end_src

#+RESULTS:
#+begin_example
Categorical columns that will be one-hot encoded:
 - SaleType
 - Condition1
 - HouseStyle
 - RoofMatl
 - Functional
 - Heating
 - Foundation
 - RoofStyle
 - SaleCondition
 - Condition2
 - BldgType
 - ExterCond
 - LotConfig
 - HeatingQC
 - MSZoning
 - ExterQual
 - KitchenQual
 - LandContour
 - LotShape
 - LandSlope
 - PavedDrive
 - Street
 - Utilities
 - CentralAir
#+end_example

#+begin_src python :results output raw :exports both
print('Categorical columns that will be dropped from the dataset:')
for column in high_cardinality_columns:
    print(f" - {column}")
#+end_src

#+RESULTS:
: Categorical columns that will be dropped from the dataset:
:  - Neighborhood
:  - Exterior2nd
:  - Exterior1st

#+begin_quote
Use the next code cell to one-hot encode the data in =X_train= and =X_valid=.  Set the preprocessed DataFrames to =OH_X_train= and =OH_X_valid=, respectively.  
 - The full list of categorical columns in the dataset can be found in the Python list =object_cols=.
 - You should only one-hot encode the categorical columns in =low_cardinality_cols=.  All other categorical columns should be dropped from the dataset. 
#+end_quote

#+begin_src python :results none
OH_X_train = X_train.drop(high_cardinality_columns, axis="columns").reset_index(drop=True)
OH_X_validate = X_validate.drop(high_cardinality_columns, axis="columns").reset_index(drop=True)
for column in low_cardinality_columns:
    encoder = OneHotEncoder(sparse=False)
    encoded = encoder.fit_transform(
        OH_X_train[column].to_numpy().reshape(-1, 1)
    )
    reencoded = pandas.DataFrame(encoded, columns=encoder.get_feature_names())
    OH_X_train = pandas.concat([OH_X_train, reencoded], axis="columns").drop(
        column, axis="columns")
   
    encoder = OneHotEncoder(sparse=False)
    encoded = encoder.fit_transform(
        OH_X_validate[column].to_numpy().reshape(-1, 1)
    )
    encoded = pandas.DataFrame(encoded, columns=encoder.get_feature_names())
    OH_X_validate = pandas.concat([OH_X_validate, encoded], axis="columns").drop(
        column, axis="columns")
#+end_src

#+begin_src python :results output :exports both
print("MAE from Approach 3 (One-Hot Encoding):") 
print(f"{score_dataset(OH_X_train, OH_X_validate, y_train, y_validate):,}")
#+end_src

#+RESULTS:
:RESULTS:
: MAE from Approach 3 (One-Hot Encoding):
# [goto error]
#+begin_example
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-148-a60fa4542679> in <module>
      1 print("MAE from Approach 3 (One-Hot Encoding):")
----> 2 print(f"{score_dataset(OH_X_train, OH_X_validate, y_train, y_validate):,}")

<ipython-input-15-f5efa66e05f2> in score_dataset(X_train, X_valid, y_train, y_valid)
      2     model = RandomForestRegressor(n_estimators=100, random_state=0)
      3     model.fit(X_train, y_train)
----> 4     preds = model.predict(X_valid)
      5     return mean_absolute_error(y_valid, preds)

~/.virtualenvs/Visions-Voices-Data/lib/python3.7/site-packages/sklearn/ensemble/forest.py in predict(self, X)
    691         check_is_fitted(self, 'estimators_')
    692         # Check data
--> 693         X = self._validate_X_predict(X)
    694 
    695         # Assign chunk of trees to jobs

~/.virtualenvs/Visions-Voices-Data/lib/python3.7/site-packages/sklearn/ensemble/forest.py in _validate_X_predict(self, X)
    357                                  "call `fit` before exploiting the model.")
    358 
--> 359         return self.estimators_[0]._validate_X_predict(X, check_input=True)
    360 
    361     @property

~/.virtualenvs/Visions-Voices-Data/lib/python3.7/site-packages/sklearn/tree/tree.py in _validate_X_predict(self, X, check_input)
    400                              "match the input. Model n_features is %s and "
    401                              "input n_features is %s "
--> 402                              % (self.n_features_, n_features))
    403 
    404         return X

ValueError: Number of features of the model must match the input. Model n_features is 155 and input n_features is 141 
#+end_example
:END:

* End
* Raw
#+begin_example


# # Step 5: Generate test predictions and submit your results
# 
# After you complete Step 4, if you'd like to use what you've learned to submit your results to the leaderboard, you'll need to preprocess the test data before generating predictions.
# 
# **This step is completely optional, and you do not need to submit results to the leaderboard to successfully complete the exercise.**
# 
# Check out the previous exercise if you need help with remembering how to [join the competition](https://www.kaggle.com/c/home-data-for-ml-course) or save your results to CSV.  Once you have generated a file with your results, follow the instructions below:
# - Begin by clicking on the blue **COMMIT** button in the top right corner.  This will generate a pop-up window.  
# - After your code has finished running, click on the blue **Open Version** button in the top right of the pop-up window.  This brings you into view mode of the same page. You will need to scroll down to get back to these instructions.
# - Click on the **Output** tab on the left of the screen.  Then, click on the **Submit to Competition** button to submit your results to the leaderboard.
# - If you want to keep working to improve your performance, select the blue **Edit** button in the top right of the screen. Then you can change your model and repeat the process.

# In[ ]:


# (Optional) Your code here


# # Keep going
# 
# With missing value handling and categorical encoding, your modeling process is getting complex. This complexity gets worse when you want to save your model to use in the future. The key to managing this complexity is something called **pipelines**. 
# 
# **[Learn to use pipelines](https://www.kaggle.com/alexisbcook/pipelines)** to preprocess datasets with categorical variables, missing values and any other messiness your data throws at you.

# ---
# **[Intermediate Machine Learning Home Page](https://www.kaggle.com/learn/intermediate-machine-learning)**
# 
# 
# 
# 
# 
# *Have questions or comments? Visit the [Learn Discussion forum](https://www.kaggle.com/learn-forum) to chat with other Learners.*
#+end_example
